{
    "docs": [
        {
            "location": "/", 
            "text": "Beam is a highly-general library for accessing any kind of database with\nHaskell. It supports several backends. \nbeam-postgres\n and \nbeam-sqlite\n are\nincluded in the main beam repository. Others are hosted and maintained\nindependently, such as \nbeam-mysql\n and \nbeam-firebird\n. The documentation here\nshows examples in all known backends.\n\n\nBeam is highly extensible and other backends can be shipped independently\nwithout requiring any changes in the core libraries.For information on creating\nadditional SQL backends, see the \nmanual section\n\nfor more.\n\n\nBeam features\n\n\n\n\nEasy schema generation\n from existing databases\n\n\nA basic migration infrastructure\n for working with multiple versions of\n  your database schema.\n\n\nSupport for most SQL92, SQL99, and SQL2003 features\n across backends that\n  support them, including aggregations, subqueries, and window functions.\n\n\nA straightforward Haskell-friendly query syntax\n. You can use Beam's \nQ\n\n  monad much like you would interact with the \n[]\n monad.\n\n\nNo Template Haskell\n Beam uses the GHC Haskell type system and nothing\n  else.  The types have been designed to be easily-inferrable by the compiler,\n  and appropriate functions to refine types have been provided for the where the\n  compiler may need more help.\n\n\n\n\nHow to install\n\n\nBeam is available via Hackage and Stackage, and can be included in your stack\nproject by adding \nbeam-core\n and an appropriate beam backend to your\n\nstack.yaml\n as an \nextra-dep\n. Some projects may want to follow the latest\nmaster, for the newest features. If so, put the following in your \nstack.yaml\n\nto build and use beam in your project!\n\n\npackages\n:\n\n\n-\n \n.\n\n\n-\n \nlocation\n:\n\n    \ngit\n:\n \nhttps://github.com/tathougies/beam.git\n\n    \ncommit\n:\n \na3b5e0763843fed48c7eef53fa7d08cfe710342d\n\n  \nextra-dep\n:\n \ntrue\n\n  \nsubdirs\n:\n\n    \n-\n \nbeam-core\n\n    \n-\n \nbackend\n\n\n\n\n\n\n\n\nNote\n\n\nthe commit will need to be changed to whatever the latest commit of master is,\nor whichever commit you want to build from even.\n\n\n\n\nand add the following to your \n.cabal\n file, in the \nbuild-depends\n section:\n\n\nbeam\n-\ncore\n,\n\n\nbackend\n\n\n\n\n\n\nYou may alse want to add the \nbeam-migrate\n package if you want to\nmanage your database schemas in Haskell as well.\n\n\nAvailable backends are:\n\n\n\n\n\n\nbeam-postgres\n -- A feature-complete backend for the Postgres RDBMS.\n  See \nthe beam-postgres documentation\n\n  for more information.\n\n\n\n\n\n\nbeam-sqlite\n -- A feature-complete backend for the Sqlite library.\n  Note that SQLite does not support all SQL92 features, so some of the examples\n  may not work. Refer\n  to \nthe beam-sqlite documentation\n for\n  more information on compatibility.\n\n\n\n\n\n\nbeam-mysql\n -- A backend for MySQL or MariaDB. Maintained\n  separately on \nGitHub\n.\n\n\n\n\n\n\nQuick Start Guide\n\n\nFor those looking to get started with beam, we first recommend you go through\nthe \ntutorial\n. The \nuser guide\n\ncontains much more detailed reference-like information. Finally, the\ndocumentation on hackage is always available (although the types may seem\nobtuse).\n\n\nIf you're interested if beam supports your favorite database feature, refer to\nthe documentation for your backend or take a look at\nthe \ncompatibility matrix\n.\n\n\nHow to Contribute\n\n\nWe always welcome contributions, especially to cover more database features or\nto add support for a new backend. Help is available on the\n\nbeam-discussion\n Google Group\n.\nThe following is a quick step-by-step guide of contributing a new feature:\n\n\n\n\nFork the github repository at \nhttps://github.com/tathougies/beam\n\n   and clone the fork to a local directory.\n\n\nWork on your feature on your own branch, or pick\n   an \nissue\n.\n\n\nWhen you feel ready to contribute the feature back to \nbeam-core\n, send a\n   Pull Request on Github, with an explanation of what your patch does and\n   whether it breaks the API.\n\n\nRespond to community comments and rework your patch.\n\n\nWhen the maintainer feels comfortable with your patch, he will commit it to\n   the \nmaster\n branch and it will be included in the next minor version.\n   API-breaking changes will not be included until the next major version.\n\n\n\n\n\n\nTip\n\n\nBe sure to add your name to\nthe\n\nCONTRIBUTORS\n file\nfor eternal fame and glory!\n\n\n\n\nQuestions, Feedback, Discussion\n\n\n\n\nFor frequently asked questions, see the \nFAQ\n.\n\n\nFor general questions, feedback on patches, support, or other concerns, please\n  write to the mailing list\n\n\nFor bugs or feature requests,\n  please \nopen an issue\n\n\n\n\nWhy Beam?\n\n\nBeam is the most feature-complete, turnkey Haskell database solution out there.\nIt supports the bulk of the SQL92, SQL99, SQL2003, SQL2006, SQL2008, SQL2011,\nand SQL2016 specifications, as well as the entire breadth of features of each of\nits backends. See the \ncompatibility matrix\n.  You will\nrarely be forced to write a SQL query 'by hand' when using Beam\n(but \nyou can\n).\n\n\nAdditionally, Beam plays nice with the rest of the Haskell ecosystem, the\nstandard Beam backends are all implemented in terms of pre-existing Haskell\npackages. Beam does not intend to make every query work across every database,\nand you are free to write queries in beam's DSL that only work on particular\nbackends, using type classes to restrict which backends work. It is assumed that\nyou have chosen you RDBMS with much care, and we want to support you in\nthat. Beam's main purpose is to marshal data back and forth, to serve as the\nsource of truth for the DB schema, and to generate properly formed SQL from\nHaskell expressions.", 
            "title": "Home"
        }, 
        {
            "location": "/#how-to-install", 
            "text": "Beam is available via Hackage and Stackage, and can be included in your stack\nproject by adding  beam-core  and an appropriate beam backend to your stack.yaml  as an  extra-dep . Some projects may want to follow the latest\nmaster, for the newest features. If so, put the following in your  stack.yaml \nto build and use beam in your project!  packages :  -   .  -   location : \n     git :   https://github.com/tathougies/beam.git \n     commit :   a3b5e0763843fed48c7eef53fa7d08cfe710342d \n   extra-dep :   true \n   subdirs : \n     -   beam-core \n     -   backend    Note  the commit will need to be changed to whatever the latest commit of master is,\nor whichever commit you want to build from even.   and add the following to your  .cabal  file, in the  build-depends  section:  beam - core ,  backend   You may alse want to add the  beam-migrate  package if you want to\nmanage your database schemas in Haskell as well.  Available backends are:    beam-postgres  -- A feature-complete backend for the Postgres RDBMS.\n  See  the beam-postgres documentation \n  for more information.    beam-sqlite  -- A feature-complete backend for the Sqlite library.\n  Note that SQLite does not support all SQL92 features, so some of the examples\n  may not work. Refer\n  to  the beam-sqlite documentation  for\n  more information on compatibility.    beam-mysql  -- A backend for MySQL or MariaDB. Maintained\n  separately on  GitHub .", 
            "title": "How to install"
        }, 
        {
            "location": "/#quick-start-guide", 
            "text": "For those looking to get started with beam, we first recommend you go through\nthe  tutorial . The  user guide \ncontains much more detailed reference-like information. Finally, the\ndocumentation on hackage is always available (although the types may seem\nobtuse).  If you're interested if beam supports your favorite database feature, refer to\nthe documentation for your backend or take a look at\nthe  compatibility matrix .", 
            "title": "Quick Start Guide"
        }, 
        {
            "location": "/#how-to-contribute", 
            "text": "We always welcome contributions, especially to cover more database features or\nto add support for a new backend. Help is available on the beam-discussion  Google Group .\nThe following is a quick step-by-step guide of contributing a new feature:   Fork the github repository at  https://github.com/tathougies/beam \n   and clone the fork to a local directory.  Work on your feature on your own branch, or pick\n   an  issue .  When you feel ready to contribute the feature back to  beam-core , send a\n   Pull Request on Github, with an explanation of what your patch does and\n   whether it breaks the API.  Respond to community comments and rework your patch.  When the maintainer feels comfortable with your patch, he will commit it to\n   the  master  branch and it will be included in the next minor version.\n   API-breaking changes will not be included until the next major version.    Tip  Be sure to add your name to\nthe CONTRIBUTORS  file\nfor eternal fame and glory!", 
            "title": "How to Contribute"
        }, 
        {
            "location": "/#questions-feedback-discussion", 
            "text": "For frequently asked questions, see the  FAQ .  For general questions, feedback on patches, support, or other concerns, please\n  write to the mailing list  For bugs or feature requests,\n  please  open an issue", 
            "title": "Questions, Feedback, Discussion"
        }, 
        {
            "location": "/#why-beam", 
            "text": "Beam is the most feature-complete, turnkey Haskell database solution out there.\nIt supports the bulk of the SQL92, SQL99, SQL2003, SQL2006, SQL2008, SQL2011,\nand SQL2016 specifications, as well as the entire breadth of features of each of\nits backends. See the  compatibility matrix .  You will\nrarely be forced to write a SQL query 'by hand' when using Beam\n(but  you can ).  Additionally, Beam plays nice with the rest of the Haskell ecosystem, the\nstandard Beam backends are all implemented in terms of pre-existing Haskell\npackages. Beam does not intend to make every query work across every database,\nand you are free to write queries in beam's DSL that only work on particular\nbackends, using type classes to restrict which backends work. It is assumed that\nyou have chosen you RDBMS with much care, and we want to support you in\nthat. Beam's main purpose is to marshal data back and forth, to serve as the\nsource of truth for the DB schema, and to generate properly formed SQL from\nHaskell expressions.", 
            "title": "Why Beam?"
        }, 
        {
            "location": "/about/faq/", 
            "text": "How does \nbeam\n compare with \nx\n?\n\n\nopaleye\n\n\nopaleye\n has similar aims as beam. However, \nbeam\n's DSL is monadic,\nand eschews the use of arrows. We use a phantom scope parameter to\nachieve the same result (it's the \ns\n parameter in the \nQ\n and \nQExpr\n\ntypes). This allows you to write queries in the same way you'd use the\nlist monad. Some people think this is more intuitive than arrows.\n\n\nBeam also uses higher-kinded types to allow the use of 'normal'\nhaskell data types, rather than a fully polymorphic type. For example,\nin opaleye you may have to write\n\n\ndata\n \nTable\n \ncolumn1\n \ncolumn2\n \ncolumn3\n \n=\n\n  \nTable\n \n{\n \ntblColumn1\n \n::\n \ncolumn1\n\n        \n,\n \ntblColumn2\n \n::\n \ncolumn2\n\n        \n,\n \ntblColumn3\n \n::\n \ncolumn3\n\n        \n}\n\n\n\n\n\n\nThis can get tiring when you have dozens of columns. In beam, types\nneed only take one polymorphic parameter.\n\n\ndata\n \nTable\n \nf\n \n=\n\n  \nTable\n \n{\n \ntblColumn1\n \n::\n \nC\n \nf\n \nColumn1Type\n\n        \n,\n \ntblColumn2\n \n::\n \nC\n \nf\n \nColumn2Type\n\n        \n,\n \ntblColumn3\n \n::\n \nC\n \nf\n \nColumn3Type\n\n        \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\n\n\n\n\nMoreover, all beam instances and type synonyms are easily written by\nhand. There is no Template Haskell magic here. What you see is what\nyou get.\n\n\nBeam is also fully polymorphic over the backend. That is to say\nthat a beam query can be written once and used across multiple\nbackends, so long as those backends support the features used in the\nquery. Feature constraints are written as class constraints. For\nexample, if you write a query that uses the SQL standard \nregr_slope\n\nfunction, you can make that query polymorphic over a choice in backend\nby using the\n\nIsSql2003EnhancedNumericFunctionsAggregationExpressionSyntax\n\nclass. You can freely mix and match backends at any time (well, within\nthe realms of possibility in terms of Haskell polymorphism). For\nexample, the \nbeam-migrate\n CLI tool loads backends at run-time and\nissues queries against them, without knowing the specifics of any\nparticular backend.\n\n\nFinally, beam produces readable queries. Here is what opaleye produces on a left join:\n\n\npersonBirthdayLeftJoin :: Query ((Column PGText, Column PGInt4, Column PGText),\n                                 ColumnNullableBirthday)\npersonBirthdayLeftJoin = leftJoin personQuery birthdayQuery eqName\n    where eqName ((name, _, _), birthdayRow) = name .== bdName birthdayRow\n\nThe generated SQL is\nghci\n printSql personBirthdayLeftJoin\nSELECT result1_0_3 as result1,\n       result1_1_3 as result2,\n       result1_2_3 as result3,\n       result2_0_3 as result4,\n       result2_1_3 as result5\nFROM (SELECT *\n      FROM (SELECT name0_1 as result1_0_3,\n                   age1_1 as result1_1_3,\n                   address2_1 as result1_2_3,\n                   name0_2 as result2_0_3,\n                   birthday1_2 as result2_1_3\n            FROM\n            (SELECT *\n             FROM (SELECT name as name0_1,\n                          age as age1_1,\n                          address as address2_1\n                   FROM personTable as T1) as T1) as T1\n            LEFT OUTER JOIN\n            (SELECT *\n             FROM (SELECT name as name0_2,\n                          birthday as birthday1_2\n                   FROM birthdayTable as T1) as T1) as T2\n            ON\n            (name0_1) = (name0_2)) as T1) as T1\n\n\n\n\n\nA similar query in beam:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nartist\n \n-\n \nall_\n \n(\nartist\n \nchinookDb\n)\n\n   \nalbum\n  \n-\n \nleftJoin_\n \n(\nall_\n \n(\nalbum\n \nchinookDb\n))\n \n(\n\\\nalbum\n \n-\n \nalbumArtist\n \nalbum\n \n==.\n \nprimaryKey\n \nartist\n)\n\n   \npure\n \n(\nartist\n,\n \nalbum\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nArtistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt1\n.\nArtistId\n \nAS\n \nres4\n\n\nFROM\n \nArtist\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nAlbum\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nArtistId\n)\n=\n(\nt0\n.\nArtistId\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nArtistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt1\n.\nArtistId\n \nAS\n \nres4\n\n\nFROM\n \nArtist\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nAlbum\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nArtistId\n)\n \n=\n \n(\nt0\n.\nArtistId\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nArtistId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt1\n`\n.\n`\nArtistId\n`\n \nAS\n \n`\nres4\n`\n\n\nFROM\n \n`\nArtist\n`\n \nAS\n \n`\nt0\n`\n\n\nLEFT\n \nJOIN\n \n`\nAlbum\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n(\n`\nt1\n`\n.\n`\nArtistId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nArtistId\n`\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\npersistent\n/\nesqueleto\n\n\nPersistent is a simple relational mapper for Haskell. Like beam, it\nalso supports multiple backends. However, unlike \nbeam\n, it does not\noffer a DSL for expressing joins or complex queries. Many people use\nthe \nesqueleto\n library to add these features to persistent. However,\n\nesqueleto\n allows a number of constructs to compile that lead to\nrun-time errors. In particular, join \nON\n conditions need to match the\norder specified in the \nFROM\n clause, but this is not checked at\ncompile time. In contrast, beam handles this for you. If the query\ncompiles, it will generate proper code.\n\n\nMoreover, beam's approach is more flexible. \nEsqueleto\n relies on\npre-defined algebraic data types. Beam uses a finally tagless encoding\nso that external packages can provide completely new\nfunctionality. For example, \nbeam-postgres\n is packaged independently\nof \nbeam-core\n and offers several advanced features, such as row-level\nlocking, JSON support, etc, without requiring any changes to core\nmodules. An OpenGIS package is also in the works, and beam's approach\nmeans this will be packaged separately from core.\n\n\ngroundhog\n\n\nhasql\n\n\nhasql\n is a library offering compile-time checking of queries using a\nquasiquoter. It's really great if you want to write your own SQL query\nand embed it in your Haskell source. However, it cannot check that the\nshape of the data returned by the query matches what your code\nexpects. For example, if you issue a command \nSELECT a, b, c, d, e\n,\nbut then unpack a 6-tuple in your Haskell code, this will lead to a\nrun-time error. Beam is much more heavy weight but guarantees that the\nshape of data matches. Also, beam allows you to write and compose\nqueries in a very straightforward Haskell style, that is more\nexpressive than vanilla SQL.\n\n\nselda\n\n\nselda\n has similar aims as beam. However, beam encourages the use of\nHaskell record types, whereas selda has its own type-level combinators\nfor constructing table types. This makes it more straightforward to\nuse beam types in pre-existing applications.\n\n\nBeam also has more robust support for migrations. Beam backends\ntypically map more features than selda ones.\n\n\nsqueal\n\n\nHelp! The type checker keeps complaining about \nSyntax\n types\n\n\nSuppose you had the following code to run a query over an arbitrary backend that\nsupported the SQL92 syntax.\n\n\nlistEmployees\n \n::\n \n(\nIsSql92Syntax\n \ncmd\n,\n \nMonadBeam\n \ncmd\n \nbe\n \nm\n)\n \n=\n \nm\n \n[\nEmployee\n]\n\n\nlistEmployees\n \n=\n \nrunSelectReturningList\n \n$\n \nselect\n \n(\nall_\n \n(\nemployees\n \nemployeeDb\n))\n\n\n\n\n\n\nYou may get an error message like the following\n\n\nMyQueries.hs:1:1: error:\n    * Could not deduce: Sql92ProjectionExpressionSyntax\n                          (Sql92SelectTableProjectionSyntax\n                             (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd)))\n                        ~\n                        Sql92SelectTableExpressionSyntax\n                          (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd))\n        arising from a use of \nselect\n\n\n\n\n\n\nBeam uses a \nfinally-tagless\n\nencoding for syntaxes. This means we never deal with concrete syntax types\ninternally, just types that fulfill certain constraints (in this case, being a\nvalid description of a SQL92 syntax). This works really nicely for\nextensibility, but makes the types slightly confusing. Here, the type checker is\ncomplaining that it cannot prove that the type of expressions used in\nprojections is the same as the type of expressions used in \nWHERE\n and \nHAVING\n\nclauses. Of course, any sane SQL92 syntax would indeed meet this criteria, but\nthis criteria is difficult to enforce at the type class level (it leads to\ncycles in superclasses, which requires the scary-looking\n\nUndecidableSuperclasses\n extension in GHC).\n\n\nNevertheless, we can avoid all this hullabaloo by using the \nSql92SanityCheck\n\nconstraint synonym. This takes a command syntax and asserts all the type\nequalities that a sane SQL92 syntax would support. Thus the code above becomes.\n\n\nlistEmployees\n \n::\n \n(\n \nIsSql92Syntax\n \ncmd\n,\n \nSql92SanityCheck\n \ncmd\n\n                 \n,\n \nMonadBeam\n \ncmd\n \nbe\n \nm\n)\n\n              \n=\n \nm\n \n[\nEmployee\n]\n\n\nlistEmployees\n \n=\n \nrunSelectReturningList\n \n$\n \nselect\n \n(\nall_\n \n(\nemployees\n \nemployeeDb\n))\n\n\n\n\n\n\nOther database mappers simulate features on databases that lack support, why not beam?\n\n\nBeam assumes that the developer has picked their RDBMS for a reason. Beam does\nnot try to take on features of the RDBMS, because often there is no reasonable\nand equally performant substitution that can be made. Beam tries to follow the\nprinciple of least surprise -- the SQL queries beam generates should be easily\nguessable from the Haskell query DSL (modulo aliasing). Generating complicated\nemulation code which can result in unpredictable performance would violate this\nprinciple.", 
            "title": "Frequently Asked Questions"
        }, 
        {
            "location": "/about/faq/#how-does-beam-compare-with-x", 
            "text": "", 
            "title": "How does beam compare with &lt;x&gt;?"
        }, 
        {
            "location": "/about/faq/#opaleye", 
            "text": "opaleye  has similar aims as beam. However,  beam 's DSL is monadic,\nand eschews the use of arrows. We use a phantom scope parameter to\nachieve the same result (it's the  s  parameter in the  Q  and  QExpr \ntypes). This allows you to write queries in the same way you'd use the\nlist monad. Some people think this is more intuitive than arrows.  Beam also uses higher-kinded types to allow the use of 'normal'\nhaskell data types, rather than a fully polymorphic type. For example,\nin opaleye you may have to write  data   Table   column1   column2   column3   = \n   Table   {   tblColumn1   ::   column1 \n         ,   tblColumn2   ::   column2 \n         ,   tblColumn3   ::   column3 \n         }   This can get tiring when you have dozens of columns. In beam, types\nneed only take one polymorphic parameter.  data   Table   f   = \n   Table   {   tblColumn1   ::   C   f   Column1Type \n         ,   tblColumn2   ::   C   f   Column2Type \n         ,   tblColumn3   ::   C   f   Column3Type \n         }   deriving   ( Generic ,   Beamable )   Moreover, all beam instances and type synonyms are easily written by\nhand. There is no Template Haskell magic here. What you see is what\nyou get.  Beam is also fully polymorphic over the backend. That is to say\nthat a beam query can be written once and used across multiple\nbackends, so long as those backends support the features used in the\nquery. Feature constraints are written as class constraints. For\nexample, if you write a query that uses the SQL standard  regr_slope \nfunction, you can make that query polymorphic over a choice in backend\nby using the IsSql2003EnhancedNumericFunctionsAggregationExpressionSyntax \nclass. You can freely mix and match backends at any time (well, within\nthe realms of possibility in terms of Haskell polymorphism). For\nexample, the  beam-migrate  CLI tool loads backends at run-time and\nissues queries against them, without knowing the specifics of any\nparticular backend.  Finally, beam produces readable queries. Here is what opaleye produces on a left join:  personBirthdayLeftJoin :: Query ((Column PGText, Column PGInt4, Column PGText),\n                                 ColumnNullableBirthday)\npersonBirthdayLeftJoin = leftJoin personQuery birthdayQuery eqName\n    where eqName ((name, _, _), birthdayRow) = name .== bdName birthdayRow\n\nThe generated SQL is\nghci  printSql personBirthdayLeftJoin\nSELECT result1_0_3 as result1,\n       result1_1_3 as result2,\n       result1_2_3 as result3,\n       result2_0_3 as result4,\n       result2_1_3 as result5\nFROM (SELECT *\n      FROM (SELECT name0_1 as result1_0_3,\n                   age1_1 as result1_1_3,\n                   address2_1 as result1_2_3,\n                   name0_2 as result2_0_3,\n                   birthday1_2 as result2_1_3\n            FROM\n            (SELECT *\n             FROM (SELECT name as name0_1,\n                          age as age1_1,\n                          address as address2_1\n                   FROM personTable as T1) as T1) as T1\n            LEFT OUTER JOIN\n            (SELECT *\n             FROM (SELECT name as name0_2,\n                          birthday as birthday1_2\n                   FROM birthdayTable as T1) as T1) as T2\n            ON\n            (name0_1) = (name0_2)) as T1) as T1  A similar query in beam:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   artist   -   all_   ( artist   chinookDb ) \n    album    -   leftJoin_   ( all_   ( album   chinookDb ))   ( \\ album   -   albumArtist   album   ==.   primaryKey   artist ) \n    pure   ( artist ,   album )  \n\n         \n    \n         \n             SELECT   t0 . ArtistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . AlbumId   AS   res2 , \n        t1 . Title   AS   res3 , \n        t1 . ArtistId   AS   res4  FROM   Artist   AS   t0  LEFT   JOIN   Album   AS   t1   ON   ( t1 . ArtistId ) = ( t0 . ArtistId );  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . ArtistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . AlbumId   AS   res2 , \n        t1 . Title   AS   res3 , \n        t1 . ArtistId   AS   res4  FROM   Artist   AS   t0  LEFT   JOIN   Album   AS   t1   ON   ( t1 . ArtistId )   =   ( t0 . ArtistId )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` ArtistId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 ` , \n        ` t1 ` . ` AlbumId `   AS   ` res2 ` , \n        ` t1 ` . ` Title `   AS   ` res3 ` , \n        ` t1 ` . ` ArtistId `   AS   ` res4 `  FROM   ` Artist `   AS   ` t0 `  LEFT   JOIN   ` Album `   AS   ` t1 `   ON   ( ` t1 ` . ` ArtistId ` )   =   ( ` t0 ` . ` ArtistId ` )", 
            "title": "opaleye"
        }, 
        {
            "location": "/about/faq/#persistentesqueleto", 
            "text": "Persistent is a simple relational mapper for Haskell. Like beam, it\nalso supports multiple backends. However, unlike  beam , it does not\noffer a DSL for expressing joins or complex queries. Many people use\nthe  esqueleto  library to add these features to persistent. However, esqueleto  allows a number of constructs to compile that lead to\nrun-time errors. In particular, join  ON  conditions need to match the\norder specified in the  FROM  clause, but this is not checked at\ncompile time. In contrast, beam handles this for you. If the query\ncompiles, it will generate proper code.  Moreover, beam's approach is more flexible.  Esqueleto  relies on\npre-defined algebraic data types. Beam uses a finally tagless encoding\nso that external packages can provide completely new\nfunctionality. For example,  beam-postgres  is packaged independently\nof  beam-core  and offers several advanced features, such as row-level\nlocking, JSON support, etc, without requiring any changes to core\nmodules. An OpenGIS package is also in the works, and beam's approach\nmeans this will be packaged separately from core.", 
            "title": "persistent/esqueleto"
        }, 
        {
            "location": "/about/faq/#groundhog", 
            "text": "", 
            "title": "groundhog"
        }, 
        {
            "location": "/about/faq/#hasql", 
            "text": "hasql  is a library offering compile-time checking of queries using a\nquasiquoter. It's really great if you want to write your own SQL query\nand embed it in your Haskell source. However, it cannot check that the\nshape of the data returned by the query matches what your code\nexpects. For example, if you issue a command  SELECT a, b, c, d, e ,\nbut then unpack a 6-tuple in your Haskell code, this will lead to a\nrun-time error. Beam is much more heavy weight but guarantees that the\nshape of data matches. Also, beam allows you to write and compose\nqueries in a very straightforward Haskell style, that is more\nexpressive than vanilla SQL.", 
            "title": "hasql"
        }, 
        {
            "location": "/about/faq/#selda", 
            "text": "selda  has similar aims as beam. However, beam encourages the use of\nHaskell record types, whereas selda has its own type-level combinators\nfor constructing table types. This makes it more straightforward to\nuse beam types in pre-existing applications.  Beam also has more robust support for migrations. Beam backends\ntypically map more features than selda ones.", 
            "title": "selda"
        }, 
        {
            "location": "/about/faq/#squeal", 
            "text": "", 
            "title": "squeal"
        }, 
        {
            "location": "/about/faq/#help-the-type-checker-keeps-complaining-about-syntax-types", 
            "text": "Suppose you had the following code to run a query over an arbitrary backend that\nsupported the SQL92 syntax.  listEmployees   ::   ( IsSql92Syntax   cmd ,   MonadBeam   cmd   be   m )   =   m   [ Employee ]  listEmployees   =   runSelectReturningList   $   select   ( all_   ( employees   employeeDb ))   You may get an error message like the following  MyQueries.hs:1:1: error:\n    * Could not deduce: Sql92ProjectionExpressionSyntax\n                          (Sql92SelectTableProjectionSyntax\n                             (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd)))\n                        ~\n                        Sql92SelectTableExpressionSyntax\n                          (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd))\n        arising from a use of  select   Beam uses a  finally-tagless \nencoding for syntaxes. This means we never deal with concrete syntax types\ninternally, just types that fulfill certain constraints (in this case, being a\nvalid description of a SQL92 syntax). This works really nicely for\nextensibility, but makes the types slightly confusing. Here, the type checker is\ncomplaining that it cannot prove that the type of expressions used in\nprojections is the same as the type of expressions used in  WHERE  and  HAVING \nclauses. Of course, any sane SQL92 syntax would indeed meet this criteria, but\nthis criteria is difficult to enforce at the type class level (it leads to\ncycles in superclasses, which requires the scary-looking UndecidableSuperclasses  extension in GHC).  Nevertheless, we can avoid all this hullabaloo by using the  Sql92SanityCheck \nconstraint synonym. This takes a command syntax and asserts all the type\nequalities that a sane SQL92 syntax would support. Thus the code above becomes.  listEmployees   ::   (   IsSql92Syntax   cmd ,   Sql92SanityCheck   cmd \n                  ,   MonadBeam   cmd   be   m ) \n               =   m   [ Employee ]  listEmployees   =   runSelectReturningList   $   select   ( all_   ( employees   employeeDb ))", 
            "title": "Help! The type checker keeps complaining about Syntax types"
        }, 
        {
            "location": "/about/faq/#other-database-mappers-simulate-features-on-databases-that-lack-support-why-not-beam", 
            "text": "Beam assumes that the developer has picked their RDBMS for a reason. Beam does\nnot try to take on features of the RDBMS, because often there is no reasonable\nand equally performant substitution that can be made. Beam tries to follow the\nprinciple of least surprise -- the SQL queries beam generates should be easily\nguessable from the Haskell query DSL (modulo aliasing). Generating complicated\nemulation code which can result in unpredictable performance would violate this\nprinciple.", 
            "title": "Other database mappers simulate features on databases that lack support, why not beam?"
        }, 
        {
            "location": "/tutorials/tutorial1/", 
            "text": "In this tutorial sequence, we'll walk through creating a schema for a simple\nshopping cart database. We'll start by defining a user table. Then, we'll show\nhow beam makes it easy to manipulate data in our database. Finally, we'll\ndemonstrate how beam lets us declare type-safe and composable queries.\n\n\nBeam Module Structure\n\n\nBeam makes extensive use of GHC's Generics mechanism. This extension means beam does not need to\nrely on template haskell.\n\n\nTo start defining beam schemas and queries, you only need to import the\n\nDatabase.Beam\n module. To interface with an actual database, you'll need to\nimport one of the database backends. We'll see how to use the Sqlite backend\nhere (found in the \nbeam-sqlite\n package). Now, open up a GHCi prompt for us to\nuse. Make sure to get the \nbeam-core\n, \nbeam-sqlite\n and \ntext\n packages.\n\n\n$\n stack repl --package beam-core --package beam-sqlite --package sqlite-simple --package beam-migrate --package text\n\n\n\n\n\nThis will put you into a GHCi prompt with the \nbeam-core\n and \nbeam-sqlite\n\npackages available. We also include the \nsqlite-simple\n package. Beam mainly\nmanages querying and data marshalling. Connections to the backends are done via\nbackend specific packages. In this case, \nbeam-sqlite\n uses the \nsqlite-simple\n\nbackend.\n\n\nBefore starting, we'll need to enable some extensions.\n\n\n :set -XDeriveGeneric -XGADTs -XOverloadedStrings -XFlexibleContexts -XFlexibleInstances -XTypeFamilies -XTypeApplications -XDeriveAnyClass\n\n\n\n\n\nAnd import some modules...\n\n\nimport\n \nDatabase.Beam\n\n\nimport\n \nDatabase.Beam.Sqlite\n\n\n\nimport\n \nData.Text\n \n(\nText\n)\n\n\n\n\n\n\nDefining our first table\n\n\nBeam tables are regular Haskell data types with a bit of scaffolding. Thankfully, the magic of the\nmodern Haskell type system allows us to remove the overhead and the syntactic fuzz of the\nscaffolding in most situations.\n\n\nWe start by declaring a data structure named \nUserT\n. As a matter of convention, Beam table types\nare suffixed with 'T'. Table types have only one constructor. Again, as a matter of convention, the\nconstructor has the same name as the table, but without the 'T' suffix. We'll soon see the reason\nfor this convention.\n\n\nIn this tutorial, I'll prefix all record selectors with an underscore. This is a matter of personal\npreference. One reason for the prefix is that it plays nicely with the \nlens\n library. Beam does not\nnecessitate the use of \nlens\n (in fact Beam includes its own mechanism to generically derive van\nLaarhoven lenses), but I recognize that some programmers use \nlens\n quite a lot.\n\n\ndata\n \nUserT\n \nf\n\n    \n=\n \nUser\n\n    \n{\n \n_userEmail\n     \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userPassword\n  \n::\n \nColumnar\n \nf\n \nText\n \n}\n\n    \nderiving\n \nGeneric\n\n\n\n\n\n\nThis data type might look very complicated, so I'd like to show you that it's not that scary. Let's\nsee if we can use GHCi to help us.\n\n\nPrelude Database.Beam.Sqlite Database.Beam Data.Text\n :t User\nUser\n  :: Columnar f Text\n     -\n Columnar f Text -\n Columnar f Text -\n Columnar f Text -\n UserT f\n\n\n\n\n\nHmm... That did not help much. Let's see what happens if we bind \nf\n to something concrete, like \nIdentity\n. Using the \nTypeApplications\n extension:\n\n\nPrelude Database.Beam Database.Beam.Sqlite Data.Text\n :t (User @Identity)\n(User @Identity) :: Text -\n Text -\n Text -\n Text -\n UserT Identity\n\n\n\n\n\nWoah! That looks a lot like what we'd expect if we had declared the type in the \"regular\" Haskell way:\n\n\ndata\n \nUser\n \n=\n \nUser\n\n          \n{\n \n_userEmail\n     \n::\n \nText\n\n          \n,\n \n_userFirstName\n \n::\n \nText\n\n          \n,\n \n_userLastName\n  \n::\n \nText\n\n          \n,\n \n_userPassword\n  \n::\n \nText\n \n}\n\n\n\n\n\n\nThis functionality is due to the fact that \nColumnar\n is a type family defined\nsuch that for any \nx\n, \nColumnar Identity x = x\n. This strategy is known as\n\ndefunctionalization\n \n1\n or \nhigher-kinded data types\n \n2\n.\n\n\nKnowing this, let's define a type synonym to make our life easier.\n\n\ntype\n \nUser\n \n=\n \nUserT\n \nIdentity\n\n\ntype\n \nUserId\n \n=\n \nPrimaryKey\n \nUserT\n \nIdentity\n\n\n\n\n\n\nNow you can see why we named the type of the table \nUserT\n and its constructor\n\nUser\n. This allows us to use the \"regular\" \nUser\n constructor to construct\nvalues of type \nUser\n. We can use the \nStandaloneDeriving\n and\n\nTypeSynonymInstances\n extensions to derive instances of \nShow\n and \nEq\n for the\n'regular' datatype.\n\n\n :set -XStandaloneDeriving -XTypeSynonymInstances -XMultiParamTypeClasses\n\n\n\n\n\nNow we can derive \nShow\n and \nEq\n instances.\n\n\nderiving\n \ninstance\n \nShow\n \nUser\n\n\nderiving\n \ninstance\n \nEq\n \nUser\n\n\n\n\n\n\nNote that this does require us to use an explicit type signature where we\notherwise wouldn't. For example,\n\n\nPrelude\n \nDatabase\n.\nBeam\n.\nSqlite\n \nDatabase\n.\nBeam\n \nData\n.\nText\n \nUser\n \njohn@example.com\n \nJohn\n \nSmith\n \npassword!\n\n\n\ninteractive\n:\n46\n:\n2\n:\n \nerror\n:\n\n    \n*\n \nNo\n \ninstance\n \nfor\n \n(\nShow\n \n(\nUserT\n \nf0\n))\n \narising\n \nfrom\n \na\n \nuse\n \nof\n \nlsquo\n;\nprint\nrsquo\n;\n\n    \n*\n \nIn\n \na\n \nstmt\n \nof\n \nan\n \ninteractive\n \nGHCi\n \ncommand\n:\n \nprint\n \nit\n\n\n\n\n\n\nHere, GHC is complaining that it cannot infer the type of the \nf\n parameter\nbased on the values we've supplied. This is because the \nColumnar\n type family\nis non-injective. However, an explicit type annotation fixes it all up.\n\n\nPrelude Database.Beam.Sqlite Database.Beam Data.Text\n User \njohn@example.com\n \nJohn\n \nSmith\n \npassword!\n :: User\nUser {_userEmail = \njohn@example.com\n, _userFirstName = \nJohn\n, _userLastName = \nSmith\n, _userPassword = \npassword!\n}\n\n\n\n\n\nYou can also use type applications, if you like that style better:\n\n\nPrelude Database.Beam Database.Beam.Sqlite Data.Text\n User @Identity \njohn@example.com\n \nJohn\n \nSmith\n \npassword!\n\nUser {_userEmail = \njohn@example.com\n, _userFirstName = \nJohn\n, _userLastName = \nSmith\n, _userPassword = \npassword!\n}\n\n\n\n\n\nUsually, you won't need to deal with this, as you'll explicitly annotate your\ntop-level functions to use the \nUser\n type.\n\n\nTeaching Beam about our table\n\n\nWe've defined a type that can represent the data in our table. Now, let's\ninform beam that we'd like to use \nUserT\n as a table.\n\n\nAll beam tables need to implement the \nBeamable\n type class. Due to GHC's\nDeriveGeneric and DefaultSignatures extensions, all these methods can be written\nfor us by the compiler at compile-time!\n\n\ninstance\n \nBeamable\n \nUserT\n\n\n\n\n\n\n\n\nTip\n\n\nIf you turn on the \nDeriveAnyClass\n feature, you can simply \nderive\n the \nBeamable\n type class. For example, the type\n\n\ndata UserT f\n    = User\n    { _userEmail     :: Columnar f Text\n    , _userFirstName :: Columnar f Text\n    , _userLastName  :: Columnar f Text\n    , _userPassword  :: Columnar f Text }\n    deriving Generic\n\n\ncould be written\n\n\ndata UserT f\n    = User\n    { _userEmail     :: Columnar f Text\n    , _userFirstName :: Columnar f Text\n    , _userLastName  :: Columnar f Text\n    , _userPassword  :: Columnar f Text }\n    deriving (Generic, Beamable)\n\n\n\n\nAdditionally, all beam tables must implement the \nTable\n type class, which we\ncan use to declare a primary key.\n\n\nThe only thing we need to provide is the type of the primary keys for users, and\na function that can extract the primary key from any \nUserT f\n object. To do\nthis, add the following lines to the instance declaration.\n\n\ninstance Table UserT where\n   data PrimaryKey UserT f = UserId (Columnar f Text) deriving (Generic, Beamable)\n   primaryKey = UserId . _userEmail\n\n\n\n\n\nThe \ndata\n declaration is similar to a toplevel data definition, construct a key\nfor \nUserT\n with the \nUserId\n constructor like a regular table.\n\n\nuserKey\n \n=\n \nUserId\n \njohn@doe.org\n\n\n\n\n\n\nDefining our database\n\n\nNow that we have our table, we're going to define a type to hold information about our\ndatabase. Defining our database is going to follow the same pattern as defining a table. We'll\ndefine a higher-kinded datatype and then declare an instance of \nDatabase\n, and let the compiler\nfigure most of it out.\n\n\nTables are a collection of \nColumnar\n values. Databases are a collection of\nentities, such as tables. Many database systems can also hold other entities\n(such as views, domain types, etc). Beam allows you to declare these as well \n3\n.\n\n\nOur database consists of only one table.\n\n\ndata\n \nShoppingCartDb\n \nf\n \n=\n \nShoppingCartDb\n\n                      \n{\n \n_shoppingCartUsers\n \n::\n \nf\n \n(\nTableEntity\n \nUserT\n)\n \n}\n\n                        \nderiving\n \n(\nGeneric\n,\n \nDatabase\n \nbe\n)\n\n\n\n\n\n\n\n\nNote\n\n\nBy deriving \nDatabase be\n we actually allowed our database to be used with any Beam\nbackend that supports it. We could also have explicitly listed the database backends we\nliked. For example, specifying \nderiving (Generic, Database Sqlite, Database Postgres\n would\nderive instances only for SQLite or Postgres.\n\n\n\n\nThe next step is to create a description of the particular database we'd like to create. This\ninvolves giving each of the tables in our database a name. If you've named all your database\nselectors using camel case, beam can automatically figure out what all the table names should be. If\nyou haven't, or you have multiple tables holding the same type in your database, you might have to\nmanually name your tables. For now, we'll let beam do the hard work \n4\n.\n\n\nshoppingCartDb\n \n::\n \nDatabaseSettings\n \nbe\n \nShoppingCartDb\n\n\nshoppingCartDb\n \n=\n \ndefaultDbSettings\n\n\n\n\n\n\nAdding users to our database\n\n\nLet's add some users to our database. As we said above, beam is\nbackend-agnostic. However, backend integration libraries are maintained in the\nofficial beam repository. The \nbeam-sqlite\n package offers straightforwards\nintegration with the \nsqlite-simple\n library.\n\n\nFirst, let's create a sqlite3 database with the right schema. Open up terminal, and do\n\n\n$\n sqlite3 shoppingcart1.db\n\nSQLite version 3.14.0 2016-07-26 15:17:14\n\n\nEnter \n.help\n for usage hints.\n\n\nsqlite\n CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));\n\n\nsqlite\n\n\n\n\n\n\nNow, let's open the database in Haskell.\n\n\nimport\n \nDatabase.SQLite.Simple\n\n\n\nconn\n \n-\n \nopen\n \nshoppingcart1.db\n\n\n\n\n\n\nNow let's add a few users. We'll give each user an MD5 encoded password too.\nWe'll use the \nrunBeamSqliteDebug\n function (supplied by \nbeam-sqlite\n) to\noutput the statements that beam would normally run. In production, you'd use the\n\nrunBeamSqlite\n function, or use the backend integration packages to directly\nuse the underlying backend library.\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \n{- for debug output -}\n \nconn\n \n$\n \nrunInsert\n \n$\n\n\ninsert\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n \n$\n\n\ninsertValues\n \n[\n \nUser\n \njames@example.com\n \nJames\n \nSmith\n \nb4cc344d25a2efe540adbf2678e2304c\n \n{- james -}\n\n             \n,\n \nUser\n \nbetty@example.com\n \nBetty\n \nJones\n \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n \n{- betty -}\n\n             \n,\n \nUser\n \nsam@example.com\n \nSam\n \nTaylor\n \n332532dcfaa1cbf61e2a266bd723612c\n \n{- sam -}\n \n]\n\n\n\n\n\n\nThe \nrunInsert\n function runs an insert statement, which we construct using the\n\ninsert\n function. Since we're inserting concrete values, we use the\n\ninsertValues\n function to supply the values. We can also use the\n\ninsertExpressions\n function to insert arbitrary SQL expressions, or the\n\ninsertFrom\n to insert the results of an arbitrary select (the \nINSERT INTO ..\nSELECT ..\n syntax).\n\n\nBecause we're in debug mode, we'll see the SQL that beam is running:\n\n\nINSERT INTO \ncart_users\n(\nemail\n, \nfirst_name\n, \nlast_name\n, \npassword\n) VALUES (?, ?, ?, ?), (?, ?, ?, ?), (?, ?, ?, ?)\n-- With values: [SQLText \njames@example.com\n,SQLText \nJames\n,SQLText \nSmith\n,SQLText \nb4cc344d25a2efe540adbf2678e2304c\n,SQLText \nbetty@example.com\n,SQLText \nBetty\n,SQLText \nJones\n,SQLText \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n,SQLText \nsam@example.com\n,SQLText \nSam\n,SQLText \nTaylor\n,SQLText \n332532dcfaa1cbf61e2a266bd723612c\n]\n\n\n\n\n\nThe \n?\n represent the values passed to the database (beam uses the backend's\nvalue interpolation to avoid SQL injection attacks).\n\n\nQuerying the database\n\n\nNow let's write some queries for the database. Let's get all the users we just\nadded. Click between the tabs to see the SQL and console output generated\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nallUsers\n \n=\n \nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nusers\n \n-\n \nrunSelectReturningList\n \n$\n \nselect\n \nallUsers\n\n  \nmapM_\n \n(\nliftIO\n \n.\n \nputStrLn\n \n.\n \nshow\n)\n \nusers\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n}\nUser {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n}\nUser {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nThe \n--\n at the ends of the console output lines are an artifact of the\ndocumentation build process. They won't appear in your console.\n\n\n\n\nNext let's suppose you wanted to sort the users into order by their first name,\nand then descending by their last name. We can use the \norderBy_\n function to\norder the query results. This is similar to the \nsortBy\n function for lists.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nsortUsersByFirstName\n \n=\n \norderBy_\n \n(\n\\\nu\n \n-\n \n(\nasc_\n \n(\n_userFirstName\n \nu\n),\n \ndesc_\n \n(\n_userLastName\n \nu\n)))\n \n(\nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n))\n\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nusers\n \n-\n \nrunSelectReturningList\n \n$\n \nselect\n \nsortUsersByFirstName\n\n  \nmapM_\n \n(\nliftIO\n \n.\n \nputStrLn\n \n.\n \nshow\n)\n \nusers\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nfirst_name\n \nASC\n,\n\n         \nt0\n.\nlast_name\n \nDESC\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n}\nUser {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n}\nUser {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can use \nlimit_\n and \noffset_\n in a similar manner to \ntake\n and \ndrop\n respectively.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nboundedQuery\n \n=\n \nlimit_\n \n1\n \n$\n \noffset_\n \n1\n \n$\n\n                   \norderBy_\n \n(\nasc_\n \n.\n \n_userFirstName\n)\n \n$\n\n                   \nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nusers\n \n-\n \nrunSelectReturningList\n \n(\nselect\n \nboundedQuery\n)\n\n  \nmapM_\n \n(\nliftIO\n \n.\n \nputStrLn\n \n.\n \nshow\n)\n \nusers\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nfirst_name\n \nASC\n\n\nLIMIT\n \n1\n\n\nOFFSET\n \n1\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nAggregations\n\n\nSometimes we also want to group our data together and perform calculations over\nthe groups of data. SQL calls these aggregations.\n\n\nThe simplest aggregation is counting. We use the \naggregate_\n function to create\naggregations. For example, to count all users, we can use the \ncountAll_\n\naggregation. We also use the \nrunSelectReturningOne\n function to get at most one\nrecord from the database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nuserCount\n \n=\n \naggregate_\n \n(\n\\\nu\n \n-\n \nas_\n \n@\nInt\n \ncountAll_\n)\n \n(\nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n))\n\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nJust\n \nc\n \n-\n \nrunSelectReturningOne\n \n$\n \nselect\n \nuserCount\n\n  \nliftIO\n \n$\n \nputStrLn\n \n(\nWe have \n \n++\n \nshow\n \nc\n \n++\n \n users in the database\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nWe have 3 users in the database\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\ncountAll_\n is happy to unmarshal into any \nIntegral\n type, so we use \nas_\n\nto constrain the type to \nInt\n.\n\n\n\n\nMaybe we'd like something a little more interesting, such as the number of users\nfor each unique first name. We can also express these aggregations using the\n\naggregate_\n function. In order to get interesting results, we'll need to add\nmore users to our database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n  \nrunInsert\n \n$\n\n  \ninsert\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n \n$\n\n  \ninsertValues\n \n[\n \nUser\n \njames@pallo.com\n \nJames\n \nPallo\n \nb4cc344d25a2efe540adbf2678e2304c\n \n{- james -}\n\n               \n,\n \nUser\n \nbetty@sims.com\n \nBetty\n \nSims\n \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n \n{- betty -}\n\n               \n,\n \nUser\n \njames@oreily.com\n \nJames\n \nO\nReily\n \nb4cc344d25a2efe540adbf2678e2304c\n \n{- james -}\n\n               \n,\n \nUser\n \nsam@sophitz.com\n \nSam\n \nSophitz\n \n332532dcfaa1cbf61e2a266bd723612c\n \n{- sam -}\n\n               \n,\n \nUser\n \nsam@jely.com\n \nSam\n \nJely\n \n332532dcfaa1cbf61e2a266bd723612c\n \n{- sam -}\n \n]\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \ncart_users\n(\nemail\n,\n\n                         \nfirst_name\n,\n\n                         \nlast_name\n,\n\n                         \npassword\n)\n\n\nVALUES\n \n(\n?\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n),\n \n(\n?\n,\n\n             \n?\n,\n\n             \n?\n,\n\n             \n?\n),\n \n(\n?\n,\n\n                  \n?\n,\n\n                  \n?\n,\n\n                  \n?\n),\n \n(\n?\n,\n\n                       \n?\n,\n\n                       \n?\n,\n\n                       \n?\n),\n \n(\n?\n,\n\n                            \n?\n,\n\n                            \n?\n,\n\n                            \n?\n);\n\n\n\n-- With values: [SQLText \njames@pallo.com\n,SQLText \nJames\n,SQLText \nPallo\n,SQLText \nb4cc344d25a2efe540adbf2678e2304c\n,SQLText \nbetty@sims.com\n,SQLText \nBetty\n,SQLText \nSims\n,SQLText \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n,SQLText \njames@oreily.com\n,SQLText \nJames\n,SQLText \nO\nReily\n,SQLText \nb4cc344d25a2efe540adbf2678e2304c\n,SQLText \nsam@sophitz.com\n,SQLText \nSam\n,SQLText \nSophitz\n,SQLText \n332532dcfaa1cbf61e2a266bd723612c\n,SQLText \nsam@jely.com\n,SQLText \nSam\n,SQLText \nJely\n,SQLText \n332532dcfaa1cbf61e2a266bd723612c\n]\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNow we can use \naggregate_\n to both group by a user's first name, and then count\nthe number of users.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nnumberOfUsersByName\n \n=\n \naggregate_\n \n(\n\\\nu\n \n-\n \n(\ngroup_\n \n(\n_userFirstName\n \nu\n),\n \nas_\n \n@\nInt\n \ncountAll_\n))\n \n$\n\n                          \nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \ncountedByName\n \n-\n \nrunSelectReturningList\n \n$\n \nselect\n \nnumberOfUsersByName\n\n  \nmapM_\n \n(\nliftIO\n \n.\n \nputStrLn\n \n.\n \nshow\n)\n \ncountedByName\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nfirst_name\n \nAS\n \nres0\n,\n\n       \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nfirst_name\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(\nBetty\n,2)\n(\nJames\n,3)\n(\nSam\n,3)\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nConclusion\n\n\nIn this tutorial, we've covered creating a database schema, opening up a beam\ndatabase, inserting values into the database, and querying values from them. We\nused the knowledge we learned to create a partial shopping cart database that\ncontains information about users. In the next tutorial, we'll delve deeper into\nthe some of the query types and show how we can create relations between tables.\nWe'll also use the monadic query interface to create SQL joins.\n\n\nUntil next time!\n\n\nIf you have any questions about beam, feel free to send them to\ntravis@athougies.net . Pull requests and bug reports are welcome\non \nGitHub\n.\n\n\n\n\n\n\n\n\n\n\nThanks to various bloggers for pointing this out. You can read more about this technique\n   \nhere\n.\n\n\n\n\n\n\nhttps://reasonablypolymorphic.com/blog/higher-kinded-data/\n\n\n\n\n\n\nAdding entities other than tables is covered in more depth in\n   the \nuser guide\n.\n\n\n\n\n\n\nMore on the default naming conventions can be found in\n   the \nmodels section\n of the user guide. We'll talk\n   about how to override defaults in the next sections.", 
            "title": "Part 1"
        }, 
        {
            "location": "/tutorials/tutorial1/#beam-module-structure", 
            "text": "Beam makes extensive use of GHC's Generics mechanism. This extension means beam does not need to\nrely on template haskell.  To start defining beam schemas and queries, you only need to import the Database.Beam  module. To interface with an actual database, you'll need to\nimport one of the database backends. We'll see how to use the Sqlite backend\nhere (found in the  beam-sqlite  package). Now, open up a GHCi prompt for us to\nuse. Make sure to get the  beam-core ,  beam-sqlite  and  text  packages.  $  stack repl --package beam-core --package beam-sqlite --package sqlite-simple --package beam-migrate --package text  This will put you into a GHCi prompt with the  beam-core  and  beam-sqlite \npackages available. We also include the  sqlite-simple  package. Beam mainly\nmanages querying and data marshalling. Connections to the backends are done via\nbackend specific packages. In this case,  beam-sqlite  uses the  sqlite-simple \nbackend.  Before starting, we'll need to enable some extensions.   :set -XDeriveGeneric -XGADTs -XOverloadedStrings -XFlexibleContexts -XFlexibleInstances -XTypeFamilies -XTypeApplications -XDeriveAnyClass  And import some modules...  import   Database.Beam  import   Database.Beam.Sqlite  import   Data.Text   ( Text )", 
            "title": "Beam Module Structure"
        }, 
        {
            "location": "/tutorials/tutorial1/#defining-our-first-table", 
            "text": "Beam tables are regular Haskell data types with a bit of scaffolding. Thankfully, the magic of the\nmodern Haskell type system allows us to remove the overhead and the syntactic fuzz of the\nscaffolding in most situations.  We start by declaring a data structure named  UserT . As a matter of convention, Beam table types\nare suffixed with 'T'. Table types have only one constructor. Again, as a matter of convention, the\nconstructor has the same name as the table, but without the 'T' suffix. We'll soon see the reason\nfor this convention.  In this tutorial, I'll prefix all record selectors with an underscore. This is a matter of personal\npreference. One reason for the prefix is that it plays nicely with the  lens  library. Beam does not\nnecessitate the use of  lens  (in fact Beam includes its own mechanism to generically derive van\nLaarhoven lenses), but I recognize that some programmers use  lens  quite a lot.  data   UserT   f \n     =   User \n     {   _userEmail       ::   Columnar   f   Text \n     ,   _userFirstName   ::   Columnar   f   Text \n     ,   _userLastName    ::   Columnar   f   Text \n     ,   _userPassword    ::   Columnar   f   Text   } \n     deriving   Generic   This data type might look very complicated, so I'd like to show you that it's not that scary. Let's\nsee if we can use GHCi to help us.  Prelude Database.Beam.Sqlite Database.Beam Data.Text  :t User\nUser\n  :: Columnar f Text\n     -  Columnar f Text -  Columnar f Text -  Columnar f Text -  UserT f  Hmm... That did not help much. Let's see what happens if we bind  f  to something concrete, like  Identity . Using the  TypeApplications  extension:  Prelude Database.Beam Database.Beam.Sqlite Data.Text  :t (User @Identity)\n(User @Identity) :: Text -  Text -  Text -  Text -  UserT Identity  Woah! That looks a lot like what we'd expect if we had declared the type in the \"regular\" Haskell way:  data   User   =   User \n           {   _userEmail       ::   Text \n           ,   _userFirstName   ::   Text \n           ,   _userLastName    ::   Text \n           ,   _userPassword    ::   Text   }   This functionality is due to the fact that  Columnar  is a type family defined\nsuch that for any  x ,  Columnar Identity x = x . This strategy is known as defunctionalization   1  or  higher-kinded data types   2 .  Knowing this, let's define a type synonym to make our life easier.  type   User   =   UserT   Identity  type   UserId   =   PrimaryKey   UserT   Identity   Now you can see why we named the type of the table  UserT  and its constructor User . This allows us to use the \"regular\"  User  constructor to construct\nvalues of type  User . We can use the  StandaloneDeriving  and TypeSynonymInstances  extensions to derive instances of  Show  and  Eq  for the\n'regular' datatype.   :set -XStandaloneDeriving -XTypeSynonymInstances -XMultiParamTypeClasses  Now we can derive  Show  and  Eq  instances.  deriving   instance   Show   User  deriving   instance   Eq   User   Note that this does require us to use an explicit type signature where we\notherwise wouldn't. For example,  Prelude   Database . Beam . Sqlite   Database . Beam   Data . Text   User   john@example.com   John   Smith   password!  interactive : 46 : 2 :   error : \n     *   No   instance   for   ( Show   ( UserT   f0 ))   arising   from   a   use   of   lsquo ; print rsquo ; \n     *   In   a   stmt   of   an   interactive   GHCi   command :   print   it   Here, GHC is complaining that it cannot infer the type of the  f  parameter\nbased on the values we've supplied. This is because the  Columnar  type family\nis non-injective. However, an explicit type annotation fixes it all up.  Prelude Database.Beam.Sqlite Database.Beam Data.Text  User  john@example.com   John   Smith   password!  :: User\nUser {_userEmail =  john@example.com , _userFirstName =  John , _userLastName =  Smith , _userPassword =  password! }  You can also use type applications, if you like that style better:  Prelude Database.Beam Database.Beam.Sqlite Data.Text  User @Identity  john@example.com   John   Smith   password! \nUser {_userEmail =  john@example.com , _userFirstName =  John , _userLastName =  Smith , _userPassword =  password! }  Usually, you won't need to deal with this, as you'll explicitly annotate your\ntop-level functions to use the  User  type.", 
            "title": "Defining our first table"
        }, 
        {
            "location": "/tutorials/tutorial1/#teaching-beam-about-our-table", 
            "text": "We've defined a type that can represent the data in our table. Now, let's\ninform beam that we'd like to use  UserT  as a table.  All beam tables need to implement the  Beamable  type class. Due to GHC's\nDeriveGeneric and DefaultSignatures extensions, all these methods can be written\nfor us by the compiler at compile-time!  instance   Beamable   UserT    Tip  If you turn on the  DeriveAnyClass  feature, you can simply  derive  the  Beamable  type class. For example, the type  data UserT f\n    = User\n    { _userEmail     :: Columnar f Text\n    , _userFirstName :: Columnar f Text\n    , _userLastName  :: Columnar f Text\n    , _userPassword  :: Columnar f Text }\n    deriving Generic  could be written  data UserT f\n    = User\n    { _userEmail     :: Columnar f Text\n    , _userFirstName :: Columnar f Text\n    , _userLastName  :: Columnar f Text\n    , _userPassword  :: Columnar f Text }\n    deriving (Generic, Beamable)   Additionally, all beam tables must implement the  Table  type class, which we\ncan use to declare a primary key.  The only thing we need to provide is the type of the primary keys for users, and\na function that can extract the primary key from any  UserT f  object. To do\nthis, add the following lines to the instance declaration.  instance Table UserT where\n   data PrimaryKey UserT f = UserId (Columnar f Text) deriving (Generic, Beamable)\n   primaryKey = UserId . _userEmail  The  data  declaration is similar to a toplevel data definition, construct a key\nfor  UserT  with the  UserId  constructor like a regular table.  userKey   =   UserId   john@doe.org", 
            "title": "Teaching Beam about our table"
        }, 
        {
            "location": "/tutorials/tutorial1/#defining-our-database", 
            "text": "Now that we have our table, we're going to define a type to hold information about our\ndatabase. Defining our database is going to follow the same pattern as defining a table. We'll\ndefine a higher-kinded datatype and then declare an instance of  Database , and let the compiler\nfigure most of it out.  Tables are a collection of  Columnar  values. Databases are a collection of\nentities, such as tables. Many database systems can also hold other entities\n(such as views, domain types, etc). Beam allows you to declare these as well  3 .  Our database consists of only one table.  data   ShoppingCartDb   f   =   ShoppingCartDb \n                       {   _shoppingCartUsers   ::   f   ( TableEntity   UserT )   } \n                         deriving   ( Generic ,   Database   be )    Note  By deriving  Database be  we actually allowed our database to be used with any Beam\nbackend that supports it. We could also have explicitly listed the database backends we\nliked. For example, specifying  deriving (Generic, Database Sqlite, Database Postgres  would\nderive instances only for SQLite or Postgres.   The next step is to create a description of the particular database we'd like to create. This\ninvolves giving each of the tables in our database a name. If you've named all your database\nselectors using camel case, beam can automatically figure out what all the table names should be. If\nyou haven't, or you have multiple tables holding the same type in your database, you might have to\nmanually name your tables. For now, we'll let beam do the hard work  4 .  shoppingCartDb   ::   DatabaseSettings   be   ShoppingCartDb  shoppingCartDb   =   defaultDbSettings", 
            "title": "Defining our database"
        }, 
        {
            "location": "/tutorials/tutorial1/#adding-users-to-our-database", 
            "text": "Let's add some users to our database. As we said above, beam is\nbackend-agnostic. However, backend integration libraries are maintained in the\nofficial beam repository. The  beam-sqlite  package offers straightforwards\nintegration with the  sqlite-simple  library.  First, let's create a sqlite3 database with the right schema. Open up terminal, and do  $  sqlite3 shoppingcart1.db SQLite version 3.14.0 2016-07-26 15:17:14  Enter  .help  for usage hints.  sqlite  CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));  sqlite   Now, let's open the database in Haskell.  import   Database.SQLite.Simple  conn   -   open   shoppingcart1.db   Now let's add a few users. We'll give each user an MD5 encoded password too.\nWe'll use the  runBeamSqliteDebug  function (supplied by  beam-sqlite ) to\noutput the statements that beam would normally run. In production, you'd use the runBeamSqlite  function, or use the backend integration packages to directly\nuse the underlying backend library.  runBeamSqliteDebug   putStrLn   {- for debug output -}   conn   $   runInsert   $  insert   ( _shoppingCartUsers   shoppingCartDb )   $  insertValues   [   User   james@example.com   James   Smith   b4cc344d25a2efe540adbf2678e2304c   {- james -} \n              ,   User   betty@example.com   Betty   Jones   82b054bd83ffad9b6cf8bdb98ce3cc2f   {- betty -} \n              ,   User   sam@example.com   Sam   Taylor   332532dcfaa1cbf61e2a266bd723612c   {- sam -}   ]   The  runInsert  function runs an insert statement, which we construct using the insert  function. Since we're inserting concrete values, we use the insertValues  function to supply the values. We can also use the insertExpressions  function to insert arbitrary SQL expressions, or the insertFrom  to insert the results of an arbitrary select (the  INSERT INTO ..\nSELECT ..  syntax).  Because we're in debug mode, we'll see the SQL that beam is running:  INSERT INTO  cart_users ( email ,  first_name ,  last_name ,  password ) VALUES (?, ?, ?, ?), (?, ?, ?, ?), (?, ?, ?, ?)\n-- With values: [SQLText  james@example.com ,SQLText  James ,SQLText  Smith ,SQLText  b4cc344d25a2efe540adbf2678e2304c ,SQLText  betty@example.com ,SQLText  Betty ,SQLText  Jones ,SQLText  82b054bd83ffad9b6cf8bdb98ce3cc2f ,SQLText  sam@example.com ,SQLText  Sam ,SQLText  Taylor ,SQLText  332532dcfaa1cbf61e2a266bd723612c ]  The  ?  represent the values passed to the database (beam uses the backend's\nvalue interpolation to avoid SQL injection attacks).", 
            "title": "Adding users to our database"
        }, 
        {
            "location": "/tutorials/tutorial1/#querying-the-database", 
            "text": "Now let's write some queries for the database. Let's get all the users we just\nadded. Click between the tabs to see the SQL and console output generated  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   allUsers   =   all_   ( _shoppingCartUsers   shoppingCartDb )  runBeamSqliteDebug   putStrLn   conn   $   do \n   users   -   runSelectReturningList   $   select   allUsers \n   mapM_   ( liftIO   .   putStrLn   .   show )   users  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c }\nUser {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f }\nUser {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c } \n\n         \n    \n         \n    \n                 \n                       Note  The  --  at the ends of the console output lines are an artifact of the\ndocumentation build process. They won't appear in your console.   Next let's suppose you wanted to sort the users into order by their first name,\nand then descending by their last name. We can use the  orderBy_  function to\norder the query results. This is similar to the  sortBy  function for lists.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   sortUsersByFirstName   =   orderBy_   ( \\ u   -   ( asc_   ( _userFirstName   u ),   desc_   ( _userLastName   u )))   ( all_   ( _shoppingCartUsers   shoppingCartDb ))  runBeamSqliteDebug   putStrLn   conn   $   do \n   users   -   runSelectReturningList   $   select   sortUsersByFirstName \n   mapM_   ( liftIO   .   putStrLn   .   show )   users  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  ORDER   BY   t0 . first_name   ASC , \n          t0 . last_name   DESC ;  -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f }\nUser {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c }\nUser {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c } \n\n         \n    \n         \n    \n                 \n                      We can use  limit_  and  offset_  in a similar manner to  take  and  drop  respectively.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   boundedQuery   =   limit_   1   $   offset_   1   $ \n                    orderBy_   ( asc_   .   _userFirstName )   $ \n                    all_   ( _shoppingCartUsers   shoppingCartDb )  runBeamSqliteDebug   putStrLn   conn   $   do \n   users   -   runSelectReturningList   ( select   boundedQuery ) \n   mapM_   ( liftIO   .   putStrLn   .   show )   users  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  ORDER   BY   t0 . first_name   ASC  LIMIT   1  OFFSET   1 ;  -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c }", 
            "title": "Querying the database"
        }, 
        {
            "location": "/tutorials/tutorial1/#aggregations", 
            "text": "Sometimes we also want to group our data together and perform calculations over\nthe groups of data. SQL calls these aggregations.  The simplest aggregation is counting. We use the  aggregate_  function to create\naggregations. For example, to count all users, we can use the  countAll_ \naggregation. We also use the  runSelectReturningOne  function to get at most one\nrecord from the database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   userCount   =   aggregate_   ( \\ u   -   as_   @ Int   countAll_ )   ( all_   ( _shoppingCartUsers   shoppingCartDb ))  runBeamSqliteDebug   putStrLn   conn   $   do \n   Just   c   -   runSelectReturningOne   $   select   userCount \n   liftIO   $   putStrLn   ( We have    ++   show   c   ++    users in the database )  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   res0  FROM   cart_users   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             We have 3 users in the database \n\n         \n    \n         \n    \n                 \n                       Note  countAll_  is happy to unmarshal into any  Integral  type, so we use  as_ \nto constrain the type to  Int .   Maybe we'd like something a little more interesting, such as the number of users\nfor each unique first name. We can also express these aggregations using the aggregate_  function. In order to get interesting results, we'll need to add\nmore users to our database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n    \n         \n            \n         \n             runBeamSqliteDebug   putStrLn   conn   $ \n   runInsert   $ \n   insert   ( _shoppingCartUsers   shoppingCartDb )   $ \n   insertValues   [   User   james@pallo.com   James   Pallo   b4cc344d25a2efe540adbf2678e2304c   {- james -} \n                ,   User   betty@sims.com   Betty   Sims   82b054bd83ffad9b6cf8bdb98ce3cc2f   {- betty -} \n                ,   User   james@oreily.com   James   O Reily   b4cc344d25a2efe540adbf2678e2304c   {- james -} \n                ,   User   sam@sophitz.com   Sam   Sophitz   332532dcfaa1cbf61e2a266bd723612c   {- sam -} \n                ,   User   sam@jely.com   Sam   Jely   332532dcfaa1cbf61e2a266bd723612c   {- sam -}   ]  \n\n         \n    \n         \n             INSERT   INTO   cart_users ( email , \n                          first_name , \n                          last_name , \n                          password )  VALUES   ( ? , \n         ? , \n         ? , \n         ? ),   ( ? , \n              ? , \n              ? , \n              ? ),   ( ? , \n                   ? , \n                   ? , \n                   ? ),   ( ? , \n                        ? , \n                        ? , \n                        ? ),   ( ? , \n                             ? , \n                             ? , \n                             ? );  -- With values: [SQLText  james@pallo.com ,SQLText  James ,SQLText  Pallo ,SQLText  b4cc344d25a2efe540adbf2678e2304c ,SQLText  betty@sims.com ,SQLText  Betty ,SQLText  Sims ,SQLText  82b054bd83ffad9b6cf8bdb98ce3cc2f ,SQLText  james@oreily.com ,SQLText  James ,SQLText  O Reily ,SQLText  b4cc344d25a2efe540adbf2678e2304c ,SQLText  sam@sophitz.com ,SQLText  Sam ,SQLText  Sophitz ,SQLText  332532dcfaa1cbf61e2a266bd723612c ,SQLText  sam@jely.com ,SQLText  Sam ,SQLText  Jely ,SQLText  332532dcfaa1cbf61e2a266bd723612c ]  \n\n         \n    \n         \n    \n                 \n                      Now we can use  aggregate_  to both group by a user's first name, and then count\nthe number of users.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   numberOfUsersByName   =   aggregate_   ( \\ u   -   ( group_   ( _userFirstName   u ),   as_   @ Int   countAll_ ))   $ \n                           all_   ( _shoppingCartUsers   shoppingCartDb )  runBeamSqliteDebug   putStrLn   conn   $   do \n   countedByName   -   runSelectReturningList   $   select   numberOfUsersByName \n   mapM_   ( liftIO   .   putStrLn   .   show )   countedByName  \n\n         \n    \n         \n             SELECT   t0 . first_name   AS   res0 , \n        COUNT ( * )   AS   res1  FROM   cart_users   AS   t0  GROUP   BY   t0 . first_name ;  -- With values: []  \n\n         \n    \n         \n             ( Betty ,2)\n( James ,3)\n( Sam ,3)", 
            "title": "Aggregations"
        }, 
        {
            "location": "/tutorials/tutorial1/#conclusion", 
            "text": "In this tutorial, we've covered creating a database schema, opening up a beam\ndatabase, inserting values into the database, and querying values from them. We\nused the knowledge we learned to create a partial shopping cart database that\ncontains information about users. In the next tutorial, we'll delve deeper into\nthe some of the query types and show how we can create relations between tables.\nWe'll also use the monadic query interface to create SQL joins.  Until next time!  If you have any questions about beam, feel free to send them to\ntravis@athougies.net . Pull requests and bug reports are welcome\non  GitHub .      Thanks to various bloggers for pointing this out. You can read more about this technique\n    here .    https://reasonablypolymorphic.com/blog/higher-kinded-data/    Adding entities other than tables is covered in more depth in\n   the  user guide .    More on the default naming conventions can be found in\n   the  models section  of the user guide. We'll talk\n   about how to override defaults in the next sections.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/tutorials/tutorial2/", 
            "text": "Introduction\n\n\nIn the last part, we created a simple database with one table. We then used the\nbeam interface to add entities into that table and query them. In this tutorial,\nwe'll see how to update and delete rows and how to establish and query relations\nbetween tables.\n\n\nWe'll then delve deeper into queries to see how to create queries that return\nmultiple tables.\n\n\nAdding a related table\n\n\nThe users in our simple e-commerce application would like to ship orders to\ntheir homes. Let's build an addresses model to allow users to add home addresses\nto their profile. Our table will store United States addresses for now. An\naddress in the United States consists of\n\n\n\n\nan auto-incrementing primary key\n\n\none required house number and street line\n\n\nan optional apartment/suite number line\n\n\na required city\n\n\na required 2-letter state/territory code\n\n\none 5-digit ZIP code\n\n\n\n\nLet's build the \nAddressT\n table. \nAddressT\n will follow a similar formula to\n\nUserT\n, but it will contain a reference to a \nUserT\n table. ]\n\n\ndata\n \nAddressT\n \nf\n \n=\n \nAddress\n\n                \n{\n \n_addressId\n    \n::\n \nC\n \nf\n \nInt\n\n                \n,\n \n_addressLine1\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressLine2\n \n::\n \nC\n \nf\n \n(\nMaybe\n \nText\n)\n\n                \n,\n \n_addressCity\n  \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressState\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressZip\n   \n::\n \nC\n \nf\n \nText\n\n\n                \n,\n \n_addressForUser\n \n::\n \nPrimaryKey\n \nUserT\n \nf\n \n}\n\n                  \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\ntype\n \nAddress\n \n=\n \nAddressT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nUserT\n \nIdentity\n)\n\n\nderiving\n \ninstance\n \nShow\n \nAddress\n\n\n\ninstance\n \nTable\n \nAddressT\n \nwhere\n\n    \ndata\n \nPrimaryKey\n \nAddressT\n \nf\n \n=\n \nAddressId\n \n(\nColumnar\n \nf\n \nInt\n)\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n    \nprimaryKey\n \n=\n \nAddressId\n \n.\n \n_addressId\n\n\ntype\n \nAddressId\n \n=\n \nPrimaryKey\n \nAddressT\n \nIdentity\n \n-- For convenience\n\n\n\n\n\n\n\n\nTip\n\n\nAbove, we used the \nC\n constructor instead of \nColumnar\n for each column.\n\nC\n is a type synonym for \nColumnar\n, and some find it reduces the syntactic\noverhead of model declaration.\n\n\n\n\nNotice that \n_addressForUser\n is declared as a \nPrimaryKey UserT f\n. This pulls\nin all the columns necessary for referencing a \nUserT\n \n1\n. Later, we'll also\nsee how beam can use the field to automatically create JOINs.\n\n\nNotice also that \n_addressId\n corresponds to our auto-increminting primary key\nfield. In general, beam doesn't care if the underlying field is assigned\nautomatically, only about the type of final values of that field.\n\n\nWe have all the tables we need now, so let's go ahead and redefine our newest\ndatabase type.\n\n\ndata\n \nShoppingCartDb\n \nf\n \n=\n \nShoppingCartDb\n\n                      \n{\n \n_shoppingCartUsers\n         \n::\n \nf\n \n(\nTableEntity\n \nUserT\n)\n\n                      \n,\n \n_shoppingCartUserAddresses\n \n::\n \nf\n \n(\nTableEntity\n \nAddressT\n)\n \n}\n\n                        \nderiving\n \n(\nGeneric\n,\n \nDatabase\n \nbe\n)\n\n\n\n\n\n\nModifying the default naming choices\n\n\nIn the last part of the tutorial, we let beam decide our field names for us.\nThis is great for simple cases. However, sometimes you want more control over\nthe naming options.\n\n\n\n\nNote\n\n\nPrevious versions of this tutorial had instructions on changing the schema\ntype of particular tables. This functionality has been moved from\n\nbeam-core\n into the \nbeam-migrate\n package. See\nthe \nmigrations guide\n for more information.\n\n\n\n\nThe \ndefaultDbSettings\n function generates names using the Haskell record\nselector names \n2\n. This function returns the \nDatabaseType\n parameterized over\n\nDatabaseEntity\n, which is a type that contains metadata about entity names. We\ncan \nmodify\n this description after it is created by using the\n\nwithDbModification\n function. You can think of \nwithDbModification\n as applying\na transformation function to each name in our database.\n\n\nMost of the time \nwithDbModification\n needs a full description of the database\nnames. However, most of the time we only want to rename certain columns or\ntables. We can use the \ndbModification\n value to construct a modification that\ndoesn't change any names. We can then use the Haskell record update syntax to\nupdate field and column names. This is best illustrated by an example.\n\n\nRecall our Haskell data types above.\n\n\ndata\n \nUserT\n \nf\n\n    \n=\n \nUser\n\n    \n{\n \n_userEmail\n     \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userPassword\n  \n::\n \nColumnar\n \nf\n \nText\n \n}\n\n    \nderiving\n \nGeneric\n\n\n\ndata\n \nAddressT\n \nf\n \n=\n \nAddress\n\n                \n{\n \n_addressId\n    \n::\n \nC\n \nf\n \nInt\n\n                \n,\n \n_addressLine1\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressLine2\n \n::\n \nC\n \nf\n \n(\nMaybe\n \nText\n)\n\n                \n,\n \n_addressCity\n  \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressState\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressZip\n   \n::\n \nC\n \nf\n \nText\n\n\n                \n,\n \n_addressForUser\n \n::\n \nPrimaryKey\n \nUserT\n \nf\n \n}\n\n                  \nderiving\n \nGeneric\n\n\n\ndata\n \nShoppingCartDb\n \nf\n \n=\n \nShoppingCartDb\n\n                      \n{\n \n_shoppingCartUsers\n         \n::\n \nf\n \n(\nTableEntity\n \nUserT\n)\n\n                      \n,\n \n_shoppingCartUserAddresses\n \n::\n \nf\n \n(\nTableEntity\n \nAddressT\n)\n \n}\n\n                        \nderiving\n \nGeneric\n\n\n\n\n\n\nNow, let's say we want beam to use the name \naddresses\n to access the\n\n_shoppingCartUserAddresses\n table, and the names \naddress1\n and \naddress2\n to\naccess \n_addressLine1\n and \n_addressLine2\n respectively.\n\n\nshoppingCartDb\n \n::\n \nDatabaseSettings\n \nbe\n \nShoppingCartDb\n\n\nshoppingCartDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n                 \ndbModification\n \n{\n\n                   \n_shoppingCartUserAddresses\n \n=\n\n                     \nsetEntityName\n \naddresses\n \n\n                     \nmodifyTableFields\n\n                       \ntableModification\n \n{\n\n                         \n_addressLine1\n \n=\n \nfieldNamed\n \naddress1\n,\n\n                         \n_addressLine2\n \n=\n \nfieldNamed\n \naddress2\n\n                       \n}\n\n                 \n}\n\n\n\n\n\n\nAbove, we use \ndbModification\n to produce a default modification, then\nwe override the \n_shoppingCartUserAddresses\n modification to change\nthe addresses table. We modify the table in two ways. First, we use\nthe \nsetEntityName\n function to change the name of the table. Then, we\nuse \nmodifyTableFields\n to change the names of each field. The\nmodifications can be combined with the semigroup operator \n(\n)\n.\n\n\nWe only override the \n_addressLine1\n and \n_addressLine2\n modifications with\n\nfieldNamed \"address1\"\n and \nfieldNamed \"address2\"\n. Because \ntableModification\n\nproduces a default modification, the other columns are kept at their default\nvalue.\n\n\n\n\nTip\n\n\nThe \nOverloadedStrings\n extension lets us avoid typing \nfieldNamed\n. For example, instead of\n\n\n_addressLine1 = fieldNamed \"address1\"\n\n\nwe could have written\n\n\n_addressLine1 = \"address1\"\n\n\n\n\nIf you didn't need to modify any of the field names, you can omit\n\nmodifyTableFields\n. For example, to simply produce a database with\nthe first table named \nusers\n and the second named \nuser_addresses\n,\nyou can do\n\n\nshoppingCartDb1\n \n::\n \nDatabaseSettings\n \nbe\n \nShoppingCartDb\n\n\nshoppingCartDb1\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n                  \ndbModification\n \n{\n\n                    \n_shoppingCartUsers\n \n=\n \nsetEntityName\n \nusers\n,\n\n                    \n_shoppingCartUserAddresses\n \n=\n \nsetEntityName\n \nuser_addresses\n\n                  \n}\n\n\n\n\n\n\nFor the purposes of this tutorial, we'll stick with \nshoppingCartDb\n.\n\n\nEasier queries with lenses\n\n\nIn the previous part, we accessed table columns by using regular Haskell record\nsyntax. Sometimes, we would like to use the more convenient lens syntax to\naccess columns. Of course, all of beam's definitions are compatible with the\n\nlens\n library -- that is to say, \nmakeLenses\n will work just fine. However,\nbeam's motivation is, in part, the avoidance of Template Haskell, and it would\nhardly be worth it if you had to include a Template Haskell splice just to have\nlenses for the models you declared TH free.\n\n\nIn reality, the \nlens\n library isn't required to construct valid lenses. Lenses\nare a plain old Haskell type.\n\n\nWe can use beam's \nColumnar\n mechanism to automatically derive lenses. The\n\ntableLenses\n function produces a table value where each column is given a type\n\nLensFor\n, which is a \nnewtype\n wrapper over a correctly constructed,\npolymorphic Van Laarhoven lens.\n\n\nWe can bring these lenses into scope globally via a global pattern match against\n\ntableLenses\n. For example, to get lenses for each column of the \nAddressT\n and\n\nUserT\n table.\n\n\n-- Add the following to the top of the file, for GHC \n8.2\n\n\n{-#  LANGUAGE ImpredicativeTypes #-}\n\n\n\nAddress\n \n(\nLensFor\n \naddressId\n)\n    \n(\nLensFor\n \naddressLine1\n)\n\n        \n(\nLensFor\n \naddressLine2\n)\n \n(\nLensFor\n \naddressCity\n)\n\n        \n(\nLensFor\n \naddressState\n)\n \n(\nLensFor\n \naddressZip\n)\n\n        \n(\nUserId\n \n(\nLensFor\n \naddressForUserId\n))\n \n=\n\n        \ntableLenses\n\n\n\nUser\n \n(\nLensFor\n \nuserEmail\n)\n    \n(\nLensFor\n \nuserFirstName\n)\n\n     \n(\nLensFor\n \nuserLastName\n)\n \n(\nLensFor\n \nuserPassword\n)\n \n=\n\n     \ntableLenses\n\n\n\n\n\n\n\n\nNote\n\n\nThe \nImpredicativeTypes\n language extension is necessary for newer\nGHC to allow the polymorphically typed lenses to be introduced at\nthe top-level. Older GHCs were more lenient.\n\n\n\n\nAs in tables, we can generate lenses for databases via the \ndbLenses\n function.\n\n\nShoppingCartDb\n \n(\nTableLens\n \nshoppingCartUsers\n)\n\n               \n(\nTableLens\n \nshoppingCartUserAddresses\n)\n \n=\n\n               \ndbLenses\n\n\n\n\n\n\nWe can ask GHCi for the type of a column lens.\n\n\nPrelude Database.Beam Database.Beam.Sqlite Data.Text Database.SQLite.Simple\n :t addressId\naddressId\n  :: Functor f2 =\n\n     (Columnar f1 Int -\n f2 (Columnar f1 Int))\n     -\n AddressT f1 -\n f2 (AddressT f1)\n\n\n\n\n\nThis lens is compatible with those of the \nlens\n library.\n\n\nAnd a table lens, for good measure\n\n\nPrelude Database.Beam Database.Beam.Sqlite Data.Text Database.SQLite.Simple\n :t shoppingCartUsers\nshoppingCartUsers\n  :: Functor f1 =\n\n     (f2 (TableEntity UserT) -\n f1 (f2 (TableEntity UserT)))\n     -\n ShoppingCartDb f2 -\n f1 (ShoppingCartDb f2)\n\n\n\n\n\n\n\nWarning\n\n\nThese lens generating functions are \nawesome\n but if you use them in a\ncompiled Haskell module (rather than GHC), GHC may give you odd compile\nerrors about ambiguous types. These occur due to what's known as the\nmonomorphism restriction. You can turn it off using the\n\nNoMonomorphismRestriction\n extension.\n\n\nThe monomorphism restriction is part of the Haskell standard, but there has\nbeen talk about removing it in future language versions. Basically, it\nrequires GHC to not automatically infer polymorphic types for global\ndefinitions. In this case though, polymorphic global definitions is exactly\nwhat we want.\n\n\n\n\nWorking with relations\n\n\nNow, let's see how we can add related addresses to our database. We begin by\nopening up a connection for us to use in the rest of the tutorial.\n\n\nFirst, let's open a new database and create the schema.\n\n\n$\n sqlite3 shoppingcart2.db\n\nSQLite version 3.14.0 2016-07-26 15:17:14\n\n\nEnter \n.help\n for usage hints.\n\n\nsqlite\n CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));\n\n\nsqlite\n CREATE TABLE addresses ( id INTEGER PRIMARY KEY, address1 VARCHAR NOT NULL, address2 VARCHAR, city VARCHAR NOT NULL, state VARCHAR NOT NULL, zip VARCHAR NOT NULL, for_user__email VARCHAR NOT NULL );\n\n\n\n\n\n\nNow, in GHCi, we can use \nsqlite-simple\n to get a handle to this database.\n\n\nconn\n \n-\n \nopen\n \nshoppingcart2.db\n\n\n\n\n\n\nBefore we add addresses, we need to add some users that we can reference.\n\n\nlet\n \njames\n \n=\n \nUser\n \njames@example.com\n \nJames\n \nSmith\n \nb4cc344d25a2efe540adbf2678e2304c\n\n    \nbetty\n \n=\n \nUser\n \nbetty@example.com\n \nBetty\n \nJones\n \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n\n    \nsam\n \n=\n \nUser\n \nsam@example.com\n \nSam\n \nTaylor\n \n332532dcfaa1cbf61e2a266bd723612c\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \nrunInsert\n \n$\n\n  \ninsert\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n \n$\n\n  \ninsertValues\n \n[\n \njames\n,\n \nbetty\n,\n \nsam\n \n]\n\n\n\n\n\n\nNow that we have some \nUser\n objects, we can create associated addresses. Notice\nthat above, we used \ninsertValues\n to insert concrete \nUser\n rows. This worked\nbecause we could determine every field of \nUser\n before insertion. \nAddress\nes\nhowever have a pesky auto-incrementing primary key field. We can get around this\nby inserting \nexpressions\n instead of \nvalues\n. We can use \ndefault_\n to stand\nfor a value that the database needs to fill in. We can use \nval_\n to lift a\nliteral value into an expression.\n\n\nWith that in mind, let's give James one address, Betty two addresses, and Sam none.\n\n\nlet\n \naddresses\n \n=\n \n[\n \nAddress\n \ndefault_\n \n(\nval_\n \n123 Little Street\n)\n \n(\nval_\n \nNothing\n)\n \n(\nval_\n \nBoston\n)\n \n(\nval_\n \nMA\n)\n \n(\nval_\n \n12345\n)\n \n(\npk\n \njames\n)\n\n                \n,\n \nAddress\n \ndefault_\n \n(\nval_\n \n222 Main Street\n)\n \n(\nval_\n \n(\nJust\n \nSte 1\n))\n \n(\nval_\n \nHouston\n)\n \n(\nval_\n \nTX\n)\n \n(\nval_\n \n8888\n)\n \n(\npk\n \nbetty\n)\n\n                \n,\n \nAddress\n \ndefault_\n \n(\nval_\n \n9999 Residence Ave\n)\n \n(\nval_\n \nNothing\n)\n \n(\nval_\n \nSugarland\n)\n \n(\nval_\n \nTX\n)\n \n(\nval_\n \n8989\n)\n \n(\npk\n \nbetty\n)\n \n]\n\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \nrunInsert\n \n$\n\n  \ninsert\n \n(\n_shoppingCartUserAddresses\n \nshoppingCartDb\n)\n \n$\n\n  \ninsertExpressions\n \naddresses\n\n\n\n\n\n\nNotice that we used the \npk\n function to assign the reference to the \nUserT\n\ntable. \npk\n is a synonym of the \nprimaryKey\n function from the \nTable\n type\nclass. It should be clear what's going on, but if it's not, let's ask GHCi.\n\n\n*NextSteps\n pk (james :: User)p\n\n\nUserId \njames@example.com\n\n\n\n\n\n\nIf we query for all the addresses, we'll see that SQLite has assigned them an\nappropriate id.\n\n\nFirst, let's use the new lenses we made. Make sure to import \nLens.Micro\n or\n\nControl.Lens\n or whichever (van Laarhoven) lens module you prefer.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- import Lens.Micro\n\n\n-- import Control.Lens\n\n\naddresses\n \n-\n \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n             \nrunSelectReturningList\n \n$\n\n             \nselect\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n))\n\n\nmapM_\n \nprint\n \naddresses\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n\n       \nt0\n.\naddress1\n \nAS\n \nres1\n,\n\n       \nt0\n.\naddress2\n \nAS\n \nres2\n,\n\n       \nt0\n.\ncity\n \nAS\n \nres3\n,\n\n       \nt0\n.\nstate\n \nAS\n \nres4\n,\n\n       \nt0\n.\nzip\n \nAS\n \nres5\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres6\n\n\nFROM\n \naddresses\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nAddress {_addressId = 1, _addressLine1 = \n123 Little Street\n, _addressLine2 = Nothing, _addressCity = \nBoston\n, _addressState = \nMA\n, _addressZip = \n12345\n, _addressForUser = UserId \njames@example.com\n}\nAddress {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n}\nAddress {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarland\n, _addressState = \nTX\n, _addressZip = \n8989\n, _addressForUser = UserId \nbetty@example.com\n}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nA note about queries\n\n\nIn the last tutorial, we saw how queries and list supported similar interfaces.\nNamely we saw how \nlimit_\n is like \ntake\n, \noffset_\n like \ndrop\n, \norderBy\n like\nan enhanced \nsortBy\n, and \naggregate\n like an enhanced \ngroupBy\n. These\ncorresponded to the \nLIMIT\n, \nOFFSET\n, \nORDER BY\n, and \nGROUP BY\n SQL\nconstructs. The missing SQL operation in this list is the \nJOIN\n, which computes\nthe cartesian product of two tables. In other words, a join between table \nA\n\nand table \nB\n results in a query of pairs \n(x, y)\n for every \nx\n in \nA\n and\nevery \ny\n in \nB\n. SQL joins can result in two-way, three-way, four-way, etc.\ncartesian products.\n\n\nThose familiar with lists in Haskell will note that there is an easy abstraction\nfor taking \nn\n-ary cartesian products over lists: monads.\n\n\nThe list monad\n\n\nWe can use GHCi to see what we mean.\n\n\n*\nNextSteps\n \ndo\n \n{\n \nx\n \n-\n \n[\n1\n,\n2\n,\n3\n];\n \ny\n \n-\n \n[\n4\n,\n5\n,\n6\n];\n \nreturn\n \n(\nx\n,\n \ny\n);\n \n}\n\n\n[(\n1\n,\n4\n),(\n1\n,\n5\n),(\n1\n,\n6\n),(\n2\n,\n4\n),(\n2\n,\n5\n),(\n2\n,\n6\n),(\n3\n,\n4\n),(\n3\n,\n5\n),(\n3\n,\n6\n)]\n\n\n\n\n\n\nWe get the two-way cartesian product of \n[1,2,3]\n and \n[4,5,6]\n. We can make the\nproduct arbitrarily long.\n\n\n*\nNextSteps\n \ndo\n \n{\n \nw\n \n-\n \n[\n10\n,\n \n20\n,\n \n30\n];\n \nx\n \n-\n \n[\n1\n,\n2\n,\n3\n];\n \ny\n \n-\n \n[\n4\n,\n5\n,\n6\n];\n \nz\n \n-\n \n[\n100\n,\n \n200\n,\n \n1\n];\n \nreturn\n \n(\nx\n,\n \ny\n,\n \nz\n,\n \nw\n);\n \n}\n\n\n[(\n1\n,\n4\n,\n100\n,\n10\n),(\n1\n,\n4\n,\n200\n,\n10\n),(\n1\n,\n4\n,\n1\n,\n10\n),(\n1\n,\n5\n,\n100\n,\n10\n),(\n1\n,\n5\n,\n200\n,\n10\n),(\n1\n,\n5\n,\n1\n,\n10\n),\n \n...\n \n]\n\n\n\n\n\n\nWe can also use \nguard\n from \nControl.Monad\n to limit the combinations that the\nlist monad puts together. For example, if we had the lists\n\n\nlet\n \nusersList\n \n=\n \n[(\n1\n,\n \njames\n),\n \n(\n2\n,\n \nbetty\n),\n \n(\n3\n,\n \ntom\n)]\n\n    \naddressesList\n \n=\n \n[(\n1\n,\n \naddress1\n),\n \n(\n1\n,\n \naddress2\n),\n \n(\n3\n,\n \naddress3\n)]\n\n\n\n\n\n\nWe can use \nguard\n to return all pairs of elements from \nusersList\n and\n\naddressesList\n that matched on their first element. For example,\n\n\n*\nNextSteps\n \ndo\n \n{\n \nuser\n \n-\n \nusersList\n;\n \naddress\n \n-\n \naddressesList\n;\n \nguard\n \n(\nfst\n \nuser\n \n==\n \nfst\n \naddress\n);\n \nreturn\n \n(\nuser\n,\n \naddress\n)\n \n}\n\n\n[((\n1\n,\njames\n),(\n1\n,\naddress1\n)),((\n1\n,\njames\n),(\n1\n,\naddress2\n)),((\n3\n,\ntom\n),(\n3\n,\naddress3\n))]\n\n\n\n\n\n\nThe query monad\n\n\nAs I claimed in the first tutorial, queries support many of the same interfaces and operations lists\ndo. It follows that queries also expose a monadic interface.\n\n\nFor example, to retrieve every pair of user and address, we can write the following query:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nallPairs\n \n-\n \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n            \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \ndo\n\n              \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n              \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n              \nreturn\n \n(\nuser\n,\n \naddress\n)\n\n\n\nmapM_\n \nprint\n \nallPairs\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nid\n \nAS\n \nres4\n,\n\n       \nt1\n.\naddress1\n \nAS\n \nres5\n,\n\n       \nt1\n.\naddress2\n \nAS\n \nres6\n,\n\n       \nt1\n.\ncity\n \nAS\n \nres7\n,\n\n       \nt1\n.\nstate\n \nAS\n \nres8\n,\n\n       \nt1\n.\nzip\n \nAS\n \nres9\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres10\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \naddresses\n \nAS\n \nt1\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = 1, _addressLine1 = \n123 Little Street\n, _addressLine2 = Nothing, _addressCity = \nBoston\n, _addressState = \nMA\n, _addressZip = \n12345\n, _addressForUser = UserId \njames@example.com\n})\n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n})\n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarland\n, _addressState = \nTX\n, _addressZip = \n8989\n, _addressForUser = UserId \nbetty@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 1, _addressLine1 = \n123 Little Street\n, _addressLine2 = Nothing, _addressCity = \nBoston\n, _addressState = \nMA\n, _addressZip = \n12345\n, _addressForUser = UserId \njames@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarland\n, _addressState = \nTX\n, _addressZip = \n8989\n, _addressForUser = UserId \nbetty@example.com\n})\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Address {_addressId = 1, _addressLine1 = \n123 Little Street\n, _addressLine2 = Nothing, _addressCity = \nBoston\n, _addressState = \nMA\n, _addressZip = \n12345\n, _addressForUser = UserId \njames@example.com\n})\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Address {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n})\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Address {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarland\n, _addressState = \nTX\n, _addressZip = \n8989\n, _addressForUser = UserId \nbetty@example.com\n})\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nJust like with lists we can also use a construct similar to guard to ensure that\nwe only retrieve users and addresses that are related. The \nguard_\n function\ntakes in expression of type \nQExpr s Bool\n which represents a SQL expression\nthat returns a boolean. \nQExpr s Bool\ns support all the common operators we have\non regular \nBool\n, except they're suffixed with a \n.\n. For example, where you'd\nuse \n(\n)\n on two Haskell-level \nBool\ns, we'd use \n(\n.)\n on \nQExpr\n-level\nbools.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersAndRelatedAddresses\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n \nselect\n \n$\n\n    \ndo\n \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n       \nguard_\n \n(\naddress\n \n^.\n \naddressForUserId\n \n==.\n \nuser\n \n^.\n \nuserEmail\n)\n\n       \npure\n \n(\nuser\n,\n \naddress\n)\n\n\n\nmapM_\n \nprint\n \nusersAndRelatedAddresses\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nid\n \nAS\n \nres4\n,\n\n       \nt1\n.\naddress1\n \nAS\n \nres5\n,\n\n       \nt1\n.\naddress2\n \nAS\n \nres6\n,\n\n       \nt1\n.\ncity\n \nAS\n \nres7\n,\n\n       \nt1\n.\nstate\n \nAS\n \nres8\n,\n\n       \nt1\n.\nzip\n \nAS\n \nres9\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres10\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \naddresses\n \nAS\n \nt1\n\n\nWHERE\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = 1, _addressLine1 = \n123 Little Street\n, _addressLine2 = Nothing, _addressCity = \nBoston\n, _addressState = \nMA\n, _addressZip = \n12345\n, _addressForUser = UserId \njames@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarland\n, _addressState = \nTX\n, _addressZip = \n8989\n, _addressForUser = UserId \nbetty@example.com\n})\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOf course this is kind of messy because it involves manually matching the\nprimary key of \nUser\n with the reference in \nAddress\n. Alternatively, we can use\nthe \nreferences_\n predicate to have beam automatically generate a \nQExpr\n\nexpression that can match primary keys together.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersAndRelatedAddressesUsingReferences\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n \nselect\n \n$\n\n    \ndo\n \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n\n       \nguard_\n \n(\n_addressForUser\n \naddress\n \n`\nreferences_\n`\n \nuser\n)\n\n       \npure\n \n(\nuser\n,\n \naddress\n)\n\n\n\nmapM_\n \nprint\n \nusersAndRelatedAddressesUsingReferences\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nid\n \nAS\n \nres4\n,\n\n       \nt1\n.\naddress1\n \nAS\n \nres5\n,\n\n       \nt1\n.\naddress2\n \nAS\n \nres6\n,\n\n       \nt1\n.\ncity\n \nAS\n \nres7\n,\n\n       \nt1\n.\nstate\n \nAS\n \nres8\n,\n\n       \nt1\n.\nzip\n \nAS\n \nres9\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres10\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \naddresses\n \nAS\n \nt1\n\n\nWHERE\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = 1, _addressLine1 = \n123 Little Street\n, _addressLine2 = Nothing, _addressCity = \nBoston\n, _addressState = \nMA\n, _addressZip = \n12345\n, _addressForUser = UserId \njames@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarland\n, _addressState = \nTX\n, _addressZip = \n8989\n, _addressForUser = UserId \nbetty@example.com\n})\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou may have noticed that the joins up until now did not include a SQL \nON\n\nclause. Instead we joined the tables together, and then used the \nWHERE\n clause\nto filter out results we don't want. If you'd like to use the \nON\n clause to\nmake the SQL clearer or save a line in your code, beam offers the \nrelated_\n\ncombinator to pull related tables directly into the query monad.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersAndRelatedAddressesUsingRelated\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n \nselect\n \n$\n\n    \ndo\n \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n       \nuser\n \n-\n \nrelated_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n \n(\n_addressForUser\n \naddress\n)\n\n       \npure\n \n(\nuser\n,\n \naddress\n)\n\n\n\nmapM_\n \nprint\n \nusersAndRelatedAddressesUsingRelated\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt1\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt1\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt1\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt0\n.\nid\n \nAS\n \nres4\n,\n\n       \nt0\n.\naddress1\n \nAS\n \nres5\n,\n\n       \nt0\n.\naddress2\n \nAS\n \nres6\n,\n\n       \nt0\n.\ncity\n \nAS\n \nres7\n,\n\n       \nt0\n.\nstate\n \nAS\n \nres8\n,\n\n       \nt0\n.\nzip\n \nAS\n \nres9\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres10\n\n\nFROM\n \naddresses\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \ncart_users\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nfor_user__email\n)\n=\n(\nt1\n.\nemail\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = 1, _addressLine1 = \n123 Little Street\n, _addressLine2 = Nothing, _addressCity = \nBoston\n, _addressState = \nMA\n, _addressZip = \n12345\n, _addressForUser = UserId \njames@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n})\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarland\n, _addressState = \nTX\n, _addressZip = \n8989\n, _addressForUser = UserId \nbetty@example.com\n})\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can also query the addresses for a particular user given a \nUserId\n.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- This is a contrived example to show how we can use an arbitrary UserId to fetch a particular user.\n\n\n-- We don\nt always have access to the full \nUser\n lying around. For example we may be in a function that\n\n\n-- only accepts \nUserId\ns.\n\n\n\nlet\n \nbettyId\n \n=\n \nUserId\n \nbetty@example.com\n \n::\n \nUserId\n\n\n\nbettysAddresses\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n \nselect\n \n$\n\n    \ndo\n \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n       \nguard_\n \n(\n_addressForUser\n \naddress\n \n==.\n \nval_\n \nbettyId\n)\n\n       \npure\n \naddress\n\n\n\nmapM_\n \nprint\n \nbettysAddresses\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n\n       \nt0\n.\naddress1\n \nAS\n \nres1\n,\n\n       \nt0\n.\naddress2\n \nAS\n \nres2\n,\n\n       \nt0\n.\ncity\n \nAS\n \nres3\n,\n\n       \nt0\n.\nstate\n \nAS\n \nres4\n,\n\n       \nt0\n.\nzip\n \nAS\n \nres5\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres6\n\n\nFROM\n \naddresses\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nfor_user__email\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLText \nbetty@example.com\n]\n\n\n\n\n        \n\n    \n        \n\n            \nAddress {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n}\nAddress {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarland\n, _addressState = \nTX\n, _addressZip = \n8989\n, _addressForUser = UserId \nbetty@example.com\n}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\nMore complicated joins are also supported. See the section\non \nrelationships\n\n\n\n\nUpdates and deletions\n\n\nSo far we've only seen how to insert data and query it. There are two other SQL\noperations that we have not covered: updates and deletions. Beam has full\nsupport for these manipulations as well.\n\n\nUpdates\n\n\nLike \nINSERT\n and \nSELECT\n, to run an \nUPDATE\n command, we use the \nrunUpdate\n\nfunction, with a value of \nSqlUpdate\n.\n\n\nThe \nsave\n function constructs a value of \nSqlUpdate\n given a full record. It\nwill generate an \nUPDATE\n that will set every field (except for the primary key\nfields) for the row that completely matches the primary key.\n\n\nLet's first look at updating passwords given a \nUser\n. For this we can use the\n\nsaveTo\n function. Suppose James wants to change his password to the md5 hash of\n\"supersecure\", which is \n52a516ca6df436828d9c0d26e31ef704\n. We have a \nUser\n\nobject representing James so we can simply call \nsaveTo\n on the update value to\nupdate the corresponding record in the database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n[\njames\n]\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \ndo\n \nrunUpdate\n \n$\n\n         \nsave\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n \n(\njames\n \n{\n \n_userPassword\n \n=\n \n52a516ca6df436828d9c0d26e31ef704\n \n})\n\n\n       \nrunSelectReturningList\n \n$\n\n         \nlookup_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n \n(\nUserId\n \njames@example.com\n)\n\n\n\nputStrLn\n \n(\nJames\ns new password is \n \n++\n \nshow\n \n(\njames\n \n^.\n \nuserPassword\n))\n\n\n\n\n        \n\n    \n        \n\n            \nUPDATE\n \ncart_users\n\n\nSET\n \nfirst_name\n=?\n,\n\n    \nlast_name\n=?\n,\n\n    \npassword\n=?\n\n\nWHERE\n \n(\n?\n)\n=\n(\nemail\n);\n\n\n\n-- With values: [SQLText \nJames\n,SQLText \nSmith\n,SQLText \n52a516ca6df436828d9c0d26e31ef704\n,SQLText \njames@example.com\n]\n\n\n\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nemail\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLText \njames@example.com\n]\n\n\n\n\n        \n\n    \n        \n\n            \nJames\ns new password is \n52a516ca6df436828d9c0d26e31ef704\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\nlookup_\n (defined in \nDatabase.Beam.Query\n) can be used to easily lookup a\nsingle entity given a table entity in a database and a primary key.\n\n\n\n\nThis works great, but \nsave\n requires that we have the whole \nUser\n object at\nour disposal. Additionally, you'll notice that it causes every field to be set\nin the \nUPDATE\n query. Typically, this doesn't matter, but sometimes we'd like\nto update fewer fields, multiple rows, or use criteria other than a primary key\nmatch. The \nupdate\n function offers finer-grained control over the command\nsubmitted to the database.\n\n\nTo illustrate use of this function, let's suppose the city of \"Sugarland, TX\"\nwas renamed \"Sugarville, TX\" and had its ZIP code changed to be \"12345\"\ncitywide. The following beam command will update all addresses in the old city\nto use the new name and ZIP code.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naddresses\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \ndo\n \nrunUpdate\n \n$\n\n         \nupdate\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n                \n(\n\\\naddress\n \n-\n \nmconcat\n\n                             \n[\n \naddress\n \n^.\n \naddressCity\n \n-.\n \nval_\n \nSugarville\n\n                             \n,\n \naddress\n \n^.\n \naddressZip\n \n-.\n \nval_\n \n12345\n \n])\n\n                \n(\n\\\naddress\n \n-\n \naddress\n \n^.\n \naddressCity\n \n==.\n \nval_\n \nSugarland\n \n.\n\n                             \naddress\n \n^.\n \naddressState\n \n==.\n \nval_\n \nTX\n)\n\n\n       \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n\n\nmapM_\n \nprint\n \naddresses\n\n\n\n\n        \n\n    \n        \n\n            \nUPDATE\n \naddresses\n\n\nSET\n \ncity\n=?\n,\n\n    \nzip\n=?\n\n\nWHERE\n \n((\ncity\n)\n=\n(\n?\n))\n\n  \nAND\n \n((\nstate\n)\n=\n(\n?\n));\n\n\n\n-- With values: [SQLText \nSugarville\n,SQLText \n12345\n,SQLText \nSugarland\n,SQLText \nTX\n]\n\n\n\nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n\n       \nt0\n.\naddress1\n \nAS\n \nres1\n,\n\n       \nt0\n.\naddress2\n \nAS\n \nres2\n,\n\n       \nt0\n.\ncity\n \nAS\n \nres3\n,\n\n       \nt0\n.\nstate\n \nAS\n \nres4\n,\n\n       \nt0\n.\nzip\n \nAS\n \nres5\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres6\n\n\nFROM\n \naddresses\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nAddress {_addressId = 1, _addressLine1 = \n123 Little Street\n, _addressLine2 = Nothing, _addressCity = \nBoston\n, _addressState = \nMA\n, _addressZip = \n12345\n, _addressForUser = UserId \njames@example.com\n}\nAddress {_addressId = 2, _addressLine1 = \n222 Main Street\n, _addressLine2 = Just \nSte 1\n, _addressCity = \nHouston\n, _addressState = \nTX\n, _addressZip = \n8888\n, _addressForUser = UserId \nbetty@example.com\n}\nAddress {_addressId = 3, _addressLine1 = \n9999 Residence Ave\n, _addressLine2 = Nothing, _addressCity = \nSugarville\n, _addressState = \nTX\n, _addressZip = \n12345\n, _addressForUser = UserId \nbetty@example.com\n}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nDeletions\n\n\nNow suppose that Betty has decided to give up her place in Houston. We can use\n\nrunDelete\n to run a \nDELETE\n command.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n  \nrunDelete\n \n$\n\n  \ndelete\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n         \n(\n\\\naddress\n \n-\n \naddress\n \n^.\n \naddressCity\n \n==.\n \nHouston\n \n.\n\n                      \n_addressForUser\n \naddress\n \n`\nreferences_\n`\n \nbetty\n)\n\n\n\n\n        \n\n    \n        \n\n            \nDELETE\n\n\nFROM\n \naddresses\n\n\nWHERE\n \n((\ncity\n)\n=\n(\n?\n))\n\n  \nAND\n \n((\nfor_user__email\n)\n=\n(\n?\n));\n\n\n\n-- With values: [SQLText \nHouston\n,SQLText \nbetty@example.com\n]\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nConclusion\n\n\nIn this tutorial we created our first beam relationship. We saw how to use the\nmodifications system to override the default names given to database entities.\nWe saw how to use \ntableLenses\n to generate lenses that can be used with any\nlens library. We used the monadic query interface to write queries that used SQL\njoins, and we saw how beam makes it easy to automatically pull related tables\ninto our queries. Finally we introduced the \nrunUpdate\n and \nrunDelete\n\nfunctions and demonstrated several ways to construct UPDATEs and DELETEs.\n\n\nAt this point, we've covered enough of the beam interface to start writing\ninteresting programs. Take some time to explore beam and create your own\ndatabases. Afterwards, read on for the last part of the tutorial.\n\n\n\n\n\n\n\n\n\n\nActually, any \nBeamable\n type can be wholly embedded in another. See the\n   section on models in the \nuser guide\n for more\n   information.\n\n\n\n\n\n\nThe \nmodels guide\n explains the exact mechanisms\n   used", 
            "title": "Part 2"
        }, 
        {
            "location": "/tutorials/tutorial2/#introduction", 
            "text": "In the last part, we created a simple database with one table. We then used the\nbeam interface to add entities into that table and query them. In this tutorial,\nwe'll see how to update and delete rows and how to establish and query relations\nbetween tables.  We'll then delve deeper into queries to see how to create queries that return\nmultiple tables.", 
            "title": "Introduction"
        }, 
        {
            "location": "/tutorials/tutorial2/#adding-a-related-table", 
            "text": "The users in our simple e-commerce application would like to ship orders to\ntheir homes. Let's build an addresses model to allow users to add home addresses\nto their profile. Our table will store United States addresses for now. An\naddress in the United States consists of   an auto-incrementing primary key  one required house number and street line  an optional apartment/suite number line  a required city  a required 2-letter state/territory code  one 5-digit ZIP code   Let's build the  AddressT  table.  AddressT  will follow a similar formula to UserT , but it will contain a reference to a  UserT  table. ]  data   AddressT   f   =   Address \n                 {   _addressId      ::   C   f   Int \n                 ,   _addressLine1   ::   C   f   Text \n                 ,   _addressLine2   ::   C   f   ( Maybe   Text ) \n                 ,   _addressCity    ::   C   f   Text \n                 ,   _addressState   ::   C   f   Text \n                 ,   _addressZip     ::   C   f   Text \n\n                 ,   _addressForUser   ::   PrimaryKey   UserT   f   } \n                   deriving   ( Generic ,   Beamable )  type   Address   =   AddressT   Identity  deriving   instance   Show   ( PrimaryKey   UserT   Identity )  deriving   instance   Show   Address  instance   Table   AddressT   where \n     data   PrimaryKey   AddressT   f   =   AddressId   ( Columnar   f   Int )   deriving   ( Generic ,   Beamable ) \n     primaryKey   =   AddressId   .   _addressId  type   AddressId   =   PrimaryKey   AddressT   Identity   -- For convenience    Tip  Above, we used the  C  constructor instead of  Columnar  for each column. C  is a type synonym for  Columnar , and some find it reduces the syntactic\noverhead of model declaration.   Notice that  _addressForUser  is declared as a  PrimaryKey UserT f . This pulls\nin all the columns necessary for referencing a  UserT   1 . Later, we'll also\nsee how beam can use the field to automatically create JOINs.  Notice also that  _addressId  corresponds to our auto-increminting primary key\nfield. In general, beam doesn't care if the underlying field is assigned\nautomatically, only about the type of final values of that field.  We have all the tables we need now, so let's go ahead and redefine our newest\ndatabase type.  data   ShoppingCartDb   f   =   ShoppingCartDb \n                       {   _shoppingCartUsers           ::   f   ( TableEntity   UserT ) \n                       ,   _shoppingCartUserAddresses   ::   f   ( TableEntity   AddressT )   } \n                         deriving   ( Generic ,   Database   be )", 
            "title": "Adding a related table"
        }, 
        {
            "location": "/tutorials/tutorial2/#modifying-the-default-naming-choices", 
            "text": "In the last part of the tutorial, we let beam decide our field names for us.\nThis is great for simple cases. However, sometimes you want more control over\nthe naming options.   Note  Previous versions of this tutorial had instructions on changing the schema\ntype of particular tables. This functionality has been moved from beam-core  into the  beam-migrate  package. See\nthe  migrations guide  for more information.   The  defaultDbSettings  function generates names using the Haskell record\nselector names  2 . This function returns the  DatabaseType  parameterized over DatabaseEntity , which is a type that contains metadata about entity names. We\ncan  modify  this description after it is created by using the withDbModification  function. You can think of  withDbModification  as applying\na transformation function to each name in our database.  Most of the time  withDbModification  needs a full description of the database\nnames. However, most of the time we only want to rename certain columns or\ntables. We can use the  dbModification  value to construct a modification that\ndoesn't change any names. We can then use the Haskell record update syntax to\nupdate field and column names. This is best illustrated by an example.  Recall our Haskell data types above.  data   UserT   f \n     =   User \n     {   _userEmail       ::   Columnar   f   Text \n     ,   _userFirstName   ::   Columnar   f   Text \n     ,   _userLastName    ::   Columnar   f   Text \n     ,   _userPassword    ::   Columnar   f   Text   } \n     deriving   Generic  data   AddressT   f   =   Address \n                 {   _addressId      ::   C   f   Int \n                 ,   _addressLine1   ::   C   f   Text \n                 ,   _addressLine2   ::   C   f   ( Maybe   Text ) \n                 ,   _addressCity    ::   C   f   Text \n                 ,   _addressState   ::   C   f   Text \n                 ,   _addressZip     ::   C   f   Text \n\n                 ,   _addressForUser   ::   PrimaryKey   UserT   f   } \n                   deriving   Generic  data   ShoppingCartDb   f   =   ShoppingCartDb \n                       {   _shoppingCartUsers           ::   f   ( TableEntity   UserT ) \n                       ,   _shoppingCartUserAddresses   ::   f   ( TableEntity   AddressT )   } \n                         deriving   Generic   Now, let's say we want beam to use the name  addresses  to access the _shoppingCartUserAddresses  table, and the names  address1  and  address2  to\naccess  _addressLine1  and  _addressLine2  respectively.  shoppingCartDb   ::   DatabaseSettings   be   ShoppingCartDb  shoppingCartDb   =   defaultDbSettings   ` withDbModification ` \n                  dbModification   { \n                    _shoppingCartUserAddresses   = \n                      setEntityName   addresses   \n                      modifyTableFields \n                        tableModification   { \n                          _addressLine1   =   fieldNamed   address1 , \n                          _addressLine2   =   fieldNamed   address2 \n                        } \n                  }   Above, we use  dbModification  to produce a default modification, then\nwe override the  _shoppingCartUserAddresses  modification to change\nthe addresses table. We modify the table in two ways. First, we use\nthe  setEntityName  function to change the name of the table. Then, we\nuse  modifyTableFields  to change the names of each field. The\nmodifications can be combined with the semigroup operator  ( ) .  We only override the  _addressLine1  and  _addressLine2  modifications with fieldNamed \"address1\"  and  fieldNamed \"address2\" . Because  tableModification \nproduces a default modification, the other columns are kept at their default\nvalue.   Tip  The  OverloadedStrings  extension lets us avoid typing  fieldNamed . For example, instead of  _addressLine1 = fieldNamed \"address1\"  we could have written  _addressLine1 = \"address1\"   If you didn't need to modify any of the field names, you can omit modifyTableFields . For example, to simply produce a database with\nthe first table named  users  and the second named  user_addresses ,\nyou can do  shoppingCartDb1   ::   DatabaseSettings   be   ShoppingCartDb  shoppingCartDb1   =   defaultDbSettings   ` withDbModification ` \n                   dbModification   { \n                     _shoppingCartUsers   =   setEntityName   users , \n                     _shoppingCartUserAddresses   =   setEntityName   user_addresses \n                   }   For the purposes of this tutorial, we'll stick with  shoppingCartDb .", 
            "title": "Modifying the default naming choices"
        }, 
        {
            "location": "/tutorials/tutorial2/#easier-queries-with-lenses", 
            "text": "In the previous part, we accessed table columns by using regular Haskell record\nsyntax. Sometimes, we would like to use the more convenient lens syntax to\naccess columns. Of course, all of beam's definitions are compatible with the lens  library -- that is to say,  makeLenses  will work just fine. However,\nbeam's motivation is, in part, the avoidance of Template Haskell, and it would\nhardly be worth it if you had to include a Template Haskell splice just to have\nlenses for the models you declared TH free.  In reality, the  lens  library isn't required to construct valid lenses. Lenses\nare a plain old Haskell type.  We can use beam's  Columnar  mechanism to automatically derive lenses. The tableLenses  function produces a table value where each column is given a type LensFor , which is a  newtype  wrapper over a correctly constructed,\npolymorphic Van Laarhoven lens.  We can bring these lenses into scope globally via a global pattern match against tableLenses . For example, to get lenses for each column of the  AddressT  and UserT  table.  -- Add the following to the top of the file, for GHC  8.2  {-#  LANGUAGE ImpredicativeTypes #-}  Address   ( LensFor   addressId )      ( LensFor   addressLine1 ) \n         ( LensFor   addressLine2 )   ( LensFor   addressCity ) \n         ( LensFor   addressState )   ( LensFor   addressZip ) \n         ( UserId   ( LensFor   addressForUserId ))   = \n         tableLenses  User   ( LensFor   userEmail )      ( LensFor   userFirstName ) \n      ( LensFor   userLastName )   ( LensFor   userPassword )   = \n      tableLenses    Note  The  ImpredicativeTypes  language extension is necessary for newer\nGHC to allow the polymorphically typed lenses to be introduced at\nthe top-level. Older GHCs were more lenient.   As in tables, we can generate lenses for databases via the  dbLenses  function.  ShoppingCartDb   ( TableLens   shoppingCartUsers ) \n                ( TableLens   shoppingCartUserAddresses )   = \n                dbLenses   We can ask GHCi for the type of a column lens.  Prelude Database.Beam Database.Beam.Sqlite Data.Text Database.SQLite.Simple  :t addressId\naddressId\n  :: Functor f2 = \n     (Columnar f1 Int -  f2 (Columnar f1 Int))\n     -  AddressT f1 -  f2 (AddressT f1)  This lens is compatible with those of the  lens  library.  And a table lens, for good measure  Prelude Database.Beam Database.Beam.Sqlite Data.Text Database.SQLite.Simple  :t shoppingCartUsers\nshoppingCartUsers\n  :: Functor f1 = \n     (f2 (TableEntity UserT) -  f1 (f2 (TableEntity UserT)))\n     -  ShoppingCartDb f2 -  f1 (ShoppingCartDb f2)   Warning  These lens generating functions are  awesome  but if you use them in a\ncompiled Haskell module (rather than GHC), GHC may give you odd compile\nerrors about ambiguous types. These occur due to what's known as the\nmonomorphism restriction. You can turn it off using the NoMonomorphismRestriction  extension.  The monomorphism restriction is part of the Haskell standard, but there has\nbeen talk about removing it in future language versions. Basically, it\nrequires GHC to not automatically infer polymorphic types for global\ndefinitions. In this case though, polymorphic global definitions is exactly\nwhat we want.", 
            "title": "Easier queries with lenses"
        }, 
        {
            "location": "/tutorials/tutorial2/#working-with-relations", 
            "text": "Now, let's see how we can add related addresses to our database. We begin by\nopening up a connection for us to use in the rest of the tutorial.  First, let's open a new database and create the schema.  $  sqlite3 shoppingcart2.db SQLite version 3.14.0 2016-07-26 15:17:14  Enter  .help  for usage hints.  sqlite  CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));  sqlite  CREATE TABLE addresses ( id INTEGER PRIMARY KEY, address1 VARCHAR NOT NULL, address2 VARCHAR, city VARCHAR NOT NULL, state VARCHAR NOT NULL, zip VARCHAR NOT NULL, for_user__email VARCHAR NOT NULL );   Now, in GHCi, we can use  sqlite-simple  to get a handle to this database.  conn   -   open   shoppingcart2.db   Before we add addresses, we need to add some users that we can reference.  let   james   =   User   james@example.com   James   Smith   b4cc344d25a2efe540adbf2678e2304c \n     betty   =   User   betty@example.com   Betty   Jones   82b054bd83ffad9b6cf8bdb98ce3cc2f \n     sam   =   User   sam@example.com   Sam   Taylor   332532dcfaa1cbf61e2a266bd723612c  runBeamSqliteDebug   putStrLn   conn   $   runInsert   $ \n   insert   ( _shoppingCartUsers   shoppingCartDb )   $ \n   insertValues   [   james ,   betty ,   sam   ]   Now that we have some  User  objects, we can create associated addresses. Notice\nthat above, we used  insertValues  to insert concrete  User  rows. This worked\nbecause we could determine every field of  User  before insertion.  Address es\nhowever have a pesky auto-incrementing primary key field. We can get around this\nby inserting  expressions  instead of  values . We can use  default_  to stand\nfor a value that the database needs to fill in. We can use  val_  to lift a\nliteral value into an expression.  With that in mind, let's give James one address, Betty two addresses, and Sam none.  let   addresses   =   [   Address   default_   ( val_   123 Little Street )   ( val_   Nothing )   ( val_   Boston )   ( val_   MA )   ( val_   12345 )   ( pk   james ) \n                 ,   Address   default_   ( val_   222 Main Street )   ( val_   ( Just   Ste 1 ))   ( val_   Houston )   ( val_   TX )   ( val_   8888 )   ( pk   betty ) \n                 ,   Address   default_   ( val_   9999 Residence Ave )   ( val_   Nothing )   ( val_   Sugarland )   ( val_   TX )   ( val_   8989 )   ( pk   betty )   ]  runBeamSqliteDebug   putStrLn   conn   $   runInsert   $ \n   insert   ( _shoppingCartUserAddresses   shoppingCartDb )   $ \n   insertExpressions   addresses   Notice that we used the  pk  function to assign the reference to the  UserT \ntable.  pk  is a synonym of the  primaryKey  function from the  Table  type\nclass. It should be clear what's going on, but if it's not, let's ask GHCi.  *NextSteps  pk (james :: User)p  UserId  james@example.com   If we query for all the addresses, we'll see that SQLite has assigned them an\nappropriate id.  First, let's use the new lenses we made. Make sure to import  Lens.Micro  or Control.Lens  or whichever (van Laarhoven) lens module you prefer.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             -- import Lens.Micro  -- import Control.Lens  addresses   -   runBeamSqliteDebug   putStrLn   conn   $ \n              runSelectReturningList   $ \n              select   ( all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ))  mapM_   print   addresses  \n\n         \n    \n         \n             SELECT   t0 . id   AS   res0 , \n        t0 . address1   AS   res1 , \n        t0 . address2   AS   res2 , \n        t0 . city   AS   res3 , \n        t0 . state   AS   res4 , \n        t0 . zip   AS   res5 , \n        t0 . for_user__email   AS   res6  FROM   addresses   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             Address {_addressId = 1, _addressLine1 =  123 Little Street , _addressLine2 = Nothing, _addressCity =  Boston , _addressState =  MA , _addressZip =  12345 , _addressForUser = UserId  james@example.com }\nAddress {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com }\nAddress {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarland , _addressState =  TX , _addressZip =  8989 , _addressForUser = UserId  betty@example.com }", 
            "title": "Working with relations"
        }, 
        {
            "location": "/tutorials/tutorial2/#a-note-about-queries", 
            "text": "In the last tutorial, we saw how queries and list supported similar interfaces.\nNamely we saw how  limit_  is like  take ,  offset_  like  drop ,  orderBy  like\nan enhanced  sortBy , and  aggregate  like an enhanced  groupBy . These\ncorresponded to the  LIMIT ,  OFFSET ,  ORDER BY , and  GROUP BY  SQL\nconstructs. The missing SQL operation in this list is the  JOIN , which computes\nthe cartesian product of two tables. In other words, a join between table  A \nand table  B  results in a query of pairs  (x, y)  for every  x  in  A  and\nevery  y  in  B . SQL joins can result in two-way, three-way, four-way, etc.\ncartesian products.  Those familiar with lists in Haskell will note that there is an easy abstraction\nfor taking  n -ary cartesian products over lists: monads.", 
            "title": "A note about queries"
        }, 
        {
            "location": "/tutorials/tutorial2/#the-list-monad", 
            "text": "We can use GHCi to see what we mean.  * NextSteps   do   {   x   -   [ 1 , 2 , 3 ];   y   -   [ 4 , 5 , 6 ];   return   ( x ,   y );   }  [( 1 , 4 ),( 1 , 5 ),( 1 , 6 ),( 2 , 4 ),( 2 , 5 ),( 2 , 6 ),( 3 , 4 ),( 3 , 5 ),( 3 , 6 )]   We get the two-way cartesian product of  [1,2,3]  and  [4,5,6] . We can make the\nproduct arbitrarily long.  * NextSteps   do   {   w   -   [ 10 ,   20 ,   30 ];   x   -   [ 1 , 2 , 3 ];   y   -   [ 4 , 5 , 6 ];   z   -   [ 100 ,   200 ,   1 ];   return   ( x ,   y ,   z ,   w );   }  [( 1 , 4 , 100 , 10 ),( 1 , 4 , 200 , 10 ),( 1 , 4 , 1 , 10 ),( 1 , 5 , 100 , 10 ),( 1 , 5 , 200 , 10 ),( 1 , 5 , 1 , 10 ),   ...   ]   We can also use  guard  from  Control.Monad  to limit the combinations that the\nlist monad puts together. For example, if we had the lists  let   usersList   =   [( 1 ,   james ),   ( 2 ,   betty ),   ( 3 ,   tom )] \n     addressesList   =   [( 1 ,   address1 ),   ( 1 ,   address2 ),   ( 3 ,   address3 )]   We can use  guard  to return all pairs of elements from  usersList  and addressesList  that matched on their first element. For example,  * NextSteps   do   {   user   -   usersList ;   address   -   addressesList ;   guard   ( fst   user   ==   fst   address );   return   ( user ,   address )   }  [(( 1 , james ),( 1 , address1 )),(( 1 , james ),( 1 , address2 )),(( 3 , tom ),( 3 , address3 ))]", 
            "title": "The list monad"
        }, 
        {
            "location": "/tutorials/tutorial2/#the-query-monad", 
            "text": "As I claimed in the first tutorial, queries support many of the same interfaces and operations lists\ndo. It follows that queries also expose a monadic interface.  For example, to retrieve every pair of user and address, we can write the following query:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             allPairs   -   runBeamSqliteDebug   putStrLn   conn   $ \n             runSelectReturningList   $   select   $   do \n               user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n               address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n               return   ( user ,   address )  mapM_   print   allPairs  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . id   AS   res4 , \n        t1 . address1   AS   res5 , \n        t1 . address2   AS   res6 , \n        t1 . city   AS   res7 , \n        t1 . state   AS   res8 , \n        t1 . zip   AS   res9 , \n        t1 . for_user__email   AS   res10  FROM   cart_users   AS   t0  INNER   JOIN   addresses   AS   t1 ;  -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = 1, _addressLine1 =  123 Little Street , _addressLine2 = Nothing, _addressCity =  Boston , _addressState =  MA , _addressZip =  12345 , _addressForUser = UserId  james@example.com })\n(User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com })\n(User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarland , _addressState =  TX , _addressZip =  8989 , _addressForUser = UserId  betty@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 1, _addressLine1 =  123 Little Street , _addressLine2 = Nothing, _addressCity =  Boston , _addressState =  MA , _addressZip =  12345 , _addressForUser = UserId  james@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarland , _addressState =  TX , _addressZip =  8989 , _addressForUser = UserId  betty@example.com })\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Address {_addressId = 1, _addressLine1 =  123 Little Street , _addressLine2 = Nothing, _addressCity =  Boston , _addressState =  MA , _addressZip =  12345 , _addressForUser = UserId  james@example.com })\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Address {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com })\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Address {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarland , _addressState =  TX , _addressZip =  8989 , _addressForUser = UserId  betty@example.com }) \n\n         \n    \n         \n    \n                 \n                      Just like with lists we can also use a construct similar to guard to ensure that\nwe only retrieve users and addresses that are related. The  guard_  function\ntakes in expression of type  QExpr s Bool  which represents a SQL expression\nthat returns a boolean.  QExpr s Bool s support all the common operators we have\non regular  Bool , except they're suffixed with a  . . For example, where you'd\nuse  ( )  on two Haskell-level  Bool s, we'd use  ( .)  on  QExpr -level\nbools.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             usersAndRelatedAddresses   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $   select   $ \n     do   user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n        guard_   ( address   ^.   addressForUserId   ==.   user   ^.   userEmail ) \n        pure   ( user ,   address )  mapM_   print   usersAndRelatedAddresses  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . id   AS   res4 , \n        t1 . address1   AS   res5 , \n        t1 . address2   AS   res6 , \n        t1 . city   AS   res7 , \n        t1 . state   AS   res8 , \n        t1 . zip   AS   res9 , \n        t1 . for_user__email   AS   res10  FROM   cart_users   AS   t0  INNER   JOIN   addresses   AS   t1  WHERE   ( t1 . for_user__email ) = ( t0 . email );  -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = 1, _addressLine1 =  123 Little Street , _addressLine2 = Nothing, _addressCity =  Boston , _addressState =  MA , _addressZip =  12345 , _addressForUser = UserId  james@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarland , _addressState =  TX , _addressZip =  8989 , _addressForUser = UserId  betty@example.com }) \n\n         \n    \n         \n    \n                 \n                      Of course this is kind of messy because it involves manually matching the\nprimary key of  User  with the reference in  Address . Alternatively, we can use\nthe  references_  predicate to have beam automatically generate a  QExpr \nexpression that can match primary keys together.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             usersAndRelatedAddressesUsingReferences   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $   select   $ \n     do   user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n\n        guard_   ( _addressForUser   address   ` references_ `   user ) \n        pure   ( user ,   address )  mapM_   print   usersAndRelatedAddressesUsingReferences  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . id   AS   res4 , \n        t1 . address1   AS   res5 , \n        t1 . address2   AS   res6 , \n        t1 . city   AS   res7 , \n        t1 . state   AS   res8 , \n        t1 . zip   AS   res9 , \n        t1 . for_user__email   AS   res10  FROM   cart_users   AS   t0  INNER   JOIN   addresses   AS   t1  WHERE   ( t1 . for_user__email ) = ( t0 . email );  -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = 1, _addressLine1 =  123 Little Street , _addressLine2 = Nothing, _addressCity =  Boston , _addressState =  MA , _addressZip =  12345 , _addressForUser = UserId  james@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarland , _addressState =  TX , _addressZip =  8989 , _addressForUser = UserId  betty@example.com }) \n\n         \n    \n         \n    \n                 \n                      You may have noticed that the joins up until now did not include a SQL  ON \nclause. Instead we joined the tables together, and then used the  WHERE  clause\nto filter out results we don't want. If you'd like to use the  ON  clause to\nmake the SQL clearer or save a line in your code, beam offers the  related_ \ncombinator to pull related tables directly into the query monad.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             usersAndRelatedAddressesUsingRelated   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $   select   $ \n     do   address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n        user   -   related_   ( shoppingCartDb   ^.   shoppingCartUsers )   ( _addressForUser   address ) \n        pure   ( user ,   address )  mapM_   print   usersAndRelatedAddressesUsingRelated  \n\n         \n    \n         \n             SELECT   t1 . email   AS   res0 , \n        t1 . first_name   AS   res1 , \n        t1 . last_name   AS   res2 , \n        t1 . password   AS   res3 , \n        t0 . id   AS   res4 , \n        t0 . address1   AS   res5 , \n        t0 . address2   AS   res6 , \n        t0 . city   AS   res7 , \n        t0 . state   AS   res8 , \n        t0 . zip   AS   res9 , \n        t0 . for_user__email   AS   res10  FROM   addresses   AS   t0  INNER   JOIN   cart_users   AS   t1   ON   ( t0 . for_user__email ) = ( t1 . email );  -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = 1, _addressLine1 =  123 Little Street , _addressLine2 = Nothing, _addressCity =  Boston , _addressState =  MA , _addressZip =  12345 , _addressForUser = UserId  james@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com })\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarland , _addressState =  TX , _addressZip =  8989 , _addressForUser = UserId  betty@example.com }) \n\n         \n    \n         \n    \n                 \n                      We can also query the addresses for a particular user given a  UserId .  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             -- This is a contrived example to show how we can use an arbitrary UserId to fetch a particular user.  -- We don t always have access to the full  User  lying around. For example we may be in a function that  -- only accepts  UserId s.  let   bettyId   =   UserId   betty@example.com   ::   UserId  bettysAddresses   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $   select   $ \n     do   address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n        guard_   ( _addressForUser   address   ==.   val_   bettyId ) \n        pure   address  mapM_   print   bettysAddresses  \n\n         \n    \n         \n             SELECT   t0 . id   AS   res0 , \n        t0 . address1   AS   res1 , \n        t0 . address2   AS   res2 , \n        t0 . city   AS   res3 , \n        t0 . state   AS   res4 , \n        t0 . zip   AS   res5 , \n        t0 . for_user__email   AS   res6  FROM   addresses   AS   t0  WHERE   ( t0 . for_user__email ) = ( ? );  -- With values: [SQLText  betty@example.com ]  \n\n         \n    \n         \n             Address {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com }\nAddress {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarland , _addressState =  TX , _addressZip =  8989 , _addressForUser = UserId  betty@example.com } \n\n         \n    \n         \n    \n                 \n                       Tip  More complicated joins are also supported. See the section\non  relationships", 
            "title": "The query monad"
        }, 
        {
            "location": "/tutorials/tutorial2/#updates-and-deletions", 
            "text": "So far we've only seen how to insert data and query it. There are two other SQL\noperations that we have not covered: updates and deletions. Beam has full\nsupport for these manipulations as well.", 
            "title": "Updates and deletions"
        }, 
        {
            "location": "/tutorials/tutorial2/#updates", 
            "text": "Like  INSERT  and  SELECT , to run an  UPDATE  command, we use the  runUpdate \nfunction, with a value of  SqlUpdate .  The  save  function constructs a value of  SqlUpdate  given a full record. It\nwill generate an  UPDATE  that will set every field (except for the primary key\nfields) for the row that completely matches the primary key.  Let's first look at updating passwords given a  User . For this we can use the saveTo  function. Suppose James wants to change his password to the md5 hash of\n\"supersecure\", which is  52a516ca6df436828d9c0d26e31ef704 . We have a  User \nobject representing James so we can simply call  saveTo  on the update value to\nupdate the corresponding record in the database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             [ james ]   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     do   runUpdate   $ \n          save   ( shoppingCartDb   ^.   shoppingCartUsers )   ( james   {   _userPassword   =   52a516ca6df436828d9c0d26e31ef704   }) \n\n        runSelectReturningList   $ \n          lookup_   ( shoppingCartDb   ^.   shoppingCartUsers )   ( UserId   james@example.com )  putStrLn   ( James s new password is    ++   show   ( james   ^.   userPassword ))  \n\n         \n    \n         \n             UPDATE   cart_users  SET   first_name =? , \n     last_name =? , \n     password =?  WHERE   ( ? ) = ( email );  -- With values: [SQLText  James ,SQLText  Smith ,SQLText  52a516ca6df436828d9c0d26e31ef704 ,SQLText  james@example.com ]  SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  WHERE   ( t0 . email ) = ( ? );  -- With values: [SQLText  james@example.com ]  \n\n         \n    \n         \n             James s new password is  52a516ca6df436828d9c0d26e31ef704  \n\n         \n    \n         \n    \n                 \n                       Tip  lookup_  (defined in  Database.Beam.Query ) can be used to easily lookup a\nsingle entity given a table entity in a database and a primary key.   This works great, but  save  requires that we have the whole  User  object at\nour disposal. Additionally, you'll notice that it causes every field to be set\nin the  UPDATE  query. Typically, this doesn't matter, but sometimes we'd like\nto update fewer fields, multiple rows, or use criteria other than a primary key\nmatch. The  update  function offers finer-grained control over the command\nsubmitted to the database.  To illustrate use of this function, let's suppose the city of \"Sugarland, TX\"\nwas renamed \"Sugarville, TX\" and had its ZIP code changed to be \"12345\"\ncitywide. The following beam command will update all addresses in the old city\nto use the new name and ZIP code.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             addresses   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     do   runUpdate   $ \n          update   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n                 ( \\ address   -   mconcat \n                              [   address   ^.   addressCity   -.   val_   Sugarville \n                              ,   address   ^.   addressZip   -.   val_   12345   ]) \n                 ( \\ address   -   address   ^.   addressCity   ==.   val_   Sugarland   . \n                              address   ^.   addressState   ==.   val_   TX ) \n\n        runSelectReturningList   $   select   $   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses )  mapM_   print   addresses  \n\n         \n    \n         \n             UPDATE   addresses  SET   city =? , \n     zip =?  WHERE   (( city ) = ( ? )) \n   AND   (( state ) = ( ? ));  -- With values: [SQLText  Sugarville ,SQLText  12345 ,SQLText  Sugarland ,SQLText  TX ]  SELECT   t0 . id   AS   res0 , \n        t0 . address1   AS   res1 , \n        t0 . address2   AS   res2 , \n        t0 . city   AS   res3 , \n        t0 . state   AS   res4 , \n        t0 . zip   AS   res5 , \n        t0 . for_user__email   AS   res6  FROM   addresses   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             Address {_addressId = 1, _addressLine1 =  123 Little Street , _addressLine2 = Nothing, _addressCity =  Boston , _addressState =  MA , _addressZip =  12345 , _addressForUser = UserId  james@example.com }\nAddress {_addressId = 2, _addressLine1 =  222 Main Street , _addressLine2 = Just  Ste 1 , _addressCity =  Houston , _addressState =  TX , _addressZip =  8888 , _addressForUser = UserId  betty@example.com }\nAddress {_addressId = 3, _addressLine1 =  9999 Residence Ave , _addressLine2 = Nothing, _addressCity =  Sugarville , _addressState =  TX , _addressZip =  12345 , _addressForUser = UserId  betty@example.com }", 
            "title": "Updates"
        }, 
        {
            "location": "/tutorials/tutorial2/#deletions", 
            "text": "Now suppose that Betty has decided to give up her place in Houston. We can use runDelete  to run a  DELETE  command.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n    \n         \n            \n         \n             runBeamSqliteDebug   putStrLn   conn   $ \n   runDelete   $ \n   delete   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n          ( \\ address   -   address   ^.   addressCity   ==.   Houston   . \n                       _addressForUser   address   ` references_ `   betty )  \n\n         \n    \n         \n             DELETE  FROM   addresses  WHERE   (( city ) = ( ? )) \n   AND   (( for_user__email ) = ( ? ));  -- With values: [SQLText  Houston ,SQLText  betty@example.com ]", 
            "title": "Deletions"
        }, 
        {
            "location": "/tutorials/tutorial2/#conclusion", 
            "text": "In this tutorial we created our first beam relationship. We saw how to use the\nmodifications system to override the default names given to database entities.\nWe saw how to use  tableLenses  to generate lenses that can be used with any\nlens library. We used the monadic query interface to write queries that used SQL\njoins, and we saw how beam makes it easy to automatically pull related tables\ninto our queries. Finally we introduced the  runUpdate  and  runDelete \nfunctions and demonstrated several ways to construct UPDATEs and DELETEs.  At this point, we've covered enough of the beam interface to start writing\ninteresting programs. Take some time to explore beam and create your own\ndatabases. Afterwards, read on for the last part of the tutorial.      Actually, any  Beamable  type can be wholly embedded in another. See the\n   section on models in the  user guide  for more\n   information.    The  models guide  explains the exact mechanisms\n   used", 
            "title": "Conclusion"
        }, 
        {
            "location": "/tutorials/tutorial3/", 
            "text": "Introduction\n\n\nIn the last part, we extended our shopping cart database to let users add\nmultiple addresses. We saw how to establish one-to-many relations between two\ntables, and how to use the monadic query interface to write SQL JOINs. In this\ninstallment, we'll be adding support for products and orders to our database\nschema. We'll see how to use an intermediary table to create many-to-many\nrelations and how to write LEFT JOINs. Finally, we'll see how to use \nNullable\n\nto create optional foreign key references.\n\n\nCreating tables is easy now\n\n\nLet's create our products table. By now, the pattern for adding a new table to\nthe schema should be pretty familiar, so I'm going to skip the explanation.\n\n\ndata\n \nProductT\n \nf\n \n=\n \nProduct\n\n                \n{\n \n_productId\n          \n::\n \nC\n \nf\n \nInt\n\n                \n,\n \n_productTitle\n       \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_productDescription\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_productPrice\n       \n::\n \nC\n \nf\n \nInt\n \n{- Price in cents -}\n \n}\n\n                  \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\ntype\n \nProduct\n \n=\n \nProductT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nProduct\n\n\n\ninstance\n \nTable\n \nProductT\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nProductT\n \nf\n \n=\n \nProductId\n \n(\nColumnar\n \nf\n \nInt\n)\n\n                               \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n  \nprimaryKey\n \n=\n \nProductId\n \n.\n \n_productId\n\n\n\n\n\n\nFor orders, we want to store an id, date created, and the user who made the\norder. We'd also like to create an optional link to a shipping information\ntable. When the shipping information is created, we'll fill in the shipping\ninformation in the order. In order to create the optional reference, we're going\nto use the \nNullable\n tag modifier to modify the column tag. \nNullable\n will\nturn all fields of type \nx\n into \nMaybe x\n. Note that we could also create this\nrelation by installing a primary key on the shipping info table, and this is\narguably the better option. However, we'll go with a nullable foreign key here\nto show the full breadth of beam's features, and because this sort of relation\nexists in many existing databases.\n\n\nimport\n \nData.Time\n\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nAddressT\n \nIdentity\n)\n\n\n\ndata\n \nOrderT\n \nf\n \n=\n \nOrder\n\n              \n{\n \n_orderId\n      \n::\n \nColumnar\n \nf\n \nInt\n\n              \n,\n \n_orderDate\n    \n::\n \nColumnar\n \nf\n \nLocalTime\n\n              \n,\n \n_orderForUser\n \n::\n \nPrimaryKey\n \nUserT\n \nf\n\n              \n,\n \n_orderShipToAddress\n \n::\n \nPrimaryKey\n \nAddressT\n \nf\n\n              \n,\n \n_orderShippingInfo\n \n::\n \nPrimaryKey\n \nShippingInfoT\n \n(\nNullable\n \nf\n)\n \n}\n\n                \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\ntype\n \nOrder\n \n=\n \nOrderT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nOrder\n\n\n\ninstance\n \nTable\n \nOrderT\n \nwhere\n\n    \ndata\n \nPrimaryKey\n \nOrderT\n \nf\n \n=\n \nOrderId\n \n(\nColumnar\n \nf\n \nInt\n)\n\n                               \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n    \nprimaryKey\n \n=\n \nOrderId\n \n.\n \n_orderId\n\n\n\ndata\n \nShippingCarrier\n \n=\n \nUSPS\n \n|\n \nFedEx\n \n|\n \nUPS\n \n|\n \nDHL\n\n                       \nderiving\n \n(\nShow\n,\n \nRead\n,\n \nEq\n,\n \nOrd\n,\n \nEnum\n)\n\n\n\ndata\n \nShippingInfoT\n \nf\n \n=\n \nShippingInfo\n\n                     \n{\n \n_shippingInfoId\n             \n::\n \nColumnar\n \nf\n \nInt\n\n                     \n,\n \n_shippingInfoCarrier\n        \n::\n \nColumnar\n \nf\n \nShippingCarrier\n\n                     \n,\n \n_shippingInfoTrackingNumber\n \n::\n \nColumnar\n \nf\n \nText\n \n}\n\n                       \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\ntype\n \nShippingInfo\n \n=\n \nShippingInfoT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nShippingInfo\n\n\n\ninstance\n \nTable\n \nShippingInfoT\n \nwhere\n\n    \ndata\n \nPrimaryKey\n \nShippingInfoT\n \nf\n \n=\n \nShippingInfoId\n \n(\nColumnar\n \nf\n \nInt\n)\n\n                                      \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n    \nprimaryKey\n \n=\n \nShippingInfoId\n \n.\n \n_shippingInfoId\n\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nShippingInfoT\n \n(\nNullable\n \nIdentity\n))\n\n\n\n\n\n\nIn the above example, we show how to use a custom data type as a beam column.\nRecall that beam lets you store any Haskell type in a \nColumnar\n. However, at\nsome point, we will need to demonstrate to SQLite how to store values of type\n\nShippingCarrier\n. We will come back to this later.\n\n\nWe would also like to be able to associate a list of products with each order as\nline items. To do this we will create a table with two foreign keys. This table\nwill establish a many-to-many relationship between orders and products.\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nOrderT\n \nIdentity\n)\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nProductT\n \nIdentity\n)\n\n\n\ndata\n \nLineItemT\n \nf\n \n=\n \nLineItem\n\n                 \n{\n \n_lineItemInOrder\n    \n::\n \nPrimaryKey\n \nOrderT\n \nf\n\n                 \n,\n \n_lineItemForProduct\n \n::\n \nPrimaryKey\n \nProductT\n \nf\n\n                 \n,\n \n_lineItemQuantity\n   \n::\n \nColumnar\n \nf\n \nInt\n \n}\n\n                   \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\ntype\n \nLineItem\n \n=\n \nLineItemT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nLineItem\n\n\n\ninstance\n \nTable\n \nLineItemT\n \nwhere\n\n    \ndata\n \nPrimaryKey\n \nLineItemT\n \nf\n \n=\n \nLineItemId\n \n(\nPrimaryKey\n \nOrderT\n \nf\n)\n \n(\nPrimaryKey\n \nProductT\n \nf\n)\n\n                                  \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n    \nprimaryKey\n \n=\n \nLineItemId\n \n$\n \n_lineItemInOrder\n \n*\n \n_lineItemForProduct\n\n\n\n\n\n\n\n\nTip\n\n\nWe used the \nApplicative\n instance for \n(-\n) a\n above to write the\n\nprimaryKey\n function. The \nApplicative ((-\n) a)\n instance operates like an\nunwrapper \nReader\n of \na\n. The applicative actions are then functions from\n\na -\n x\n that inject values from the \na\n into the applicative bind.\n\n\n\n\nNow we'll add all these tables to our database.\n\n\n-- Some convenience lenses\n\n\n\nLineItem\n \n_\n \n_\n \n(\nLensFor\n \nlineItemQuantity\n)\n \n=\n \ntableLenses\n\n\nProduct\n \n(\nLensFor\n \nproductId\n)\n \n(\nLensFor\n \nproductTitle\n)\n \n(\nLensFor\n \nproductDescription\n)\n \n(\nLensFor\n \nproductPrice\n)\n \n=\n \ntableLenses\n\n\n\ndata\n \nShoppingCartDb\n \nf\n \n=\n \nShoppingCartDb\n\n                      \n{\n \n_shoppingCartUsers\n         \n::\n \nf\n \n(\nTableEntity\n \nUserT\n)\n\n                      \n,\n \n_shoppingCartUserAddresses\n \n::\n \nf\n \n(\nTableEntity\n \nAddressT\n)\n\n                      \n,\n \n_shoppingCartProducts\n      \n::\n \nf\n \n(\nTableEntity\n \nProductT\n)\n\n                      \n,\n \n_shoppingCartOrders\n        \n::\n \nf\n \n(\nTableEntity\n \nOrderT\n)\n\n                      \n,\n \n_shoppingCartShippingInfos\n \n::\n \nf\n \n(\nTableEntity\n \nShippingInfoT\n)\n\n                      \n,\n \n_shoppingCartLineItems\n     \n::\n \nf\n \n(\nTableEntity\n \nLineItemT\n)\n \n}\n\n                        \nderiving\n \n(\nGeneric\n,\n \nDatabase\n \nbe\n)\n\n\n\nShoppingCartDb\n \n(\nTableLens\n \nshoppingCartUsers\n)\n \n(\nTableLens\n \nshoppingCartUserAddresses\n)\n\n               \n(\nTableLens\n \nshoppingCartProducts\n)\n \n(\nTableLens\n \nshoppingCartOrders\n)\n\n               \n(\nTableLens\n \nshoppingCartShippingInfos\n)\n \n(\nTableLens\n \nshoppingCartLineItems\n)\n \n=\n \ndbLenses\n\n\n\nshoppingCartDb\n \n::\n \nDatabaseSettings\n \nbe\n \nShoppingCartDb\n\n\nshoppingCartDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n                 \ndbModification\n \n{\n\n                   \n_shoppingCartUserAddresses\n \n=\n\n                     \nsetEntityName\n \naddresses\n \n\n                     \nmodifyTableFields\n \ntableModification\n \n{\n\n                       \n_addressLine1\n \n=\n \naddress1\n,\n\n                       \n_addressLine2\n \n=\n \naddress2\n\n                     \n},\n\n                   \n_shoppingCartProducts\n \n=\n \nsetEntityName\n \nproducts\n,\n\n                   \n_shoppingCartOrders\n \n=\n \nsetEntityName\n \norders\n \n\n                                         \nmodifyTableFields\n \ntableModification\n \n{\n\n                                           \n_orderShippingInfo\n \n=\n \nShippingInfoId\n \nshipping_info__id\n\n                                         \n},\n\n                   \n_shoppingCartShippingInfos\n \n=\n \nsetEntityName\n \nshipping_info\n \n\n                                                \nmodifyTableFields\n \ntableModification\n \n{\n\n                                                  \n_shippingInfoId\n \n=\n \nid\n,\n\n                                                  \n_shippingInfoCarrier\n \n=\n \ncarrier\n,\n\n                                                  \n_shippingInfoTrackingNumber\n \n=\n \ntracking_number\n\n                                                \n},\n\n                   \n_shoppingCartLineItems\n \n=\n \nsetEntityName\n \nline_items\n\n                 \n}\n\n\n\n\n\n\nFixtures\n\n\nLet's put some sample data into a new database.\n\n\nconn\n \n-\n \nopen\n \nshoppingcart3.db\n\n\n\nexecute_\n \nconn\n \nCREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));\n\n\nexecute_\n \nconn\n \nCREATE TABLE addresses ( id INTEGER PRIMARY KEY AUTOINCREMENT, address1 VARCHAR NOT NULL, address2 VARCHAR, city VARCHAR NOT NULL, state VARCHAR NOT NULL, zip VARCHAR NOT NULL, for_user__email VARCHAR NOT NULL );\n\n\nexecute_\n \nconn\n \nCREATE TABLE products ( id INTEGER PRIMARY KEY AUTOINCREMENT, title VARCHAR NOT NULL, description VARCHAR NOT NULL, price INT NOT NULL );\n\n\nexecute_\n \nconn\n \nCREATE TABLE orders ( id INTEGER PRIMARY KEY AUTOINCREMENT, date TIMESTAMP NOT NULL, for_user__email VARCHAR NOT NULL, ship_to_address__id INT NOT NULL, shipping_info__id INT);\n\n\nexecute_\n \nconn\n \nCREATE TABLE shipping_info ( id INTEGER PRIMARY KEY AUTOINCREMENT, carrier VARCHAR NOT NULL, tracking_number VARCHAR NOT NULL);\n\n\nexecute_\n \nconn\n \nCREATE TABLE line_items (item_in_order__id INTEGER NOT NULL, item_for_product__id INTEGER NOT NULL, item_quantity INTEGER NOT NULL)\n\n\n\n\n\n\nLet's put some sample data into our database. Below, we will use the\n\nbeam-sqlite\n functions \ninsertReturning\n and \nrunInsertReturningList\n to insert\nrows \nand\n retrieve the inserted rows from the database. This will let us see\nwhat values the auto-incremented \nid\n columns took on, which will allow us to\ncreate references to these inserted rows.\n\n\nlet\n \nusers\n@\n[\njames\n,\n \nbetty\n,\n \nsam\n]\n \n=\n\n          \n[\n \nUser\n \njames@example.com\n \nJames\n \nSmith\n  \nb4cc344d25a2efe540adbf2678e2304c\n \n{- james -}\n\n          \n,\n \nUser\n \nbetty@example.com\n \nBetty\n \nJones\n  \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n \n{- betty -}\n\n          \n,\n \nUser\n \nsam@example.com\n   \nSam\n   \nTaylor\n \n332532dcfaa1cbf61e2a266bd723612c\n \n{- sam -}\n \n]\n\n    \naddresses\n \n=\n \n[\n \nAddress\n \ndefault_\n \n(\nval_\n \n123 Little Street\n)\n \n(\nval_\n \nNothing\n)\n \n(\nval_\n \nBoston\n)\n \n(\nval_\n \nMA\n)\n \n(\nval_\n \n12345\n)\n \n(\npk\n \njames\n)\n\n                \n,\n \nAddress\n \ndefault_\n \n(\nval_\n \n222 Main Street\n)\n \n(\nval_\n \n(\nJust\n \nSte 1\n))\n \n(\nval_\n \nHouston\n)\n \n(\nval_\n \nTX\n)\n \n(\nval_\n \n8888\n)\n \n(\npk\n \nbetty\n)\n\n                \n,\n \nAddress\n \ndefault_\n \n(\nval_\n \n9999 Residence Ave\n)\n \n(\nval_\n \nNothing\n)\n \n(\nval_\n \nSugarland\n)\n \n(\nval_\n \nTX\n)\n \n(\nval_\n \n8989\n)\n \n(\npk\n \nbetty\n)\n \n]\n\n\n    \nproducts\n \n=\n \n[\n \nProduct\n \ndefault_\n \n(\nval_\n \nRed Ball\n)\n \n(\nval_\n \nA bright red, very spherical ball\n)\n \n(\nval_\n \n1000\n)\n\n               \n,\n \nProduct\n \ndefault_\n \n(\nval_\n \nMath Textbook\n)\n \n(\nval_\n \nContains a lot of important math theorems and formulae\n)\n \n(\nval_\n \n2500\n)\n\n               \n,\n \nProduct\n \ndefault_\n \n(\nval_\n \nIntro to Haskell\n)\n \n(\nval_\n \nLearn the best programming language in the world\n)\n \n(\nval_\n \n3000\n)\n\n               \n,\n \nProduct\n \ndefault_\n \n(\nval_\n \nSuitcase\n)\n \nA hard durable suitcase\n \n15000\n \n]\n\n\n\n(\njamesAddress1\n,\n \nbettyAddress1\n,\n \nbettyAddress2\n,\n \nredBall\n,\n \nmathTextbook\n,\n \nintroToHaskell\n,\n \nsuitcase\n)\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n    \nrunInsert\n \n$\n \ninsert\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n \n$\n\n                \ninsertValues\n \nusers\n\n\n    \n[\njamesAddress1\n,\n \nbettyAddress1\n,\n \nbettyAddress2\n]\n \n-\n\n      \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n \n$\n \ninsertExpressions\n \naddresses\n\n\n    \n[\nredBall\n,\n \nmathTextbook\n,\n \nintroToHaskell\n,\n \nsuitcase\n]\n \n-\n\n      \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartProducts\n)\n \n$\n \ninsertExpressions\n \nproducts\n\n\n    \npure\n \n(\n \njamesAddress1\n,\n \nbettyAddress1\n,\n \nbettyAddress2\n,\n \nredBall\n,\n \nmathTextbook\n,\n \nintroToHaskell\n,\n \nsuitcase\n \n)\n\n\n\n\n\n\nNow, if we take a look at one of the returned addresses, like\n\njamesAddress1\n, we see it has had the \ndefault_\n values assigned\ncorrectly.\n\n\nPrelude\n \nDatabase\n.\nBeam\n \nDatabase\n.\nBeam\n.\nSqlite\n \nData\n.\nTime\n \nDatabase\n.\nSQLite\n.\nSimple\n \nData\n.\nText\n \nLens\n.\nMicro\n \njamesAddress1\n\n\nAddress\n \n{\n_addressId\n \n=\n \n1\n,\n \n_addressLine1\n \n=\n \n123 Little Street\n,\n \n_addressLine2\n \n=\n \nNothing\n,\n \n_addressCity\n \n=\n \nBoston\n,\n \n_addressState\n \n=\n \nMA\n,\n \n_addressZip\n \n=\n \n12345\n,\n \n_addressForUser\n \n=\n \nUserId\n \njames@example.com\n}\n\n\n\n\n\n\nMarshalling a custom type\n\n\nNow we can insert shipping information. Of course, the shipping information\ncontains the \nShippingCarrier\n enumeration.\n\n\nbettyShippingInfo\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n    \n[\nbettyShippingInfo\n]\n \n-\n\n      \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartShippingInfos\n)\n \n$\n\n      \ninsertExpressions\n \n[\n \nShippingInfo\n \ndefault_\n \n(\nval_\n \nUSPS\n)\n \n(\nval_\n \n12345790ABCDEFGHI\n)\n \n]\n\n    \npure\n \nbettyShippingInfo\n\n\n\n\n\n\nIf you run this, you'll get an error from GHCi.\n\n\n```\n:845:7: error:\n    \u2022 No instance for (FromBackendRow Sqlite ShippingCarrier)\n        arising from a use of \u2018runInsertReturningList\u2019\n    \u2022 In a stmt of a 'do' block:\n        [bettyShippingInfo] \n- runInsertReturningList\n                                 $ insertReturning (shoppingCartDb ^. shoppingCartShippingInfos)\n                                     $ insertExpressions\n                                         [ShippingInfo\n                                            default_ (val_ USPS) (val_ \"12345790ABCDEFGHI\")]\n...\n\n\n:847:50: error:\n    \u2022 No instance for (Database.Beam.Backend.SQL.SQL92.HasSqlValueSyntax\n                         Database.Beam.Sqlite.Syntax.SqliteValueSyntax ShippingCarrier)\n\n\nThese\n \nerrors\n \nare\n \nbecause\n \nthere\ns no way to express a `ShippingCarrier` in the\n\n\nbackend\n \nsyntax\n.\n \nWe\n \ncan\n \nfix\n \nthis\n \nby\n \nwriting\n \ninstances\n \nfor\n \nbeam\n.\n \nWe\n \ncan\n \nre\n-\nuse\n \nthe\n\n\nfunctionality\n \nwe\n \nalready\n \nhave\n \nfor\n \n`String`\n.\n\n\n\nThe\n \n`HasSqlValueSyntax`\n \nclass\n \ntells\n \nus\n \nhow\n \nto\n \nconvert\n \na\n \nHaskell\n \nvalue\n \ninto\n \na\n\n\ncorresponding\n \nbackend\n \nvalue\n.\n\n\n\n``\n`\nhaskell\n\n\nimport\n \nDatabase.Beam.Backend.SQL\n\n\n\n:\nset\n \n-\nXUndecidableInstances\n\n\n\ninstance\n \nHasSqlValueSyntax\n \nbe\n \nString\n \n=\n \nHasSqlValueSyntax\n \nbe\n \nShippingCarrier\n \nwhere\n\n  \nsqlValueSyntax\n \n=\n \nautoSqlValueSyntax\n\n\n\n\n\n\nautoSqlValueSyntax\n uses the underlying \nShow\n instance to serialize\na type to a string representation.\n\n\nThe \nFromBackendRow\n class tells us how to convert a value from the database\ninto a corresponding Haskell value.\n\n\nimport\n \nqualified\n \nData.Text\n \nas\n \nT\n \n-- for unpack\n\n\n\ninstance\n \nFromBackendRow\n \nSqlite\n \nShippingCarrier\n \nwhere\n\n  \nfromBackendRow\n \n=\n \nread\n \n.\n \nT\n.\nunpack\n \n$\n \nfromBackendRow\n\n\n\n\n\n\nSince, \nautoSqlValueSyntax\n uses the \nShow\n instance, we can simply use the \nRead\n instance.\n\n\nNow, if we try to insert the shipping info again, it works.\n\n\nbettyShippingInfo\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n    \n[\nbettyShippingInfo\n]\n \n-\n\n      \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartShippingInfos\n)\n \n$\n\n      \ninsertExpressions\n \n[\n \nShippingInfo\n \ndefault_\n \n(\nval_\n \nUSPS\n)\n \n(\nval_\n \n12345790ABCDEFGHI\n)\n \n]\n\n    \npure\n \nbettyShippingInfo\n\n\n\n\n\n\nAnd if we look at the value of \nbettyShippingInfo\n, \nShippingCarrier\n has been\nstored correctly.\n\n\n \nbettyShippingInfo\n\n\nShippingInfo\n \n{\n_shippingInfoId\n \n=\n \n1\n,\n \n_shippingInfoCarrier\n \n=\n \nUSPS\n,\n \n_shippingInfoTrackingNumber\n \n=\n \n12345790ABCDEFGHI\n}\n\n\n\n\n\n\nNow, let's insert some orders that just came in. We want to insert\ntransactions with the current database timestamp (i.e.,\n\nCURRENT_TIMESTAMP\n in SQL). We can do this using\n\ninsertExpressions\n. If you run the example below, you'll see the\nresulting rows have a timestamp set by the database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n[\n \njamesOrder1\n,\n \nbettyOrder1\n,\n \njamesOrder2\n \n]\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n    \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n)\n \n$\n\n      \ninsertExpressions\n \n$\n\n      \n[\n \nOrder\n \ndefault_\n \ncurrentTimestamp_\n \n(\nval_\n \n(\npk\n \njames\n))\n \n(\nval_\n \n(\npk\n \njamesAddress1\n))\n \nnothing_\n\n      \n,\n \nOrder\n \ndefault_\n \ncurrentTimestamp_\n \n(\nval_\n \n(\npk\n \nbetty\n))\n \n(\nval_\n \n(\npk\n \nbettyAddress1\n))\n \n(\njust_\n \n(\nval_\n \n(\npk\n \nbettyShippingInfo\n)))\n\n      \n,\n \nOrder\n \ndefault_\n \ncurrentTimestamp_\n \n(\nval_\n \n(\npk\n \njames\n))\n \n(\nval_\n \n(\npk\n \njamesAddress1\n))\n \nnothing_\n \n]\n\n\n\nprint\n \njamesOrder1\n\n\nprint\n \nbettyOrder1\n\n\nprint\n \njamesOrder2\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \norders\n(\ndate\n,\n\n                     \nfor_user__email\n,\n\n                     \nship_to_address__id\n,\n\n                     \nshipping_info__id\n)\n\n\nVALUES\n \n(\nCURRENT_TIMESTAMP\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \nNULL\n);\n\n\n\n-- With values: [SQLText \njames@example.com\n,SQLInteger 1]\n\n\n\nINSERT\n \nINTO\n \norders\n(\ndate\n,\n\n                     \nfor_user__email\n,\n\n                     \nship_to_address__id\n,\n\n                     \nshipping_info__id\n)\n\n\nVALUES\n \n(\nCURRENT_TIMESTAMP\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n);\n\n\n\n-- With values: [SQLText \nbetty@example.com\n,SQLInteger 2,SQLInteger 1]\n\n\n\nINSERT\n \nINTO\n \norders\n(\ndate\n,\n\n                     \nfor_user__email\n,\n\n                     \nship_to_address__id\n,\n\n                     \nshipping_info__id\n)\n\n\nVALUES\n \n(\nCURRENT_TIMESTAMP\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \nNULL\n);\n\n\n\n-- With values: [SQLText \njames@example.com\n,SQLInteger 1]\n\n\n\n\n        \n\n    \n        \n\n            \nOrder {_orderId = 1, _orderDate = 2019-03-19 17:09:19, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}\n\n\nOrder {_orderId = 2, _orderDate = 2019-03-19 17:09:19, _orderForUser = UserId \nbetty@example.com\n, _orderShipToAddress = AddressId 2, _orderShippingInfo = ShippingInfoId (Just 1)}\n\n\nOrder {_orderId = 3, _orderDate = 2019-03-19 17:09:19, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nFinally, let's add some line items\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nlineItems\n \n=\n \n[\n \nLineItem\n \n(\npk\n \njamesOrder1\n)\n \n(\npk\n \nredBall\n)\n \n10\n\n                \n,\n \nLineItem\n \n(\npk\n \njamesOrder1\n)\n \n(\npk\n \nmathTextbook\n)\n \n1\n\n                \n,\n \nLineItem\n \n(\npk\n \njamesOrder1\n)\n \n(\npk\n \nintroToHaskell\n)\n \n4\n\n\n                \n,\n \nLineItem\n \n(\npk\n \nbettyOrder1\n)\n \n(\npk\n \nmathTextbook\n)\n \n3\n\n                \n,\n \nLineItem\n \n(\npk\n \nbettyOrder1\n)\n \n(\npk\n \nintroToHaskell\n)\n \n3\n\n\n                \n,\n \nLineItem\n \n(\npk\n \njamesOrder2\n)\n \n(\npk\n \nmathTextbook\n)\n \n1\n \n]\n\n\n\nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nrunInsert\n \n$\n \ninsert\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartLineItems\n)\n \n$\n\n    \ninsertValues\n \nlineItems\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nline_items\n(\nitem_in_order__id\n,\n\n                         \nitem_for_product__id\n,\n\n                         \nitem_quantity\n)\n\n\nVALUES\n \n(\n?\n,\n\n        \n?\n,\n\n        \n?\n),\n \n(\n?\n,\n\n             \n?\n,\n\n             \n?\n),\n \n(\n?\n,\n\n                  \n?\n,\n\n                  \n?\n),\n \n(\n?\n,\n\n                       \n?\n,\n\n                       \n?\n),\n \n(\n?\n,\n\n                            \n?\n,\n\n                            \n?\n),\n \n(\n?\n,\n\n                                 \n?\n,\n\n                                 \n?\n);\n\n\n\n-- With values: [SQLInteger 1,SQLInteger 1,SQLInteger 10,SQLInteger 1,SQLInteger 2,SQLInteger 1,SQLInteger 1,SQLInteger 3,SQLInteger 4,SQLInteger 2,SQLInteger 2,SQLInteger 3,SQLInteger 2,SQLInteger 3,SQLInteger 3,SQLInteger 3,SQLInteger 2,SQLInteger 1]\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nPhew! Let's write some queries on this data!\n\n\nWould you like some left joins with that?\n\n\nSuppose we want to do some analytics on our users, and so we want to know how many orders each user\nhas made in our system. We can write a query to list every user along with the orders they've\nmade. We can use \nleftJoin_\n to include all users in our result set, even those who have no\norders.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersAndOrders\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n \ndo\n\n      \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n      \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n      \npure\n \n(\nuser\n,\n \norder\n)\n\n\n\nmapM_\n \nprint\n \nusersAndOrders\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nid\n \nAS\n \nres4\n,\n\n       \nt1\n.\ndate\n \nAS\n \nres5\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres6\n,\n\n       \nt1\n.\nship_to_address__id\n \nAS\n \nres7\n,\n\n       \nt1\n.\nshipping_info__id\n \nAS\n \nres8\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Just (Order {_orderId = 1, _orderDate = 2019-03-19 17:09:29, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}))\n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Just (Order {_orderId = 3, _orderDate = 2019-03-19 17:09:29, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}))\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Just (Order {_orderId = 2, _orderDate = 2019-03-19 17:09:29, _orderForUser = UserId \nbetty@example.com\n, _orderShipToAddress = AddressId 2, _orderShippingInfo = ShippingInfoId (Just 1)}))\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Nothing)\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that Sam is included in the result set, even though he doesn't have any\nassociated orders. Instead of a \nJust (Order ..)\n, \nNothing\n is returned\ninstead.\n\n\nNext, perhaps our marketing team wanted to send e-mails out to all users with no\norders. We can use \nisNothing_\n or \nisJust_\n to determine the status if a\nnullable table or \nQExpr s (Maybe x)\n. The following query uses \nisNothing_\n to\nfind users who have no associated orders.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersWithNoOrders\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n \ndo\n\n      \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n      \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n      \nguard_\n \n(\nisNothing_\n \norder\n)\n\n      \npure\n \nuser\n\n\n\nmapM_\n \nprint\n \nusersWithNoOrders\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n\n\nWHERE\n \n(((((\nt1\n.\nid\n)\n \nIS\n \nNULL\n)\n\n         \nAND\n \n((\nt1\n.\ndate\n)\n \nIS\n \nNULL\n))\n\n        \nAND\n \n((\nt1\n.\nfor_user__email\n)\n \nIS\n \nNULL\n))\n\n       \nAND\n \n((\nt1\n.\nship_to_address__id\n)\n \nIS\n \nNULL\n))\n\n  \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNULL\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe see that beam generates a sensible SQL \nSELECT\n and \nWHERE\n clause.\n\n\nWe can also use the \nexists_\n combinator to utilize the SQL \nEXISTS\n clause.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersWithNoOrders\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n \ndo\n\n      \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n      \nguard_\n \n(\nnot_\n \n(\nexists_\n \n(\nfilter_\n \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n)))))\n\n      \npure\n \nuser\n\n\n\nmapM_\n \nprint\n \nusersWithNoOrders\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nWHERE\n \nNOT\n(\nEXISTS\n\n            \n(\nSELECT\n \nsub_t0\n.\nid\n \nAS\n \nres0\n,\n \nsub_t0\n.\ndate\n \nAS\n \nres1\n,\n \nsub_t0\n.\nfor_user__email\n \nAS\n \nres2\n,\n \nsub_t0\n.\nship_to_address__id\n \nAS\n \nres3\n,\n \nsub_t0\n.\nshipping_info__id\n \nAS\n \nres4\n\n             \nFROM\n \norders\n \nAS\n \nsub_t0\n\n             \nWHERE\n \n(\nsub_t0\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)));\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNow suppose we wanted to do some analysis on the orders themselves. To start, we\nwant to get the orders sorted by their portion of revenue. We can use\n\naggregate_\n to list every order and the total amount of all products in that\norder.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nordersWithCostOrdered\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \norderBy_\n \n(\n\\\n(\norder\n,\n \ntotal\n)\n \n-\n \ndesc_\n \ntotal\n)\n \n$\n\n    \naggregate_\n \n(\n\\\n(\norder\n,\n \nlineItem\n,\n \nproduct\n)\n \n-\n\n                   \n(\ngroup_\n \norder\n,\n \nsum_\n \n(\nlineItem\n \n^.\n \nlineItemQuantity\n \n*\n \nproduct\n \n^.\n \nproductPrice\n)))\n \n$\n\n    \ndo\n \nlineItem\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartLineItems\n)\n\n       \norder\n    \n-\n \nrelated_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n)\n \n(\n_lineItemInOrder\n \nlineItem\n)\n\n       \nproduct\n  \n-\n \nrelated_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartProducts\n)\n \n(\n_lineItemForProduct\n \nlineItem\n)\n\n       \npure\n \n(\norder\n,\n \nlineItem\n,\n \nproduct\n)\n\n\n\nmapM_\n \nprint\n \nordersWithCostOrdered\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nid\n \nAS\n \nres0\n,\n\n       \nt1\n.\ndate\n \nAS\n \nres1\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres2\n,\n\n       \nt1\n.\nship_to_address__id\n \nAS\n \nres3\n,\n\n       \nt1\n.\nshipping_info__id\n \nAS\n \nres4\n,\n\n       \nSUM\n((\nt0\n.\nitem_quantity\n)\n \n*\n \n(\nt2\n.\nprice\n))\n \nAS\n \nres5\n\n\nFROM\n \nline_items\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nitem_in_order__id\n)\n=\n(\nt1\n.\nid\n)\n\n\nINNER\n \nJOIN\n \nproducts\n \nAS\n \nt2\n \nON\n \n(\nt0\n.\nitem_for_product__id\n)\n=\n(\nt2\n.\nid\n)\n\n\nGROUP\n \nBY\n \nt1\n.\nid\n,\n\n         \nt1\n.\ndate\n,\n\n         \nt1\n.\nfor_user__email\n,\n\n         \nt1\n.\nship_to_address__id\n,\n\n         \nt1\n.\nshipping_info__id\n\n\nORDER\n \nBY\n \nSUM\n((\nt0\n.\nitem_quantity\n)\n \n*\n \n(\nt2\n.\nprice\n))\n \nDESC\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(Order {_orderId = 1, _orderDate = 2019-03-19 17:09:49, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing},Just 24500)\n(Order {_orderId = 2, _orderDate = 2019-03-19 17:09:49, _orderForUser = UserId \nbetty@example.com\n, _orderShipToAddress = AddressId 2, _orderShippingInfo = ShippingInfoId (Just 1)},Just 16500)\n(Order {_orderId = 3, _orderDate = 2019-03-19 17:09:49, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing},Just 2500)\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can also get the total amount spent by each user, even including users with no orders. Notice\nthat we have to use \nmaybe_\n below in order to handle the fact that some tables have been introduced\ninto our query with a left join. \nmaybe_\n is to \nQExpr\n what \nmaybe\n is to normal Haskell\nvalues. \nmaybe_\n is polymorphic to either \nQExpr\ns or full on tables of \nQExpr\ns. For our purposes,\nthe type of \nmaybe_\n is\n\n\nmaybe_\n \n::\n \nQExpr\n \nbe\n \ns\n \na\n \n-\n \n(\nQExpr\n \nbe\n \ns\n \nb\n \n-\n \nQExpr\n \nbe\n \ns\n \na\n)\n \n-\n \nQExpr\n \nbe\n \ns\n \n(\nMaybe\n \nb\n)\n \n-\n \nQExpr\n \nbe\n \ns\n \na\n\n\n\n\n\n\nWith that in mind, we can write the query to get the total spent by user\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nallUsersAndTotals\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \norderBy_\n \n(\n\\\n(\nuser\n,\n \ntotal\n)\n \n-\n \ndesc_\n \ntotal\n)\n \n$\n\n    \naggregate_\n \n(\n\\\n(\nuser\n,\n \nlineItem\n,\n \nproduct\n)\n \n-\n\n                   \n(\ngroup_\n \nuser\n,\n \nsum_\n \n(\nmaybe_\n \n0\n \nid\n \n(\n_lineItemQuantity\n \nlineItem\n)\n \n*\n \nmaybe_\n \n0\n \nid\n \n(\nproduct\n \n^.\n \nproductPrice\n))))\n \n$\n\n    \ndo\n \nuser\n     \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \norder\n    \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                             \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n       \nlineItem\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartLineItems\n))\n\n                             \n(\n\\\nlineItem\n \n-\n \nmaybe_\n \n(\nval_\n \nFalse\n)\n \n(\n\\\norder\n \n-\n \n_lineItemInOrder\n \nlineItem\n \n`\nreferences_\n`\n \norder\n)\n \norder\n)\n\n       \nproduct\n  \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartProducts\n))\n\n                             \n(\n\\\nproduct\n \n-\n \nmaybe_\n \n(\nval_\n \nFalse\n)\n \n(\n\\\nlineItem\n \n-\n \n_lineItemForProduct\n \nlineItem\n \n`\nreferences_\n`\n \nproduct\n)\n \nlineItem\n)\n\n       \npure\n \n(\nuser\n,\n \nlineItem\n,\n \nproduct\n)\n\n\n\nmapM_\n \nprint\n \nallUsersAndTotals\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nSUM\n((\nCASE\n\n                \nWHEN\n \n(\nt2\n.\nitem_quantity\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt2\n.\nitem_quantity\n\n                \nELSE\n \n?\n\n            \nEND\n)\n \n*\n \n(\nCASE\n\n                        \nWHEN\n \n(\nt3\n.\nprice\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt3\n.\nprice\n\n                        \nELSE\n \n?\n\n                    \nEND\n))\n \nAS\n \nres4\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n\n\nLEFT\n \nJOIN\n \nline_items\n \nAS\n \nt2\n \nON\n \nCASE\n\n                                      \nWHEN\n \n(((((\nt1\n.\nid\n)\n \nIS\n \nNOT\n \nNULL\n)\n\n                                              \nAND\n \n((\nt1\n.\ndate\n)\n \nIS\n \nNOT\n \nNULL\n))\n\n                                             \nAND\n \n((\nt1\n.\nfor_user__email\n)\n \nIS\n \nNOT\n \nNULL\n))\n\n                                            \nAND\n \n((\nt1\n.\nship_to_address__id\n)\n \nIS\n \nNOT\n \nNULL\n))\n\n                                           \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNOT\n \nNULL\n)\n \nTHEN\n \n(\nt2\n.\nitem_in_order__id\n)\n=\n(\nt1\n.\nid\n)\n\n                                      \nELSE\n \n?\n\n                                  \nEND\n\n\nLEFT\n \nJOIN\n \nproducts\n \nAS\n \nt3\n \nON\n \nCASE\n\n                                    \nWHEN\n \n(((\nt2\n.\nitem_in_order__id\n)\n \nIS\n \nNOT\n \nNULL\n)\n\n                                          \nAND\n \n((\nt2\n.\nitem_for_product__id\n)\n \nIS\n \nNOT\n \nNULL\n))\n\n                                         \nAND\n \n((\nt2\n.\nitem_quantity\n)\n \nIS\n \nNOT\n \nNULL\n)\n \nTHEN\n \n(\nt2\n.\nitem_for_product__id\n)\n=\n(\nt3\n.\nid\n)\n\n                                    \nELSE\n \n?\n\n                                \nEND\n\n\nGROUP\n \nBY\n \nt0\n.\nemail\n,\n\n         \nt0\n.\nfirst_name\n,\n\n         \nt0\n.\nlast_name\n,\n\n         \nt0\n.\npassword\n\n\nORDER\n \nBY\n \nSUM\n((\nCASE\n\n                  \nWHEN\n \n(\nt2\n.\nitem_quantity\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt2\n.\nitem_quantity\n\n                  \nELSE\n \n?\n\n              \nEND\n)\n \n*\n \n(\nCASE\n\n                          \nWHEN\n \n(\nt3\n.\nprice\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt3\n.\nprice\n\n                          \nELSE\n \n?\n\n                      \nEND\n))\n \nDESC\n;\n\n\n\n-- With values: [SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Just 16500)\n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Just 0)\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Just 0)\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nTake a couple seconds to examine the SQL generated by this query. Notice how every time we used\n\nmaybe_\n a \nCASE\n statement was emitted. While this provides a good match for Haskell semantics\nwe are used to, it is also not always desireable in practice due to severe performance implications.\n\n\nSome RDBMSs, like Postgres, given such a query will be unable to utilize available indexes\nto perform join operations - this translates to \nextremely\n poor perfomance for even moderately\nsized data.\n\n\nLuckily, Beam also provides an alternate way to phrase things that directly maps to SQL semantics\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nallUsersAndTotals2\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \norderBy_\n \n(\n\\\n(\nuser\n,\n \ntotal\n)\n \n-\n \ndesc_\n \ntotal\n)\n \n$\n\n    \naggregate_\n \n(\n\\\n(\nuser\n,\n \nlineItem\n,\n \nproduct\n)\n \n-\n\n                   \n(\ngroup_\n \nuser\n,\n \nsum_\n \n(\nmaybe_\n \n0\n \nid\n \n(\n_lineItemQuantity\n \nlineItem\n)\n \n*\n \nmaybe_\n \n0\n \nid\n \n(\nproduct\n \n^.\n \nproductPrice\n))))\n \n$\n\n    \ndo\n \nuser\n     \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \norder\n    \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                             \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n       \nlineItem\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartLineItems\n))\n\n                              \n(\n\\\nlineItem\n \n-\n \njust_\n \n(\n_lineItemInOrder\n \nlineItem\n)\n \n==?.\n \npk\n \norder\n)\n\n       \nproduct\n  \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartProducts\n))\n\n                              \n(\n\\\nproduct\n \n-\n \n_lineItemForProduct\n \nlineItem\n \n==?.\n \njust_\n \n(\npk\n \nproduct\n))\n\n       \npure\n \n(\nuser\n,\n \nlineItem\n,\n \nproduct\n)\n\n\n\nmapM_\n \nprint\n \nallUsersAndTotals2\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nSUM\n((\nCASE\n\n                \nWHEN\n \n(\nt2\n.\nitem_quantity\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt2\n.\nitem_quantity\n\n                \nELSE\n \n?\n\n            \nEND\n)\n \n*\n \n(\nCASE\n\n                        \nWHEN\n \n(\nt3\n.\nprice\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt3\n.\nprice\n\n                        \nELSE\n \n?\n\n                    \nEND\n))\n \nAS\n \nres4\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n\n\nLEFT\n \nJOIN\n \nline_items\n \nAS\n \nt2\n \nON\n \n(\nt2\n.\nitem_in_order__id\n)\n=\n(\nt1\n.\nid\n)\n\n\nLEFT\n \nJOIN\n \nproducts\n \nAS\n \nt3\n \nON\n \n(\nt2\n.\nitem_for_product__id\n)\n=\n(\nt3\n.\nid\n)\n\n\nGROUP\n \nBY\n \nt0\n.\nemail\n,\n\n         \nt0\n.\nfirst_name\n,\n\n         \nt0\n.\nlast_name\n,\n\n         \nt0\n.\npassword\n\n\nORDER\n \nBY\n \nSUM\n((\nCASE\n\n                  \nWHEN\n \n(\nt2\n.\nitem_quantity\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt2\n.\nitem_quantity\n\n                  \nELSE\n \n?\n\n              \nEND\n)\n \n*\n \n(\nCASE\n\n                          \nWHEN\n \n(\nt3\n.\nprice\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt3\n.\nprice\n\n                          \nELSE\n \n?\n\n                      \nEND\n))\n \nDESC\n;\n\n\n\n-- With values: [SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Just 27000)\n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Just 16500)\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Just 0)\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice how we managed to eliminate \nmaybe_\n from the join conditions by using the \nSqlBool\n version of\n\nleftJoin_\n, \nleftJoin_'\n together with \njust_\n and the \nSqlBool\n version of the equality operator \n==?.\n.\nCompare the generated SQL with the previous query. You can read more about how Beam handles NULL values\nin the Queries, Relationships section in the User Guide.\n\n\nQueries with nullable foreign keys\n\n\nRecall that our schema contains a nullable foreign key from \nOrderT\n to \nShippingInfoT\n. Above,\nwe've seen how \nleftJoin_\n introduces nullable tables into our queries. Below, we'll see how to use\nnullable primary keys to optionally include information.\n\n\nSuppose we want to find all orders who have not been shipped. We can do this by simply writing a query over the orders.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nallUnshippedOrders\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \nfilter_\n \n(\nisNothing_\n \n.\n \n_orderShippingInfo\n)\n \n$\n\n    \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n)\n\n\n\nmapM_\n \nprint\n \nallUnshippedOrders\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n\n       \nt0\n.\ndate\n \nAS\n \nres1\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres2\n,\n\n       \nt0\n.\nship_to_address__id\n \nAS\n \nres3\n,\n\n       \nt0\n.\nshipping_info__id\n \nAS\n \nres4\n\n\nFROM\n \norders\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nshipping_info__id\n)\n \nIS\n \nNULL\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nOrder {_orderId = 1, _orderDate = 2019-03-19 17:10:10, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}\nOrder {_orderId = 3, _orderDate = 2019-03-19 17:10:10, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nLet's count up all shipped and unshipped orders by user, including users who have no orders.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nshippingInformationByUser\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \naggregate_\n \n(\n\\\n(\nuser\n,\n \norder\n)\n \n-\n\n                   \nlet\n \nShippingInfoId\n \nshippingInfoId\n \n=\n \n_orderShippingInfo\n \norder\n\n                   \nin\n \n(\n \ngroup_\n \nuser\n\n                      \n,\n \nas_\n \n@\nInt\n \n$\n \ncount_\n \n(\nas_\n \n@\n(\nMaybe\n \nInt\n)\n \n(\nmaybe_\n \n(\njust_\n \n1\n)\n \n(\n\\\n_\n \n-\n \nnothing_\n)\n \nshippingInfoId\n))\n\n                      \n,\n \nas_\n \n@\nInt\n \n$\n \ncount_\n \nshippingInfoId\n \n)\n \n)\n \n$\n\n    \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n       \npure\n \n(\nuser\n,\n \norder\n)\n\n\n\nmapM_\n \nprint\n \nshippingInformationByUser\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nCOUNT\n(\nCASE\n\n                 \nWHEN\n \n(\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nNULL\n\n                 \nELSE\n \n?\n\n             \nEND\n)\n \nAS\n \nres4\n,\n\n       \nCOUNT\n(\nt1\n.\nshipping_info__id\n)\n \nAS\n \nres5\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n\n\nGROUP\n \nBY\n \nt0\n.\nemail\n,\n\n         \nt0\n.\nfirst_name\n,\n\n         \nt0\n.\nlast_name\n,\n\n         \nt0\n.\npassword\n;\n\n\n\n-- With values: [SQLInteger 1]\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},0,1)\n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},2,0)\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},1,0)\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nUh-oh! There's an error in the result set! Sam is reported as having one\nunshipped order, instead of zero.\n\n\nHere we hit one of the limitations of beam's mapping to SQL, and really one of\nthe limitations of SQL itself. Namely, the NULL in the result rows for Sam is\nnot distinguished from the NULL in the shipping info key itself. Beam however\ndoes make the distinction.\n\n\nWhen beam deserializes a \nNULL\n in a \nMaybe\n field, the outermost \nMaybe\n is the\none populated with \nNothing\n. Thus it is impossible to retrieve a value like\n\nJust Nothing\n from the database using the default serializers and\ndeserializers. In general, it's best to avoid highly nested \nMaybe\ns in your\nqueries because it makes them more difficult to understand.\n\n\nOne way to work around this issue in the above query is to use subselects.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nshippingInformationByUser\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \ndo\n \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n\n       \n(\nuserEmail\n,\n \nunshippedCount\n)\n \n-\n\n         \naggregate_\n \n(\n\\\n(\nuserEmail\n,\n \norder\n)\n \n-\n \n(\ngroup_\n \nuserEmail\n,\n \ncountAll_\n))\n \n$\n\n         \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n            \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                               \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n \n.\n \nisNothing_\n \n(\n_orderShippingInfo\n \norder\n))\n\n            \npure\n \n(\npk\n \nuser\n,\n \norder\n)\n\n\n       \nguard_\n \n(\nuserEmail\n \n`\nreferences_\n`\n \nuser\n)\n\n\n       \n(\nuserEmail\n,\n \nshippedCount\n)\n \n-\n\n         \naggregate_\n \n(\n\\\n(\nuserEmail\n,\n \norder\n)\n \n-\n \n(\ngroup_\n \nuserEmail\n,\n \ncountAll_\n))\n \n$\n\n         \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n            \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                               \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n \n.\n \nisJust_\n \n(\n_orderShippingInfo\n \norder\n))\n\n            \npure\n \n(\npk\n \nuser\n,\n \norder\n)\n\n       \nguard_\n \n(\nuserEmail\n \n`\nreferences_\n`\n \nuser\n)\n\n\n       \npure\n \n(\nuser\n,\n \nunshippedCount\n,\n \nshippedCount\n)\n\n\n\nmapM_\n \nprint\n \nshippingInformationByUser\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres4\n,\n\n       \nt2\n.\nres1\n \nAS\n \nres5\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n   \nFROM\n \ncart_users\n \nAS\n \nt0\n\n   \nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n((\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n))\n\n   \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNULL\n)\n\n   \nGROUP\n \nBY\n \nt0\n.\nemail\n)\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n   \nFROM\n \ncart_users\n \nAS\n \nt0\n\n   \nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n((\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n))\n\n   \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNOT\n \nNULL\n)\n\n   \nGROUP\n \nBY\n \nt0\n.\nemail\n)\n \nAS\n \nt2\n\n\nWHERE\n \n((\nt1\n.\nres0\n)\n=\n(\nt0\n.\nemail\n))\n\n  \nAND\n \n((\nt2\n.\nres0\n)\n=\n(\nt0\n.\nemail\n));\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},1,1)\n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},2,1)\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},1,1)\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that the \naggregate_\ns embedded in the \nQ\n monad were automatically\nconverted into sub \nSELECT\ns. This is because beam queries are composable -- you\ncan use them wherever they type check and sensible SQL will result. Of course,\nif you want more control, you can also use the \nsubselect_\n combinator to force\ngeneration of a sub \nSELECT\n.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nshippingInformationByUser\n \n-\n\n  \nrunBeamSqliteDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \ndo\n \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n\n       \n(\nuserEmail\n,\n \nunshippedCount\n)\n \n-\n\n         \nsubselect_\n \n$\n\n         \naggregate_\n \n(\n\\\n(\nuserEmail\n,\n \norder\n)\n \n-\n \n(\ngroup_\n \nuserEmail\n,\n \ncountAll_\n))\n \n$\n\n         \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n            \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                               \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n \n.\n \nisNothing_\n \n(\n_orderShippingInfo\n \norder\n))\n\n            \npure\n \n(\npk\n \nuser\n,\n \norder\n)\n\n\n       \nguard_\n \n(\nuserEmail\n \n`\nreferences_\n`\n \nuser\n)\n\n\n       \n(\nuserEmail\n,\n \nshippedCount\n)\n \n-\n\n         \nsubselect_\n \n$\n\n         \naggregate_\n \n(\n\\\n(\nuserEmail\n,\n \norder\n)\n \n-\n \n(\ngroup_\n \nuserEmail\n,\n \ncountAll_\n))\n \n$\n\n         \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n            \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                               \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n \n.\n \nisJust_\n \n(\n_orderShippingInfo\n \norder\n))\n\n            \npure\n \n(\npk\n \nuser\n,\n \norder\n)\n\n       \nguard_\n \n(\nuserEmail\n \n`\nreferences_\n`\n \nuser\n)\n\n\n       \npure\n \n(\nuser\n,\n \nunshippedCount\n,\n \nshippedCount\n)\n\n\n\nmapM_\n \nprint\n \nshippingInformationByUser\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres4\n,\n\n       \nt2\n.\nres1\n \nAS\n \nres5\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n             \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n      \nFROM\n \ncart_users\n \nAS\n \nt0\n\n      \nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n((\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n))\n\n      \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNULL\n)\n\n      \nGROUP\n \nBY\n \nt0\n.\nemail\n)\n \nAS\n \nt0\n)\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n             \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n      \nFROM\n \ncart_users\n \nAS\n \nt0\n\n      \nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n((\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n))\n\n      \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNOT\n \nNULL\n)\n\n      \nGROUP\n \nBY\n \nt0\n.\nemail\n)\n \nAS\n \nt0\n)\n \nAS\n \nt2\n\n\nWHERE\n \n((\nt1\n.\nres0\n)\n=\n(\nt0\n.\nemail\n))\n\n  \nAND\n \n((\nt2\n.\nres0\n)\n=\n(\nt0\n.\nemail\n));\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \nbetty@example.com\n, _userFirstName = \nBetty\n, _userLastName = \nJones\n, _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},1,1)\n(User {_userEmail = \njames@example.com\n, _userFirstName = \nJames\n, _userLastName = \nSmith\n, _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},2,1)\n(User {_userEmail = \nsam@example.com\n, _userFirstName = \nSam\n, _userLastName = \nTaylor\n, _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},1,1)\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nConclusion\n\n\nThis tutorial completes our sequence on creating a shopping cart. Throughout the\ntutorials, we saw how to create tables using regular Haskell data types, how to\nlink those tables up using relations, how to query tables using both the monadic\ninterface and the list-like functions on queries. We saw ha few examples of\nusing beam to generate advanced queries. More information on the Beam API is\nhavailable on \nhackage\n. Happy beaming!\n\n\nBeam is a work in progress. Please submit bugs and patches\non \nGitHub\n.", 
            "title": "Part 3"
        }, 
        {
            "location": "/tutorials/tutorial3/#introduction", 
            "text": "In the last part, we extended our shopping cart database to let users add\nmultiple addresses. We saw how to establish one-to-many relations between two\ntables, and how to use the monadic query interface to write SQL JOINs. In this\ninstallment, we'll be adding support for products and orders to our database\nschema. We'll see how to use an intermediary table to create many-to-many\nrelations and how to write LEFT JOINs. Finally, we'll see how to use  Nullable \nto create optional foreign key references.", 
            "title": "Introduction"
        }, 
        {
            "location": "/tutorials/tutorial3/#creating-tables-is-easy-now", 
            "text": "Let's create our products table. By now, the pattern for adding a new table to\nthe schema should be pretty familiar, so I'm going to skip the explanation.  data   ProductT   f   =   Product \n                 {   _productId            ::   C   f   Int \n                 ,   _productTitle         ::   C   f   Text \n                 ,   _productDescription   ::   C   f   Text \n                 ,   _productPrice         ::   C   f   Int   {- Price in cents -}   } \n                   deriving   ( Generic ,   Beamable )  type   Product   =   ProductT   Identity  deriving   instance   Show   Product  instance   Table   ProductT   where \n   data   PrimaryKey   ProductT   f   =   ProductId   ( Columnar   f   Int ) \n                                deriving   ( Generic ,   Beamable ) \n   primaryKey   =   ProductId   .   _productId   For orders, we want to store an id, date created, and the user who made the\norder. We'd also like to create an optional link to a shipping information\ntable. When the shipping information is created, we'll fill in the shipping\ninformation in the order. In order to create the optional reference, we're going\nto use the  Nullable  tag modifier to modify the column tag.  Nullable  will\nturn all fields of type  x  into  Maybe x . Note that we could also create this\nrelation by installing a primary key on the shipping info table, and this is\narguably the better option. However, we'll go with a nullable foreign key here\nto show the full breadth of beam's features, and because this sort of relation\nexists in many existing databases.  import   Data.Time  deriving   instance   Show   ( PrimaryKey   AddressT   Identity )  data   OrderT   f   =   Order \n               {   _orderId        ::   Columnar   f   Int \n               ,   _orderDate      ::   Columnar   f   LocalTime \n               ,   _orderForUser   ::   PrimaryKey   UserT   f \n               ,   _orderShipToAddress   ::   PrimaryKey   AddressT   f \n               ,   _orderShippingInfo   ::   PrimaryKey   ShippingInfoT   ( Nullable   f )   } \n                 deriving   ( Generic ,   Beamable )  type   Order   =   OrderT   Identity  deriving   instance   Show   Order  instance   Table   OrderT   where \n     data   PrimaryKey   OrderT   f   =   OrderId   ( Columnar   f   Int ) \n                                deriving   ( Generic ,   Beamable ) \n     primaryKey   =   OrderId   .   _orderId  data   ShippingCarrier   =   USPS   |   FedEx   |   UPS   |   DHL \n                        deriving   ( Show ,   Read ,   Eq ,   Ord ,   Enum )  data   ShippingInfoT   f   =   ShippingInfo \n                      {   _shippingInfoId               ::   Columnar   f   Int \n                      ,   _shippingInfoCarrier          ::   Columnar   f   ShippingCarrier \n                      ,   _shippingInfoTrackingNumber   ::   Columnar   f   Text   } \n                        deriving   ( Generic ,   Beamable )  type   ShippingInfo   =   ShippingInfoT   Identity  deriving   instance   Show   ShippingInfo  instance   Table   ShippingInfoT   where \n     data   PrimaryKey   ShippingInfoT   f   =   ShippingInfoId   ( Columnar   f   Int ) \n                                       deriving   ( Generic ,   Beamable ) \n     primaryKey   =   ShippingInfoId   .   _shippingInfoId  deriving   instance   Show   ( PrimaryKey   ShippingInfoT   ( Nullable   Identity ))   In the above example, we show how to use a custom data type as a beam column.\nRecall that beam lets you store any Haskell type in a  Columnar . However, at\nsome point, we will need to demonstrate to SQLite how to store values of type ShippingCarrier . We will come back to this later.  We would also like to be able to associate a list of products with each order as\nline items. To do this we will create a table with two foreign keys. This table\nwill establish a many-to-many relationship between orders and products.  deriving   instance   Show   ( PrimaryKey   OrderT   Identity )  deriving   instance   Show   ( PrimaryKey   ProductT   Identity )  data   LineItemT   f   =   LineItem \n                  {   _lineItemInOrder      ::   PrimaryKey   OrderT   f \n                  ,   _lineItemForProduct   ::   PrimaryKey   ProductT   f \n                  ,   _lineItemQuantity     ::   Columnar   f   Int   } \n                    deriving   ( Generic ,   Beamable )  type   LineItem   =   LineItemT   Identity  deriving   instance   Show   LineItem  instance   Table   LineItemT   where \n     data   PrimaryKey   LineItemT   f   =   LineItemId   ( PrimaryKey   OrderT   f )   ( PrimaryKey   ProductT   f ) \n                                   deriving   ( Generic ,   Beamable ) \n     primaryKey   =   LineItemId   $   _lineItemInOrder   *   _lineItemForProduct    Tip  We used the  Applicative  instance for  (- ) a  above to write the primaryKey  function. The  Applicative ((- ) a)  instance operates like an\nunwrapper  Reader  of  a . The applicative actions are then functions from a -  x  that inject values from the  a  into the applicative bind.   Now we'll add all these tables to our database.  -- Some convenience lenses  LineItem   _   _   ( LensFor   lineItemQuantity )   =   tableLenses  Product   ( LensFor   productId )   ( LensFor   productTitle )   ( LensFor   productDescription )   ( LensFor   productPrice )   =   tableLenses  data   ShoppingCartDb   f   =   ShoppingCartDb \n                       {   _shoppingCartUsers           ::   f   ( TableEntity   UserT ) \n                       ,   _shoppingCartUserAddresses   ::   f   ( TableEntity   AddressT ) \n                       ,   _shoppingCartProducts        ::   f   ( TableEntity   ProductT ) \n                       ,   _shoppingCartOrders          ::   f   ( TableEntity   OrderT ) \n                       ,   _shoppingCartShippingInfos   ::   f   ( TableEntity   ShippingInfoT ) \n                       ,   _shoppingCartLineItems       ::   f   ( TableEntity   LineItemT )   } \n                         deriving   ( Generic ,   Database   be )  ShoppingCartDb   ( TableLens   shoppingCartUsers )   ( TableLens   shoppingCartUserAddresses ) \n                ( TableLens   shoppingCartProducts )   ( TableLens   shoppingCartOrders ) \n                ( TableLens   shoppingCartShippingInfos )   ( TableLens   shoppingCartLineItems )   =   dbLenses  shoppingCartDb   ::   DatabaseSettings   be   ShoppingCartDb  shoppingCartDb   =   defaultDbSettings   ` withDbModification ` \n                  dbModification   { \n                    _shoppingCartUserAddresses   = \n                      setEntityName   addresses   \n                      modifyTableFields   tableModification   { \n                        _addressLine1   =   address1 , \n                        _addressLine2   =   address2 \n                      }, \n                    _shoppingCartProducts   =   setEntityName   products , \n                    _shoppingCartOrders   =   setEntityName   orders   \n                                          modifyTableFields   tableModification   { \n                                            _orderShippingInfo   =   ShippingInfoId   shipping_info__id \n                                          }, \n                    _shoppingCartShippingInfos   =   setEntityName   shipping_info   \n                                                 modifyTableFields   tableModification   { \n                                                   _shippingInfoId   =   id , \n                                                   _shippingInfoCarrier   =   carrier , \n                                                   _shippingInfoTrackingNumber   =   tracking_number \n                                                 }, \n                    _shoppingCartLineItems   =   setEntityName   line_items \n                  }", 
            "title": "Creating tables is easy now"
        }, 
        {
            "location": "/tutorials/tutorial3/#fixtures", 
            "text": "Let's put some sample data into a new database.  conn   -   open   shoppingcart3.db  execute_   conn   CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));  execute_   conn   CREATE TABLE addresses ( id INTEGER PRIMARY KEY AUTOINCREMENT, address1 VARCHAR NOT NULL, address2 VARCHAR, city VARCHAR NOT NULL, state VARCHAR NOT NULL, zip VARCHAR NOT NULL, for_user__email VARCHAR NOT NULL );  execute_   conn   CREATE TABLE products ( id INTEGER PRIMARY KEY AUTOINCREMENT, title VARCHAR NOT NULL, description VARCHAR NOT NULL, price INT NOT NULL );  execute_   conn   CREATE TABLE orders ( id INTEGER PRIMARY KEY AUTOINCREMENT, date TIMESTAMP NOT NULL, for_user__email VARCHAR NOT NULL, ship_to_address__id INT NOT NULL, shipping_info__id INT);  execute_   conn   CREATE TABLE shipping_info ( id INTEGER PRIMARY KEY AUTOINCREMENT, carrier VARCHAR NOT NULL, tracking_number VARCHAR NOT NULL);  execute_   conn   CREATE TABLE line_items (item_in_order__id INTEGER NOT NULL, item_for_product__id INTEGER NOT NULL, item_quantity INTEGER NOT NULL)   Let's put some sample data into our database. Below, we will use the beam-sqlite  functions  insertReturning  and  runInsertReturningList  to insert\nrows  and  retrieve the inserted rows from the database. This will let us see\nwhat values the auto-incremented  id  columns took on, which will allow us to\ncreate references to these inserted rows.  let   users @ [ james ,   betty ,   sam ]   = \n           [   User   james@example.com   James   Smith    b4cc344d25a2efe540adbf2678e2304c   {- james -} \n           ,   User   betty@example.com   Betty   Jones    82b054bd83ffad9b6cf8bdb98ce3cc2f   {- betty -} \n           ,   User   sam@example.com     Sam     Taylor   332532dcfaa1cbf61e2a266bd723612c   {- sam -}   ] \n     addresses   =   [   Address   default_   ( val_   123 Little Street )   ( val_   Nothing )   ( val_   Boston )   ( val_   MA )   ( val_   12345 )   ( pk   james ) \n                 ,   Address   default_   ( val_   222 Main Street )   ( val_   ( Just   Ste 1 ))   ( val_   Houston )   ( val_   TX )   ( val_   8888 )   ( pk   betty ) \n                 ,   Address   default_   ( val_   9999 Residence Ave )   ( val_   Nothing )   ( val_   Sugarland )   ( val_   TX )   ( val_   8989 )   ( pk   betty )   ] \n\n     products   =   [   Product   default_   ( val_   Red Ball )   ( val_   A bright red, very spherical ball )   ( val_   1000 ) \n                ,   Product   default_   ( val_   Math Textbook )   ( val_   Contains a lot of important math theorems and formulae )   ( val_   2500 ) \n                ,   Product   default_   ( val_   Intro to Haskell )   ( val_   Learn the best programming language in the world )   ( val_   3000 ) \n                ,   Product   default_   ( val_   Suitcase )   A hard durable suitcase   15000   ]  ( jamesAddress1 ,   bettyAddress1 ,   bettyAddress2 ,   redBall ,   mathTextbook ,   introToHaskell ,   suitcase )   - \n   runBeamSqliteDebug   putStrLn   conn   $   do \n     runInsert   $   insert   ( shoppingCartDb   ^.   shoppingCartUsers )   $ \n                 insertValues   users \n\n     [ jamesAddress1 ,   bettyAddress1 ,   bettyAddress2 ]   - \n       runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartUserAddresses )   $   insertExpressions   addresses \n\n     [ redBall ,   mathTextbook ,   introToHaskell ,   suitcase ]   - \n       runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartProducts )   $   insertExpressions   products \n\n     pure   (   jamesAddress1 ,   bettyAddress1 ,   bettyAddress2 ,   redBall ,   mathTextbook ,   introToHaskell ,   suitcase   )   Now, if we take a look at one of the returned addresses, like jamesAddress1 , we see it has had the  default_  values assigned\ncorrectly.  Prelude   Database . Beam   Database . Beam . Sqlite   Data . Time   Database . SQLite . Simple   Data . Text   Lens . Micro   jamesAddress1  Address   { _addressId   =   1 ,   _addressLine1   =   123 Little Street ,   _addressLine2   =   Nothing ,   _addressCity   =   Boston ,   _addressState   =   MA ,   _addressZip   =   12345 ,   _addressForUser   =   UserId   james@example.com }", 
            "title": "Fixtures"
        }, 
        {
            "location": "/tutorials/tutorial3/#marshalling-a-custom-type", 
            "text": "Now we can insert shipping information. Of course, the shipping information\ncontains the  ShippingCarrier  enumeration.  bettyShippingInfo   - \n   runBeamSqliteDebug   putStrLn   conn   $   do \n     [ bettyShippingInfo ]   - \n       runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartShippingInfos )   $ \n       insertExpressions   [   ShippingInfo   default_   ( val_   USPS )   ( val_   12345790ABCDEFGHI )   ] \n     pure   bettyShippingInfo   If you run this, you'll get an error from GHCi.  ``` :845:7: error:\n    \u2022 No instance for (FromBackendRow Sqlite ShippingCarrier)\n        arising from a use of \u2018runInsertReturningList\u2019\n    \u2022 In a stmt of a 'do' block:\n        [bettyShippingInfo]  - runInsertReturningList\n                                 $ insertReturning (shoppingCartDb ^. shoppingCartShippingInfos)\n                                     $ insertExpressions\n                                         [ShippingInfo\n                                            default_ (val_ USPS) (val_ \"12345790ABCDEFGHI\")]\n...  :847:50: error:\n    \u2022 No instance for (Database.Beam.Backend.SQL.SQL92.HasSqlValueSyntax\n                         Database.Beam.Sqlite.Syntax.SqliteValueSyntax ShippingCarrier)  These   errors   are   because   there s no way to express a `ShippingCarrier` in the  backend   syntax .   We   can   fix   this   by   writing   instances   for   beam .   We   can   re - use   the  functionality   we   already   have   for   `String` .  The   `HasSqlValueSyntax`   class   tells   us   how   to   convert   a   Haskell   value   into   a  corresponding   backend   value .  `` ` haskell  import   Database.Beam.Backend.SQL  : set   - XUndecidableInstances  instance   HasSqlValueSyntax   be   String   =   HasSqlValueSyntax   be   ShippingCarrier   where \n   sqlValueSyntax   =   autoSqlValueSyntax   autoSqlValueSyntax  uses the underlying  Show  instance to serialize\na type to a string representation.  The  FromBackendRow  class tells us how to convert a value from the database\ninto a corresponding Haskell value.  import   qualified   Data.Text   as   T   -- for unpack  instance   FromBackendRow   Sqlite   ShippingCarrier   where \n   fromBackendRow   =   read   .   T . unpack   $   fromBackendRow   Since,  autoSqlValueSyntax  uses the  Show  instance, we can simply use the  Read  instance.  Now, if we try to insert the shipping info again, it works.  bettyShippingInfo   - \n   runBeamSqliteDebug   putStrLn   conn   $   do \n     [ bettyShippingInfo ]   - \n       runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartShippingInfos )   $ \n       insertExpressions   [   ShippingInfo   default_   ( val_   USPS )   ( val_   12345790ABCDEFGHI )   ] \n     pure   bettyShippingInfo   And if we look at the value of  bettyShippingInfo ,  ShippingCarrier  has been\nstored correctly.    bettyShippingInfo  ShippingInfo   { _shippingInfoId   =   1 ,   _shippingInfoCarrier   =   USPS ,   _shippingInfoTrackingNumber   =   12345790ABCDEFGHI }   Now, let's insert some orders that just came in. We want to insert\ntransactions with the current database timestamp (i.e., CURRENT_TIMESTAMP  in SQL). We can do this using insertExpressions . If you run the example below, you'll see the\nresulting rows have a timestamp set by the database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             [   jamesOrder1 ,   bettyOrder1 ,   jamesOrder2   ]   - \n   runBeamSqliteDebug   putStrLn   conn   $   do \n     runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartOrders )   $ \n       insertExpressions   $ \n       [   Order   default_   currentTimestamp_   ( val_   ( pk   james ))   ( val_   ( pk   jamesAddress1 ))   nothing_ \n       ,   Order   default_   currentTimestamp_   ( val_   ( pk   betty ))   ( val_   ( pk   bettyAddress1 ))   ( just_   ( val_   ( pk   bettyShippingInfo ))) \n       ,   Order   default_   currentTimestamp_   ( val_   ( pk   james ))   ( val_   ( pk   jamesAddress1 ))   nothing_   ]  print   jamesOrder1  print   bettyOrder1  print   jamesOrder2  \n\n         \n    \n         \n             INSERT   INTO   orders ( date , \n                      for_user__email , \n                      ship_to_address__id , \n                      shipping_info__id )  VALUES   ( CURRENT_TIMESTAMP , \n         ? , \n         ? , \n         NULL );  -- With values: [SQLText  james@example.com ,SQLInteger 1]  INSERT   INTO   orders ( date , \n                      for_user__email , \n                      ship_to_address__id , \n                      shipping_info__id )  VALUES   ( CURRENT_TIMESTAMP , \n         ? , \n         ? , \n         ? );  -- With values: [SQLText  betty@example.com ,SQLInteger 2,SQLInteger 1]  INSERT   INTO   orders ( date , \n                      for_user__email , \n                      ship_to_address__id , \n                      shipping_info__id )  VALUES   ( CURRENT_TIMESTAMP , \n         ? , \n         ? , \n         NULL );  -- With values: [SQLText  james@example.com ,SQLInteger 1]  \n\n         \n    \n         \n             Order {_orderId = 1, _orderDate = 2019-03-19 17:09:19, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}  Order {_orderId = 2, _orderDate = 2019-03-19 17:09:19, _orderForUser = UserId  betty@example.com , _orderShipToAddress = AddressId 2, _orderShippingInfo = ShippingInfoId (Just 1)}  Order {_orderId = 3, _orderDate = 2019-03-19 17:09:19, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}  \n\n         \n    \n         \n    \n                 \n                      Finally, let's add some line items  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n    \n         \n            \n         \n             let   lineItems   =   [   LineItem   ( pk   jamesOrder1 )   ( pk   redBall )   10 \n                 ,   LineItem   ( pk   jamesOrder1 )   ( pk   mathTextbook )   1 \n                 ,   LineItem   ( pk   jamesOrder1 )   ( pk   introToHaskell )   4 \n\n                 ,   LineItem   ( pk   bettyOrder1 )   ( pk   mathTextbook )   3 \n                 ,   LineItem   ( pk   bettyOrder1 )   ( pk   introToHaskell )   3 \n\n                 ,   LineItem   ( pk   jamesOrder2 )   ( pk   mathTextbook )   1   ]  runBeamSqliteDebug   putStrLn   conn   $   do \n   runInsert   $   insert   ( shoppingCartDb   ^.   shoppingCartLineItems )   $ \n     insertValues   lineItems  \n\n         \n    \n         \n             INSERT   INTO   line_items ( item_in_order__id , \n                          item_for_product__id , \n                          item_quantity )  VALUES   ( ? , \n         ? , \n         ? ),   ( ? , \n              ? , \n              ? ),   ( ? , \n                   ? , \n                   ? ),   ( ? , \n                        ? , \n                        ? ),   ( ? , \n                             ? , \n                             ? ),   ( ? , \n                                  ? , \n                                  ? );  -- With values: [SQLInteger 1,SQLInteger 1,SQLInteger 10,SQLInteger 1,SQLInteger 2,SQLInteger 1,SQLInteger 1,SQLInteger 3,SQLInteger 4,SQLInteger 2,SQLInteger 2,SQLInteger 3,SQLInteger 2,SQLInteger 3,SQLInteger 3,SQLInteger 3,SQLInteger 2,SQLInteger 1]  \n\n         \n    \n         \n    \n                 \n                      Phew! Let's write some queries on this data!", 
            "title": "Marshalling a custom type"
        }, 
        {
            "location": "/tutorials/tutorial3/#would-you-like-some-left-joins-with-that", 
            "text": "Suppose we want to do some analytics on our users, and so we want to know how many orders each user\nhas made in our system. We can write a query to list every user along with the orders they've\nmade. We can use  leftJoin_  to include all users in our result set, even those who have no\norders.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             usersAndOrders   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $   do \n       user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n       order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders ))   ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n       pure   ( user ,   order )  mapM_   print   usersAndOrders  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . id   AS   res4 , \n        t1 . date   AS   res5 , \n        t1 . for_user__email   AS   res6 , \n        t1 . ship_to_address__id   AS   res7 , \n        t1 . shipping_info__id   AS   res8  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email );  -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Just (Order {_orderId = 1, _orderDate = 2019-03-19 17:09:29, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}))\n(User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Just (Order {_orderId = 3, _orderDate = 2019-03-19 17:09:29, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}))\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Just (Order {_orderId = 2, _orderDate = 2019-03-19 17:09:29, _orderForUser = UserId  betty@example.com , _orderShipToAddress = AddressId 2, _orderShippingInfo = ShippingInfoId (Just 1)}))\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Nothing) \n\n         \n    \n         \n    \n                 \n                      Notice that Sam is included in the result set, even though he doesn't have any\nassociated orders. Instead of a  Just (Order ..) ,  Nothing  is returned\ninstead.  Next, perhaps our marketing team wanted to send e-mails out to all users with no\norders. We can use  isNothing_  or  isJust_  to determine the status if a\nnullable table or  QExpr s (Maybe x) . The following query uses  isNothing_  to\nfind users who have no associated orders.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             usersWithNoOrders   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $   do \n       user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n       order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders ))   ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n       guard_   ( isNothing_   order ) \n       pure   user  mapM_   print   usersWithNoOrders  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email )  WHERE   ((((( t1 . id )   IS   NULL ) \n          AND   (( t1 . date )   IS   NULL )) \n         AND   (( t1 . for_user__email )   IS   NULL )) \n        AND   (( t1 . ship_to_address__id )   IS   NULL )) \n   AND   (( t1 . shipping_info__id )   IS   NULL );  -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c } \n\n         \n    \n         \n    \n                 \n                      We see that beam generates a sensible SQL  SELECT  and  WHERE  clause.  We can also use the  exists_  combinator to utilize the SQL  EXISTS  clause.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             usersWithNoOrders   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $   do \n       user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n       guard_   ( not_   ( exists_   ( filter_   ( \\ order   -   _orderForUser   order   ` references_ `   user )   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders ))))) \n       pure   user  mapM_   print   usersWithNoOrders  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  WHERE   NOT ( EXISTS \n             ( SELECT   sub_t0 . id   AS   res0 ,   sub_t0 . date   AS   res1 ,   sub_t0 . for_user__email   AS   res2 ,   sub_t0 . ship_to_address__id   AS   res3 ,   sub_t0 . shipping_info__id   AS   res4 \n              FROM   orders   AS   sub_t0 \n              WHERE   ( sub_t0 . for_user__email ) = ( t0 . email )));  -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c } \n\n         \n    \n         \n    \n                 \n                      Now suppose we wanted to do some analysis on the orders themselves. To start, we\nwant to get the orders sorted by their portion of revenue. We can use aggregate_  to list every order and the total amount of all products in that\norder.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             ordersWithCostOrdered   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     orderBy_   ( \\ ( order ,   total )   -   desc_   total )   $ \n     aggregate_   ( \\ ( order ,   lineItem ,   product )   - \n                    ( group_   order ,   sum_   ( lineItem   ^.   lineItemQuantity   *   product   ^.   productPrice )))   $ \n     do   lineItem   -   all_   ( shoppingCartDb   ^.   shoppingCartLineItems ) \n        order      -   related_   ( shoppingCartDb   ^.   shoppingCartOrders )   ( _lineItemInOrder   lineItem ) \n        product    -   related_   ( shoppingCartDb   ^.   shoppingCartProducts )   ( _lineItemForProduct   lineItem ) \n        pure   ( order ,   lineItem ,   product )  mapM_   print   ordersWithCostOrdered  \n\n         \n    \n         \n             SELECT   t1 . id   AS   res0 , \n        t1 . date   AS   res1 , \n        t1 . for_user__email   AS   res2 , \n        t1 . ship_to_address__id   AS   res3 , \n        t1 . shipping_info__id   AS   res4 , \n        SUM (( t0 . item_quantity )   *   ( t2 . price ))   AS   res5  FROM   line_items   AS   t0  INNER   JOIN   orders   AS   t1   ON   ( t0 . item_in_order__id ) = ( t1 . id )  INNER   JOIN   products   AS   t2   ON   ( t0 . item_for_product__id ) = ( t2 . id )  GROUP   BY   t1 . id , \n          t1 . date , \n          t1 . for_user__email , \n          t1 . ship_to_address__id , \n          t1 . shipping_info__id  ORDER   BY   SUM (( t0 . item_quantity )   *   ( t2 . price ))   DESC ;  -- With values: []  \n\n         \n    \n         \n             (Order {_orderId = 1, _orderDate = 2019-03-19 17:09:49, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing},Just 24500)\n(Order {_orderId = 2, _orderDate = 2019-03-19 17:09:49, _orderForUser = UserId  betty@example.com , _orderShipToAddress = AddressId 2, _orderShippingInfo = ShippingInfoId (Just 1)},Just 16500)\n(Order {_orderId = 3, _orderDate = 2019-03-19 17:09:49, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing},Just 2500) \n\n         \n    \n         \n    \n                 \n                      We can also get the total amount spent by each user, even including users with no orders. Notice\nthat we have to use  maybe_  below in order to handle the fact that some tables have been introduced\ninto our query with a left join.  maybe_  is to  QExpr  what  maybe  is to normal Haskell\nvalues.  maybe_  is polymorphic to either  QExpr s or full on tables of  QExpr s. For our purposes,\nthe type of  maybe_  is  maybe_   ::   QExpr   be   s   a   -   ( QExpr   be   s   b   -   QExpr   be   s   a )   -   QExpr   be   s   ( Maybe   b )   -   QExpr   be   s   a   With that in mind, we can write the query to get the total spent by user  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             allUsersAndTotals   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     orderBy_   ( \\ ( user ,   total )   -   desc_   total )   $ \n     aggregate_   ( \\ ( user ,   lineItem ,   product )   - \n                    ( group_   user ,   sum_   ( maybe_   0   id   ( _lineItemQuantity   lineItem )   *   maybe_   0   id   ( product   ^.   productPrice ))))   $ \n     do   user       -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        order      -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                              ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n        lineItem   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartLineItems )) \n                              ( \\ lineItem   -   maybe_   ( val_   False )   ( \\ order   -   _lineItemInOrder   lineItem   ` references_ `   order )   order ) \n        product    -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartProducts )) \n                              ( \\ product   -   maybe_   ( val_   False )   ( \\ lineItem   -   _lineItemForProduct   lineItem   ` references_ `   product )   lineItem ) \n        pure   ( user ,   lineItem ,   product )  mapM_   print   allUsersAndTotals  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        SUM (( CASE \n                 WHEN   ( t2 . item_quantity )   IS   NOT   NULL   THEN   t2 . item_quantity \n                 ELSE   ? \n             END )   *   ( CASE \n                         WHEN   ( t3 . price )   IS   NOT   NULL   THEN   t3 . price \n                         ELSE   ? \n                     END ))   AS   res4  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email )  LEFT   JOIN   line_items   AS   t2   ON   CASE \n                                       WHEN   ((((( t1 . id )   IS   NOT   NULL ) \n                                               AND   (( t1 . date )   IS   NOT   NULL )) \n                                              AND   (( t1 . for_user__email )   IS   NOT   NULL )) \n                                             AND   (( t1 . ship_to_address__id )   IS   NOT   NULL )) \n                                            AND   (( t1 . shipping_info__id )   IS   NOT   NULL )   THEN   ( t2 . item_in_order__id ) = ( t1 . id ) \n                                       ELSE   ? \n                                   END  LEFT   JOIN   products   AS   t3   ON   CASE \n                                     WHEN   ((( t2 . item_in_order__id )   IS   NOT   NULL ) \n                                           AND   (( t2 . item_for_product__id )   IS   NOT   NULL )) \n                                          AND   (( t2 . item_quantity )   IS   NOT   NULL )   THEN   ( t2 . item_for_product__id ) = ( t3 . id ) \n                                     ELSE   ? \n                                 END  GROUP   BY   t0 . email , \n          t0 . first_name , \n          t0 . last_name , \n          t0 . password  ORDER   BY   SUM (( CASE \n                   WHEN   ( t2 . item_quantity )   IS   NOT   NULL   THEN   t2 . item_quantity \n                   ELSE   ? \n               END )   *   ( CASE \n                           WHEN   ( t3 . price )   IS   NOT   NULL   THEN   t3 . price \n                           ELSE   ? \n                       END ))   DESC ;  -- With values: [SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0]  \n\n         \n    \n         \n             (User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Just 16500)\n(User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Just 0)\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Just 0) \n\n         \n    \n         \n    \n                 \n                      Take a couple seconds to examine the SQL generated by this query. Notice how every time we used maybe_  a  CASE  statement was emitted. While this provides a good match for Haskell semantics\nwe are used to, it is also not always desireable in practice due to severe performance implications.  Some RDBMSs, like Postgres, given such a query will be unable to utilize available indexes\nto perform join operations - this translates to  extremely  poor perfomance for even moderately\nsized data.  Luckily, Beam also provides an alternate way to phrase things that directly maps to SQL semantics  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             allUsersAndTotals2   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     orderBy_   ( \\ ( user ,   total )   -   desc_   total )   $ \n     aggregate_   ( \\ ( user ,   lineItem ,   product )   - \n                    ( group_   user ,   sum_   ( maybe_   0   id   ( _lineItemQuantity   lineItem )   *   maybe_   0   id   ( product   ^.   productPrice ))))   $ \n     do   user       -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        order      -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                              ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n        lineItem   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartLineItems )) \n                               ( \\ lineItem   -   just_   ( _lineItemInOrder   lineItem )   ==?.   pk   order ) \n        product    -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartProducts )) \n                               ( \\ product   -   _lineItemForProduct   lineItem   ==?.   just_   ( pk   product )) \n        pure   ( user ,   lineItem ,   product )  mapM_   print   allUsersAndTotals2  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        SUM (( CASE \n                 WHEN   ( t2 . item_quantity )   IS   NOT   NULL   THEN   t2 . item_quantity \n                 ELSE   ? \n             END )   *   ( CASE \n                         WHEN   ( t3 . price )   IS   NOT   NULL   THEN   t3 . price \n                         ELSE   ? \n                     END ))   AS   res4  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email )  LEFT   JOIN   line_items   AS   t2   ON   ( t2 . item_in_order__id ) = ( t1 . id )  LEFT   JOIN   products   AS   t3   ON   ( t2 . item_for_product__id ) = ( t3 . id )  GROUP   BY   t0 . email , \n          t0 . first_name , \n          t0 . last_name , \n          t0 . password  ORDER   BY   SUM (( CASE \n                   WHEN   ( t2 . item_quantity )   IS   NOT   NULL   THEN   t2 . item_quantity \n                   ELSE   ? \n               END )   *   ( CASE \n                           WHEN   ( t3 . price )   IS   NOT   NULL   THEN   t3 . price \n                           ELSE   ? \n                       END ))   DESC ;  -- With values: [SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0]  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Just 27000)\n(User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Just 16500)\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Just 0) \n\n         \n    \n         \n    \n                 \n                      Notice how we managed to eliminate  maybe_  from the join conditions by using the  SqlBool  version of leftJoin_ ,  leftJoin_'  together with  just_  and the  SqlBool  version of the equality operator  ==?. .\nCompare the generated SQL with the previous query. You can read more about how Beam handles NULL values\nin the Queries, Relationships section in the User Guide.", 
            "title": "Would you like some left joins with that?"
        }, 
        {
            "location": "/tutorials/tutorial3/#queries-with-nullable-foreign-keys", 
            "text": "Recall that our schema contains a nullable foreign key from  OrderT  to  ShippingInfoT . Above,\nwe've seen how  leftJoin_  introduces nullable tables into our queries. Below, we'll see how to use\nnullable primary keys to optionally include information.  Suppose we want to find all orders who have not been shipped. We can do this by simply writing a query over the orders.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             allUnshippedOrders   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     filter_   ( isNothing_   .   _orderShippingInfo )   $ \n     all_   ( shoppingCartDb   ^.   shoppingCartOrders )  mapM_   print   allUnshippedOrders  \n\n         \n    \n         \n             SELECT   t0 . id   AS   res0 , \n        t0 . date   AS   res1 , \n        t0 . for_user__email   AS   res2 , \n        t0 . ship_to_address__id   AS   res3 , \n        t0 . shipping_info__id   AS   res4  FROM   orders   AS   t0  WHERE   ( t0 . shipping_info__id )   IS   NULL ;  -- With values: []  \n\n         \n    \n         \n             Order {_orderId = 1, _orderDate = 2019-03-19 17:10:10, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing}\nOrder {_orderId = 3, _orderDate = 2019-03-19 17:10:10, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId 1, _orderShippingInfo = ShippingInfoId Nothing} \n\n         \n    \n         \n    \n                 \n                      Let's count up all shipped and unshipped orders by user, including users who have no orders.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             shippingInformationByUser   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     aggregate_   ( \\ ( user ,   order )   - \n                    let   ShippingInfoId   shippingInfoId   =   _orderShippingInfo   order \n                    in   (   group_   user \n                       ,   as_   @ Int   $   count_   ( as_   @ ( Maybe   Int )   ( maybe_   ( just_   1 )   ( \\ _   -   nothing_ )   shippingInfoId )) \n                       ,   as_   @ Int   $   count_   shippingInfoId   )   )   $ \n     do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders ))   ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n        pure   ( user ,   order )  mapM_   print   shippingInformationByUser  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        COUNT ( CASE \n                  WHEN   ( t1 . shipping_info__id )   IS   NOT   NULL   THEN   NULL \n                  ELSE   ? \n              END )   AS   res4 , \n        COUNT ( t1 . shipping_info__id )   AS   res5  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email )  GROUP   BY   t0 . email , \n          t0 . first_name , \n          t0 . last_name , \n          t0 . password ;  -- With values: [SQLInteger 1]  \n\n         \n    \n         \n             (User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },0,1)\n(User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },2,0)\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },1,0) \n\n         \n    \n         \n    \n                 \n                      Uh-oh! There's an error in the result set! Sam is reported as having one\nunshipped order, instead of zero.  Here we hit one of the limitations of beam's mapping to SQL, and really one of\nthe limitations of SQL itself. Namely, the NULL in the result rows for Sam is\nnot distinguished from the NULL in the shipping info key itself. Beam however\ndoes make the distinction.  When beam deserializes a  NULL  in a  Maybe  field, the outermost  Maybe  is the\none populated with  Nothing . Thus it is impossible to retrieve a value like Just Nothing  from the database using the default serializers and\ndeserializers. In general, it's best to avoid highly nested  Maybe s in your\nqueries because it makes them more difficult to understand.  One way to work around this issue in the above query is to use subselects.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             shippingInformationByUser   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     do   user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n\n        ( userEmail ,   unshippedCount )   - \n          aggregate_   ( \\ ( userEmail ,   order )   -   ( group_   userEmail ,   countAll_ ))   $ \n          do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n             order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                                ( \\ order   -   _orderForUser   order   ` references_ `   user   .   isNothing_   ( _orderShippingInfo   order )) \n             pure   ( pk   user ,   order ) \n\n        guard_   ( userEmail   ` references_ `   user ) \n\n        ( userEmail ,   shippedCount )   - \n          aggregate_   ( \\ ( userEmail ,   order )   -   ( group_   userEmail ,   countAll_ ))   $ \n          do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n             order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                                ( \\ order   -   _orderForUser   order   ` references_ `   user   .   isJust_   ( _orderShippingInfo   order )) \n             pure   ( pk   user ,   order ) \n        guard_   ( userEmail   ` references_ `   user ) \n\n        pure   ( user ,   unshippedCount ,   shippedCount )  mapM_   print   shippingInformationByUser  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . res1   AS   res4 , \n        t2 . res1   AS   res5  FROM   cart_users   AS   t0  INNER   JOIN \n   ( SELECT   t0 . email   AS   res0 , \n           COUNT ( * )   AS   res1 \n    FROM   cart_users   AS   t0 \n    LEFT   JOIN   orders   AS   t1   ON   (( t1 . for_user__email ) = ( t0 . email )) \n    AND   (( t1 . shipping_info__id )   IS   NULL ) \n    GROUP   BY   t0 . email )   AS   t1  INNER   JOIN \n   ( SELECT   t0 . email   AS   res0 , \n           COUNT ( * )   AS   res1 \n    FROM   cart_users   AS   t0 \n    LEFT   JOIN   orders   AS   t1   ON   (( t1 . for_user__email ) = ( t0 . email )) \n    AND   (( t1 . shipping_info__id )   IS   NOT   NULL ) \n    GROUP   BY   t0 . email )   AS   t2  WHERE   (( t1 . res0 ) = ( t0 . email )) \n   AND   (( t2 . res0 ) = ( t0 . email ));  -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },1,1)\n(User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },2,1)\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },1,1) \n\n         \n    \n         \n    \n                 \n                      Notice that the  aggregate_ s embedded in the  Q  monad were automatically\nconverted into sub  SELECT s. This is because beam queries are composable -- you\ncan use them wherever they type check and sensible SQL will result. Of course,\nif you want more control, you can also use the  subselect_  combinator to force\ngeneration of a sub  SELECT .  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             shippingInformationByUser   - \n   runBeamSqliteDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     do   user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n\n        ( userEmail ,   unshippedCount )   - \n          subselect_   $ \n          aggregate_   ( \\ ( userEmail ,   order )   -   ( group_   userEmail ,   countAll_ ))   $ \n          do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n             order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                                ( \\ order   -   _orderForUser   order   ` references_ `   user   .   isNothing_   ( _orderShippingInfo   order )) \n             pure   ( pk   user ,   order ) \n\n        guard_   ( userEmail   ` references_ `   user ) \n\n        ( userEmail ,   shippedCount )   - \n          subselect_   $ \n          aggregate_   ( \\ ( userEmail ,   order )   -   ( group_   userEmail ,   countAll_ ))   $ \n          do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n             order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                                ( \\ order   -   _orderForUser   order   ` references_ `   user   .   isJust_   ( _orderShippingInfo   order )) \n             pure   ( pk   user ,   order ) \n        guard_   ( userEmail   ` references_ `   user ) \n\n        pure   ( user ,   unshippedCount ,   shippedCount )  mapM_   print   shippingInformationByUser  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . res1   AS   res4 , \n        t2 . res1   AS   res5  FROM   cart_users   AS   t0  INNER   JOIN \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 \n    FROM \n      ( SELECT   t0 . email   AS   res0 , \n              COUNT ( * )   AS   res1 \n       FROM   cart_users   AS   t0 \n       LEFT   JOIN   orders   AS   t1   ON   (( t1 . for_user__email ) = ( t0 . email )) \n       AND   (( t1 . shipping_info__id )   IS   NULL ) \n       GROUP   BY   t0 . email )   AS   t0 )   AS   t1  INNER   JOIN \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 \n    FROM \n      ( SELECT   t0 . email   AS   res0 , \n              COUNT ( * )   AS   res1 \n       FROM   cart_users   AS   t0 \n       LEFT   JOIN   orders   AS   t1   ON   (( t1 . for_user__email ) = ( t0 . email )) \n       AND   (( t1 . shipping_info__id )   IS   NOT   NULL ) \n       GROUP   BY   t0 . email )   AS   t0 )   AS   t2  WHERE   (( t1 . res0 ) = ( t0 . email )) \n   AND   (( t2 . res0 ) = ( t0 . email ));  -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  betty@example.com , _userFirstName =  Betty , _userLastName =  Jones , _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },1,1)\n(User {_userEmail =  james@example.com , _userFirstName =  James , _userLastName =  Smith , _userPassword =  b4cc344d25a2efe540adbf2678e2304c },2,1)\n(User {_userEmail =  sam@example.com , _userFirstName =  Sam , _userLastName =  Taylor , _userPassword =  332532dcfaa1cbf61e2a266bd723612c },1,1)", 
            "title": "Queries with nullable foreign keys"
        }, 
        {
            "location": "/tutorials/tutorial3/#conclusion", 
            "text": "This tutorial completes our sequence on creating a shopping cart. Throughout the\ntutorials, we saw how to create tables using regular Haskell data types, how to\nlink those tables up using relations, how to query tables using both the monadic\ninterface and the list-like functions on queries. We saw ha few examples of\nusing beam to generate advanced queries. More information on the Beam API is\nhavailable on  hackage . Happy beaming!  Beam is a work in progress. Please submit bugs and patches\non  GitHub .", 
            "title": "Conclusion"
        }, 
        {
            "location": "/user-guide/models/", 
            "text": "A beam model is any single-constructer Haskell record type parameterized by a\ntype of kind \n* -\n *\n. The model must have an instance of \nGeneric\n, \nBeamable\n,\nand \nTable\n. \nGeneric\n can be derived using the \nDeriveGeneric\n extension of\nGHC. \nBeamable\n must be given an empty instance declaration (\ninstance Beamable\nTbl\n for a table of type \nTbl\n). \nTable\n is discussed next.\n\n\nEach field in the record type must either be a sub-table (another parameterized\ntype with a \nBeamable\n instance) or an explicit column. A column is specified\nusing the \nColumnar\n type family applied to the type's parameter and the\nunderlying Haskell type of the field.\n\n\nThe \nTable\n type class\n\n\nTable\n is a type class that must be instantiated for all types that you would\nlike to use as a table. It has one associated \ndata\n instance and one function.\n\n\nYou must create a type to represent the primary key of the table. The primary\nkey of a table \nTbl\n is the associated data type \nPrimaryKey Tbl\n. Like \nTbl\n,\nit takes one type parameter of kind \n* -\n *\n. It must have only one constructor\nwhich can hold all fields in the primary key. The constructor need not be a\nrecord constructor (although it can be).\n\n\nYou must also write a function \nprimaryKey\n that takes an instance of \nTbl\n\n(parameterized over any functor \nf\n) and returns the associated \nPrimaryKey\n\ntype. It is sometimes easiest to use the \nApplicative\n instance for \nr -\n to\nwrite this function. For example, if \ntblField1\n and \ntblField2\n are part of the\nprimary key, you can write\n\n\ninstance\n \nTable\n \nTbl\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nTbl\n \nf\n \n=\n \nTblKey\n \n(\nColumnar\n \nf\n \n..\n)\n \n(\nColumnar\n \nf\n \n..\n)\n\n  \nprimaryKey\n \nt\n \n=\n \nTblKey\n \n(\ntblField1\n \nt\n)\n \n(\ntblField2\n \nt\n)\n\n\n\n\n\n\nmore simply as\n\n\ninstance\n \nTable\n \nTbl\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nTbl\n \nf\n \n=\n \nTblKey\n \n(\nColumnar\n \nf\n \n..\n)\n \n(\nColumnar\n \nf\n \n..\n)\n\n  \nprimaryKey\n \n=\n \nTblKey\n \n$\n \ntblField1\n \n*\n \ntblField2\n\n\n\n\n\n\nThe \nIdentity\n trick\n\n\nBeam table types are commonly prefixed by a \nT\n to indicate the name of the\ngeneric table type. Usually, a type synonym named by leaving out the \nT\n is\ndefined by applying the table to \nIdentity\n. Recall each field in the table is\neither another table or an application of \nColumnar\n to the type parameter. When\nthe type is parameterized by \nIdentity\n, every column is also parameterized by\n\nIdentity\n.\n\n\nColumnar\n is a type family defined such that \nColumnar Identity x ~ x\n. Thus,\nwhen parameterized over \nIdentity\n, every field in the table type takes on the\nunderlying Haskell type.\n\n\nSuppose you have a table type \nModelT\n and a type synonym \ntype Model = ModelT\nIdentity\n. Notice that deriving \nShow\n, \nEq\n, and other standard Haskell type\nclasses won't generally work for \nModelT\n. However, you can use the standalone\nderiving mechanism to derive these instances for \nModel\n.\n\n\ndata\n \nModelT\n \nf\n \n=\n \nModel\n \n{\n \n..\n \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\n\n-- deriving instance Show (ModelT f) -- Won\nt work because GHC won\nt get the constraints right\n\n\n\ntype\n \nModel\n \n=\n \nModelT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nModel\n\n\nderiving\n \ninstance\n \nEq\n \nModel\n\n\nderiving\n \ninstance\n \nOrd\n \nModel\n\n\n\n\n\n\nAllowed data types\n\n\nAny data type can be used within a \nColumnar\n. Beam does no checking that a\nfield can be used against a particular database when the data type is defined.\nInstead, type errors will occur when the table is being used as a query. For\nexample, the following is allowed, even though many backends will not work with\narray data types.\n\n\nimport\n \nqualified\n \nData.Vector\n \nas\n \nV\n\n\n\ndata\n \nArrayTable\n \nf\n\n    \n=\n \nArrayTable\n\n    \n{\n \narrayTablePoints\n \n::\n \nColumnar\n \nf\n \n(\nV\n.\nVector\n \nInt32\n)\n\n    \n}\n \nderiving\n \nGeneric\n\n\n\n\n\n\nYou can construct values of type \nArrayTable Identity\n and even write queries\nover it (relying on type inference to get the constraints right). However, if\nyou attempt to solve the constraints over a database that doesn't support\ncolumns of type \nV.Vector Int32\n, GHC will throw an error. Thus, it's important\nto understand the limits of your backend when deciding which types to use. In\ngeneral, numeric, floating-point, and text types are well supported.\n\n\nMaybe\n types\n\n\nOptional fields (those that allow a SQL \nNULL\n) can usually be given a \nMaybe\n\ntype. However, you cannot use \nMaybe\n around an embedded table (you will be\nunable to instantiate \nBeamable\n).\n\n\nBeam offers a way around this. Instead of embedding the table applied to the\ntype parameter \nf\n, apply it to \nNullable f\n. \nColumnar (Nullable f) a ~ Maybe\n(Columnar f a)\n for all \na\n. Thus, this will make every column in the embedded\ntable take on the corresponding \nMaybe\n type.\n\n\n\n\nWarning\n\n\nNullable\n will nest \nMaybe\ns. That is \nColumnar (Nullable f) (Maybe a) ~\nMaybe (Maybe a)\n. This is bad from a SQL perspective, since SQL has no\nconcept of a nested optional type. Beam treats a \nNothing\n at any 'layer' of\nthe \nMaybe\n stack as a corresponding SQL \nNULL\n. When marshalling data back,\na SQL \nNULL\n is read in as a top-level \nNothing\n.\n\n\nThe reasons for this misfeature is basically code simplicity. Fixing this is\na top priority of future versions of beam.\n\n\n\n\nColumn tags\n\n\nAbove, we saw that applying \nIdentity\n to a table type results in a type whose\ncolumns are the underlying Haskell type. Beam uses other column tags for\nquerying and describing databases. Below is a table of common column tags and\ntheir meaning.\n\n\nConverting between tags\n\n\nSuppose you have a \nBeamable\n type paramaterized over a tag \nf\n and needed one\nparameterized over a tag \ng\n. Given a function \nconv :: forall a. Columnar f a\n-\n Columnar g a\n, you can use \nchangeBeamRep\n to convert between the tables.\n\n\nThere is one caveat however -- since \nColumnar\n is a type family, the type of\n\nconv\n is actually ambiguous. We need a way to carry the type of \nf\n, \ng\n, and\n\na\n into the code. For this reason, \nconv\n must actually be written over the\n\nColumnar'\n(notice the tick) \nnewtype\n. \nColumnar'\n is a newtype defined as such\n\n\nnewtype\n \nColumnar\n \nf\n \na\n \n=\n \nColumnar\n \n(\nColumnar\n \nf\n \na\n)\n\n\n\n\n\n\nNotice that, unlinke \nColumnar\n (a non-injective type family), \nColumnar'\n is a\nfull type. The type of \nconv' :: forall a. Columnar' f a -\n Columnar' g a\n is\nnow unambiguous. You can easily use \nconv\n to implement \nconv'\n:\n\n\nconv\n \n(\nColumnar\n \na\n)\n \n=\n \nColumnar\n \n(\nconv\n \na\n)\n\n\n\n\n\n\nThe \nBeamable\n type class\n\n\nAll beam tables, primary keys, and shared data fields must be instances of the\n\nBeamable\n class. You cannot override the methods of \nBeamable\n. Rather, they\nare derived using GHC's generics mechanism. Once you've declared your data type,\nyou can simply write \ninstance Beamable \nyour-type-name\n to instantiate the\ncorrect \nBeamable\n instance for your type.\n\n\nThe \nTable\n type class\n\n\nAll \nBeamable\n data types that you want to include as a \nTableEntity\n in your\ndatabase must be members of the \nTable\n type class. The \nTable\n type class\ndefines one associated type family \nPrimaryKey\n and a function \nprimaryKey\n that\ntakes a table over an arbitrary column tag and produces that table's\n\nPrimaryKey\n. For example, if you have a model\n\n\ndata\n \nPersonT\n \nf\n\n    \n=\n \nPerson\n\n    \n{\n \npersonEmail\n     \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npersonFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npersonLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npersonAge\n       \n::\n \nColumnar\n \nf\n \nInt\n\n    \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\n\n\n\n\nand you want the \npersonEmail\n field to form the primary key, you would define a \nTable\n instance as such\n\n\ninstance\n \nTable\n \nPersonT\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nPersonT\n \nf\n\n      \n=\n \nPersonKey\n \n(\nColumnar\n \nf\n \nText\n)\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n  \nprimaryKey\n \nperson\n \n=\n \nPersonKey\n \n$\n \npersonEmail\n\n\n\n\n\n\n\n\nTip\n\n\nMany people find it useful to use the \nApplicative\n instance for \n(-\n) a\n to\nwrite \nprimaryKey\n. For example, we could have written the above \nprimaryKey\nperson = PersonKey (personFirstName person) (personLastName person)\n as\n\nprimaryKey = PersonKey \n$\n personFirstName \n*\n personLastName\n.\n\n\n\n\n\n\nTip\n\n\nTyping \nColumnar\n may become tiresome. \nDatabase.Beam\n also exports \nC\n as a\ntype alias for \nColumnar\n, which may make writing models easier. Since \nC\n\nmay cause name clashes, all examples are given using \nColumnar\n.\n\n\n\n\nMany also like defining type synonyms for their table and primary key types. For\nexample, for the table \nPersonT\n above, a programmer may define.\n\n\ntype\n \nPerson\n \n=\n \nPersonT\n \nIdentity\n\n\ntype\n \nPersonKey\n \n=\n \nPrimaryKey\n \nPersonT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nPerson\n;\n \nderiving\n \ninstance\n \nEq\n \nPerson\n\n\nderiving\n \ninstance\n \nShow\n \nPersonKey\n;\n \nderiving\n \ninstance\n \nEq\n \nPersonKey\n\n\n\n\n\n\nBy convention, beam table types are suffixed with \nT\n to distinguish their type\nnames from the same type parameterized over \nIdentity\n (the 'regular' Haskell\ndata type).\n\n\nWhat about tables without primary keys?\n\n\nTables without primary keys are considered bad style. However, sometimes you\nneed to use beam with a schema that you have no control over. To declare a table\nwithout a primary key, simply instantiate the \nTable\n class and set \nPrimaryKey\ntbl\n to a type with no fields. Then just produce this type in \nprimaryKey\n.\n\n\nFor example\n\n\ndata\n \nBadT\n \nf\n\n  \n=\n \nBadT\n\n  \n{\n \nbadFirstName\n \n::\n \nC\n \nf\n \nText\n\n  \n,\n \nbadLastName\n  \n::\n \nC\n \nf\n \nText\n\n  \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\ninstance\n \nBeamable\n \nBadT\n\n\ninstance\n \nTable\n \nBadT\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nBadT\n \nf\n \n=\n \nBadNoId\n\n    \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n  \nprimaryKey\n \n_\n \n=\n \nBadNoId\n\n\n\n\n\n\nForeign references\n\n\nForeign references are also easily supported in models by simply\nembedding the \nPrimaryKey\n of the referred to table directly in the\nparent. For example, suppose we want to create a new model\nrepresenting a post by a user.\n\n\ndata\n \nPostT\n \nf\n\n    \n=\n \nPost\n\n    \n{\n \npostId\n       \n::\n \nColumnar\n \nf\n \n(\nSqlSerial\n \nInt\n)\n\n    \n,\n \npostPostedAt\n \n::\n \nColumnar\n \nf\n \nLocalTime\n\n    \n,\n \npostContent\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npostPoster\n   \n::\n \nPrimaryKey\n \nPersonT\n \nf\n\n    \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\n\ninstance\n \nTable\n \nPostT\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nPostT\n \nf\n\n      \n=\n \nPostId\n \n(\nColumnar\n \nf\n \n(\nSqlSerial\n \nInt\n))\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n  \nprimaryKey\n \n=\n \nPostId\n \n.\n \npostId\n\n\n\ntype\n \nPost\n \n=\n \nPostT\n \nIdentity\n\n\ntype\n \nPostId\n \n=\n \nPrimaryKey\n \nPostT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nPost\n;\n \nderiving\n \ninstance\n \nEq\n \nPost\n\n\nderiving\n \ninstance\n \nShow\n \nPostId\n;\n \nderiving\n \ninstance\n \nEq\n \nPostId\n\n\n\n\n\n\nNullable foreign references\n\n\nAbove, any non-bottom value of type \nPostT Identity\n must carry a concrete value\nof \nPrimaryKey PersonT Identity\n. Sometimes, you may want to optionally include\na foreign key. You can make a foreign key nullable by embedding the primary key\nand adding the \nNullable\n column tag modifier.\n\n\nFor example, to make the poster optional above.\n\n\ndata\n \nPostT\n \nf\n\n    \n=\n \nPost\n\n    \n{\n \npostId\n       \n::\n \nColumnar\n \nf\n \n(\nSqlSerial\n \nInt\n)\n\n    \n,\n \npostPostedAt\n \n::\n \nColumnar\n \nf\n \nLocalTime\n\n    \n,\n \npostContent\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npostPoster\n   \n::\n \nPrimaryKey\n \nPersonT\n \n(\nNullable\n \nf\n)\n\n    \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\n\n\n\n\nMore complicated relationships\n\n\nThis is the extent of beam's support for defining models. Although\nsimilar packages in other languages provide support for declaring\none-to-many, many-to-one, and many-to-many relationships, beam's\nfocused is providing a direct mapping of relational database concepts\nto Haskell, not on abstracting away the complexities of database\nquerying. Thus, beam does not use 'lazy-loading' or other tricks that\nobfuscate performance. Because of this, the bulk of the functionality\ndealing with different types of relations is found in the querying\nsupport, rather than in the model declarations.\n\n\nAlso, notice that beam does not allow you to specify any kind of reference\nconstraints between tables in your data types. This is because references are a\nproperty of the database, not a particular table schema. Such relationships can\nbe defined using the \nbeam-migrate\n package.\n\n\nEmbedding\n\n\nSometimes, we want to declare multiple models with fields in common. Beam allows\nyou to simple embed such fields in common types and embed those directly into\nmodels. For example, in\nthe\n\nChinook example schema\n,\nwe define the following structure for addresses.\n\n\ndata\n \nAddressMixin\n \nf\n\n  \n=\n \nAddress\n\n  \n{\n \naddress\n           \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \naddressCity\n       \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \naddressState\n      \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \naddressCountry\n    \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \naddressPostalCode\n \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\ntype\n \nAddress\n \n=\n \nAddressMixin\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \n(\nAddressMixin\n \nIdentity\n)\n\n\n\n\n\n\nWe can then use \nAddressMixin\n in our models.\n\n\ndata\n \nEmployeeT\n \nf\n\n  \n=\n \nEmployee\n\n  \n{\n \nemployeeId\n        \n::\n \nColumnar\n \nf\n \nInt32\n\n  \n,\n \nemployeeLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \nemployeeFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \nemployeeTitle\n     \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \nemployeeReportsTo\n \n::\n \nPrimaryKey\n \nEmployeeT\n \n(\nNullable\n \nf\n)\n\n  \n,\n \nemployeeBirthDate\n \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nLocalTime\n)\n\n  \n,\n \nemployeeHireDate\n  \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nLocalTime\n)\n\n  \n,\n \nemployeeAddress\n   \n::\n \nAddressMixin\n \nf\n\n  \n,\n \nemployeePhone\n     \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \nemployeeFax\n       \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \nemployeeEmail\n     \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\n-- ...\n\n\ndata\n \nCustomerT\n \nf\n\n  \n=\n \nCustomer\n\n  \n{\n \ncustomerId\n        \n::\n \nColumnar\n \nf\n \nInt32\n\n  \n,\n \ncustomerFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \ncustomerLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \ncustomerCompany\n   \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \ncustomerAddress\n   \n::\n \nAddressMixin\n \nf\n\n  \n,\n \ncustomerPhone\n     \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \ncustomerFax\n       \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \ncustomerEmail\n     \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \ncustomerSupportRep\n \n::\n \nPrimaryKey\n \nEmployeeT\n \n(\nNullable\n \nf\n)\n\n  \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\n\n\n\n\nDefaults\n\n\nBased on your data type declarations, beam can already guess a lot\nabout your tables. For example, it already assumes that the\n\npersonFirstName\n field is accessible in SQL as \nfirst_name\n. This\ndefaulting behavior makes it very easy to interact with typical\ndatabases.\n\n\nFor the easiest user experience, it's best to follow beam's\nconventions for declaring models. In particular, the defaulting\nmechanisms rely on each table type declaring only one constructor\nwhich has fields named in the camelCase style.\n\n\nWhen defaulting the name of a table field or column, beam\nun-camelCases the field name (after dropping leading underscores) and\ndrops the first word. The remaining words are joined with\nunderscores. If there is only one component, it is not\ndropped. Trailing and internal underscores are preserved in the name\nand if the name consists solely of underscores, beam makes no\nchanges. A summary of these rules is given in the table below.\n\n\n\n\n\n\n\n\nHaskell field name\n\n\nBeam defaulted column name\n\n\n\n\n\n\n\n\n\n\npersonFirstName\n\n\nfirst_name\n\n\n\n\n\n\n_personLastName\n\n\nlast_name\n\n\n\n\n\n\nname\n\n\nname\n\n\n\n\n\n\nfirst_name\n\n\nfirst_name\n\n\n\n\n\n\n_first_name\n\n\nfirst_name\n\n\n\n\n\n\n___\n (three underscores)\n\n\n___\n (no changes)\n\n\n\n\n\n\n\n\nNote that beam only uses lower case in field names. While typically\ncase does not matter for SQL queries, beam always quotes\nidentifiers. Many DBMS's are case-sensitive for quoted\nidentifiers. Thus, queries can sometimes fail if your tables use\nmixtures of lower- and upper-case to distinguish between fields.\n\n\nFor information on modifying the defaults, see the \nnext section\n.", 
            "title": "Models"
        }, 
        {
            "location": "/user-guide/models/#the-table-type-class", 
            "text": "Table  is a type class that must be instantiated for all types that you would\nlike to use as a table. It has one associated  data  instance and one function.  You must create a type to represent the primary key of the table. The primary\nkey of a table  Tbl  is the associated data type  PrimaryKey Tbl . Like  Tbl ,\nit takes one type parameter of kind  * -  * . It must have only one constructor\nwhich can hold all fields in the primary key. The constructor need not be a\nrecord constructor (although it can be).  You must also write a function  primaryKey  that takes an instance of  Tbl \n(parameterized over any functor  f ) and returns the associated  PrimaryKey \ntype. It is sometimes easiest to use the  Applicative  instance for  r -  to\nwrite this function. For example, if  tblField1  and  tblField2  are part of the\nprimary key, you can write  instance   Table   Tbl   where \n   data   PrimaryKey   Tbl   f   =   TblKey   ( Columnar   f   .. )   ( Columnar   f   .. ) \n   primaryKey   t   =   TblKey   ( tblField1   t )   ( tblField2   t )   more simply as  instance   Table   Tbl   where \n   data   PrimaryKey   Tbl   f   =   TblKey   ( Columnar   f   .. )   ( Columnar   f   .. ) \n   primaryKey   =   TblKey   $   tblField1   *   tblField2", 
            "title": "The Table type class"
        }, 
        {
            "location": "/user-guide/models/#the-identity-trick", 
            "text": "Beam table types are commonly prefixed by a  T  to indicate the name of the\ngeneric table type. Usually, a type synonym named by leaving out the  T  is\ndefined by applying the table to  Identity . Recall each field in the table is\neither another table or an application of  Columnar  to the type parameter. When\nthe type is parameterized by  Identity , every column is also parameterized by Identity .  Columnar  is a type family defined such that  Columnar Identity x ~ x . Thus,\nwhen parameterized over  Identity , every field in the table type takes on the\nunderlying Haskell type.  Suppose you have a table type  ModelT  and a type synonym  type Model = ModelT\nIdentity . Notice that deriving  Show ,  Eq , and other standard Haskell type\nclasses won't generally work for  ModelT . However, you can use the standalone\nderiving mechanism to derive these instances for  Model .  data   ModelT   f   =   Model   {   ..   }   deriving   ( Generic ,   Beamable )  -- deriving instance Show (ModelT f) -- Won t work because GHC won t get the constraints right  type   Model   =   ModelT   Identity  deriving   instance   Show   Model  deriving   instance   Eq   Model  deriving   instance   Ord   Model", 
            "title": "The Identity trick"
        }, 
        {
            "location": "/user-guide/models/#allowed-data-types", 
            "text": "Any data type can be used within a  Columnar . Beam does no checking that a\nfield can be used against a particular database when the data type is defined.\nInstead, type errors will occur when the table is being used as a query. For\nexample, the following is allowed, even though many backends will not work with\narray data types.  import   qualified   Data.Vector   as   V  data   ArrayTable   f \n     =   ArrayTable \n     {   arrayTablePoints   ::   Columnar   f   ( V . Vector   Int32 ) \n     }   deriving   Generic   You can construct values of type  ArrayTable Identity  and even write queries\nover it (relying on type inference to get the constraints right). However, if\nyou attempt to solve the constraints over a database that doesn't support\ncolumns of type  V.Vector Int32 , GHC will throw an error. Thus, it's important\nto understand the limits of your backend when deciding which types to use. In\ngeneral, numeric, floating-point, and text types are well supported.", 
            "title": "Allowed data types"
        }, 
        {
            "location": "/user-guide/models/#maybe-types", 
            "text": "Optional fields (those that allow a SQL  NULL ) can usually be given a  Maybe \ntype. However, you cannot use  Maybe  around an embedded table (you will be\nunable to instantiate  Beamable ).  Beam offers a way around this. Instead of embedding the table applied to the\ntype parameter  f , apply it to  Nullable f .  Columnar (Nullable f) a ~ Maybe\n(Columnar f a)  for all  a . Thus, this will make every column in the embedded\ntable take on the corresponding  Maybe  type.   Warning  Nullable  will nest  Maybe s. That is  Columnar (Nullable f) (Maybe a) ~\nMaybe (Maybe a) . This is bad from a SQL perspective, since SQL has no\nconcept of a nested optional type. Beam treats a  Nothing  at any 'layer' of\nthe  Maybe  stack as a corresponding SQL  NULL . When marshalling data back,\na SQL  NULL  is read in as a top-level  Nothing .  The reasons for this misfeature is basically code simplicity. Fixing this is\na top priority of future versions of beam.", 
            "title": "Maybe types"
        }, 
        {
            "location": "/user-guide/models/#column-tags", 
            "text": "Above, we saw that applying  Identity  to a table type results in a type whose\ncolumns are the underlying Haskell type. Beam uses other column tags for\nquerying and describing databases. Below is a table of common column tags and\ntheir meaning.", 
            "title": "Column tags"
        }, 
        {
            "location": "/user-guide/models/#converting-between-tags", 
            "text": "Suppose you have a  Beamable  type paramaterized over a tag  f  and needed one\nparameterized over a tag  g . Given a function  conv :: forall a. Columnar f a\n-  Columnar g a , you can use  changeBeamRep  to convert between the tables.  There is one caveat however -- since  Columnar  is a type family, the type of conv  is actually ambiguous. We need a way to carry the type of  f ,  g , and a  into the code. For this reason,  conv  must actually be written over the Columnar' (notice the tick)  newtype .  Columnar'  is a newtype defined as such  newtype   Columnar   f   a   =   Columnar   ( Columnar   f   a )   Notice that, unlinke  Columnar  (a non-injective type family),  Columnar'  is a\nfull type. The type of  conv' :: forall a. Columnar' f a -  Columnar' g a  is\nnow unambiguous. You can easily use  conv  to implement  conv' :  conv   ( Columnar   a )   =   Columnar   ( conv   a )", 
            "title": "Converting between tags"
        }, 
        {
            "location": "/user-guide/models/#the-beamable-type-class", 
            "text": "All beam tables, primary keys, and shared data fields must be instances of the Beamable  class. You cannot override the methods of  Beamable . Rather, they\nare derived using GHC's generics mechanism. Once you've declared your data type,\nyou can simply write  instance Beamable  your-type-name  to instantiate the\ncorrect  Beamable  instance for your type.", 
            "title": "The Beamable type class"
        }, 
        {
            "location": "/user-guide/models/#the-table-type-class_1", 
            "text": "All  Beamable  data types that you want to include as a  TableEntity  in your\ndatabase must be members of the  Table  type class. The  Table  type class\ndefines one associated type family  PrimaryKey  and a function  primaryKey  that\ntakes a table over an arbitrary column tag and produces that table's PrimaryKey . For example, if you have a model  data   PersonT   f \n     =   Person \n     {   personEmail       ::   Columnar   f   Text \n     ,   personFirstName   ::   Columnar   f   Text \n     ,   personLastName    ::   Columnar   f   Text \n     ,   personAge         ::   Columnar   f   Int \n     }   deriving   ( Generic ,   Beamable )   and you want the  personEmail  field to form the primary key, you would define a  Table  instance as such  instance   Table   PersonT   where \n   data   PrimaryKey   PersonT   f \n       =   PersonKey   ( Columnar   f   Text )   deriving   ( Generic ,   Beamable ) \n   primaryKey   person   =   PersonKey   $   personEmail    Tip  Many people find it useful to use the  Applicative  instance for  (- ) a  to\nwrite  primaryKey . For example, we could have written the above  primaryKey\nperson = PersonKey (personFirstName person) (personLastName person)  as primaryKey = PersonKey  $  personFirstName  *  personLastName .    Tip  Typing  Columnar  may become tiresome.  Database.Beam  also exports  C  as a\ntype alias for  Columnar , which may make writing models easier. Since  C \nmay cause name clashes, all examples are given using  Columnar .   Many also like defining type synonyms for their table and primary key types. For\nexample, for the table  PersonT  above, a programmer may define.  type   Person   =   PersonT   Identity  type   PersonKey   =   PrimaryKey   PersonT   Identity  deriving   instance   Show   Person ;   deriving   instance   Eq   Person  deriving   instance   Show   PersonKey ;   deriving   instance   Eq   PersonKey   By convention, beam table types are suffixed with  T  to distinguish their type\nnames from the same type parameterized over  Identity  (the 'regular' Haskell\ndata type).", 
            "title": "The Table type class"
        }, 
        {
            "location": "/user-guide/models/#what-about-tables-without-primary-keys", 
            "text": "Tables without primary keys are considered bad style. However, sometimes you\nneed to use beam with a schema that you have no control over. To declare a table\nwithout a primary key, simply instantiate the  Table  class and set  PrimaryKey\ntbl  to a type with no fields. Then just produce this type in  primaryKey .  For example  data   BadT   f \n   =   BadT \n   {   badFirstName   ::   C   f   Text \n   ,   badLastName    ::   C   f   Text \n   }   deriving   ( Generic ,   Beamable )  instance   Beamable   BadT  instance   Table   BadT   where \n   data   PrimaryKey   BadT   f   =   BadNoId \n     deriving   ( Generic ,   Beamable ) \n   primaryKey   _   =   BadNoId", 
            "title": "What about tables without primary keys?"
        }, 
        {
            "location": "/user-guide/models/#foreign-references", 
            "text": "Foreign references are also easily supported in models by simply\nembedding the  PrimaryKey  of the referred to table directly in the\nparent. For example, suppose we want to create a new model\nrepresenting a post by a user.  data   PostT   f \n     =   Post \n     {   postId         ::   Columnar   f   ( SqlSerial   Int ) \n     ,   postPostedAt   ::   Columnar   f   LocalTime \n     ,   postContent    ::   Columnar   f   Text \n     ,   postPoster     ::   PrimaryKey   PersonT   f \n     }   deriving   ( Generic ,   Beamable )  instance   Table   PostT   where \n   data   PrimaryKey   PostT   f \n       =   PostId   ( Columnar   f   ( SqlSerial   Int ))   deriving   ( Generic ,   Beamable ) \n   primaryKey   =   PostId   .   postId  type   Post   =   PostT   Identity  type   PostId   =   PrimaryKey   PostT   Identity  deriving   instance   Show   Post ;   deriving   instance   Eq   Post  deriving   instance   Show   PostId ;   deriving   instance   Eq   PostId", 
            "title": "Foreign references"
        }, 
        {
            "location": "/user-guide/models/#nullable-foreign-references", 
            "text": "Above, any non-bottom value of type  PostT Identity  must carry a concrete value\nof  PrimaryKey PersonT Identity . Sometimes, you may want to optionally include\na foreign key. You can make a foreign key nullable by embedding the primary key\nand adding the  Nullable  column tag modifier.  For example, to make the poster optional above.  data   PostT   f \n     =   Post \n     {   postId         ::   Columnar   f   ( SqlSerial   Int ) \n     ,   postPostedAt   ::   Columnar   f   LocalTime \n     ,   postContent    ::   Columnar   f   Text \n     ,   postPoster     ::   PrimaryKey   PersonT   ( Nullable   f ) \n     }   deriving   ( Generic ,   Beamable )", 
            "title": "Nullable foreign references"
        }, 
        {
            "location": "/user-guide/models/#more-complicated-relationships", 
            "text": "This is the extent of beam's support for defining models. Although\nsimilar packages in other languages provide support for declaring\none-to-many, many-to-one, and many-to-many relationships, beam's\nfocused is providing a direct mapping of relational database concepts\nto Haskell, not on abstracting away the complexities of database\nquerying. Thus, beam does not use 'lazy-loading' or other tricks that\nobfuscate performance. Because of this, the bulk of the functionality\ndealing with different types of relations is found in the querying\nsupport, rather than in the model declarations.  Also, notice that beam does not allow you to specify any kind of reference\nconstraints between tables in your data types. This is because references are a\nproperty of the database, not a particular table schema. Such relationships can\nbe defined using the  beam-migrate  package.", 
            "title": "More complicated relationships"
        }, 
        {
            "location": "/user-guide/models/#embedding", 
            "text": "Sometimes, we want to declare multiple models with fields in common. Beam allows\nyou to simple embed such fields in common types and embed those directly into\nmodels. For example, in\nthe Chinook example schema ,\nwe define the following structure for addresses.  data   AddressMixin   f \n   =   Address \n   {   address             ::   Columnar   f   ( Maybe   Text ) \n   ,   addressCity         ::   Columnar   f   ( Maybe   Text ) \n   ,   addressState        ::   Columnar   f   ( Maybe   Text ) \n   ,   addressCountry      ::   Columnar   f   ( Maybe   Text ) \n   ,   addressPostalCode   ::   Columnar   f   ( Maybe   Text ) \n   }   deriving   ( Generic ,   Beamable )  type   Address   =   AddressMixin   Identity  deriving   instance   Show   ( AddressMixin   Identity )   We can then use  AddressMixin  in our models.  data   EmployeeT   f \n   =   Employee \n   {   employeeId          ::   Columnar   f   Int32 \n   ,   employeeLastName    ::   Columnar   f   Text \n   ,   employeeFirstName   ::   Columnar   f   Text \n   ,   employeeTitle       ::   Columnar   f   ( Maybe   Text ) \n   ,   employeeReportsTo   ::   PrimaryKey   EmployeeT   ( Nullable   f ) \n   ,   employeeBirthDate   ::   Columnar   f   ( Maybe   LocalTime ) \n   ,   employeeHireDate    ::   Columnar   f   ( Maybe   LocalTime ) \n   ,   employeeAddress     ::   AddressMixin   f \n   ,   employeePhone       ::   Columnar   f   ( Maybe   Text ) \n   ,   employeeFax         ::   Columnar   f   ( Maybe   Text ) \n   ,   employeeEmail       ::   Columnar   f   ( Maybe   Text ) \n   }   deriving   ( Generic ,   Beamable )  -- ...  data   CustomerT   f \n   =   Customer \n   {   customerId          ::   Columnar   f   Int32 \n   ,   customerFirstName   ::   Columnar   f   Text \n   ,   customerLastName    ::   Columnar   f   Text \n   ,   customerCompany     ::   Columnar   f   ( Maybe   Text ) \n   ,   customerAddress     ::   AddressMixin   f \n   ,   customerPhone       ::   Columnar   f   ( Maybe   Text ) \n   ,   customerFax         ::   Columnar   f   ( Maybe   Text ) \n   ,   customerEmail       ::   Columnar   f   Text \n   ,   customerSupportRep   ::   PrimaryKey   EmployeeT   ( Nullable   f ) \n   }   deriving   ( Generic ,   Beamable )", 
            "title": "Embedding"
        }, 
        {
            "location": "/user-guide/models/#defaults", 
            "text": "Based on your data type declarations, beam can already guess a lot\nabout your tables. For example, it already assumes that the personFirstName  field is accessible in SQL as  first_name . This\ndefaulting behavior makes it very easy to interact with typical\ndatabases.  For the easiest user experience, it's best to follow beam's\nconventions for declaring models. In particular, the defaulting\nmechanisms rely on each table type declaring only one constructor\nwhich has fields named in the camelCase style.  When defaulting the name of a table field or column, beam\nun-camelCases the field name (after dropping leading underscores) and\ndrops the first word. The remaining words are joined with\nunderscores. If there is only one component, it is not\ndropped. Trailing and internal underscores are preserved in the name\nand if the name consists solely of underscores, beam makes no\nchanges. A summary of these rules is given in the table below.     Haskell field name  Beam defaulted column name      personFirstName  first_name    _personLastName  last_name    name  name    first_name  first_name    _first_name  first_name    ___  (three underscores)  ___  (no changes)     Note that beam only uses lower case in field names. While typically\ncase does not matter for SQL queries, beam always quotes\nidentifiers. Many DBMS's are case-sensitive for quoted\nidentifiers. Thus, queries can sometimes fail if your tables use\nmixtures of lower- and upper-case to distinguish between fields.  For information on modifying the defaults, see the  next section .", 
            "title": "Defaults"
        }, 
        {
            "location": "/user-guide/databases/", 
            "text": "In addition to defining types for each of your tables, beam also\nrequires you to declare your database as a type with fields for\nholding all entities in your database. This includes more than just\ntables. For example, user-defined types that you would like to work\nwith must also be included in your database type.\n\n\nA simple database type\n\n\nLike tables, a database type takes a functor and applies it to each\nentity in the database. For example, a database type for the two\ntables defined above has the form.\n\n\ndata\n \nExampleDb\n \nf\n\n    \n=\n \nExampleDb\n\n    \n{\n \npersons\n \n::\n \nf\n \n(\nTableEntity\n \nPersonT\n)\n\n    \n,\n \nposts\n   \n::\n \nf\n \n(\nTableEntity\n \nPostT\n)\n\n    \n}\n \nderiving\n \n(\nGeneric\n,\n \nDatabase\n \nbe\n)\n\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n\n\n\n\n\n\nOther database entities\n\n\nViews\n\n\nSome databases also offer the concept of 'views' -- pseudo-tables that\nare built from a pre-defined query. Suppose we wanted to create a view\nthat returned the latest comments and their respective posters.\n\n\ndata\n \nPostAndPosterView\n \nf\n\n    \n=\n \nPostAndPosterView\n\n    \n{\n \npost\n   \n::\n \nPostT\n \nf\n\n    \n,\n \nposter\n \n::\n \nPersonT\n \nf\n\n    \n}\n \nderiving\n \n(\nGeneric\n,\n \nBeamable\n)\n\n\n\n\n\n\nWe can include this in our database:\n\n\ndata\n \nExampleDb\n \nf\n\n    \n=\n \nExampleDb\n\n    \n{\n \npersons\n        \n::\n \nf\n \n(\nTableEntity\n \nPersonT\n)\n\n    \n,\n \nposts\n          \n::\n \nf\n \n(\nTableEntity\n \nPostT\n)\n\n    \n,\n \npostAndPosters\n \n::\n \nf\n \n(\nViewEntity\n \nPostAndPosterView\n)\n\n    \n}\n \nderiving\n \n(\nGeneric\n,\n \nDatabase\n \nbe\n)\n\n\n\n\n\n\nNow we can use \npostAndPosters\n wherever we'd use a table. Note that you do not\nneed to specify the definition of the view. The definition is not important to\naccess the view, so beam does not need to know about it at the type-level. If\nyou want to manipulate view definitions, use the migrations package.\n\n\nNote that the \nall_\n query primitive requires a \nTableEntity\n. Thus, \nall_\n(postAndPosters exampleDb)\n will fail to type-check. Use the \nallFromView_\n\ncombinator instead.\n\n\n\n\nNote\n\n\nYou could also declare a view as a \nTableEntity\n. The main advantage of\ndeclaring an entity as \nViewEntity\n is that you will be prevented by the\nHaskell type system from constructing \nINSERT\ns, \nUPDATE\ns, and \nDELETE\ns\nusing your view. Also, \nbeam-migrate\n will not recognize database schema\nequivalence if a view is declared as a table or vice versa.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain types\n\n\nDomain types are a way of creating new database types with additional\nconstraints. Beam supports declaring these types as part of your\ndatabase, so they can be used anywhere a data type can. In order to\nuse your domain type, you need to supply beam a Haskell newtype that\nis used to represent values of this type in Haskell.\n\n\nCharacter sets\n\n\nBeam does not yet support character sets. Support is planned in future releases.\n\n\nCollations\n\n\nBeam does not yet support collations. Support is planned in future releases.\n\n\nTranslations\n\n\nBeam does not yet support translations. Support is planned in future releases.\n\n\nOther database entities\n\n\nOther standard SQL database entities (like triggers) are defined by\n\nbeam-migrate\n as they have no effect on query semantics.\n\n\nDatabase descriptors\n\n\nIn order to interact with the database, beam needs to know more about\nthe data structure, it also needs to know how to refer to each entity\nin your database. For the most part, beam can figure out the names for\nyou using its Generics-based defaulting mechanims. Once you have a\ndatabase type defined, you can create a database descriptor using the\n\ndefaultDbSettings\n function.\n\n\nFor example, to create a backend-agnostic database descriptor for the\n\nExampleDb\n type:\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n\n\n\n\n\n\nThe \ndefaultDbSettings\n function produces a settings value where each entity is\ngiven a default name as explained in the \nprevious section\n.\n\n\nNow, we can use the entities in \nexampleDb\n to write queries. The\nrules for name defaulting for database entities are the same as those\nfor \ntable fields\n\n\nModifying the defaults\n\n\nThe \nwithDbModification\n function can be used to modify the output of the\n\ndefaultDbSettings\n. It combines a database settings value with a \ndatabase\nmodifications value\n. The easiest way to construct a database modification value\nis with the \ndbModification\n function, which produces a modification that makes\nno changes.\n\n\nYou can then use Haskell record syntax to specify table or other entity\nmodifications. Modifications can be combined with the \n(\n)\n semigroup operator.\n\n\nOne common operation is renaming an entity. The \nsetEntityName\n\nfunction can be used to set the name of any entity (table, view,\netc). The \nmodifyEntityName\n function can be used to derive a new name\nbased on the default-assigned beam one.\n\n\nAnother common operation is renaming table fields. You can use the\n\nmodifyTableFields\n modification for this. Simply pass a\n\ntableModification\n where each record contains the new name of the\nfield.\n\n\nFor example, to rename the \npersons\n table as \npeople\n in the database above,\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n            \ndbModification\n \n{\n\n              \npersons\n \n=\n \nsetEntityName\n \npeople\n\n            \n}\n\n\n\n\n\n\nOr, to keep the \npersons\n table named as it is, but change the name of\nthe \npersonEmail\n field from \n\"email\"\n to \n\"email_address\"\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n            \ndbModification\n \n{\n\n              \npersons\n \n=\n \nmodifyTableFields\n\n                          \ntableModification\n \n{\n\n                            \npersonEmail\n \n=\n \nfieldNamed\n \nemail_address\n\n                          \n}\n\n            \n}\n\n\n\n\n\n\nTo do both,\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n            \ndbModification\n \n{\n\n              \npersons\n \n=\n \nsetEntityName\n \npeople\n \n\n                        \nmodifyTableFields\n\n                          \ntableModification\n \n{\n\n                            \npersonEmail\n \n=\n \nfieldNamed\n \nemail_address\n\n                          \n}\n\n            \n}\n\n\n\n\n\n\nAn appropriate \nIsString\n instance is also given so you can avoid the use of\n\nfieldNamed\n. For example, the above is equivalent to\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n            \ndbModification\n \n{\n\n              \npersons\n \n=\n \nsetEntityName\n \npeople\n \n\n                        \nmodifyTableFields\n\n                          \ntableModification\n \n{\n\n                            \npersonEmail\n \n=\n \nemail_address\n\n                          \n}\n\n            \n}", 
            "title": "Databases"
        }, 
        {
            "location": "/user-guide/databases/#a-simple-database-type", 
            "text": "Like tables, a database type takes a functor and applies it to each\nentity in the database. For example, a database type for the two\ntables defined above has the form.  data   ExampleDb   f \n     =   ExampleDb \n     {   persons   ::   f   ( TableEntity   PersonT ) \n     ,   posts     ::   f   ( TableEntity   PostT ) \n     }   deriving   ( Generic ,   Database   be )  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings", 
            "title": "A simple database type"
        }, 
        {
            "location": "/user-guide/databases/#other-database-entities", 
            "text": "", 
            "title": "Other database entities"
        }, 
        {
            "location": "/user-guide/databases/#views", 
            "text": "Some databases also offer the concept of 'views' -- pseudo-tables that\nare built from a pre-defined query. Suppose we wanted to create a view\nthat returned the latest comments and their respective posters.  data   PostAndPosterView   f \n     =   PostAndPosterView \n     {   post     ::   PostT   f \n     ,   poster   ::   PersonT   f \n     }   deriving   ( Generic ,   Beamable )   We can include this in our database:  data   ExampleDb   f \n     =   ExampleDb \n     {   persons          ::   f   ( TableEntity   PersonT ) \n     ,   posts            ::   f   ( TableEntity   PostT ) \n     ,   postAndPosters   ::   f   ( ViewEntity   PostAndPosterView ) \n     }   deriving   ( Generic ,   Database   be )   Now we can use  postAndPosters  wherever we'd use a table. Note that you do not\nneed to specify the definition of the view. The definition is not important to\naccess the view, so beam does not need to know about it at the type-level. If\nyou want to manipulate view definitions, use the migrations package.  Note that the  all_  query primitive requires a  TableEntity . Thus,  all_\n(postAndPosters exampleDb)  will fail to type-check. Use the  allFromView_ \ncombinator instead.   Note  You could also declare a view as a  TableEntity . The main advantage of\ndeclaring an entity as  ViewEntity  is that you will be prevented by the\nHaskell type system from constructing  INSERT s,  UPDATE s, and  DELETE s\nusing your view. Also,  beam-migrate  will not recognize database schema\nequivalence if a view is declared as a table or vice versa.", 
            "title": "Views"
        }, 
        {
            "location": "/user-guide/databases/#domain-types", 
            "text": "Domain types are a way of creating new database types with additional\nconstraints. Beam supports declaring these types as part of your\ndatabase, so they can be used anywhere a data type can. In order to\nuse your domain type, you need to supply beam a Haskell newtype that\nis used to represent values of this type in Haskell.", 
            "title": "Domain types"
        }, 
        {
            "location": "/user-guide/databases/#character-sets", 
            "text": "Beam does not yet support character sets. Support is planned in future releases.", 
            "title": "Character sets"
        }, 
        {
            "location": "/user-guide/databases/#collations", 
            "text": "Beam does not yet support collations. Support is planned in future releases.", 
            "title": "Collations"
        }, 
        {
            "location": "/user-guide/databases/#translations", 
            "text": "Beam does not yet support translations. Support is planned in future releases.", 
            "title": "Translations"
        }, 
        {
            "location": "/user-guide/databases/#other-database-entities_1", 
            "text": "Other standard SQL database entities (like triggers) are defined by beam-migrate  as they have no effect on query semantics.", 
            "title": "Other database entities"
        }, 
        {
            "location": "/user-guide/databases/#database-descriptors", 
            "text": "In order to interact with the database, beam needs to know more about\nthe data structure, it also needs to know how to refer to each entity\nin your database. For the most part, beam can figure out the names for\nyou using its Generics-based defaulting mechanims. Once you have a\ndatabase type defined, you can create a database descriptor using the defaultDbSettings  function.  For example, to create a backend-agnostic database descriptor for the ExampleDb  type:  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   The  defaultDbSettings  function produces a settings value where each entity is\ngiven a default name as explained in the  previous section .  Now, we can use the entities in  exampleDb  to write queries. The\nrules for name defaulting for database entities are the same as those\nfor  table fields", 
            "title": "Database descriptors"
        }, 
        {
            "location": "/user-guide/databases/#modifying-the-defaults", 
            "text": "The  withDbModification  function can be used to modify the output of the defaultDbSettings . It combines a database settings value with a  database\nmodifications value . The easiest way to construct a database modification value\nis with the  dbModification  function, which produces a modification that makes\nno changes.  You can then use Haskell record syntax to specify table or other entity\nmodifications. Modifications can be combined with the  ( )  semigroup operator.  One common operation is renaming an entity. The  setEntityName \nfunction can be used to set the name of any entity (table, view,\netc). The  modifyEntityName  function can be used to derive a new name\nbased on the default-assigned beam one.  Another common operation is renaming table fields. You can use the modifyTableFields  modification for this. Simply pass a tableModification  where each record contains the new name of the\nfield.  For example, to rename the  persons  table as  people  in the database above,  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   ` withDbModification ` \n             dbModification   { \n               persons   =   setEntityName   people \n             }   Or, to keep the  persons  table named as it is, but change the name of\nthe  personEmail  field from  \"email\"  to  \"email_address\"  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   ` withDbModification ` \n             dbModification   { \n               persons   =   modifyTableFields \n                           tableModification   { \n                             personEmail   =   fieldNamed   email_address \n                           } \n             }   To do both,  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   ` withDbModification ` \n             dbModification   { \n               persons   =   setEntityName   people   \n                         modifyTableFields \n                           tableModification   { \n                             personEmail   =   fieldNamed   email_address \n                           } \n             }   An appropriate  IsString  instance is also given so you can avoid the use of fieldNamed . For example, the above is equivalent to  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   ` withDbModification ` \n             dbModification   { \n               persons   =   setEntityName   people   \n                         modifyTableFields \n                           tableModification   { \n                             personEmail   =   email_address \n                           } \n             }", 
            "title": "Modifying the defaults"
        }, 
        {
            "location": "/user-guide/backends/", 
            "text": "Beam is backend-agnostic and doesn't provide any means to connect to a\ndatabase. Beam backend libraries usually use well-used Haskell\nlibraries to provide database connectivity. For example, the\n\nbeam-sqlite\n backend uses the \nsqlite-simple\n backend.\n\n\nBeam distinguishes each backend via type indexes. Each backend defines\na type that is used to enable backend-specific behavior. For example,\nthe \nbeam-sqlite\n backend ships with the \nSqlite\n type that is used to\ndistinguish sqlite specific constructs with generic or other\nbackend-specific ones.\n\n\nEach backend can have one or more 'syntaxes', which are particular\nways to query the database. While the \nbeam-core\n library ships with a\nstandard ANSI SQL builder, few real-world database implementations\nfully follow the standard. Most backends use their own custom syntax\ntype. Internally, beam uses a finally-tagless representation for\nsyntax trees that allow straightforward construction against any\nbackend.\n\n\nBeam offers backend-generic functions for the most common operations\nagainst databases. These functions are meant to fit the lowest common\ndenominator. For example, no control is offered over streaming results\nfrom SELECT statements. While these backend-generic functions are\nuseful for ad-hoc querying and development, it is wisest to use\nbackend-specific functions in production for maximum control. Refer to\nbackend-specific documentation for more information.\n\n\nFor our examples, we will use the \nbeam-sqlite\n backend and demonstrate\nusage of the beam standard query functions.\n\n\nConnecting to a database\n\n\nOkay, so we can print out a SQL statement, but how do we execute it against a\ndatabase? Beam provides a convenient \nMonadBeam\n type class that allows us to\nwrite queries in a backend agnostic manner. This is good-enough for most\napplications and preserves portability across databases. However, \nMonadBeam\n\ndoes not support features specific to each backend, nor does it guarantee the\nhighest-performance. Most backends provide additional methods to query a\ndatabase, and you should prefer these if you've committed to a particular\nbackend. For tutorial purposes, we will use the \nbeam-sqlite\n backend.\n\n\nFirst, install \nbeam-sqlite\n with \ncabal\n or \nstack\n:\n\n\n$ cabal install beam-sqlite\n\n# or\n\n$ stack install beam-sqlite\n\n\n\n\n\nNow, load \nbeam-sqlite\n in GHCi. \n\n\nPrelude\n \nimport\n \nDatabase.Beam.Sqlite\n\n\nPrelude\n \nDatabase\n.\nBeam\n.\nSqlite\n \n\n\n\n\n\nNow, in another terminal, load the example database provided. \n\n\n$ sqlite3 basics.db \n beam-sqlite/examples/basics.sql\n\n\n\n\n\nNow, back in GHCi, we can create a connection to this database.\n\n\nPrelude\n \nDatabase.Beam.Sqlite\n \nbasics\n \n-\n \nopen\n \nbasics.db\n\n\nPrelude\n \nDatabase.Beam.Sqlite\n \nrunBeamSqlite\n \nbasics\n \n$\n \nrunSelectReturningList \n(\nselect \n(\nall_ \n(\npersons\n \nexampleDb\n)))\n\n\n[\n \n..\n \n]\n\n\n\n\n\n\nThe \nrunSelectReturningList\n function takes a \nSqlSelect\n for the given syntax\nand returns the results via a list.\n\n\nVoil\u00e0! We've successfully created our first query and run it against an example\ndatabase. We have now seen the major functionalities of the beam library. In the\nnext section we'll explore more advanced querying and using relationships\nbetween tables.\n\n\nInserting data\n\n\nFirst, let's connect to a sqlite database, and create our schema. The\n\nbeam-core\n does not offer any support for the SQL DDL language. There\nis a separate core library \nbeam-migrate\n that offers complete support\nfor ANSI-standard SQL DDL operations, as well as tools to manipulate\ndatabase schemas. See the section on migrations for more information.\n\n\nFor our example, we will simply issue a \nCREATE TABLE\n command\ndirectly against the database using \nsqlite-simple\n functionality:\n\n\nPrelude Schema\n execute_ conn \nCREATE TABLE persons ( first_name TEXT NOT NULL, last_name TEXT NOT NULL, age INT NOT NULL, PRIMARY KEY(first_name, last_name) )\n\n\n\n\n\n\nNow we can insert some data into our database. \nbeam-sqlite\n ships with a\nfunction \nrunBeamSqlite\n, with the following signature:\n\n\nrunBeamSqlite\n \n::\n \nConnection\n \n-\n \nSqliteM\n \na\n \n-\n \nIO\n \na\n\n\n\n\n\n\nbeam-sqlite\n uses the \nsqlite-simple\n library, so its handle type is\n\nConnection\n from \nDatabase.SQLite.Simple\n.\n\n\nSqliteM\n is a monad implementing \nMonadBeam\n which we can use to construct\ndatabase actions from individual SQL commands (select, insert, update, delete).\n\nMonadBeam\n is a type class that relates a particular SQL syntax (\nsyntax\n) to a\nbackend (\nbe\n), and a command monad (\nm\n). Inside the \nm\n monad, we can execute\ndata query and manipulation commands.\n\n\nLet's insert some data into our database. We are going to use the \nrunInsert\n\nfunction from \nMonadBeam\n. INSERTs are discussed in more detail in\nthe \ndata manipulation guide\n.\n\n\nPrelude Schema\n :{\nPrelude Schema| runBeamSqlite conn $ do\nPrelude Schema|   runInsert $ insert (persons exampleDb) $\nPrelude Schema|               insertValues [ Person \nBob\n \nSmith\n 50\nPrelude Schema|                            , Person \nAlice\n \nWong\n 55\nPrelude Schema|                            , Person \nJohn\n \nQuincy\n 30 ]\nPrelude Schema| :}\n\n\n\n\n\nThe \nrunInsert\n function has the type signature\n\n\nrunInsert\n \n::\n \nMonadBeam\n \nsyntax\n \nbe\n \nm\n \n=\n \nSqlInsert\n \nsyntax\n \n-\n \nm\n \n()\n\n\n\n\n\n\nSqlInsert syntax\n represents a SQL \nINSERT\n command in the given\n\nsyntax\n. We construct this value using the \ninsert\n function from\n\nDatabase.Beam.Query\n.\n\n\ninsert\n \n::\n \nIsSql92InsertSyntax\n \nsyntax\n \n=\n\n          \nDatabaseEntity\n \nbe\n \ndb\n \n(\nTableEntity\n \ntable\n)\n\n       \n-\n \nSql92InsertValuesSyntax\n \nsyntax\n\n       \n-\n \nSqlInsert\n \nsyntax\n\n\n\n\n\n\nIntuitively, \ninsert\n takes a database table descriptor and some\nvalues (particular to the given syntax) and returns a statement to\ninsert these values. \nSql92InsertValuesSyntax syntax\n always\nimplements the \nIsSql92InsertValuesSyntax\n typeclass, which is where\nwe get the \ninsertValues\n function from. \nIsSql92InsertValuesSyntax\n\nalso defines the \ninsertSelect\n function for inserting values from the\nresult of a \nSELECT\n statement. Other backends may provide other ways\nof specifying the source of values.\n\n\nNow, we can query the database, using the \nrunSelect\n function. Like \nrunInsert\n\nand \ninsert\n, we use the \nselect\n function to construct a value of type\n\nSqlSelect syntax\n, which can be run inside \nMonadBeam\n.\n\n\nWe can use the \nrunBeamSqliteDebug\n function to install a hook that beam will\ncall with every SQL command it is about to run. In the following example, beam\nwill print its query to stdout via \nputStrLn\n. You can use this functionality to hook beam in to a logging framework.\n\n\nPrelude Schema\n runBeamSqliteDebug putStrLn conn $ runSelect (select (all_ (persons exampleDb)))\n[ Person { personFirstName = \nBob\n, personLastName=\nSmith\n, personAge=50 }, ... ]", 
            "title": "Backends"
        }, 
        {
            "location": "/user-guide/backends/#connecting-to-a-database", 
            "text": "Okay, so we can print out a SQL statement, but how do we execute it against a\ndatabase? Beam provides a convenient  MonadBeam  type class that allows us to\nwrite queries in a backend agnostic manner. This is good-enough for most\napplications and preserves portability across databases. However,  MonadBeam \ndoes not support features specific to each backend, nor does it guarantee the\nhighest-performance. Most backends provide additional methods to query a\ndatabase, and you should prefer these if you've committed to a particular\nbackend. For tutorial purposes, we will use the  beam-sqlite  backend.  First, install  beam-sqlite  with  cabal  or  stack :  $ cabal install beam-sqlite # or \n$ stack install beam-sqlite  Now, load  beam-sqlite  in GHCi.   Prelude   import   Database.Beam.Sqlite  Prelude   Database . Beam . Sqlite    Now, in another terminal, load the example database provided.   $ sqlite3 basics.db   beam-sqlite/examples/basics.sql  Now, back in GHCi, we can create a connection to this database.  Prelude   Database.Beam.Sqlite   basics   -   open   basics.db  Prelude   Database.Beam.Sqlite   runBeamSqlite   basics   $   runSelectReturningList  ( select  ( all_  ( persons   exampleDb )))  [   ..   ]   The  runSelectReturningList  function takes a  SqlSelect  for the given syntax\nand returns the results via a list.  Voil\u00e0! We've successfully created our first query and run it against an example\ndatabase. We have now seen the major functionalities of the beam library. In the\nnext section we'll explore more advanced querying and using relationships\nbetween tables.", 
            "title": "Connecting to a database"
        }, 
        {
            "location": "/user-guide/backends/#inserting-data", 
            "text": "First, let's connect to a sqlite database, and create our schema. The beam-core  does not offer any support for the SQL DDL language. There\nis a separate core library  beam-migrate  that offers complete support\nfor ANSI-standard SQL DDL operations, as well as tools to manipulate\ndatabase schemas. See the section on migrations for more information.  For our example, we will simply issue a  CREATE TABLE  command\ndirectly against the database using  sqlite-simple  functionality:  Prelude Schema  execute_ conn  CREATE TABLE persons ( first_name TEXT NOT NULL, last_name TEXT NOT NULL, age INT NOT NULL, PRIMARY KEY(first_name, last_name) )   Now we can insert some data into our database.  beam-sqlite  ships with a\nfunction  runBeamSqlite , with the following signature:  runBeamSqlite   ::   Connection   -   SqliteM   a   -   IO   a   beam-sqlite  uses the  sqlite-simple  library, so its handle type is Connection  from  Database.SQLite.Simple .  SqliteM  is a monad implementing  MonadBeam  which we can use to construct\ndatabase actions from individual SQL commands (select, insert, update, delete). MonadBeam  is a type class that relates a particular SQL syntax ( syntax ) to a\nbackend ( be ), and a command monad ( m ). Inside the  m  monad, we can execute\ndata query and manipulation commands.  Let's insert some data into our database. We are going to use the  runInsert \nfunction from  MonadBeam . INSERTs are discussed in more detail in\nthe  data manipulation guide .  Prelude Schema  :{\nPrelude Schema| runBeamSqlite conn $ do\nPrelude Schema|   runInsert $ insert (persons exampleDb) $\nPrelude Schema|               insertValues [ Person  Bob   Smith  50\nPrelude Schema|                            , Person  Alice   Wong  55\nPrelude Schema|                            , Person  John   Quincy  30 ]\nPrelude Schema| :}  The  runInsert  function has the type signature  runInsert   ::   MonadBeam   syntax   be   m   =   SqlInsert   syntax   -   m   ()   SqlInsert syntax  represents a SQL  INSERT  command in the given syntax . We construct this value using the  insert  function from Database.Beam.Query .  insert   ::   IsSql92InsertSyntax   syntax   = \n           DatabaseEntity   be   db   ( TableEntity   table ) \n        -   Sql92InsertValuesSyntax   syntax \n        -   SqlInsert   syntax   Intuitively,  insert  takes a database table descriptor and some\nvalues (particular to the given syntax) and returns a statement to\ninsert these values.  Sql92InsertValuesSyntax syntax  always\nimplements the  IsSql92InsertValuesSyntax  typeclass, which is where\nwe get the  insertValues  function from.  IsSql92InsertValuesSyntax \nalso defines the  insertSelect  function for inserting values from the\nresult of a  SELECT  statement. Other backends may provide other ways\nof specifying the source of values.  Now, we can query the database, using the  runSelect  function. Like  runInsert \nand  insert , we use the  select  function to construct a value of type SqlSelect syntax , which can be run inside  MonadBeam .  We can use the  runBeamSqliteDebug  function to install a hook that beam will\ncall with every SQL command it is about to run. In the following example, beam\nwill print its query to stdout via  putStrLn . You can use this functionality to hook beam in to a logging framework.  Prelude Schema  runBeamSqliteDebug putStrLn conn $ runSelect (select (all_ (persons exampleDb)))\n[ Person { personFirstName =  Bob , personLastName= Smith , personAge=50 }, ... ]", 
            "title": "Inserting data"
        }, 
        {
            "location": "/user-guide/expressions/", 
            "text": "Typing\n\n\nThe type of all SQL-level expressions is \nQGenExpr\n. See the \nquery tutorial\n for more information.\n\n\nIn many cases, you'd like to type the SQL-level result of an expression without\nhaving to give explicit types for the other \nQGenExpr\n parameters. You can do\nthis with the \nas_\n combinator and \n-XTypeApplications\n.\n\n\nThe following code types the literal 1 as a \nDouble\n.\n\n\nas_\n \n@\nDouble\n \n1\n\n\n\n\n\n\nThis is rarely needed, but there are a few cases where the beam types are too\ngeneral for the compiler to meaningfully infer types.\n\n\nLiterals\n\n\n\n\nInteger literals\n can be constructed using \nfromIntegral\n in the \nNum\n\n  typeclass. This means you can also just use a Haskell integer literal as a\n  \nQGenExpr\n in any context.\n\n\nRational literals\n can be constructed via \nfromRational\n in \nRational\n.\n  Regular Haskell rational literals will be automatically converted to\n  \nQGenExprs\n.\n\n\nText literals\n can be constructed via \nfromString\n in \nIsString\n. Again,\n  Haskell string constants will automatically be converted to \nQGenExprs\n,\n  although you may have to provide an explicit type, as different backends\n  support different text types natively.\n\n\nAll other literals\n can be constructed using the \nval_\n function in\n  \nSqlValable\n. This requires that there is an implementation of\n  \nHasSqlValueSyntax (Sql92ExpressionValueSyntax syntax) x\n for the type \nx\n in\n  the appropriate \nsyntax\n for the \nQGenExpr\n. For example, to construct a value\n  of type \nVector Int\n in the \nbeam-postgres\n backend.\n\n\n\n\nval_\n \n(\nV\n.\nfromList\n \n[\n1\n,\n \n2\n,\n \n3\n \n::\n \nInt\n])\n\n\n\n\n\n\n\n\nExplicit tables\n can be brought to the SQL value level by using \nval_\n as\n  well. For example, if you have an \nAddressT Identity\n named \na\n, \nval_ a ::\n  AddressT (QGenExpr context expr s)\n.\n\n\n\n\nUTF support\n\n\nAll included beam backends play nicely with UTF. New backends should also\nsupport UTF, if they support syntaxes and deserializers for \nString\n or \nText\n.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_\n \n(\n\\\ns\n \n-\n \ncustomerFirstName\n \ns\n \n==.\n \n\u3042\u304d\u3089\n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nFirstName\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLText \n\\12354\\12365\\12425\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nFirstName\n)\n \n=\n \n(\n\u3042\u304d\u3089\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \n=\n \n(\n\u3042\u304d\u3089\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nArithmetic\n\n\nArithmetic operations that are part of the \nFractional\n and \nNum\n classes can be\nused directly. For example, if \na\n and \nb\n are \nQGenExpr\ns of the same type,\nthen \na + b\n is a \nQGenExpr\n of the same type.\n\n\nBecause of the \ntoInteger\n class method in \nIntegral\n, \nQGenExpr\ns cannot\nimplement \nIntegral\n. Nevertheless, versions of \ndiv\n and \nmod\n are available as\n\ndiv_\n and \nmod_\n, respectively, having the corresponding type.\n\n\nComparison\n\n\nSQL comparison is not as simple as you may think. \nNULL\n handling in particular\nactually makes things rather complicated.  SQL comparison operators actually\nreturn a \ntri-state boolean\n, representing true, false, and \nunknown\n, which is\nthe result when two nulls are compared. Boolean combinators (\nAND\n and \nOR\n)\nhandle these values in different ways. Beam abstracts some of this difference\naway, if you ask it to.\n\n\nHaskell-like comparisons\n\n\nHaskell provides much more reasonable equality between potentially optional\nvalues. For example, \nNothing == Nothing\n always! SQL does not provide a similar\nguarantee. However, beam can emulate Haskell-like equality in SQL using the\n\n==.\n operator. This uses a \nCASE .. WHEN ..\n statement or a special operator\nthat properly handles \nNULL\ns in your given backend. Depending on your backend,\nthis can severely impact performance, but it's 'correct'.\n\n\nFor example, to find all customers living in Berlin:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_\n \n(\n\\\ns\n \n-\n \naddressCity\n \n(\ncustomerAddress\n \ns\n)\n \n==.\n \nval_\n \n(\nJust\n \nBerlin\n))\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\nt0\n.\nCity\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nt0\n.\nCity\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nt0\n.\nCity\n)\n=\n(\n?\n)\n\n      \nEND\n;\n\n\n\n-- With values: [SQLText \nBerlin\n,SQLInteger 1,SQLText \nBerlin\n,SQLInteger 0,SQLText \nBerlin\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCity\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n  \nFROM\n \n(\nBerlin\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCity\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nBerlin\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCity\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nBerlin\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nt0\n`\n.\n`\nCity\n`\n)\n \n=\n \n(\nBerlin\n)\n\n      \nEND\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that SQLite uses a \nCASE .. WHEN ..\n statement, while Postgres uses the\n\nIS NOT DISTINCT FROM\n operator.\n\n\nThe inequality operator is named \n/=.\n, as expected. Note that both \n==.\n and\n\n/=.\n return a SQL expression whose type is \nBool\n.\n\n\nSQL-like comparisons\n\n\nBeam also provides equality operators that act like their underlying SQL\ncounterparts. These operators map most directly to the SQL \n=\n and \n\noperators, but they require you to explicitly handle the possibility of\n\nNULL\ns. These operators are named \n==?.\n and \n/=?.\n respectively.\n\n\nUnlike \n==.\n and \n/=.\n, these operators return an expression of type\n\nSqlBool\n. \nSqlBool\n is a type that can only be manipulated as part of a SQL\nexpression, and cannot be serialized or deserialized to/from Haskell. You need\nto convert it to a \nBool\n value explicitly in order to get the result or use it\nwith more advanced operators, such as \nCASE .. WHEN ..\n.\n\n\nIn SQL, you can handle potentially unknown comparisons using the \nIS TRUE\n, \nIS\nNOT TRUE\n, \nIS FALSE\n, \nIS NOT FALSE\n, \nIS UNKNOWN\n, and \nIS NOT UNKNOWN\n\noperators. These are provided as the beam functions \nisTrue_\n, \nisNotTrue_\n,\netc. These each take a SQL expression of type \nSqlBool\n and return one of type\n\nBool\n.\n\n\nFor example, to join every employee and customer who live in the same city, but\nusing SQL-like equality and making sure the comparison really is true (i.e.,\ncustomers and employees who both have \nNULL\n cities will not be included).\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nc\n \n-\n \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n   \ne\n \n-\n \njoin_\n \n(\nemployee\n \nchinookDb\n)\n \n$\n \n\\\ne\n \n-\n\n        \nisTrue_\n \n(\naddressCity\n \n(\ncustomerAddress\n \nc\n)\n \n==?.\n \naddressCity\n \n(\nemployeeAddress\n \ne\n))\n\n   \npure\n \n(\nc\n,\n \ne\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres15\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres16\n,\n\n       \nt1\n.\nReportsTo\n \nAS\n \nres17\n,\n\n       \nt1\n.\nBirthDate\n \nAS\n \nres18\n,\n\n       \nt1\n.\nHireDate\n \nAS\n \nres19\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres20\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres21\n,\n\n       \nt1\n.\nState\n \nAS\n \nres22\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres24\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres25\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres26\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres27\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \n((\nt0\n.\nCity\n)\n=\n(\nt1\n.\nCity\n))\n \nIS\n \n1\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres15\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres16\n,\n\n       \nt1\n.\nReportsTo\n \nAS\n \nres17\n,\n\n       \nt1\n.\nBirthDate\n \nAS\n \nres18\n,\n\n       \nt1\n.\nHireDate\n \nAS\n \nres19\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres20\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres21\n,\n\n       \nt1\n.\nState\n \nAS\n \nres22\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres24\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres25\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres26\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres27\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \n((\nt0\n.\nCity\n)\n \n=\n \n(\nt1\n.\nCity\n))\n \nIS\n \nTRUE\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nEmployeeId\n`\n \nAS\n \n`\nres13\n`\n,\n\n       \n`\nt1\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres14\n`\n,\n\n       \n`\nt1\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres15\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres16\n`\n,\n\n       \n`\nt1\n`\n.\n`\nReportsTo\n`\n \nAS\n \n`\nres17\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBirthDate\n`\n \nAS\n \n`\nres18\n`\n,\n\n       \n`\nt1\n`\n.\n`\nHireDate\n`\n \nAS\n \n`\nres19\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres20\n`\n,\n\n       \n`\nt1\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres21\n`\n,\n\n       \n`\nt1\n`\n.\n`\nState\n`\n \nAS\n \n`\nres22\n`\n,\n\n       \n`\nt1\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres23\n`\n,\n\n       \n`\nt1\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres24\n`\n,\n\n       \n`\nt1\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres25\n`\n,\n\n       \n`\nt1\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres26\n`\n,\n\n       \n`\nt1\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres27\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nEmployee\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n((\n`\nt0\n`\n.\n`\nCity\n`\n)\n \n=\n \n(\n`\nt1\n`\n.\n`\nCity\n`\n))\n \nIS\n \nTRUE\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThinking of which \nIS ..\n operator to use can be confusing. If you have a\ndefault value you'd like to return in the case of an unknown comparison, use the\n\nunknownAs_\n function. For example, if we want to treat unknown values as \nTrue\n\ninstead (i.e, we want customers and employees who both have \nNULL\n cities to be\nincluded)\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nc\n \n-\n \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n   \ne\n \n-\n \njoin_\n \n(\nemployee\n \nchinookDb\n)\n \n$\n \n\\\ne\n \n-\n\n        \nunknownAs_\n \nTrue\n \n(\naddressCity\n \n(\ncustomerAddress\n \nc\n)\n \n==?.\n \naddressCity\n \n(\nemployeeAddress\n \ne\n))\n\n   \npure\n \n(\nc\n,\n \ne\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres15\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres16\n,\n\n       \nt1\n.\nReportsTo\n \nAS\n \nres17\n,\n\n       \nt1\n.\nBirthDate\n \nAS\n \nres18\n,\n\n       \nt1\n.\nHireDate\n \nAS\n \nres19\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres20\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres21\n,\n\n       \nt1\n.\nState\n \nAS\n \nres22\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres24\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres25\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres26\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres27\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \n((\nt0\n.\nCity\n)\n=\n(\nt1\n.\nCity\n))\n \nIS\n \nNOT\n \n0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres15\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres16\n,\n\n       \nt1\n.\nReportsTo\n \nAS\n \nres17\n,\n\n       \nt1\n.\nBirthDate\n \nAS\n \nres18\n,\n\n       \nt1\n.\nHireDate\n \nAS\n \nres19\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres20\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres21\n,\n\n       \nt1\n.\nState\n \nAS\n \nres22\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres24\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres25\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres26\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres27\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \n((\nt0\n.\nCity\n)\n \n=\n \n(\nt1\n.\nCity\n))\n \nIS\n \nNOT\n \nFALSE\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nEmployeeId\n`\n \nAS\n \n`\nres13\n`\n,\n\n       \n`\nt1\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres14\n`\n,\n\n       \n`\nt1\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres15\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres16\n`\n,\n\n       \n`\nt1\n`\n.\n`\nReportsTo\n`\n \nAS\n \n`\nres17\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBirthDate\n`\n \nAS\n \n`\nres18\n`\n,\n\n       \n`\nt1\n`\n.\n`\nHireDate\n`\n \nAS\n \n`\nres19\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres20\n`\n,\n\n       \n`\nt1\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres21\n`\n,\n\n       \n`\nt1\n`\n.\n`\nState\n`\n \nAS\n \n`\nres22\n`\n,\n\n       \n`\nt1\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres23\n`\n,\n\n       \n`\nt1\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres24\n`\n,\n\n       \n`\nt1\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres25\n`\n,\n\n       \n`\nt1\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres26\n`\n,\n\n       \n`\nt1\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres27\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nEmployee\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n((\n`\nt0\n`\n.\n`\nCity\n`\n)\n \n=\n \n(\n`\nt1\n`\n.\n`\nCity\n`\n))\n \nIS\n \nNOT\n \nFALSE\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nQuantified comparison\n\n\nSQL also allows comparisons to be \nquantified\n. For example, the SQL expression\n\na == ANY(b)\n evaluates to true only if one row of \nb\n is equal to \na\n.\nSimilarly, \na \n ALL(b)\n returns true if \na \n x\n for every \nx\n in \nb\n.\n\n\nThese are also supported using the \n==*.\n, \n/=*.\n, \n*.\n, \n*.\n, \n=*.\n, and\n\n=*.\n operators. Like their unquantified counterparts, these operators yield a\n\nQGenExpr\n of type \nBool\n. Unlike the unquantified operators, the second\nargument of these operators is of type \nQQuantified\n. You can create a\n\nQQuantified\n from a \nQGenExpr\n by using the \nanyOf_/anyIn_\n or \nallOf_/allIn_\n\nfunctions, which correspond to the \nANY\n and \nALL\n syntax respectively. \nanyOf_\n\nand \nallOf_\n take \nQ\n expressions (representing a query) and \nanyIn_\n and\n\nallIn_\n take lists of expressions.\n\n\nQuantified comparisons are always performed according to SQL semantics, meaning\nthat they return values of type \nSqlBOol\n. This is because proper NULL handling\nwith quantified comparisons cannot be expressed in a reasonable way. Use the\nfunctions described in \nthe section above\n.\n\n\nFor example, to get all invoice lines containing tracks longer than 3 minutes:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ntracksLongerThanThreeMinutes\n \n=\n\n      \nfmap\n \ntrackId\n \n$\n\n      \nfilter_\n \n(\n\\\nt\n \n-\n \ntrackMilliseconds\n \nt\n \n=.\n \n180000\n)\n \n$\n\n        \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\nin\n \nfilter_\n \n(\n\\\nln\n \n-\n \nlet\n \nTrackId\n \nlnTrackId\n \n=\n \ninvoiceLineTrack\n \nln\n\n                   \nin\n \nunknownAs_\n \nFalse\n \n(\nlnTrackId\n \n==*.\n \nanyOf_\n \ntracksLongerThanThreeMinutes\n))\n \n$\n\n     \nall_\n \n(\ninvoiceLine\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceLineId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nInvoiceId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres3\n,\n\n       \nt0\n.\nQuantity\n \nAS\n \nres4\n\n\nFROM\n \nInvoiceLine\n \nAS\n \nt0\n\n\nWHERE\n \n((\nt0\n.\nTrackId\n)\n \n=\n \nANY\n\n         \n(\nSELECT\n \nsub_t0\n.\nTrackId\n \nAS\n \nres0\n\n          \nFROM\n \nTrack\n \nAS\n \nsub_t0\n\n          \nWHERE\n \n(\nsub_t0\n.\nMilliseconds\n)\n \n=\n \n(\n180000\n)))\n \nIS\n \nTRUE\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceLineId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nQuantity\n`\n \nAS\n \n`\nres4\n`\n\n\nFROM\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n((\n`\nt0\n`\n.\n`\nTrackId\n`\n)\n \n=\n \nANY\n \n(\n\n                                 \n(\nSELECT\n \n`\nsub_t0\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres0\n`\n\n                                  \nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nsub_t0\n`\n\n                                  \nWHERE\n \n(\n`\nsub_t0\n`\n.\n`\nMilliseconds\n`\n)\n \n=\n \n(\n180000\n))))\n \nIS\n \nTRUE\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can also supply a concrete list of values. For example to get everyone living\nin either Los Angeles or Manila:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_\n \n(\n\\\nc\n \n-\n  \nunknownAs_\n \nFalse\n \n(\naddressCity\n \n(\ncustomerAddress\n \nc\n)\n \n==*.\n \nanyIn_\n \n[\n \njust_\n \nLos Angeles\n,\n \njust_\n \nManila\n \n]))\n \n$\n\n     \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n((\nt0\n.\nCity\n)\n \n=\n \nANY\n \n(\n\n                            \nVALUES\n \n(\nLos Angeles\n),\n \n(\nManila\n)))\n \nIS\n \nTRUE\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe \nIN\n predicate\n\n\nYou can also use \nin_\n to use the common \nIN\n predicate.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_\n \n10\n \n$\n\n  \nfilter_\n \n(\n\\\ncustomer\n \n-\n \ncustomerFirstName\n \ncustomer\n \n`\nin_\n`\n \n[\nval_\n \nJohannes\n,\n \nval_\n \nAaron\n,\n \nval_\n \nEllie\n])\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nFirstName\n)\n \nIN\n \n(\n?\n,\n\n                             \n?\n,\n\n                             \n?\n)\n\n\nLIMIT\n \n10\n;\n\n\n\n-- With values: [SQLText \nJohannes\n,SQLText \nAaron\n,SQLText \nEllie\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nFirstName\n)\n \nIN\n \n(\nJohannes\n,\n\n                             \nAaron\n,\n\n                             \nEllie\n)\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \nIN\n \n(\nJohannes\n,\n\n                             \nAaron\n,\n\n                             \nEllie\n)\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nCASE .. WHEN .. ELSE ..\n statements\n\n\nThe SQL \nCASE .. WHEN .. ELSE\n construct can be used to implement a multi-way\nif. The corresponding beam syntax is\n\n\nif_\n \n[\n \ncond1\n \n`\nthen_\n`\n \nresult1\n,\n \ncond2\n \n`\nthen_\n`\n \nresult2\n,\n \n...\n \n]\n \n(\nelse_\n \nelseResult\n)\n\n\n\n\n\n\nwhere \ncond\nn\n are \nQGenExpr\n of type \nBool\n, and \nresult1\n, \nresult2\n, and\n\nelseResult\n are \nQGenExprs\n of the same type.\n\n\nManipulating types with \nCAST\n\n\nOftentimes, you want to cast data between two different types. SQL\nprovides the \nCAST\n function for this purpose. Beam exposes this\nfunctionality through the \ncast_\n function which takes an expression\nand a datatype. For example, to select all line items where the first\ndigit of the quantity is 2:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_\n \n(\n\\\nln\n \n-\n \ncast_\n \n(\ninvoiceLineQuantity\n \nln\n)\n \n(\nvarchar\n \nNothing\n)\n \n`\nlike_\n`\n \n2%\n)\n \n$\n\n  \nall_\n \n(\ninvoiceLine\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceLineId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nInvoiceId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres3\n,\n\n       \nt0\n.\nQuantity\n \nAS\n \nres4\n\n\nFROM\n \nInvoiceLine\n \nAS\n \nt0\n\n\nWHERE\n \n(\nCAST\n((\nt0\n.\nQuantity\n)\n \nAS\n \nVARCHAR\n))\n \nLIKE\n \n(\n?\n);\n\n\n\n-- With values: [SQLText \n2%\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceLineId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nInvoiceId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres3\n,\n\n       \nt0\n.\nQuantity\n \nAS\n \nres4\n\n\nFROM\n \nInvoiceLine\n \nAS\n \nt0\n\n\nWHERE\n \n(\nCAST\n((\nt0\n.\nQuantity\n)\n \nAS\n \nVARCHAR\n))\n \nLIKE\n \n(\n2%\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceLineId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nQuantity\n`\n \nAS\n \n`\nres4\n`\n\n\nFROM\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\nCAST\n((\n`\nt0\n`\n.\n`\nQuantity\n`\n)\n \nAS\n \nCHAR\n))\n \nLIKE\n \n(\n2%\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nSQL Functions and operators\n\n\n\n\n\n\n\n\nSQL construct\n\n\nSQL standard\n\n\nBeam equivalent\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nEXISTS (x)\n\n\nSQL92\n\n\nexists_ x\n\n\nHere, \nx\n is any query (of type \nQ\n)\n\n\n\n\n\n\nUNIQUE (x)\n\n\nSQL92\n\n\nunique_ x\n\n\nSee note for \nEXISTS (x)\n\n\n\n\n\n\nDISTINCT (x)\n\n\nSQL99\n\n\ndistinct_ x\n\n\nSee note for \nEXISTS (x)\n\n\n\n\n\n\nSELECT .. FROM ...\n \n as an expression (subqueries)\n\n\nSQL92\n\n\nsubquery_ x\n\n\nx\n is an query (of type \nQ\n)\n\n\n\n\n\n\nCOALESCE(a, b, c, ...)\n\n\nSQL92\n\n\ncoalesce_ [a, b, c, ...]\n\n\na\n, \nb\n, and \nc\n must be of \ntype \nMaybe a\n.\nThe result has type \na\n\n\n\n\n\n\na BETWEEN b AND c\n\n\nSQL92\n\n\nbetween_ a b c\n\n\n\n\n\n\n\n\na LIKE b\n\n\nSQL92\n\n\na `like_` b\n\n\na\n and \nb\n should be string types\n\n\n\n\n\n\na SIMILAR TO b\n\n\nSQL99\n\n\na `similarTo_` b\n\n\nSee note for \nLIKE\n\n\n\n\n\n\nPOSITION(x IN y)\n\n\nSQL92\n\n\nposition_ x y\n\n\nx\n and \ny\n should be string types\n\n\n\n\n\n\nCHAR_LENGTH(x)\n\n\nSQL92\n\n\ncharLength_ x\n\n\n\n\n\n\n\n\nOCTET_LENGTH(x)\n\n\nSQL92\n\n\noctetLength_ x\n\n\n\n\n\n\n\n\nBIT_LENGTH(x)\n\n\nSQL92\n\n\nbitLength_ x\n\n\nx\n must be of the beam-specific \nSqlBitString\n type\n\n\n\n\n\n\nx IS TRUE\n / \nx IS NOT TRUE\n\n\nSQL92\n\n\nisTrue_ x\n / \nisNotTrue_ x\n\n\n\n\n\n\n\n\nx IS FALSE\n / \nx IS NOT FALSE\n\n\nSQL92\n\n\nisFalse_ x\n / \nisNotFalse_ x\n\n\n\n\n\n\n\n\nx IS UNKNOWN\n / \nx IS NOT UNKNOWN\n\n\nSQL92\n\n\nisUnknown_ x\n / \nisNotUnknown_ x\n\n\n\n\n\n\n\n\nNOT x\n\n\nSQL92\n\n\nnot_ x\n\n\n\n\n\n\n\n\nLOWER (x)\n\n\nSQL92\n\n\nlower_ x\n\n\n\n\n\n\n\n\nUPPER (x)\n\n\nSQL92\n\n\nupper_ x\n\n\n\n\n\n\n\n\nTRIM (x)\n\n\nSQL92\n\n\ntrim_ x\n\n\n\n\n\n\n\n\n\n\nMy favorite operator / function isn't listed here!\n\n\nIf your favorite operator or function is not provided here, first ask yourself\nif it is part of any SQL standard. If it is not, then check the backend you are\nusing to see if it provides a corresponding construct. If the backend does not\nor if the function / operator you need is part of a SQL standard, please open an\nissue on GitHub. Alternatively, implement the construct yourself and send us a\npull request! See the section on \nadding your own functions", 
            "title": "Expressions"
        }, 
        {
            "location": "/user-guide/expressions/#typing", 
            "text": "The type of all SQL-level expressions is  QGenExpr . See the  query tutorial  for more information.  In many cases, you'd like to type the SQL-level result of an expression without\nhaving to give explicit types for the other  QGenExpr  parameters. You can do\nthis with the  as_  combinator and  -XTypeApplications .  The following code types the literal 1 as a  Double .  as_   @ Double   1   This is rarely needed, but there are a few cases where the beam types are too\ngeneral for the compiler to meaningfully infer types.", 
            "title": "Typing"
        }, 
        {
            "location": "/user-guide/expressions/#literals", 
            "text": "Integer literals  can be constructed using  fromIntegral  in the  Num \n  typeclass. This means you can also just use a Haskell integer literal as a\n   QGenExpr  in any context.  Rational literals  can be constructed via  fromRational  in  Rational .\n  Regular Haskell rational literals will be automatically converted to\n   QGenExprs .  Text literals  can be constructed via  fromString  in  IsString . Again,\n  Haskell string constants will automatically be converted to  QGenExprs ,\n  although you may have to provide an explicit type, as different backends\n  support different text types natively.  All other literals  can be constructed using the  val_  function in\n   SqlValable . This requires that there is an implementation of\n   HasSqlValueSyntax (Sql92ExpressionValueSyntax syntax) x  for the type  x  in\n  the appropriate  syntax  for the  QGenExpr . For example, to construct a value\n  of type  Vector Int  in the  beam-postgres  backend.   val_   ( V . fromList   [ 1 ,   2 ,   3   ::   Int ])    Explicit tables  can be brought to the SQL value level by using  val_  as\n  well. For example, if you have an  AddressT Identity  named  a ,  val_ a ::\n  AddressT (QGenExpr context expr s) .", 
            "title": "Literals"
        }, 
        {
            "location": "/user-guide/expressions/#utf-support", 
            "text": "All included beam backends play nicely with UTF. New backends should also\nsupport UTF, if they support syntaxes and deserializers for  String  or  Text .  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             filter_   ( \\ s   -   customerFirstName   s   ==.   \u3042\u304d\u3089 )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . FirstName ) = ( ? );  -- With values: [SQLText  \\12354\\12365\\12425 ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . FirstName )   =   ( \u3042\u304d\u3089 )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ( ` t0 ` . ` FirstName ` )   =   ( \u3042\u304d\u3089 )", 
            "title": "UTF support"
        }, 
        {
            "location": "/user-guide/expressions/#arithmetic", 
            "text": "Arithmetic operations that are part of the  Fractional  and  Num  classes can be\nused directly. For example, if  a  and  b  are  QGenExpr s of the same type,\nthen  a + b  is a  QGenExpr  of the same type.  Because of the  toInteger  class method in  Integral ,  QGenExpr s cannot\nimplement  Integral . Nevertheless, versions of  div  and  mod  are available as div_  and  mod_ , respectively, having the corresponding type.", 
            "title": "Arithmetic"
        }, 
        {
            "location": "/user-guide/expressions/#comparison", 
            "text": "SQL comparison is not as simple as you may think.  NULL  handling in particular\nactually makes things rather complicated.  SQL comparison operators actually\nreturn a  tri-state boolean , representing true, false, and  unknown , which is\nthe result when two nulls are compared. Boolean combinators ( AND  and  OR )\nhandle these values in different ways. Beam abstracts some of this difference\naway, if you ask it to.", 
            "title": "Comparison"
        }, 
        {
            "location": "/user-guide/expressions/#haskell-like-comparisons", 
            "text": "Haskell provides much more reasonable equality between potentially optional\nvalues. For example,  Nothing == Nothing  always! SQL does not provide a similar\nguarantee. However, beam can emulate Haskell-like equality in SQL using the ==.  operator. This uses a  CASE .. WHEN ..  statement or a special operator\nthat properly handles  NULL s in your given backend. Depending on your backend,\nthis can severely impact performance, but it's 'correct'.  For example, to find all customers living in Berlin:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             filter_   ( \\ s   -   addressCity   ( customerAddress   s )   ==.   val_   ( Just   Berlin ))   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   CASE \n           WHEN   (( t0 . City )   IS   NULL ) \n                AND   (( ? )   IS   NULL )   THEN   ? \n           WHEN   (( t0 . City )   IS   NULL ) \n                OR   (( ? )   IS   NULL )   THEN   ? \n           ELSE   ( t0 . City ) = ( ? ) \n       END ;  -- With values: [SQLText  Berlin ,SQLInteger 1,SQLText  Berlin ,SQLInteger 0,SQLText  Berlin ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . City )   IS   NOT   DISTINCT \n   FROM   ( Berlin )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   CASE \n           WHEN   (( ` t0 ` . ` City ` )   IS   NULL ) \n                AND   (( Berlin )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` t0 ` . ` City ` )   IS   NULL ) \n                OR   (( Berlin )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` t0 ` . ` City ` )   =   ( Berlin ) \n       END  \n\n         \n    \n         \n    \n                 \n                      Notice that SQLite uses a  CASE .. WHEN ..  statement, while Postgres uses the IS NOT DISTINCT FROM  operator.  The inequality operator is named  /=. , as expected. Note that both  ==.  and /=.  return a SQL expression whose type is  Bool .", 
            "title": "Haskell-like comparisons"
        }, 
        {
            "location": "/user-guide/expressions/#sql-like-comparisons", 
            "text": "Beam also provides equality operators that act like their underlying SQL\ncounterparts. These operators map most directly to the SQL  =  and  \noperators, but they require you to explicitly handle the possibility of NULL s. These operators are named  ==?.  and  /=?.  respectively.  Unlike  ==.  and  /=. , these operators return an expression of type SqlBool .  SqlBool  is a type that can only be manipulated as part of a SQL\nexpression, and cannot be serialized or deserialized to/from Haskell. You need\nto convert it to a  Bool  value explicitly in order to get the result or use it\nwith more advanced operators, such as  CASE .. WHEN .. .  In SQL, you can handle potentially unknown comparisons using the  IS TRUE ,  IS\nNOT TRUE ,  IS FALSE ,  IS NOT FALSE ,  IS UNKNOWN , and  IS NOT UNKNOWN \noperators. These are provided as the beam functions  isTrue_ ,  isNotTrue_ ,\netc. These each take a SQL expression of type  SqlBool  and return one of type Bool .  For example, to join every employee and customer who live in the same city, but\nusing SQL-like equality and making sure the comparison really is true (i.e.,\ncustomers and employees who both have  NULL  cities will not be included).  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   c   -   all_   ( customer   chinookDb ) \n    e   -   join_   ( employee   chinookDb )   $   \\ e   - \n         isTrue_   ( addressCity   ( customerAddress   c )   ==?.   addressCity   ( employeeAddress   e )) \n    pure   ( c ,   e )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12 , \n        t1 . EmployeeId   AS   res13 , \n        t1 . LastName   AS   res14 , \n        t1 . FirstName   AS   res15 , \n        t1 . Title   AS   res16 , \n        t1 . ReportsTo   AS   res17 , \n        t1 . BirthDate   AS   res18 , \n        t1 . HireDate   AS   res19 , \n        t1 . Address   AS   res20 , \n        t1 . City   AS   res21 , \n        t1 . State   AS   res22 , \n        t1 . Country   AS   res23 , \n        t1 . PostalCode   AS   res24 , \n        t1 . Phone   AS   res25 , \n        t1 . Fax   AS   res26 , \n        t1 . Email   AS   res27  FROM   Customer   AS   t0  INNER   JOIN   Employee   AS   t1   ON   (( t0 . City ) = ( t1 . City ))   IS   1 ;  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12 , \n        t1 . EmployeeId   AS   res13 , \n        t1 . LastName   AS   res14 , \n        t1 . FirstName   AS   res15 , \n        t1 . Title   AS   res16 , \n        t1 . ReportsTo   AS   res17 , \n        t1 . BirthDate   AS   res18 , \n        t1 . HireDate   AS   res19 , \n        t1 . Address   AS   res20 , \n        t1 . City   AS   res21 , \n        t1 . State   AS   res22 , \n        t1 . Country   AS   res23 , \n        t1 . PostalCode   AS   res24 , \n        t1 . Phone   AS   res25 , \n        t1 . Fax   AS   res26 , \n        t1 . Email   AS   res27  FROM   Customer   AS   t0  INNER   JOIN   Employee   AS   t1   ON   (( t0 . City )   =   ( t1 . City ))   IS   TRUE  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 ` , \n        ` t1 ` . ` EmployeeId `   AS   ` res13 ` , \n        ` t1 ` . ` LastName `   AS   ` res14 ` , \n        ` t1 ` . ` FirstName `   AS   ` res15 ` , \n        ` t1 ` . ` Title `   AS   ` res16 ` , \n        ` t1 ` . ` ReportsTo `   AS   ` res17 ` , \n        ` t1 ` . ` BirthDate `   AS   ` res18 ` , \n        ` t1 ` . ` HireDate `   AS   ` res19 ` , \n        ` t1 ` . ` Address `   AS   ` res20 ` , \n        ` t1 ` . ` City `   AS   ` res21 ` , \n        ` t1 ` . ` State `   AS   ` res22 ` , \n        ` t1 ` . ` Country `   AS   ` res23 ` , \n        ` t1 ` . ` PostalCode `   AS   ` res24 ` , \n        ` t1 ` . ` Phone `   AS   ` res25 ` , \n        ` t1 ` . ` Fax `   AS   ` res26 ` , \n        ` t1 ` . ` Email `   AS   ` res27 `  FROM   ` Customer `   AS   ` t0 `  JOIN   ` Employee `   AS   ` t1 `   ON   (( ` t0 ` . ` City ` )   =   ( ` t1 ` . ` City ` ))   IS   TRUE  \n\n         \n    \n         \n    \n                 \n                      Thinking of which  IS ..  operator to use can be confusing. If you have a\ndefault value you'd like to return in the case of an unknown comparison, use the unknownAs_  function. For example, if we want to treat unknown values as  True \ninstead (i.e, we want customers and employees who both have  NULL  cities to be\nincluded)  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   c   -   all_   ( customer   chinookDb ) \n    e   -   join_   ( employee   chinookDb )   $   \\ e   - \n         unknownAs_   True   ( addressCity   ( customerAddress   c )   ==?.   addressCity   ( employeeAddress   e )) \n    pure   ( c ,   e )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12 , \n        t1 . EmployeeId   AS   res13 , \n        t1 . LastName   AS   res14 , \n        t1 . FirstName   AS   res15 , \n        t1 . Title   AS   res16 , \n        t1 . ReportsTo   AS   res17 , \n        t1 . BirthDate   AS   res18 , \n        t1 . HireDate   AS   res19 , \n        t1 . Address   AS   res20 , \n        t1 . City   AS   res21 , \n        t1 . State   AS   res22 , \n        t1 . Country   AS   res23 , \n        t1 . PostalCode   AS   res24 , \n        t1 . Phone   AS   res25 , \n        t1 . Fax   AS   res26 , \n        t1 . Email   AS   res27  FROM   Customer   AS   t0  INNER   JOIN   Employee   AS   t1   ON   (( t0 . City ) = ( t1 . City ))   IS   NOT   0 ;  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12 , \n        t1 . EmployeeId   AS   res13 , \n        t1 . LastName   AS   res14 , \n        t1 . FirstName   AS   res15 , \n        t1 . Title   AS   res16 , \n        t1 . ReportsTo   AS   res17 , \n        t1 . BirthDate   AS   res18 , \n        t1 . HireDate   AS   res19 , \n        t1 . Address   AS   res20 , \n        t1 . City   AS   res21 , \n        t1 . State   AS   res22 , \n        t1 . Country   AS   res23 , \n        t1 . PostalCode   AS   res24 , \n        t1 . Phone   AS   res25 , \n        t1 . Fax   AS   res26 , \n        t1 . Email   AS   res27  FROM   Customer   AS   t0  INNER   JOIN   Employee   AS   t1   ON   (( t0 . City )   =   ( t1 . City ))   IS   NOT   FALSE  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 ` , \n        ` t1 ` . ` EmployeeId `   AS   ` res13 ` , \n        ` t1 ` . ` LastName `   AS   ` res14 ` , \n        ` t1 ` . ` FirstName `   AS   ` res15 ` , \n        ` t1 ` . ` Title `   AS   ` res16 ` , \n        ` t1 ` . ` ReportsTo `   AS   ` res17 ` , \n        ` t1 ` . ` BirthDate `   AS   ` res18 ` , \n        ` t1 ` . ` HireDate `   AS   ` res19 ` , \n        ` t1 ` . ` Address `   AS   ` res20 ` , \n        ` t1 ` . ` City `   AS   ` res21 ` , \n        ` t1 ` . ` State `   AS   ` res22 ` , \n        ` t1 ` . ` Country `   AS   ` res23 ` , \n        ` t1 ` . ` PostalCode `   AS   ` res24 ` , \n        ` t1 ` . ` Phone `   AS   ` res25 ` , \n        ` t1 ` . ` Fax `   AS   ` res26 ` , \n        ` t1 ` . ` Email `   AS   ` res27 `  FROM   ` Customer `   AS   ` t0 `  JOIN   ` Employee `   AS   ` t1 `   ON   (( ` t0 ` . ` City ` )   =   ( ` t1 ` . ` City ` ))   IS   NOT   FALSE", 
            "title": "SQL-like comparisons"
        }, 
        {
            "location": "/user-guide/expressions/#quantified-comparison", 
            "text": "SQL also allows comparisons to be  quantified . For example, the SQL expression a == ANY(b)  evaluates to true only if one row of  b  is equal to  a .\nSimilarly,  a   ALL(b)  returns true if  a   x  for every  x  in  b .  These are also supported using the  ==*. ,  /=*. ,  *. ,  *. ,  =*. , and =*.  operators. Like their unquantified counterparts, these operators yield a QGenExpr  of type  Bool . Unlike the unquantified operators, the second\nargument of these operators is of type  QQuantified . You can create a QQuantified  from a  QGenExpr  by using the  anyOf_/anyIn_  or  allOf_/allIn_ \nfunctions, which correspond to the  ANY  and  ALL  syntax respectively.  anyOf_ \nand  allOf_  take  Q  expressions (representing a query) and  anyIn_  and allIn_  take lists of expressions.  Quantified comparisons are always performed according to SQL semantics, meaning\nthat they return values of type  SqlBOol . This is because proper NULL handling\nwith quantified comparisons cannot be expressed in a reasonable way. Use the\nfunctions described in  the section above .  For example, to get all invoice lines containing tracks longer than 3 minutes:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             let   tracksLongerThanThreeMinutes   = \n       fmap   trackId   $ \n       filter_   ( \\ t   -   trackMilliseconds   t   =.   180000 )   $ \n         all_   ( track   chinookDb )  in   filter_   ( \\ ln   -   let   TrackId   lnTrackId   =   invoiceLineTrack   ln \n                    in   unknownAs_   False   ( lnTrackId   ==*.   anyOf_   tracksLongerThanThreeMinutes ))   $ \n      all_   ( invoiceLine   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . InvoiceLineId   AS   res0 , \n        t0 . InvoiceId   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . UnitPrice   AS   res3 , \n        t0 . Quantity   AS   res4  FROM   InvoiceLine   AS   t0  WHERE   (( t0 . TrackId )   =   ANY \n          ( SELECT   sub_t0 . TrackId   AS   res0 \n           FROM   Track   AS   sub_t0 \n           WHERE   ( sub_t0 . Milliseconds )   =   ( 180000 )))   IS   TRUE  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` InvoiceLineId `   AS   ` res0 ` , \n        ` t0 ` . ` InvoiceId `   AS   ` res1 ` , \n        ` t0 ` . ` TrackId `   AS   ` res2 ` , \n        ` t0 ` . ` UnitPrice `   AS   ` res3 ` , \n        ` t0 ` . ` Quantity `   AS   ` res4 `  FROM   ` InvoiceLine `   AS   ` t0 `  WHERE   (( ` t0 ` . ` TrackId ` )   =   ANY   ( \n                                  ( SELECT   ` sub_t0 ` . ` TrackId `   AS   ` res0 ` \n                                   FROM   ` Track `   AS   ` sub_t0 ` \n                                   WHERE   ( ` sub_t0 ` . ` Milliseconds ` )   =   ( 180000 ))))   IS   TRUE  \n\n         \n    \n         \n    \n                 \n                      We can also supply a concrete list of values. For example to get everyone living\nin either Los Angeles or Manila:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             filter_   ( \\ c   -    unknownAs_   False   ( addressCity   ( customerAddress   c )   ==*.   anyIn_   [   just_   Los Angeles ,   just_   Manila   ]))   $ \n      all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   (( t0 . City )   =   ANY   ( \n                             VALUES   ( Los Angeles ),   ( Manila )))   IS   TRUE", 
            "title": "Quantified comparison"
        }, 
        {
            "location": "/user-guide/expressions/#the-in-predicate", 
            "text": "You can also use  in_  to use the common  IN  predicate.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             limit_   10   $ \n   filter_   ( \\ customer   -   customerFirstName   customer   ` in_ `   [ val_   Johannes ,   val_   Aaron ,   val_   Ellie ])   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . FirstName )   IN   ( ? , \n                              ? , \n                              ? )  LIMIT   10 ;  -- With values: [SQLText  Johannes ,SQLText  Aaron ,SQLText  Ellie ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . FirstName )   IN   ( Johannes , \n                              Aaron , \n                              Ellie )  LIMIT   10  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ( ` t0 ` . ` FirstName ` )   IN   ( Johannes , \n                              Aaron , \n                              Ellie )  LIMIT   10", 
            "title": "The IN predicate"
        }, 
        {
            "location": "/user-guide/expressions/#case-when-else-statements", 
            "text": "The SQL  CASE .. WHEN .. ELSE  construct can be used to implement a multi-way\nif. The corresponding beam syntax is  if_   [   cond1   ` then_ `   result1 ,   cond2   ` then_ `   result2 ,   ...   ]   ( else_   elseResult )   where  cond n  are  QGenExpr  of type  Bool , and  result1 ,  result2 , and elseResult  are  QGenExprs  of the same type.", 
            "title": "CASE .. WHEN .. ELSE .. statements"
        }, 
        {
            "location": "/user-guide/expressions/#manipulating-types-with-cast", 
            "text": "Oftentimes, you want to cast data between two different types. SQL\nprovides the  CAST  function for this purpose. Beam exposes this\nfunctionality through the  cast_  function which takes an expression\nand a datatype. For example, to select all line items where the first\ndigit of the quantity is 2:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             filter_   ( \\ ln   -   cast_   ( invoiceLineQuantity   ln )   ( varchar   Nothing )   ` like_ `   2% )   $ \n   all_   ( invoiceLine   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . InvoiceLineId   AS   res0 , \n        t0 . InvoiceId   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . UnitPrice   AS   res3 , \n        t0 . Quantity   AS   res4  FROM   InvoiceLine   AS   t0  WHERE   ( CAST (( t0 . Quantity )   AS   VARCHAR ))   LIKE   ( ? );  -- With values: [SQLText  2% ]  \n\n         \n    \n         \n             SELECT   t0 . InvoiceLineId   AS   res0 , \n        t0 . InvoiceId   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . UnitPrice   AS   res3 , \n        t0 . Quantity   AS   res4  FROM   InvoiceLine   AS   t0  WHERE   ( CAST (( t0 . Quantity )   AS   VARCHAR ))   LIKE   ( 2% )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` InvoiceLineId `   AS   ` res0 ` , \n        ` t0 ` . ` InvoiceId `   AS   ` res1 ` , \n        ` t0 ` . ` TrackId `   AS   ` res2 ` , \n        ` t0 ` . ` UnitPrice `   AS   ` res3 ` , \n        ` t0 ` . ` Quantity `   AS   ` res4 `  FROM   ` InvoiceLine `   AS   ` t0 `  WHERE   ( CAST (( ` t0 ` . ` Quantity ` )   AS   CHAR ))   LIKE   ( 2% )", 
            "title": "Manipulating types with CAST"
        }, 
        {
            "location": "/user-guide/expressions/#sql-functions-and-operators", 
            "text": "SQL construct  SQL standard  Beam equivalent  Notes      EXISTS (x)  SQL92  exists_ x  Here,  x  is any query (of type  Q )    UNIQUE (x)  SQL92  unique_ x  See note for  EXISTS (x)    DISTINCT (x)  SQL99  distinct_ x  See note for  EXISTS (x)    SELECT .. FROM ...    as an expression (subqueries)  SQL92  subquery_ x  x  is an query (of type  Q )    COALESCE(a, b, c, ...)  SQL92  coalesce_ [a, b, c, ...]  a ,  b , and  c  must be of  type  Maybe a . The result has type  a    a BETWEEN b AND c  SQL92  between_ a b c     a LIKE b  SQL92  a `like_` b  a  and  b  should be string types    a SIMILAR TO b  SQL99  a `similarTo_` b  See note for  LIKE    POSITION(x IN y)  SQL92  position_ x y  x  and  y  should be string types    CHAR_LENGTH(x)  SQL92  charLength_ x     OCTET_LENGTH(x)  SQL92  octetLength_ x     BIT_LENGTH(x)  SQL92  bitLength_ x  x  must be of the beam-specific  SqlBitString  type    x IS TRUE  /  x IS NOT TRUE  SQL92  isTrue_ x  /  isNotTrue_ x     x IS FALSE  /  x IS NOT FALSE  SQL92  isFalse_ x  /  isNotFalse_ x     x IS UNKNOWN  /  x IS NOT UNKNOWN  SQL92  isUnknown_ x  /  isNotUnknown_ x     NOT x  SQL92  not_ x     LOWER (x)  SQL92  lower_ x     UPPER (x)  SQL92  upper_ x     TRIM (x)  SQL92  trim_ x", 
            "title": "SQL Functions and operators"
        }, 
        {
            "location": "/user-guide/expressions/#my-favorite-operator-function-isnt-listed-here", 
            "text": "If your favorite operator or function is not provided here, first ask yourself\nif it is part of any SQL standard. If it is not, then check the backend you are\nusing to see if it provides a corresponding construct. If the backend does not\nor if the function / operator you need is part of a SQL standard, please open an\nissue on GitHub. Alternatively, implement the construct yourself and send us a\npull request! See the section on  adding your own functions", 
            "title": "My favorite operator / function isn't listed here!"
        }, 
        {
            "location": "/user-guide/queries/basic/", 
            "text": "Given our database definition and database descriptor, we can query database\nentities and retrieve data. Before we discuss writing queries, we will take a\nlook at some of the important query types.\n\n\nData types\n\n\nThe \nQ\n data type\n\n\nBeam queries are built using the \nQ\n data type. \nQ\n's signature is as follows\n\n\ndata\n \nQ\n \nbe\n \ndb\n \ns\n \na\n\n\n\n\n\n\nIn this definition\n\n\n\n\nbe\n is the particular Beam backend this \nQ\n monad is written\n  for. Each beam backend defines a custom tag type. For example,\n  \nbeam-sqlite\n provides the \nSqlite\n tag, and \nbeam-postgres\n\n  provides the \nPostgres\n tag. You can see what SQL backends are available\n  in GHCi by asking for info on the \nBeamSqlBackend\n class.\n\n\n\n\nPrelude Database.Beam Database.Beam.Sqlite Data.Text Database.SQLite.Simple Lens.Micro Data.Time Database.Beam.Backend.SQL T\n :info BeamSqlBackend\nass (Database.Beam.Backend.Types.BeamBackend be,\n     IsSql92Syntax (BeamSqlBackendSyntax be),\n     Sql92SanityCheck (BeamSqlBackendSyntax be),\n     HasSqlValueSyntax (BeamSqlBackendValueSyntax be) Bool,\n     HasSqlValueSyntax (BeamSqlBackendValueSyntax be) SqlNull,\n     Eq (BeamSqlBackendExpressionSyntax be)) =\n\n    BeamSqlBackend be\n    -- Defined at /Users/travis/Projects/beam/beam-core/Database/Beam/Backend/SQL.hs:212:1\nstance BeamSqlBackend Sqlite\n-- Defined at /Users/travis/Projects/beam/beam-sqlite/Database/Beam/Sqlite/Connection.hs:157:10\nstance (IsSql92Syntax syntax, Sql92SanityCheck syntax,\n        HasSqlValueSyntax (Sql92ValueSyntax syntax) Bool,\n        HasSqlValueSyntax (Sql92ValueSyntax syntax) SqlNull,\n        Eq (Sql92ExpressionSyntax syntax)) =\n\n       BeamSqlBackend (MockSqlBackend syntax)\n-- Defined at /Users/travis/Projects/beam/beam-core/Database/Beam/Backend/SQL.hs:238:10\n\n\n\n\n\n\n\n\n\ndb\n is the type of the database (as we defined above). This is used to ensure\n  you only query database entities that are in scope in this database.\n\n\n\n\n\n\ns\n is the scope parameter. For the most part, you'll write your queries so\n  that they work over all \ns\n. Beam manipulates this parameter internally to\n  ensure that the fields in your expressions are always in scope at run-time.\n\n\n\n\n\n\na\n is the type of the result of the query.\n\n\n\n\n\n\nQ\n is a monad, which means you can use your favorite \nMonad\n, \nApplicative\n,\nand \nFunctor\n functions. The \nFunctor\n instance can be used to create\nprojections\nas \nexplained in the next section\n.\nThe \nMonad\n and \nApplicative\n instances can be used\nto \ncreate JOINs\n.\n\n\nThe \nQGenExpr\n type\n\n\nWhile \nQ\n represents the result of whole queries (entire \nSELECT\ns for example),\n\nQGenExpr\n represents the type of SQL expressions. \nQGenExpr\n also takes some\ntype parameters:\n\n\ndata\n \nQGenExpr\n \ncontext\n \nbe\n \ns\n \na\n\n\n\n\n\n\n\n\n\n\ncontext\n is the particular way in which this expression is being used. For\n  example, expressions containing aggregates have \ncontext ~ QAggregateContext\n.\n  Expressions returning scalar values have \ncontext ~ QValueContext\n.\n\n\n\n\n\n\nbe\n is the backend for which this expression is written. For\n  example, expressions destined for execution in PostgreSQL, will\n  substitute this for \nPostgres\n (from \nDatabase.Beam.Postgres\n in the\n  \nbeam-postgres\n package). You can also leave this polymorphic if you\n  want your expression to be useable across multiple backends.\n\n\n\n\n\n\n\n\nNote\n\n\nIn previous versions of beam \nbe\n indicated the 'syntax' rather\nthan the backend. This was confusing because the syntax and backend\ntypes were not obviously related. Beam \n=0.8.0.0 uses the backend\ntype consistently to indicate where an expression is being used.\n\n\n\n\n\n\n\n\ns\n is a scoping parameter, which will match the \ns\n in \nQ\n.\n\n\n\n\n\n\na\n is the type of this expression. For example, expressions returning SQL\n  \nint\n values, will have Haskell type \nInt\n. This ensures that your SQL query\n  won't fail at run-time with a type error.\n\n\n\n\n\n\nBeam defines some specializations of \nQGenExpr\n for common uses.\n\n\ntype\n \nQExpr\n \n=\n \nQGenExpr\n \nQValueContext\n\n\ntype\n \nQAgg\n \n=\n \nQGenExpr\n \nQAggregateContext\n\n\ntype\n \nQOrd\n \n=\n \nQGenExpr\n \nQOrderingContext\n\n\ntype\n \nQWindowExpr\n \n=\n \nQGenExpr\n \nQWindowingContext\n\n\ntype\n \nQWindowFrame\n \n=\n \nQGenExpr\n \nQWindowFrameContext\n\n\ntype\n \nQGroupExpr\n \n=\n \nQGenExpr\n \nQGroupingContext\n\n\n\n\n\n\nThus, value expressions can be given the simpler type of \nQExpr be s a\n.\nExpressions containing aggregates are typed as \nQAgg be s a\n.\n\n\nA note on type inference\n\n\nThese types may seem incredibly complicated. Indeed, the safety that beam tries\nto provide requires these scary-looking types.\n\n\nBut alas, do not fear! Beam is also designed to assist type inference. For the\nmost part, you will rarely need to annotate these types in your code.\nOccassionally you will need to provide a type for the result of an expression.\nFor example, \nSELECT\ning just the literal \n1\n may cause an ambiguity, because\nthe compiler won't know which \nIntegral\n type to use. Beam provides an easy\nutility function \nas_\n for this. With \n-XTypeApplications\n enabled,\n\n\nas_\n \n@\nInt\n \n(\nambiguous\n \nexpression\n)\n\n\n\n\n\n\nensures that \nambiguous expression\n has the type \nQGenExpr ctxt be s Int\n\nwith the \nctxt\n, \nbe\n, and \ns\n types appropriately inferred.\n\n\nSimple queries\n\n\nThe easiest query is simply getting all the rows in a specific table. If you\nhave a database object (something with type \nDatabaseSettings be db\n) with some\ntable or view entities, you can use the \nall_\n function to retrieve all rows in\na specific table or view.\n\n\nFor example, to retrieve all \nPersonT\n entries in the \nexampleDb\n we defined in\nthe last section, we can say\n\n\nall_\n \n(\npersons\n \nexampleDb\n)\n \n::\n \nQ\n \nbe\n \nExampleDb\n \ns\n \n(\nPersonT\n \n(\nQExpr\n \ns\n))\n\n\n\n\n\n\n\n\nNote\n\n\nWe give the full type of the query here for illustrative purposes only. There\nis no need to do so in your own code\n\n\n\n\nTwo things to note. Firstly, here \nPersonT\n is parameterized over the \nQExpr s\n\nhigher-kinded type. This means that each field in \nPersonT\n now contains a SQL\nexpression instead of a Haskell value. This is the magic that our parameterized\ntypes allow.\n\n\nThus,\n\n\npersonFirstName\n \n(\nall_\n \n(\npersons\n \nexampleDb\n))\n \n::\n \nQExpr\n \nbe\n \ns\n \nText\n\n\n\n\n\n\nand\n\n\npersonFirstName\n \n(\nPerson\n \nJohn\n \nSmith\n \n23\n \njohn.smith@example.com\n \n8888888888\n \n::\n \nPerson\n)\n \n::\n \nText\n\n\n\n\n\n\nSecondly, the field type has the same scope variable as the entire query. This\nmeans, it can only be used in the scope of this query. You will never be able to\ninspect the type of \ns\n from outside \nQ\n.\n\n\nOnce we have a query in terms of \nQ\n, we can use the \nselect\n function from\n\nDatabase.Beam.Query\n to turn it into a select statement that can be run against\nthe backend. \nselect\n takes an expression of type \nQ\n, and converts it into a\nSQL statement, ready to be executed against the database.\n\n\nThe output of the query passed to \nselect\n must follow some conventions, so that\nbeam knows how to serialize, deserialize, and project the appropriate values\nfrom the query. In particular, the return type of your query must be either\n\n\n\n\na plain expression (i.e., type \nQExpr\n),\n\n\na \nBeamable\n type (i.e., a table or primary key, defined as above), or\n\n\nany combination of tuples of the above (Beam supports up to 8-tuples by\n  default). Higher-order tuples can be formed by nested tuples. For example, for\n  16 return values, you can return a 2-tuple of 8-tuples or an 8-tuple of\n  2-tuples or a 4-tuple of 4-tuples, etc.\n\n\n\n\nWith this in mind, we can use \nselect\n to get a query statement against our\ndatabase. The return type of \nall_\n is just the table we ask for. In this case,\nwe're interested in the \npersons\n table. The \npersons\n table has the \nBeamable\n\ntype \nPersonT\n. As expected, the \nSqlSelect\n will return us concrete \nPerson\n\nvalues (recall that \nPerson\n is equivalent to \nPersonT Identity\n).\n\n\nselect\n \n(\nall_\n \n(\npersons\n \nexampleDb\n))\n \n::\n \nHasQBuilder\n \nbe\n \n=\n \nSqlSelect\n \nbe\n \nPerson\n\n\n\n\n\n\nNormally, you'd ship this select statement off to a backend to run, but for the\npurposes of this tutorial, we can also ask beam to dump what the standard SQL\nexpression this query encodes.\n\n\ndumpSqlSelect\n \n(\nall_\n \n(\npersons\n \nexampleDb\n))\n\n\nSELECT\n \n`\nt0\n`\n.\n`\nemail\n`\n \nAS\n \nres0\n,\n \n`\nt0\n`\n.\n`\nfirst_name\n`\n \nAS\n \nres1\n,\n \n`\nt0\n`\n.\n`\nlast_name\n`\n \nAS\n \nres2\n,\n \n`\nt0\n`\n.\n`\npassword\n`\n \nAS\n \nres3\n \nFROM\n \ncart_users\n \nAS\n \nt0\n\n\n\n\n\n\nInternally, \ndumpSqlSelect\n uses a \nbeam-core\n provided syntax to generate\nstandard ANSI SQL expressions. Note that these expressions should not be shipped\nto a backend directly, as they may not be escaped properly. Still, it is useful\nto see what would run.\n\n\n\n\nTip\n\n\nall_\n only works for \nTableEntity\ns. Use \nallFromView_\n for \nViewEntity\ns.\n\n\n\n\nA note on composability\n\n\nAll beam queries are \ncomposable\n. This means that you can freely mix values of\ntype \nQ\n in whichever way typechecks and expect a reasonable SQL query. This\ndiffers from the behavior of SQL, where the syntax for composing queries depends\non the structure of that query.\n\n\nFor example, suppose you wanted to fetch all rows of a table, filter them by a\ncondition, limit the amount of rows returned and then join these rows with\nanother table. In SQL, you'd have to write explicit subselects, take care of\nhandling projections, etc. This is because this query doesn't fit into the\n'standard' SQL query structure.\n\n\nHowever, in beam, you can simply write this query. Beam will take care of\ngenerating explicit subselects and handling projections. Scoping rules enforced\nby the Haskell type system ensure that the query is constructed correctly.\n\n\nFor example, we can write the following (meaningless) query, and things will work as expected.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ntbl1\n \n-\n\n     \nlimit_\n \n10\n \n$\n\n     \nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                           \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n             \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n   \ntbl2\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \npure\n \n(\ntbl1\n,\n \ntbl2\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt0\n.\nres9\n \nAS\n \nres9\n,\n\n       \nt0\n.\nres10\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres11\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres12\n \nAS\n \nres12\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres15\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres16\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres17\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres18\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres19\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres20\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres21\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n          \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n          \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n          \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n          \nt0\n.\nState\n \nAS\n \nres6\n,\n\n          \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n          \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n          \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n          \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n          \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n          \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\n?\n))\n\n          \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\n?\n)))\n\n     \nAND\n \n((\nCASE\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n           \nEND\n)\n\n          \nOR\n \n(\nCASE\n\n                  \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                       \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                  \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                       \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                  \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n              \nEND\n))\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n;\n\n\n\n-- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLInteger 1,SQLText \nCA\n,SQLInteger 0,SQLText \nCA\n,SQLText \nWA\n,SQLInteger 1,SQLText \nWA\n,SQLInteger 0,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt0\n.\nres9\n \nAS\n \nres9\n,\n\n       \nt0\n.\nres10\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres11\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres12\n \nAS\n \nres12\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres15\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres16\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres17\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres18\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres19\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres20\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres21\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n          \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n          \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n          \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n          \nt0\n.\nState\n \nAS\n \nres6\n,\n\n          \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n          \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n          \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n          \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n          \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n          \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n          \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n     \nAND\n \n(((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n           \nFROM\n \n(\nCA\n))\n\n          \nOR\n \n((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n              \nFROM\n \n(\nWA\n)))\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres4\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres5\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres6\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres7\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres8\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres9\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres10\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres11\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres12\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres13\n`\n,\n\n       \n`\nt1\n`\n.\n`\nName\n`\n \nAS\n \n`\nres14\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres15\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres16\n`\n,\n\n       \n`\nt1\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres17\n`\n,\n\n       \n`\nt1\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres18\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres19\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres20\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres21\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n          \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n          \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n          \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n          \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n          \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n          \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n          \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n          \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n          \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n          \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n   \nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n   \nWHERE\n \n(((\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \nLIKE\n \n(\nJo%\n))\n\n          \nAND\n \n((\n`\nt0\n`\n.\n`\nLastName\n`\n)\n \nLIKE\n \n(\nS%\n)))\n\n     \nAND\n \n((\nCASE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n               \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nCA\n)\n\n           \nEND\n)\n\n          \nOR\n \n(\nCASE\n\n                  \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                       \nAND\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n                  \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                       \nOR\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n                  \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nWA\n)\n\n              \nEND\n))\n\n   \nLIMIT\n \n10\n)\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThis allows you to easily factor out queries. This means you can build a query\nlibrary in your application and then freely mix and match these queries as\nnecessary. This allows you to offload as much processing to the database as\npossible, rather than shipping data to your application pre-processing.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- \ncomplicatedQuery\n could be declared and imported from an external module here. The generated query is the same regardless\n\n\nlet\n \ncomplicatedQuery\n \n=\n\n       \nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                             \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n               \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\nin\n \ndo\n \ntbl1\n \n-\n \nlimit_\n \n10\n \n$\n \ncomplicatedQuery\n\n      \ntbl2\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n      \npure\n \n(\ntbl1\n,\n \ntbl2\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt0\n.\nres9\n \nAS\n \nres9\n,\n\n       \nt0\n.\nres10\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres11\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres12\n \nAS\n \nres12\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres15\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres16\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres17\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres18\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres19\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres20\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres21\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n          \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n          \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n          \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n          \nt0\n.\nState\n \nAS\n \nres6\n,\n\n          \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n          \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n          \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n          \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n          \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n          \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\n?\n))\n\n          \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\n?\n)))\n\n     \nAND\n \n((\nCASE\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n           \nEND\n)\n\n          \nOR\n \n(\nCASE\n\n                  \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                       \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                  \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                       \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                  \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n              \nEND\n))\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n;\n\n\n\n-- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLInteger 1,SQLText \nCA\n,SQLInteger 0,SQLText \nCA\n,SQLText \nWA\n,SQLInteger 1,SQLText \nWA\n,SQLInteger 0,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt0\n.\nres9\n \nAS\n \nres9\n,\n\n       \nt0\n.\nres10\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres11\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres12\n \nAS\n \nres12\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres15\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres16\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres17\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres18\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres19\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres20\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres21\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n          \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n          \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n          \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n          \nt0\n.\nState\n \nAS\n \nres6\n,\n\n          \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n          \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n          \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n          \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n          \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n          \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n          \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n     \nAND\n \n(((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n           \nFROM\n \n(\nCA\n))\n\n          \nOR\n \n((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n              \nFROM\n \n(\nWA\n)))\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres4\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres5\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres6\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres7\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres8\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres9\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres10\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres11\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres12\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres13\n`\n,\n\n       \n`\nt1\n`\n.\n`\nName\n`\n \nAS\n \n`\nres14\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres15\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres16\n`\n,\n\n       \n`\nt1\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres17\n`\n,\n\n       \n`\nt1\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres18\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres19\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres20\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres21\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n          \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n          \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n          \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n          \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n          \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n          \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n          \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n          \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n          \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n          \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n   \nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n   \nWHERE\n \n(((\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \nLIKE\n \n(\nJo%\n))\n\n          \nAND\n \n((\n`\nt0\n`\n.\n`\nLastName\n`\n)\n \nLIKE\n \n(\nS%\n)))\n\n     \nAND\n \n((\nCASE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n               \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nCA\n)\n\n           \nEND\n)\n\n          \nOR\n \n(\nCASE\n\n                  \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                       \nAND\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n                  \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                       \nOR\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n                  \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nWA\n)\n\n              \nEND\n))\n\n   \nLIMIT\n \n10\n)\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`", 
            "title": "Basic Queries"
        }, 
        {
            "location": "/user-guide/queries/basic/#data-types", 
            "text": "", 
            "title": "Data types"
        }, 
        {
            "location": "/user-guide/queries/basic/#the-q-data-type", 
            "text": "Beam queries are built using the  Q  data type.  Q 's signature is as follows  data   Q   be   db   s   a   In this definition   be  is the particular Beam backend this  Q  monad is written\n  for. Each beam backend defines a custom tag type. For example,\n   beam-sqlite  provides the  Sqlite  tag, and  beam-postgres \n  provides the  Postgres  tag. You can see what SQL backends are available\n  in GHCi by asking for info on the  BeamSqlBackend  class.   Prelude Database.Beam Database.Beam.Sqlite Data.Text Database.SQLite.Simple Lens.Micro Data.Time Database.Beam.Backend.SQL T  :info BeamSqlBackend\nass (Database.Beam.Backend.Types.BeamBackend be,\n     IsSql92Syntax (BeamSqlBackendSyntax be),\n     Sql92SanityCheck (BeamSqlBackendSyntax be),\n     HasSqlValueSyntax (BeamSqlBackendValueSyntax be) Bool,\n     HasSqlValueSyntax (BeamSqlBackendValueSyntax be) SqlNull,\n     Eq (BeamSqlBackendExpressionSyntax be)) = \n    BeamSqlBackend be\n    -- Defined at /Users/travis/Projects/beam/beam-core/Database/Beam/Backend/SQL.hs:212:1\nstance BeamSqlBackend Sqlite\n-- Defined at /Users/travis/Projects/beam/beam-sqlite/Database/Beam/Sqlite/Connection.hs:157:10\nstance (IsSql92Syntax syntax, Sql92SanityCheck syntax,\n        HasSqlValueSyntax (Sql92ValueSyntax syntax) Bool,\n        HasSqlValueSyntax (Sql92ValueSyntax syntax) SqlNull,\n        Eq (Sql92ExpressionSyntax syntax)) = \n       BeamSqlBackend (MockSqlBackend syntax)\n-- Defined at /Users/travis/Projects/beam/beam-core/Database/Beam/Backend/SQL.hs:238:10    db  is the type of the database (as we defined above). This is used to ensure\n  you only query database entities that are in scope in this database.    s  is the scope parameter. For the most part, you'll write your queries so\n  that they work over all  s . Beam manipulates this parameter internally to\n  ensure that the fields in your expressions are always in scope at run-time.    a  is the type of the result of the query.    Q  is a monad, which means you can use your favorite  Monad ,  Applicative ,\nand  Functor  functions. The  Functor  instance can be used to create\nprojections\nas  explained in the next section .\nThe  Monad  and  Applicative  instances can be used\nto  create JOINs .", 
            "title": "The Q data type"
        }, 
        {
            "location": "/user-guide/queries/basic/#the-qgenexpr-type", 
            "text": "While  Q  represents the result of whole queries (entire  SELECT s for example), QGenExpr  represents the type of SQL expressions.  QGenExpr  also takes some\ntype parameters:  data   QGenExpr   context   be   s   a     context  is the particular way in which this expression is being used. For\n  example, expressions containing aggregates have  context ~ QAggregateContext .\n  Expressions returning scalar values have  context ~ QValueContext .    be  is the backend for which this expression is written. For\n  example, expressions destined for execution in PostgreSQL, will\n  substitute this for  Postgres  (from  Database.Beam.Postgres  in the\n   beam-postgres  package). You can also leave this polymorphic if you\n  want your expression to be useable across multiple backends.     Note  In previous versions of beam  be  indicated the 'syntax' rather\nthan the backend. This was confusing because the syntax and backend\ntypes were not obviously related. Beam  =0.8.0.0 uses the backend\ntype consistently to indicate where an expression is being used.     s  is a scoping parameter, which will match the  s  in  Q .    a  is the type of this expression. For example, expressions returning SQL\n   int  values, will have Haskell type  Int . This ensures that your SQL query\n  won't fail at run-time with a type error.    Beam defines some specializations of  QGenExpr  for common uses.  type   QExpr   =   QGenExpr   QValueContext  type   QAgg   =   QGenExpr   QAggregateContext  type   QOrd   =   QGenExpr   QOrderingContext  type   QWindowExpr   =   QGenExpr   QWindowingContext  type   QWindowFrame   =   QGenExpr   QWindowFrameContext  type   QGroupExpr   =   QGenExpr   QGroupingContext   Thus, value expressions can be given the simpler type of  QExpr be s a .\nExpressions containing aggregates are typed as  QAgg be s a .", 
            "title": "The QGenExpr type"
        }, 
        {
            "location": "/user-guide/queries/basic/#a-note-on-type-inference", 
            "text": "These types may seem incredibly complicated. Indeed, the safety that beam tries\nto provide requires these scary-looking types.  But alas, do not fear! Beam is also designed to assist type inference. For the\nmost part, you will rarely need to annotate these types in your code.\nOccassionally you will need to provide a type for the result of an expression.\nFor example,  SELECT ing just the literal  1  may cause an ambiguity, because\nthe compiler won't know which  Integral  type to use. Beam provides an easy\nutility function  as_  for this. With  -XTypeApplications  enabled,  as_   @ Int   ( ambiguous   expression )   ensures that  ambiguous expression  has the type  QGenExpr ctxt be s Int \nwith the  ctxt ,  be , and  s  types appropriately inferred.", 
            "title": "A note on type inference"
        }, 
        {
            "location": "/user-guide/queries/basic/#simple-queries", 
            "text": "The easiest query is simply getting all the rows in a specific table. If you\nhave a database object (something with type  DatabaseSettings be db ) with some\ntable or view entities, you can use the  all_  function to retrieve all rows in\na specific table or view.  For example, to retrieve all  PersonT  entries in the  exampleDb  we defined in\nthe last section, we can say  all_   ( persons   exampleDb )   ::   Q   be   ExampleDb   s   ( PersonT   ( QExpr   s ))    Note  We give the full type of the query here for illustrative purposes only. There\nis no need to do so in your own code   Two things to note. Firstly, here  PersonT  is parameterized over the  QExpr s \nhigher-kinded type. This means that each field in  PersonT  now contains a SQL\nexpression instead of a Haskell value. This is the magic that our parameterized\ntypes allow.  Thus,  personFirstName   ( all_   ( persons   exampleDb ))   ::   QExpr   be   s   Text   and  personFirstName   ( Person   John   Smith   23   john.smith@example.com   8888888888   ::   Person )   ::   Text   Secondly, the field type has the same scope variable as the entire query. This\nmeans, it can only be used in the scope of this query. You will never be able to\ninspect the type of  s  from outside  Q .  Once we have a query in terms of  Q , we can use the  select  function from Database.Beam.Query  to turn it into a select statement that can be run against\nthe backend.  select  takes an expression of type  Q , and converts it into a\nSQL statement, ready to be executed against the database.  The output of the query passed to  select  must follow some conventions, so that\nbeam knows how to serialize, deserialize, and project the appropriate values\nfrom the query. In particular, the return type of your query must be either   a plain expression (i.e., type  QExpr ),  a  Beamable  type (i.e., a table or primary key, defined as above), or  any combination of tuples of the above (Beam supports up to 8-tuples by\n  default). Higher-order tuples can be formed by nested tuples. For example, for\n  16 return values, you can return a 2-tuple of 8-tuples or an 8-tuple of\n  2-tuples or a 4-tuple of 4-tuples, etc.   With this in mind, we can use  select  to get a query statement against our\ndatabase. The return type of  all_  is just the table we ask for. In this case,\nwe're interested in the  persons  table. The  persons  table has the  Beamable \ntype  PersonT . As expected, the  SqlSelect  will return us concrete  Person \nvalues (recall that  Person  is equivalent to  PersonT Identity ).  select   ( all_   ( persons   exampleDb ))   ::   HasQBuilder   be   =   SqlSelect   be   Person   Normally, you'd ship this select statement off to a backend to run, but for the\npurposes of this tutorial, we can also ask beam to dump what the standard SQL\nexpression this query encodes.  dumpSqlSelect   ( all_   ( persons   exampleDb ))  SELECT   ` t0 ` . ` email `   AS   res0 ,   ` t0 ` . ` first_name `   AS   res1 ,   ` t0 ` . ` last_name `   AS   res2 ,   ` t0 ` . ` password `   AS   res3   FROM   cart_users   AS   t0   Internally,  dumpSqlSelect  uses a  beam-core  provided syntax to generate\nstandard ANSI SQL expressions. Note that these expressions should not be shipped\nto a backend directly, as they may not be escaped properly. Still, it is useful\nto see what would run.   Tip  all_  only works for  TableEntity s. Use  allFromView_  for  ViewEntity s.", 
            "title": "Simple queries"
        }, 
        {
            "location": "/user-guide/queries/basic/#a-note-on-composability", 
            "text": "All beam queries are  composable . This means that you can freely mix values of\ntype  Q  in whichever way typechecks and expect a reasonable SQL query. This\ndiffers from the behavior of SQL, where the syntax for composing queries depends\non the structure of that query.  For example, suppose you wanted to fetch all rows of a table, filter them by a\ncondition, limit the amount of rows returned and then join these rows with\nanother table. In SQL, you'd have to write explicit subselects, take care of\nhandling projections, etc. This is because this query doesn't fit into the\n'standard' SQL query structure.  However, in beam, you can simply write this query. Beam will take care of\ngenerating explicit subselects and handling projections. Scoping rules enforced\nby the Haskell type system ensure that the query is constructed correctly.  For example, we can write the following (meaningless) query, and things will work as expected.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   tbl1   - \n      limit_   10   $ \n      filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                            ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n              all_   ( customer   chinookDb ) \n    tbl2   -   all_   ( track   chinookDb ) \n    pure   ( tbl1 ,   tbl2 )  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t0 . res9   AS   res9 , \n        t0 . res10   AS   res10 , \n        t0 . res11   AS   res11 , \n        t0 . res12   AS   res12 , \n        t1 . TrackId   AS   res13 , \n        t1 . Name   AS   res14 , \n        t1 . AlbumId   AS   res15 , \n        t1 . MediaTypeId   AS   res16 , \n        t1 . GenreId   AS   res17 , \n        t1 . Composer   AS   res18 , \n        t1 . Milliseconds   AS   res19 , \n        t1 . Bytes   AS   res20 , \n        t1 . UnitPrice   AS   res21  FROM \n   ( SELECT   t0 . CustomerId   AS   res0 , \n           t0 . FirstName   AS   res1 , \n           t0 . LastName   AS   res2 , \n           t0 . Company   AS   res3 , \n           t0 . Address   AS   res4 , \n           t0 . City   AS   res5 , \n           t0 . State   AS   res6 , \n           t0 . Country   AS   res7 , \n           t0 . PostalCode   AS   res8 , \n           t0 . Phone   AS   res9 , \n           t0 . Fax   AS   res10 , \n           t0 . Email   AS   res11 , \n           t0 . SupportRepId   AS   res12 \n    FROM   Customer   AS   t0 \n    WHERE   ((( t0 . FirstName )   LIKE   ( ? )) \n           AND   (( t0 . LastName )   LIKE   ( ? ))) \n      AND   (( CASE \n                WHEN   (( t0 . State )   IS   NULL ) \n                     AND   (( ? )   IS   NULL )   THEN   ? \n                WHEN   (( t0 . State )   IS   NULL ) \n                     OR   (( ? )   IS   NULL )   THEN   ? \n                ELSE   ( t0 . State ) = ( ? ) \n            END ) \n           OR   ( CASE \n                   WHEN   (( t0 . State )   IS   NULL ) \n                        AND   (( ? )   IS   NULL )   THEN   ? \n                   WHEN   (( t0 . State )   IS   NULL ) \n                        OR   (( ? )   IS   NULL )   THEN   ? \n                   ELSE   ( t0 . State ) = ( ? ) \n               END )) \n    LIMIT   10 )   AS   t0  INNER   JOIN   Track   AS   t1 ;  -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLInteger 1,SQLText  CA ,SQLInteger 0,SQLText  CA ,SQLText  WA ,SQLInteger 1,SQLText  WA ,SQLInteger 0,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t0 . res9   AS   res9 , \n        t0 . res10   AS   res10 , \n        t0 . res11   AS   res11 , \n        t0 . res12   AS   res12 , \n        t1 . TrackId   AS   res13 , \n        t1 . Name   AS   res14 , \n        t1 . AlbumId   AS   res15 , \n        t1 . MediaTypeId   AS   res16 , \n        t1 . GenreId   AS   res17 , \n        t1 . Composer   AS   res18 , \n        t1 . Milliseconds   AS   res19 , \n        t1 . Bytes   AS   res20 , \n        t1 . UnitPrice   AS   res21  FROM \n   ( SELECT   t0 . CustomerId   AS   res0 , \n           t0 . FirstName   AS   res1 , \n           t0 . LastName   AS   res2 , \n           t0 . Company   AS   res3 , \n           t0 . Address   AS   res4 , \n           t0 . City   AS   res5 , \n           t0 . State   AS   res6 , \n           t0 . Country   AS   res7 , \n           t0 . PostalCode   AS   res8 , \n           t0 . Phone   AS   res9 , \n           t0 . Fax   AS   res10 , \n           t0 . Email   AS   res11 , \n           t0 . SupportRepId   AS   res12 \n    FROM   Customer   AS   t0 \n    WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n           AND   (( t0 . LastName )   LIKE   ( S% ))) \n      AND   ((( t0 . State )   IS   NOT   DISTINCT \n            FROM   ( CA )) \n           OR   (( t0 . State )   IS   NOT   DISTINCT \n               FROM   ( WA ))) \n    LIMIT   10 )   AS   t0  CROSS   JOIN   Track   AS   t1  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 ` , \n        ` t0 ` . ` res2 `   AS   ` res2 ` , \n        ` t0 ` . ` res3 `   AS   ` res3 ` , \n        ` t0 ` . ` res4 `   AS   ` res4 ` , \n        ` t0 ` . ` res5 `   AS   ` res5 ` , \n        ` t0 ` . ` res6 `   AS   ` res6 ` , \n        ` t0 ` . ` res7 `   AS   ` res7 ` , \n        ` t0 ` . ` res8 `   AS   ` res8 ` , \n        ` t0 ` . ` res9 `   AS   ` res9 ` , \n        ` t0 ` . ` res10 `   AS   ` res10 ` , \n        ` t0 ` . ` res11 `   AS   ` res11 ` , \n        ` t0 ` . ` res12 `   AS   ` res12 ` , \n        ` t1 ` . ` TrackId `   AS   ` res13 ` , \n        ` t1 ` . ` Name `   AS   ` res14 ` , \n        ` t1 ` . ` AlbumId `   AS   ` res15 ` , \n        ` t1 ` . ` MediaTypeId `   AS   ` res16 ` , \n        ` t1 ` . ` GenreId `   AS   ` res17 ` , \n        ` t1 ` . ` Composer `   AS   ` res18 ` , \n        ` t1 ` . ` Milliseconds `   AS   ` res19 ` , \n        ` t1 ` . ` Bytes `   AS   ` res20 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res21 `  FROM \n   ( SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n           ` t0 ` . ` FirstName `   AS   ` res1 ` , \n           ` t0 ` . ` LastName `   AS   ` res2 ` , \n           ` t0 ` . ` Company `   AS   ` res3 ` , \n           ` t0 ` . ` Address `   AS   ` res4 ` , \n           ` t0 ` . ` City `   AS   ` res5 ` , \n           ` t0 ` . ` State `   AS   ` res6 ` , \n           ` t0 ` . ` Country `   AS   ` res7 ` , \n           ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n           ` t0 ` . ` Phone `   AS   ` res9 ` , \n           ` t0 ` . ` Fax `   AS   ` res10 ` , \n           ` t0 ` . ` Email `   AS   ` res11 ` , \n           ` t0 ` . ` SupportRepId `   AS   ` res12 ` \n    FROM   ` Customer `   AS   ` t0 ` \n    WHERE   ((( ` t0 ` . ` FirstName ` )   LIKE   ( Jo% )) \n           AND   (( ` t0 ` . ` LastName ` )   LIKE   ( S% ))) \n      AND   (( CASE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     AND   (( CA )   IS   NULL )   THEN   TRUE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     OR   (( CA )   IS   NULL )   THEN   FALSE \n                ELSE   ( ` t0 ` . ` State ` )   =   ( CA ) \n            END ) \n           OR   ( CASE \n                   WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                        AND   (( WA )   IS   NULL )   THEN   TRUE \n                   WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                        OR   (( WA )   IS   NULL )   THEN   FALSE \n                   ELSE   ( ` t0 ` . ` State ` )   =   ( WA ) \n               END )) \n    LIMIT   10 )   AS   ` t0 `  JOIN   ` Track `   AS   ` t1 `  \n\n         \n    \n         \n    \n                 \n                      This allows you to easily factor out queries. This means you can build a query\nlibrary in your application and then freely mix and match these queries as\nnecessary. This allows you to offload as much processing to the database as\npossible, rather than shipping data to your application pre-processing.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             --  complicatedQuery  could be declared and imported from an external module here. The generated query is the same regardless  let   complicatedQuery   = \n        filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                              ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n                all_   ( customer   chinookDb )  in   do   tbl1   -   limit_   10   $   complicatedQuery \n       tbl2   -   all_   ( track   chinookDb ) \n       pure   ( tbl1 ,   tbl2 )  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t0 . res9   AS   res9 , \n        t0 . res10   AS   res10 , \n        t0 . res11   AS   res11 , \n        t0 . res12   AS   res12 , \n        t1 . TrackId   AS   res13 , \n        t1 . Name   AS   res14 , \n        t1 . AlbumId   AS   res15 , \n        t1 . MediaTypeId   AS   res16 , \n        t1 . GenreId   AS   res17 , \n        t1 . Composer   AS   res18 , \n        t1 . Milliseconds   AS   res19 , \n        t1 . Bytes   AS   res20 , \n        t1 . UnitPrice   AS   res21  FROM \n   ( SELECT   t0 . CustomerId   AS   res0 , \n           t0 . FirstName   AS   res1 , \n           t0 . LastName   AS   res2 , \n           t0 . Company   AS   res3 , \n           t0 . Address   AS   res4 , \n           t0 . City   AS   res5 , \n           t0 . State   AS   res6 , \n           t0 . Country   AS   res7 , \n           t0 . PostalCode   AS   res8 , \n           t0 . Phone   AS   res9 , \n           t0 . Fax   AS   res10 , \n           t0 . Email   AS   res11 , \n           t0 . SupportRepId   AS   res12 \n    FROM   Customer   AS   t0 \n    WHERE   ((( t0 . FirstName )   LIKE   ( ? )) \n           AND   (( t0 . LastName )   LIKE   ( ? ))) \n      AND   (( CASE \n                WHEN   (( t0 . State )   IS   NULL ) \n                     AND   (( ? )   IS   NULL )   THEN   ? \n                WHEN   (( t0 . State )   IS   NULL ) \n                     OR   (( ? )   IS   NULL )   THEN   ? \n                ELSE   ( t0 . State ) = ( ? ) \n            END ) \n           OR   ( CASE \n                   WHEN   (( t0 . State )   IS   NULL ) \n                        AND   (( ? )   IS   NULL )   THEN   ? \n                   WHEN   (( t0 . State )   IS   NULL ) \n                        OR   (( ? )   IS   NULL )   THEN   ? \n                   ELSE   ( t0 . State ) = ( ? ) \n               END )) \n    LIMIT   10 )   AS   t0  INNER   JOIN   Track   AS   t1 ;  -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLInteger 1,SQLText  CA ,SQLInteger 0,SQLText  CA ,SQLText  WA ,SQLInteger 1,SQLText  WA ,SQLInteger 0,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t0 . res9   AS   res9 , \n        t0 . res10   AS   res10 , \n        t0 . res11   AS   res11 , \n        t0 . res12   AS   res12 , \n        t1 . TrackId   AS   res13 , \n        t1 . Name   AS   res14 , \n        t1 . AlbumId   AS   res15 , \n        t1 . MediaTypeId   AS   res16 , \n        t1 . GenreId   AS   res17 , \n        t1 . Composer   AS   res18 , \n        t1 . Milliseconds   AS   res19 , \n        t1 . Bytes   AS   res20 , \n        t1 . UnitPrice   AS   res21  FROM \n   ( SELECT   t0 . CustomerId   AS   res0 , \n           t0 . FirstName   AS   res1 , \n           t0 . LastName   AS   res2 , \n           t0 . Company   AS   res3 , \n           t0 . Address   AS   res4 , \n           t0 . City   AS   res5 , \n           t0 . State   AS   res6 , \n           t0 . Country   AS   res7 , \n           t0 . PostalCode   AS   res8 , \n           t0 . Phone   AS   res9 , \n           t0 . Fax   AS   res10 , \n           t0 . Email   AS   res11 , \n           t0 . SupportRepId   AS   res12 \n    FROM   Customer   AS   t0 \n    WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n           AND   (( t0 . LastName )   LIKE   ( S% ))) \n      AND   ((( t0 . State )   IS   NOT   DISTINCT \n            FROM   ( CA )) \n           OR   (( t0 . State )   IS   NOT   DISTINCT \n               FROM   ( WA ))) \n    LIMIT   10 )   AS   t0  CROSS   JOIN   Track   AS   t1  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 ` , \n        ` t0 ` . ` res2 `   AS   ` res2 ` , \n        ` t0 ` . ` res3 `   AS   ` res3 ` , \n        ` t0 ` . ` res4 `   AS   ` res4 ` , \n        ` t0 ` . ` res5 `   AS   ` res5 ` , \n        ` t0 ` . ` res6 `   AS   ` res6 ` , \n        ` t0 ` . ` res7 `   AS   ` res7 ` , \n        ` t0 ` . ` res8 `   AS   ` res8 ` , \n        ` t0 ` . ` res9 `   AS   ` res9 ` , \n        ` t0 ` . ` res10 `   AS   ` res10 ` , \n        ` t0 ` . ` res11 `   AS   ` res11 ` , \n        ` t0 ` . ` res12 `   AS   ` res12 ` , \n        ` t1 ` . ` TrackId `   AS   ` res13 ` , \n        ` t1 ` . ` Name `   AS   ` res14 ` , \n        ` t1 ` . ` AlbumId `   AS   ` res15 ` , \n        ` t1 ` . ` MediaTypeId `   AS   ` res16 ` , \n        ` t1 ` . ` GenreId `   AS   ` res17 ` , \n        ` t1 ` . ` Composer `   AS   ` res18 ` , \n        ` t1 ` . ` Milliseconds `   AS   ` res19 ` , \n        ` t1 ` . ` Bytes `   AS   ` res20 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res21 `  FROM \n   ( SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n           ` t0 ` . ` FirstName `   AS   ` res1 ` , \n           ` t0 ` . ` LastName `   AS   ` res2 ` , \n           ` t0 ` . ` Company `   AS   ` res3 ` , \n           ` t0 ` . ` Address `   AS   ` res4 ` , \n           ` t0 ` . ` City `   AS   ` res5 ` , \n           ` t0 ` . ` State `   AS   ` res6 ` , \n           ` t0 ` . ` Country `   AS   ` res7 ` , \n           ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n           ` t0 ` . ` Phone `   AS   ` res9 ` , \n           ` t0 ` . ` Fax `   AS   ` res10 ` , \n           ` t0 ` . ` Email `   AS   ` res11 ` , \n           ` t0 ` . ` SupportRepId `   AS   ` res12 ` \n    FROM   ` Customer `   AS   ` t0 ` \n    WHERE   ((( ` t0 ` . ` FirstName ` )   LIKE   ( Jo% )) \n           AND   (( ` t0 ` . ` LastName ` )   LIKE   ( S% ))) \n      AND   (( CASE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     AND   (( CA )   IS   NULL )   THEN   TRUE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     OR   (( CA )   IS   NULL )   THEN   FALSE \n                ELSE   ( ` t0 ` . ` State ` )   =   ( CA ) \n            END ) \n           OR   ( CASE \n                   WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                        AND   (( WA )   IS   NULL )   THEN   TRUE \n                   WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                        OR   (( WA )   IS   NULL )   THEN   FALSE \n                   ELSE   ( ` t0 ` . ` State ` )   =   ( WA ) \n               END )) \n    LIMIT   10 )   AS   ` t0 `  JOIN   ` Track `   AS   ` t1 `", 
            "title": "A note on composability"
        }, 
        {
            "location": "/user-guide/queries/select/", 
            "text": "We've seen how to create simple queries from our schema. Beam supports other\nclauses in the SQL SELECT statement.\n\n\nFor these examples, we're going to use the \nbeam-sqlite\n backend with the\nprovided sample Chinook database. The Chinook database schema is modeled after a\nfictional record store. It provides several tables containing information on the\nmusic as well as the billing operations. Thus, it provides a good 'real-world'\ndemonstration of beam's capabalities.\n\n\nFirst, create a SQLite database from the included example.\n\n\n$\n sqlite3 chinook.db \n beam-sqlite/examples/chinook.sql\n\n\n\n\n\nNow, load the chinook database schema in GHCi.\n\n\nPrelude\n \nDatabase\n.\nBeam\n.\nSqlite\n \n:\nload\n \nbeam\n-\nsqlite\n/\nexamples\n/\nChinook\n/\nSchema\n.\nhs\n\n\nPrelude\n \nChinook\n.\nSchema\n \nchinook\n \n-\n \nopen\n \nchinook.db\n\n\n\n\n\n\nOne more thing, before we see more complex examples, let's define a quick\nutility function.\n\n\nPrelude\n \nChinook\n.\nSchema\n \nlet\n \nwithConnectionTutorial\n \n=\n \nrunBeamSqliteDebug\n \nputStrLn\n \nchinook\n\n\n\n\n\n\nLet's test it!\n\n\nWe can run all our queries like:\n\n\nwithConnectionTutorial\n \n$\n \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \nquery\n\n\n\n\n\n\nLet's select all the tracks.\n\n\nwithConnectionTutorial\n \n$\n \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n\n\n\n\nFor the rest of the guide, we will also show the generated SQL code for both\nsqlite and postgres.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nTrackId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres3\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres5\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres7\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres8\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nTrackId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres3\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres5\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres7\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres8\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres8\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nReturning a subset of columns\n\n\nOftentimes we only care about the value of a few columns, rather than every\ncolumn in the table. Beam fully supports taking projections of tables. As said\nbefore, \nQ\n is a \nMonad\n. Thus, we can use monadic \ndo\n notation to only select a\ncertain subset of columns. For example, to fetch \nonly\n the name of every track:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ntracks\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \npure\n \n(\ntrackName\n \ntracks\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that beam has properly written the \nSELECT\n projection to only include\nthe \nName\n field.\n\n\nWe can also return multiple fields, by returning a tuple. Perhaps we would also\nlike to know the composer:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ntracks\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \npure\n \n(\ntrackName\n \ntracks\n,\n \ntrackComposer\n \ntracks\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres1\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres1\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres1\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou can also return arbitrary expressions in the projection. For example to\nreturn the name, composer, unit price, and length in seconds (where the database stores it in milliseconds):\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ntracks\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \npure\n \n(\ntrackName\n \ntracks\n,\n \ntrackComposer\n \ntracks\n,\n \ntrackMilliseconds\n \ntracks\n \n`\ndiv_\n`\n \n1000\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres1\n,\n\n       \n(\nt0\n.\nMilliseconds\n)\n \n/\n \n(\n?\n)\n \nAS\n \nres2\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n;\n\n\n\n-- With values: [SQLInteger 1000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres1\n,\n\n       \n(\nt0\n.\nMilliseconds\n)\n \n/\n \n(\n1000\n)\n \nAS\n \nres2\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n(\n`\nt0\n`\n.\n`\nMilliseconds\n`\n)\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres2\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nBeam includes instances to support returning up to 6-tuples. To return more,\nfeel free to nest tuples. As an example, we can write the above query as\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ntracks\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \npure\n \n((\ntrackName\n \ntracks\n,\n \ntrackComposer\n \ntracks\n),\n \ntrackMilliseconds\n \ntracks\n \n`\ndiv_\n`\n \n1000\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres1\n,\n\n       \n(\nt0\n.\nMilliseconds\n)\n \n/\n \n(\n?\n)\n \nAS\n \nres2\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n;\n\n\n\n-- With values: [SQLInteger 1000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres1\n,\n\n       \n(\nt0\n.\nMilliseconds\n)\n \n/\n \n(\n1000\n)\n \nAS\n \nres2\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n(\n`\nt0\n`\n.\n`\nMilliseconds\n`\n)\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres2\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that the nesting of tuples does not affect the generated SQL projection.\nThe tuple structure is only used when reading back the row from the database.\n\n\nThe \nQ\n monad is perfectly rule-abiding, which means it also implements a valid\n\nFunctor\n instance. Thus the above could more easily be written.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfmap\n \n(\n\\\ntracks\n \n-\n \n(\ntrackName\n \ntracks\n,\n \ntrackComposer\n \ntracks\n,\n \ntrackMilliseconds\n \ntracks\n \n`\ndiv_\n`\n \n1000\n))\n \n$\n\n\nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres1\n,\n\n       \n(\nt0\n.\nMilliseconds\n)\n \n/\n \n(\n?\n)\n \nAS\n \nres2\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n;\n\n\n\n-- With values: [SQLInteger 1000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres1\n,\n\n       \n(\nt0\n.\nMilliseconds\n)\n \n/\n \n(\n1000\n)\n \nAS\n \nres2\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n(\n`\nt0\n`\n.\n`\nMilliseconds\n`\n)\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres2\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWHERE\n clause\n\n\nWe've seen how to use \nall_\n to select all rows of a table. Sometimes, you would\nlike to filter results based on the result of some condition. For example,\nperhaps you would like to fetch all customers whose names start with \"Jo\". We\ncan filter over results using the \nfilter_\n function.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_\n \n(\n\\\ncustomer\n \n-\n \ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n$\n\n\nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\n?\n);\n\n\n\n-- With values: [SQLText \nJo%\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \nLIKE\n \n(\nJo%\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou can use \n(\n.)\n and \n(||.)\n to combine boolean expressions, as you'd expect.\nFor example, to select all customers whose first name begins with \"Jo\", last\nname begins with \"S\", and who live in either California or Washington:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                      \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n        \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\n?\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\n?\n)))\n\n  \nAND\n \n((\nCASE\n\n            \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                 \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n            \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                 \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n            \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n        \nEND\n)\n\n       \nOR\n \n(\nCASE\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n           \nEND\n));\n\n\n\n-- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLInteger 1,SQLText \nCA\n,SQLInteger 0,SQLText \nCA\n,SQLText \nWA\n,SQLInteger 1,SQLText \nWA\n,SQLInteger 0,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n(((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n        \nFROM\n \n(\nCA\n))\n\n       \nOR\n \n((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n           \nFROM\n \n(\nWA\n)))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(((\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\n`\nt0\n`\n.\n`\nLastName\n`\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n((\nCASE\n\n            \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                 \nAND\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n            \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                 \nOR\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n            \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nCA\n)\n\n        \nEND\n)\n\n       \nOR\n \n(\nCASE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n               \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nWA\n)\n\n           \nEND\n))\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nWe had to use the \njust_\n function above to compare\n\naddressState (customerAddress customer)\n. This is because \naddressState\n(customerAddress customer)\n represents a nullable column which beam types as\n\nMaybe Text\n. Just as in Haskell, we need to explicitly unwrap the \nMaybe\n\ntype. This is an example of beam offering stronger typing than SQL itself.\n\n\n\n\nLIMIT\n/\nOFFSET\n support\n\n\nThe \nlimit_\n and \noffset_\n functions can be used to truncate the result set at a\ncertain length and fetch different portions of the result. They correspond to\nthe \nLIMIT\n and \nOFFSET\n SQL constructs.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_\n \n10\n \n$\n \noffset_\n \n100\n \n$\n\n\nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                      \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n        \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\n?\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\n?\n)))\n\n  \nAND\n \n((\nCASE\n\n            \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                 \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n            \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                 \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n            \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n        \nEND\n)\n\n       \nOR\n \n(\nCASE\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n           \nEND\n))\n\n\nLIMIT\n \n10\n\n\nOFFSET\n \n100\n;\n\n\n\n-- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLInteger 1,SQLText \nCA\n,SQLInteger 0,SQLText \nCA\n,SQLText \nWA\n,SQLInteger 1,SQLText \nWA\n,SQLInteger 0,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n(((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n        \nFROM\n \n(\nCA\n))\n\n       \nOR\n \n((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n           \nFROM\n \n(\nWA\n)))\n\n\nLIMIT\n \n10\n\n\nOFFSET\n \n100\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(((\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\n`\nt0\n`\n.\n`\nLastName\n`\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n((\nCASE\n\n            \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                 \nAND\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n            \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                 \nOR\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n            \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nCA\n)\n\n        \nEND\n)\n\n       \nOR\n \n(\nCASE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n               \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nWA\n)\n\n           \nEND\n))\n\n\nLIMIT\n \n100\n,\n\n      \n10\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nNested \nlimit_\ns and \noffset_\ns compose in the way you'd expect without\ngenerating extraneous subqueries.\n\n\n\n\n\n\nWarning\n\n\nNote that the order of the \nlimit_\n and \noffset_\n functions matter.\nOffseting an already limited result is not the same as limiting an offseted\nresult. For example, if you offset three rows into a limited set of five\nresults, you will get at most two rows. On the other hand, if you offset\nthree rows and then limit the result to the next five, you may get up to\nfive. Beam will generate exactly the query you specify. Notice the\ndifference below, where the order of the clauses made beam generate a query\nthat returns no results.\n\n\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \noffset_\n \n100\n \n$\n \nlimit_\n \n10\n \n$\n\n\nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                      \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n        \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\n?\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\n?\n)))\n\n  \nAND\n \n((\nCASE\n\n            \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                 \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n            \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                 \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n            \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n        \nEND\n)\n\n       \nOR\n \n(\nCASE\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n           \nEND\n))\n\n\nLIMIT\n \n0\n\n\nOFFSET\n \n100\n;\n\n\n\n-- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLInteger 1,SQLText \nCA\n,SQLInteger 0,SQLText \nCA\n,SQLText \nWA\n,SQLInteger 1,SQLText \nWA\n,SQLInteger 0,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n(((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n        \nFROM\n \n(\nCA\n))\n\n       \nOR\n \n((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n           \nFROM\n \n(\nWA\n)))\n\n\nLIMIT\n \n0\n\n\nOFFSET\n \n100\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(((\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\n`\nt0\n`\n.\n`\nLastName\n`\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n((\nCASE\n\n            \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                 \nAND\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n            \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                 \nOR\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n            \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nCA\n)\n\n        \nEND\n)\n\n       \nOR\n \n(\nCASE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n               \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nWA\n)\n\n           \nEND\n))\n\n\nLIMIT\n \n100\n,\n\n      \n0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nBackends often differ as to how they implement LIMIT/OFFSET. For example, SQLite\nrequires that \nLIMIT\n always be given if an \nOFFSET\n is provided. Beam correctly\nhandles this behavior.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \noffset_\n \n100\n \n$\n\n\nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                      \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n        \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\n?\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\n?\n)))\n\n  \nAND\n \n((\nCASE\n\n            \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                 \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n            \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                 \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n            \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n        \nEND\n)\n\n       \nOR\n \n(\nCASE\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nWHEN\n \n((\nt0\n.\nState\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n               \nELSE\n \n(\nt0\n.\nState\n)\n=\n(\n?\n)\n\n           \nEND\n))\n\n\nLIMIT\n \n-\n1\n\n\nOFFSET\n \n100\n;\n\n\n\n-- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLInteger 1,SQLText \nCA\n,SQLInteger 0,SQLText \nCA\n,SQLText \nWA\n,SQLInteger 1,SQLText \nWA\n,SQLInteger 0,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n(((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n        \nFROM\n \n(\nCA\n))\n\n       \nOR\n \n((\nt0\n.\nState\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n           \nFROM\n \n(\nWA\n)))\n\n  \nOFFSET\n \n100\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(((\n`\nt0\n`\n.\n`\nFirstName\n`\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\n`\nt0\n`\n.\n`\nLastName\n`\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n((\nCASE\n\n            \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                 \nAND\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n            \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                 \nOR\n \n((\nCA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n            \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nCA\n)\n\n        \nEND\n)\n\n       \nOR\n \n(\nCASE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nAND\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n               \nWHEN\n \n((\n`\nt0\n`\n.\n`\nState\n`\n)\n \nIS\n \nNULL\n)\n\n                    \nOR\n \n((\nWA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n               \nELSE\n \n(\n`\nt0\n`\n.\n`\nState\n`\n)\n \n=\n \n(\nWA\n)\n\n           \nEND\n))\n\n\nLIMIT\n \n1000000000\n\n\nOFFSET\n \n100\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that the SQLite query output has provided a dummy \nLIMIT -1\n clause,\nwhile the Postgres query has not.\n\n\nDISTINCT\n support\n\n\nSQL can only return unique results from a query through the \nSELECT DISTINCT\n\nstatement. Beam supports this using the \nnub_\n command. For example, to get all\nthe unique postal codes where our customers live.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nnub_\n \n$\n \nfmap\n \n(\naddressPostalCode\n \n.\n \ncustomerAddress\n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nDISTINCT\n \nt0\n.\nPostalCode\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nDISTINCT\n \nt0\n.\nPostalCode\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nDISTINCT\n \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nVALUES\n support\n\n\nSometimes you want to select from an explicit group of values. This is\nmost helpful if you want to join against a set of values that isn't in\nthe database.\n\n\nFor example, to get all customers we know to be in New York, California, and Texas.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nc\n \n-\n \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n   \nst\n \n-\n \nvalues_\n \n[\n \nNY\n,\n \nCA\n,\n \nTX\n \n]\n\n   \nguard_\n \n(\njust_\n \nst\n \n==?.\n \naddressState\n \n(\ncustomerAddress\n \nc\n))\n\n   \npure\n \nc\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \n(\n\n            \nVALUES\n \n(\nNY\n),\n \n(\nCA\n),\n \n(\nTX\n))\n \nAS\n \nt1\n(\nres0\n)\n\n\nWHERE\n \n(\nt1\n.\nres0\n)\n \n=\n \n(\nt0\n.\nState\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nbeam-sqlite\n does not support \nVALUES\n clauses anywhere within a\nquery, but only within a common table expression.", 
            "title": "More complex SELECTs"
        }, 
        {
            "location": "/user-guide/queries/select/#returning-a-subset-of-columns", 
            "text": "Oftentimes we only care about the value of a few columns, rather than every\ncolumn in the table. Beam fully supports taking projections of tables. As said\nbefore,  Q  is a  Monad . Thus, we can use monadic  do  notation to only select a\ncertain subset of columns. For example, to fetch  only  the name of every track:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   tracks   -   all_   ( track   chinookDb ) \n    pure   ( trackName   tracks )  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0  FROM   Track   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0  FROM   Track   AS   t0  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` Name `   AS   ` res0 `  FROM   ` Track `   AS   ` t0 `  \n\n         \n    \n         \n    \n                 \n                      Notice that beam has properly written the  SELECT  projection to only include\nthe  Name  field.  We can also return multiple fields, by returning a tuple. Perhaps we would also\nlike to know the composer:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   tracks   -   all_   ( track   chinookDb ) \n    pure   ( trackName   tracks ,   trackComposer   tracks )  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0 , \n        t0 . Composer   AS   res1  FROM   Track   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0 , \n        t0 . Composer   AS   res1  FROM   Track   AS   t0  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` Name `   AS   ` res0 ` , \n        ` t0 ` . ` Composer `   AS   ` res1 `  FROM   ` Track `   AS   ` t0 `  \n\n         \n    \n         \n    \n                 \n                      You can also return arbitrary expressions in the projection. For example to\nreturn the name, composer, unit price, and length in seconds (where the database stores it in milliseconds):  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   tracks   -   all_   ( track   chinookDb ) \n    pure   ( trackName   tracks ,   trackComposer   tracks ,   trackMilliseconds   tracks   ` div_ `   1000 )  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0 , \n        t0 . Composer   AS   res1 , \n        ( t0 . Milliseconds )   /   ( ? )   AS   res2  FROM   Track   AS   t0 ;  -- With values: [SQLInteger 1000]  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0 , \n        t0 . Composer   AS   res1 , \n        ( t0 . Milliseconds )   /   ( 1000 )   AS   res2  FROM   Track   AS   t0  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` Name `   AS   ` res0 ` , \n        ` t0 ` . ` Composer `   AS   ` res1 ` , \n        ( ` t0 ` . ` Milliseconds ` )   /   ( 1000 )   AS   ` res2 `  FROM   ` Track `   AS   ` t0 `  \n\n         \n    \n         \n    \n                 \n                      Beam includes instances to support returning up to 6-tuples. To return more,\nfeel free to nest tuples. As an example, we can write the above query as  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   tracks   -   all_   ( track   chinookDb ) \n    pure   (( trackName   tracks ,   trackComposer   tracks ),   trackMilliseconds   tracks   ` div_ `   1000 )  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0 , \n        t0 . Composer   AS   res1 , \n        ( t0 . Milliseconds )   /   ( ? )   AS   res2  FROM   Track   AS   t0 ;  -- With values: [SQLInteger 1000]  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0 , \n        t0 . Composer   AS   res1 , \n        ( t0 . Milliseconds )   /   ( 1000 )   AS   res2  FROM   Track   AS   t0  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` Name `   AS   ` res0 ` , \n        ` t0 ` . ` Composer `   AS   ` res1 ` , \n        ( ` t0 ` . ` Milliseconds ` )   /   ( 1000 )   AS   ` res2 `  FROM   ` Track `   AS   ` t0 `  \n\n         \n    \n         \n    \n                 \n                      Notice that the nesting of tuples does not affect the generated SQL projection.\nThe tuple structure is only used when reading back the row from the database.  The  Q  monad is perfectly rule-abiding, which means it also implements a valid Functor  instance. Thus the above could more easily be written.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             fmap   ( \\ tracks   -   ( trackName   tracks ,   trackComposer   tracks ,   trackMilliseconds   tracks   ` div_ `   1000 ))   $  all_   ( track   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0 , \n        t0 . Composer   AS   res1 , \n        ( t0 . Milliseconds )   /   ( ? )   AS   res2  FROM   Track   AS   t0 ;  -- With values: [SQLInteger 1000]  \n\n         \n    \n         \n             SELECT   t0 . Name   AS   res0 , \n        t0 . Composer   AS   res1 , \n        ( t0 . Milliseconds )   /   ( 1000 )   AS   res2  FROM   Track   AS   t0  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` Name `   AS   ` res0 ` , \n        ` t0 ` . ` Composer `   AS   ` res1 ` , \n        ( ` t0 ` . ` Milliseconds ` )   /   ( 1000 )   AS   ` res2 `  FROM   ` Track `   AS   ` t0 `", 
            "title": "Returning a subset of columns"
        }, 
        {
            "location": "/user-guide/queries/select/#where-clause", 
            "text": "We've seen how to use  all_  to select all rows of a table. Sometimes, you would\nlike to filter results based on the result of some condition. For example,\nperhaps you would like to fetch all customers whose names start with \"Jo\". We\ncan filter over results using the  filter_  function.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             filter_   ( \\ customer   -   customerFirstName   customer   ` like_ `   Jo% )   $  all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . FirstName )   LIKE   ( ? );  -- With values: [SQLText  Jo% ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . FirstName )   LIKE   ( Jo% )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ( ` t0 ` . ` FirstName ` )   LIKE   ( Jo% )  \n\n         \n    \n         \n    \n                 \n                      You can use  ( .)  and  (||.)  to combine boolean expressions, as you'd expect.\nFor example, to select all customers whose first name begins with \"Jo\", last\nname begins with \"S\", and who live in either California or Washington:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                       ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n         all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( ? )) \n        AND   (( t0 . LastName )   LIKE   ( ? ))) \n   AND   (( CASE \n             WHEN   (( t0 . State )   IS   NULL ) \n                  AND   (( ? )   IS   NULL )   THEN   ? \n             WHEN   (( t0 . State )   IS   NULL ) \n                  OR   (( ? )   IS   NULL )   THEN   ? \n             ELSE   ( t0 . State ) = ( ? ) \n         END ) \n        OR   ( CASE \n                WHEN   (( t0 . State )   IS   NULL ) \n                     AND   (( ? )   IS   NULL )   THEN   ? \n                WHEN   (( t0 . State )   IS   NULL ) \n                     OR   (( ? )   IS   NULL )   THEN   ? \n                ELSE   ( t0 . State ) = ( ? ) \n            END ));  -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLInteger 1,SQLText  CA ,SQLInteger 0,SQLText  CA ,SQLText  WA ,SQLInteger 1,SQLText  WA ,SQLInteger 0,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n        AND   (( t0 . LastName )   LIKE   ( S% ))) \n   AND   ((( t0 . State )   IS   NOT   DISTINCT \n         FROM   ( CA )) \n        OR   (( t0 . State )   IS   NOT   DISTINCT \n            FROM   ( WA )))  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ((( ` t0 ` . ` FirstName ` )   LIKE   ( Jo% )) \n        AND   (( ` t0 ` . ` LastName ` )   LIKE   ( S% ))) \n   AND   (( CASE \n             WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                  AND   (( CA )   IS   NULL )   THEN   TRUE \n             WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                  OR   (( CA )   IS   NULL )   THEN   FALSE \n             ELSE   ( ` t0 ` . ` State ` )   =   ( CA ) \n         END ) \n        OR   ( CASE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     AND   (( WA )   IS   NULL )   THEN   TRUE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     OR   (( WA )   IS   NULL )   THEN   FALSE \n                ELSE   ( ` t0 ` . ` State ` )   =   ( WA ) \n            END ))  \n\n         \n    \n         \n    \n                 \n                       Note  We had to use the  just_  function above to compare addressState (customerAddress customer) . This is because  addressState\n(customerAddress customer)  represents a nullable column which beam types as Maybe Text . Just as in Haskell, we need to explicitly unwrap the  Maybe \ntype. This is an example of beam offering stronger typing than SQL itself.", 
            "title": "WHERE clause"
        }, 
        {
            "location": "/user-guide/queries/select/#limitoffset-support", 
            "text": "The  limit_  and  offset_  functions can be used to truncate the result set at a\ncertain length and fetch different portions of the result. They correspond to\nthe  LIMIT  and  OFFSET  SQL constructs.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             limit_   10   $   offset_   100   $  filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                       ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n         all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( ? )) \n        AND   (( t0 . LastName )   LIKE   ( ? ))) \n   AND   (( CASE \n             WHEN   (( t0 . State )   IS   NULL ) \n                  AND   (( ? )   IS   NULL )   THEN   ? \n             WHEN   (( t0 . State )   IS   NULL ) \n                  OR   (( ? )   IS   NULL )   THEN   ? \n             ELSE   ( t0 . State ) = ( ? ) \n         END ) \n        OR   ( CASE \n                WHEN   (( t0 . State )   IS   NULL ) \n                     AND   (( ? )   IS   NULL )   THEN   ? \n                WHEN   (( t0 . State )   IS   NULL ) \n                     OR   (( ? )   IS   NULL )   THEN   ? \n                ELSE   ( t0 . State ) = ( ? ) \n            END ))  LIMIT   10  OFFSET   100 ;  -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLInteger 1,SQLText  CA ,SQLInteger 0,SQLText  CA ,SQLText  WA ,SQLInteger 1,SQLText  WA ,SQLInteger 0,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n        AND   (( t0 . LastName )   LIKE   ( S% ))) \n   AND   ((( t0 . State )   IS   NOT   DISTINCT \n         FROM   ( CA )) \n        OR   (( t0 . State )   IS   NOT   DISTINCT \n            FROM   ( WA )))  LIMIT   10  OFFSET   100  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ((( ` t0 ` . ` FirstName ` )   LIKE   ( Jo% )) \n        AND   (( ` t0 ` . ` LastName ` )   LIKE   ( S% ))) \n   AND   (( CASE \n             WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                  AND   (( CA )   IS   NULL )   THEN   TRUE \n             WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                  OR   (( CA )   IS   NULL )   THEN   FALSE \n             ELSE   ( ` t0 ` . ` State ` )   =   ( CA ) \n         END ) \n        OR   ( CASE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     AND   (( WA )   IS   NULL )   THEN   TRUE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     OR   (( WA )   IS   NULL )   THEN   FALSE \n                ELSE   ( ` t0 ` . ` State ` )   =   ( WA ) \n            END ))  LIMIT   100 , \n       10  \n\n         \n    \n         \n    \n                 \n                       Note  Nested  limit_ s and  offset_ s compose in the way you'd expect without\ngenerating extraneous subqueries.    Warning  Note that the order of the  limit_  and  offset_  functions matter.\nOffseting an already limited result is not the same as limiting an offseted\nresult. For example, if you offset three rows into a limited set of five\nresults, you will get at most two rows. On the other hand, if you offset\nthree rows and then limit the result to the next five, you may get up to\nfive. Beam will generate exactly the query you specify. Notice the\ndifference below, where the order of the clauses made beam generate a query\nthat returns no results.   \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             offset_   100   $   limit_   10   $  filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                       ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n         all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( ? )) \n        AND   (( t0 . LastName )   LIKE   ( ? ))) \n   AND   (( CASE \n             WHEN   (( t0 . State )   IS   NULL ) \n                  AND   (( ? )   IS   NULL )   THEN   ? \n             WHEN   (( t0 . State )   IS   NULL ) \n                  OR   (( ? )   IS   NULL )   THEN   ? \n             ELSE   ( t0 . State ) = ( ? ) \n         END ) \n        OR   ( CASE \n                WHEN   (( t0 . State )   IS   NULL ) \n                     AND   (( ? )   IS   NULL )   THEN   ? \n                WHEN   (( t0 . State )   IS   NULL ) \n                     OR   (( ? )   IS   NULL )   THEN   ? \n                ELSE   ( t0 . State ) = ( ? ) \n            END ))  LIMIT   0  OFFSET   100 ;  -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLInteger 1,SQLText  CA ,SQLInteger 0,SQLText  CA ,SQLText  WA ,SQLInteger 1,SQLText  WA ,SQLInteger 0,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n        AND   (( t0 . LastName )   LIKE   ( S% ))) \n   AND   ((( t0 . State )   IS   NOT   DISTINCT \n         FROM   ( CA )) \n        OR   (( t0 . State )   IS   NOT   DISTINCT \n            FROM   ( WA )))  LIMIT   0  OFFSET   100  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ((( ` t0 ` . ` FirstName ` )   LIKE   ( Jo% )) \n        AND   (( ` t0 ` . ` LastName ` )   LIKE   ( S% ))) \n   AND   (( CASE \n             WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                  AND   (( CA )   IS   NULL )   THEN   TRUE \n             WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                  OR   (( CA )   IS   NULL )   THEN   FALSE \n             ELSE   ( ` t0 ` . ` State ` )   =   ( CA ) \n         END ) \n        OR   ( CASE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     AND   (( WA )   IS   NULL )   THEN   TRUE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     OR   (( WA )   IS   NULL )   THEN   FALSE \n                ELSE   ( ` t0 ` . ` State ` )   =   ( WA ) \n            END ))  LIMIT   100 , \n       0  \n\n         \n    \n         \n    \n                 \n                      Backends often differ as to how they implement LIMIT/OFFSET. For example, SQLite\nrequires that  LIMIT  always be given if an  OFFSET  is provided. Beam correctly\nhandles this behavior.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             offset_   100   $  filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                       ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n         all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( ? )) \n        AND   (( t0 . LastName )   LIKE   ( ? ))) \n   AND   (( CASE \n             WHEN   (( t0 . State )   IS   NULL ) \n                  AND   (( ? )   IS   NULL )   THEN   ? \n             WHEN   (( t0 . State )   IS   NULL ) \n                  OR   (( ? )   IS   NULL )   THEN   ? \n             ELSE   ( t0 . State ) = ( ? ) \n         END ) \n        OR   ( CASE \n                WHEN   (( t0 . State )   IS   NULL ) \n                     AND   (( ? )   IS   NULL )   THEN   ? \n                WHEN   (( t0 . State )   IS   NULL ) \n                     OR   (( ? )   IS   NULL )   THEN   ? \n                ELSE   ( t0 . State ) = ( ? ) \n            END ))  LIMIT   - 1  OFFSET   100 ;  -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLInteger 1,SQLText  CA ,SQLInteger 0,SQLText  CA ,SQLText  WA ,SQLInteger 1,SQLText  WA ,SQLInteger 0,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n        AND   (( t0 . LastName )   LIKE   ( S% ))) \n   AND   ((( t0 . State )   IS   NOT   DISTINCT \n         FROM   ( CA )) \n        OR   (( t0 . State )   IS   NOT   DISTINCT \n            FROM   ( WA ))) \n   OFFSET   100  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ((( ` t0 ` . ` FirstName ` )   LIKE   ( Jo% )) \n        AND   (( ` t0 ` . ` LastName ` )   LIKE   ( S% ))) \n   AND   (( CASE \n             WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                  AND   (( CA )   IS   NULL )   THEN   TRUE \n             WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                  OR   (( CA )   IS   NULL )   THEN   FALSE \n             ELSE   ( ` t0 ` . ` State ` )   =   ( CA ) \n         END ) \n        OR   ( CASE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     AND   (( WA )   IS   NULL )   THEN   TRUE \n                WHEN   (( ` t0 ` . ` State ` )   IS   NULL ) \n                     OR   (( WA )   IS   NULL )   THEN   FALSE \n                ELSE   ( ` t0 ` . ` State ` )   =   ( WA ) \n            END ))  LIMIT   1000000000  OFFSET   100  \n\n         \n    \n         \n    \n                 \n                      Notice that the SQLite query output has provided a dummy  LIMIT -1  clause,\nwhile the Postgres query has not.", 
            "title": "LIMIT/OFFSET support"
        }, 
        {
            "location": "/user-guide/queries/select/#distinct-support", 
            "text": "SQL can only return unique results from a query through the  SELECT DISTINCT \nstatement. Beam supports this using the  nub_  command. For example, to get all\nthe unique postal codes where our customers live.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             nub_   $   fmap   ( addressPostalCode   .   customerAddress )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   DISTINCT   t0 . PostalCode   AS   res0  FROM   Customer   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             SELECT   DISTINCT   t0 . PostalCode   AS   res0  FROM   Customer   AS   t0  \n\n         \n    \n         \n             SELECT   DISTINCT   ` t0 ` . ` PostalCode `   AS   ` res0 `  FROM   ` Customer `   AS   ` t0 `", 
            "title": "DISTINCT support"
        }, 
        {
            "location": "/user-guide/queries/select/#values-support", 
            "text": "Sometimes you want to select from an explicit group of values. This is\nmost helpful if you want to join against a set of values that isn't in\nthe database.  For example, to get all customers we know to be in New York, California, and Texas.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do   c   -   all_   ( customer   chinookDb ) \n    st   -   values_   [   NY ,   CA ,   TX   ] \n    guard_   ( just_   st   ==?.   addressState   ( customerAddress   c )) \n    pure   c  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  CROSS   JOIN   ( \n             VALUES   ( NY ),   ( CA ),   ( TX ))   AS   t1 ( res0 )  WHERE   ( t1 . res0 )   =   ( t0 . State )  \n\n         \n    \n         \n    \n                 \n                       Note  beam-sqlite  does not support  VALUES  clauses anywhere within a\nquery, but only within a common table expression.", 
            "title": "VALUES support"
        }, 
        {
            "location": "/user-guide/queries/ordering/", 
            "text": "Usually, queries are ordered before \nLIMIT\n and \nOFFSET\n are applied. Beam\nsupports the standard SQL \nORDER BY\n construct through the \norderBy_\n function.\n\n\norderBy_\n works like the Haskell function \nsortBy\n, with some restrictions. Its\nfirst argument is a function which takes as input the output of the given query.\nThe function should return a sorting key, which is either a single sort ordering\nor a tuple of them. A sort ordering specifies an expression and a direction by\nwhich to sort. The result is then sorted lexicographically based on these sort\nexpressions. The second argument to \norderBy_\n is the query whose results to\nsort.\n\n\nUse the \nasc_\n and \ndesc_\n functions to specify the sort ordering over an\narbitrary expression.\n\n\n\n\nNote\n\n\nUse \nnullsFirst_\n and \nnullsLast_\n to control the ordering of nulls.\nSee \nadvanced features\n for more information.\n\n\n\n\nFor example, to get the first ten albums when sorted lexicographically, use\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_\n \n10\n  \n$\n\n\norderBy_\n \n(\nasc_\n \n.\n \nalbumTitle\n)\n \n$\n\n\nall_\n \n(\nalbum\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nTitle\n \nAS\n \nres1\n,\n\n       \nt0\n.\nArtistId\n \nAS\n \nres2\n\n\nFROM\n \nAlbum\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nTitle\n \nASC\n\n\nLIMIT\n \n10\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nTitle\n \nAS\n \nres1\n,\n\n       \nt0\n.\nArtistId\n \nAS\n \nres2\n\n\nFROM\n \nAlbum\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nTitle\n \nASC\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nArtistId\n`\n \nAS\n \n`\nres2\n`\n\n\nFROM\n \n`\nAlbum\n`\n \nAS\n \n`\nt0\n`\n\n\nORDER\n \nBY\n \n`\nt0\n`\n.\n`\nTitle\n`\n \nASC\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nAgain, note that the ordering in which you apply the \nlimit_\n and \norderBy_\n\nmatters. In general, you want to sort before you limit or offset, to keep your\nresult set stable. However, if you really want to sort a limited number of\narbitrarily chosen rows, you can use a different ordering.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \norderBy_\n \n(\nasc_\n \n.\n \nalbumTitle\n)\n \n$\n\n\nlimit_\n \n10\n \n$\n\n\nall_\n \n(\nalbum\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nTitle\n \nAS\n \nres1\n,\n\n          \nt0\n.\nArtistId\n \nAS\n \nres2\n\n   \nFROM\n \nAlbum\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nres1\n \nASC\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nTitle\n \nAS\n \nres1\n,\n\n          \nt0\n.\nArtistId\n \nAS\n \nres2\n\n   \nFROM\n \nAlbum\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nres1\n \nASC\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres2\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \n`\nt0\n`\n.\n`\nArtistId\n`\n \nAS\n \n`\nres2\n`\n\n   \nFROM\n \n`\nAlbum\n`\n \nAS\n \n`\nt0\n`\n\n   \nLIMIT\n \n10\n)\n \nAS\n \n`\nt0\n`\n\n\nORDER\n \nBY\n \n`\nt0\n`\n.\n`\nres1\n`\n \nASC\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nMultiple ordering keys\n\n\nYou can specify multiple keys to order by as well. Keys are sorted\nlexicographically in the given direction, as specified in the SQL standard.\n\n\nFor example, we can sort all employees by their state of residence in ascending\norder and by their city name in descending order.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_\n \n10\n \n$\n\n\norderBy_\n \n(\n\\\ne\n \n-\n \n(\nasc_\n \n(\naddressState\n \n(\nemployeeAddress\n \ne\n)),\n \ndesc_\n \n(\naddressCity\n \n(\nemployeeAddress\n \ne\n))))\n \n$\n\n\nall_\n \n(\nemployee\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nEmployeeId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt0\n.\nReportsTo\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBirthDate\n \nAS\n \nres5\n,\n\n       \nt0\n.\nHireDate\n \nAS\n \nres6\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres7\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres8\n,\n\n       \nt0\n.\nState\n \nAS\n \nres9\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres10\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres11\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres12\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres13\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres14\n\n\nFROM\n \nEmployee\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nState\n \nASC\n,\n\n         \nt0\n.\nCity\n \nDESC\n\n\nLIMIT\n \n10\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nEmployeeId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt0\n.\nReportsTo\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBirthDate\n \nAS\n \nres5\n,\n\n       \nt0\n.\nHireDate\n \nAS\n \nres6\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres7\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres8\n,\n\n       \nt0\n.\nState\n \nAS\n \nres9\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres10\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres11\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres12\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres13\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres14\n\n\nFROM\n \nEmployee\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nState\n \nASC\n,\n\n         \nt0\n.\nCity\n \nDESC\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nEmployeeId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nReportsTo\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBirthDate\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nHireDate\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres13\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres14\n`\n\n\nFROM\n \n`\nEmployee\n`\n \nAS\n \n`\nt0\n`\n\n\nORDER\n \nBY\n \n`\nt0\n`\n.\n`\nState\n`\n \nASC\n,\n\n         \n`\nt0\n`\n.\n`\nCity\n`\n \nDESC\n\n\nLIMIT\n \n10", 
            "title": "Ordering"
        }, 
        {
            "location": "/user-guide/queries/ordering/#multiple-ordering-keys", 
            "text": "You can specify multiple keys to order by as well. Keys are sorted\nlexicographically in the given direction, as specified in the SQL standard.  For example, we can sort all employees by their state of residence in ascending\norder and by their city name in descending order.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             limit_   10   $  orderBy_   ( \\ e   -   ( asc_   ( addressState   ( employeeAddress   e )),   desc_   ( addressCity   ( employeeAddress   e ))))   $  all_   ( employee   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . EmployeeId   AS   res0 , \n        t0 . LastName   AS   res1 , \n        t0 . FirstName   AS   res2 , \n        t0 . Title   AS   res3 , \n        t0 . ReportsTo   AS   res4 , \n        t0 . BirthDate   AS   res5 , \n        t0 . HireDate   AS   res6 , \n        t0 . Address   AS   res7 , \n        t0 . City   AS   res8 , \n        t0 . State   AS   res9 , \n        t0 . Country   AS   res10 , \n        t0 . PostalCode   AS   res11 , \n        t0 . Phone   AS   res12 , \n        t0 . Fax   AS   res13 , \n        t0 . Email   AS   res14  FROM   Employee   AS   t0  ORDER   BY   t0 . State   ASC , \n          t0 . City   DESC  LIMIT   10 ;  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . EmployeeId   AS   res0 , \n        t0 . LastName   AS   res1 , \n        t0 . FirstName   AS   res2 , \n        t0 . Title   AS   res3 , \n        t0 . ReportsTo   AS   res4 , \n        t0 . BirthDate   AS   res5 , \n        t0 . HireDate   AS   res6 , \n        t0 . Address   AS   res7 , \n        t0 . City   AS   res8 , \n        t0 . State   AS   res9 , \n        t0 . Country   AS   res10 , \n        t0 . PostalCode   AS   res11 , \n        t0 . Phone   AS   res12 , \n        t0 . Fax   AS   res13 , \n        t0 . Email   AS   res14  FROM   Employee   AS   t0  ORDER   BY   t0 . State   ASC , \n          t0 . City   DESC  LIMIT   10  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` EmployeeId `   AS   ` res0 ` , \n        ` t0 ` . ` LastName `   AS   ` res1 ` , \n        ` t0 ` . ` FirstName `   AS   ` res2 ` , \n        ` t0 ` . ` Title `   AS   ` res3 ` , \n        ` t0 ` . ` ReportsTo `   AS   ` res4 ` , \n        ` t0 ` . ` BirthDate `   AS   ` res5 ` , \n        ` t0 ` . ` HireDate `   AS   ` res6 ` , \n        ` t0 ` . ` Address `   AS   ` res7 ` , \n        ` t0 ` . ` City `   AS   ` res8 ` , \n        ` t0 ` . ` State `   AS   ` res9 ` , \n        ` t0 ` . ` Country `   AS   ` res10 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res11 ` , \n        ` t0 ` . ` Phone `   AS   ` res12 ` , \n        ` t0 ` . ` Fax `   AS   ` res13 ` , \n        ` t0 ` . ` Email `   AS   ` res14 `  FROM   ` Employee `   AS   ` t0 `  ORDER   BY   ` t0 ` . ` State `   ASC , \n          ` t0 ` . ` City `   DESC  LIMIT   10", 
            "title": "Multiple ordering keys"
        }, 
        {
            "location": "/user-guide/queries/relationships/", 
            "text": "Relational databases are so-named because they're good at expressing relations\namong data and providing related data in queries. Beam exposes these features in\nits DSL.\n\n\nFor these examples, we're going to use the \nbeam-sqlite\n backend with the\nprovided sample Chinook database.\n\n\nFirst, create a SQLite database from the included example.\n\n\n sqlite3 chinook.db \n beam-sqlite/examples/chinook.sql\n\n\n\n\n\nNow, load the chinook database schema in GHCi.\n\n\nPrelude\n \nDatabase\n.\nBeam\n.\nSqlite\n \n:\nload\n \nbeam\n-\nsqlite\n/\nexamples\n/\nChinook\n/\nSchema\n.\nhs\n\n\nPrelude\n \nChinook\n.\nSchema\n \nchinook\n \n-\n \nopen\n \nchinook.db\n\n\n\n\n\n\nOne more thing, before we explore how beam handles relationships. Before we do, let's define a quick utility function.\n\n\nPrelude\n \nChinook\n.\nSchema\n \nlet\n \nwithConnectionTutorial\n \n=\n \nrunBeamSqliteDebug\n \nputStrLn\n \nchinook\n\n\n\n\n\n\nThis function prints each of our queries to standard output before running them.\nUsing this function will let us see what SQL is executing.\n\n\nFull inner joins\n\n\nRecall that the \nQ\n type is a monad. In many respects, \nQ\n operates like the\nlist monad. For those unfamiliar, the monadic bind operator for \n[]\n is defined\nas \nconcatMap\n. Thus,\n\n\ndo\n \na\n \n-\n \n[\n1\n,\n2\n,\n3\n]\n\n   \nb\n \n-\n \n[\n4\n,\n5\n,\n6\n]\n\n   \nreturn\n \n(\na\n,\n \nb\n)\n\n\n\n\n\n\nis equivalent to \n[(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)]\n.\n\n\nThis operation is similar to the cartesian product from set theory or the \ninner\njoin\n from relational algebra. The \nQ\n monad fully supports this notion of join,\nand in fact, every other join is built off of this primitive.\n\n\nFor example, to get every row from the invoice table and every row from the\ninvoice line table, with no attention paid to any relationship between the two:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \nall_\n \n(\ninvoiceLine\n \nchinookDb\n)\n\n   \npure\n \n(\ni\n,\n \nln\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nInvoiceDate\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingAddress\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCity\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingState\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCountry\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingPostalCode\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTotal\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceLineId\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nQuantity\n`\n \nAS\n \n`\nres13\n`\n\n\nFROM\n \n`\nInvoice\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt1\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOf course, most of the time you only want to fetch relevant rows. Going back to\nthe list monad example, suppose we only want to fetch pairs where the second\nnumber is less than or equal to twice the first. In Haskell, we'd use the\n\nguard\n function.\n\n\ndo\n \na\n \n-\n \n[\n1\n,\n2\n,\n3\n]\n\n   \nb\n \n-\n \n[\n4\n,\n5\n,\n6\n]\n\n   \nguard\n \n(\nb\n \n=\n \na\n \n*\n \n2\n)\n\n   \nreturn\n \n(\na\n,\n \nb\n)\n\n\n\n\n\n\nThis would return \n[(2,4),(3,4),(3,5)]\n.\n\n\nBeam offers a similar function for the \nQ\n monad, named \nguard_\n. Note that\nwhereas the \nQ\n bind operator is the same as the Haskell monadic bind, the\ncorresponding \nguard\n function is not from \nMonadZero\n, as it is in Haskell. The\ntechnical reason is that the argument to \nguard_\n in \nQ\n represents a SQL\nexpression returning a boolean, rather than a Haskell boolean itself.\n\n\nGoing back to our invoice line example above, we can fetch every invoice along\nwith only those invoice lines corresponding to that invoice.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \nall_\n \n(\ninvoiceLine\n \nchinookDb\n)\n\n   \nguard_\n \n(\ninvoiceLineInvoice\n \nln\n \n`\nreferences_\n`\n \ni\n)\n\n   \npure\n \n(\ni\n,\n \nln\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n\n\nWHERE\n \n(\nt1\n.\nInvoiceId\n)\n=\n(\nt0\n.\nInvoiceId\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n\n\nWHERE\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nInvoiceId\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nInvoiceDate\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingAddress\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCity\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingState\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCountry\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingPostalCode\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTotal\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceLineId\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nQuantity\n`\n \nAS\n \n`\nres13\n`\n\n\nFROM\n \n`\nInvoice\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt1\n`\n\n\nWHERE\n \n(\n`\nt1\n`\n.\n`\nInvoiceId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nInvoiceId\n`\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNote that beam has floated the \nguard_\n expression into the \nWHERE\n clause,\nrather than the \nON\n clause, This is fine for most inner joins on most database\nengines, as the query optimizer will execute both queries similarly. However,\nsome backends are more temperamental, so Beam offers several more idiomatic ways\nto express joins which more closely reflect the underlying SQL. In practice,\nmost users will use the methods below to express JOINs, but it is nevertheless\nimportant to understand that joining is fundamental to the structure of the \nQ\n\nmoand.\n\n\nOne-to-many\n\n\nBeam supports querying for one-to-many joins. For example, to get every\n\nInvoiceLine\n for each \nInvoice\n, use the \noneToMany_\n combinator.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \noneToMany_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \ninvoiceLineInvoice\n \ni\n\n   \npure\n \n(\ni\n,\n \nln\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n=\n(\nt0\n.\nInvoiceId\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nInvoiceId\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nInvoiceDate\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingAddress\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCity\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingState\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCountry\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingPostalCode\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTotal\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceLineId\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nQuantity\n`\n \nAS\n \n`\nres13\n`\n\n\nFROM\n \n`\nInvoice\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n(\n`\nt1\n`\n.\n`\nInvoiceId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nInvoiceId\n`\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOr, if you have an actual \nInvoice\n (called \noneInvoice\n) and you want all the\nassociated \nInvoiceLine\ns, you can use \nval_\n to convert \noneInvoice\n to the SQL\nexpression level.\n\n\noneToMany_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \ninvoiceLineInvoice\n \n(\nval_\n \noneInvoice\n)\n\n\n\n\n\n\nIf you find yourself repeating yourself constantly, you can define a helper.\n\n\ninvoiceLines_\n \n::\n \nOneToMany\n \nInvoiceT\n \nInvoiceLineT\n\n\ninvoiceLines_\n \n=\n \noneToMany_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \ninvoiceLineInvoice\n\n\n\n\n\n\nThen the above queries become\n\n\ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \ninvoiceLines_\n \ni\n\n\n\n\n\n\nand\n\n\ninvoiceLines\n \n(\nval_\n \ni\n)\n\n\n\n\n\n\nNotice that, instead of floating the join condition to the \nWHERE\n clause, beam\ngenerates an \nINNER JOIN ... ON\n expression. These statements are equivalent,\nalthough the \nON\n expression is more idiomatic.\n\n\nNullable columns\n\n\nIf you have a nullable foreign key in your many table, you can use\n\noneToManyOptional_\n and \nOneToManyOptional\n, respectively. For example, \n\n\nOne-to-one\n\n\nOne to one relationships are a special case of one to many relationships, save\nfor a unique constraint on one column. Thus, there are no special constructs for\none-to-one relationships.\n\n\nFor convenience, \noneToOne_\n and \nOneToOne\n are equivalent to \noneToMany_\n and\n\nOneToMany\n. Additionally, \noneToMaybe_\n and \nOneToMaybe\n correspond to\n\noneToManyOptional_\n and \nOneToManyOptional\n.\n\n\nMany-to-many\n\n\nMany to many relationships require a linking table, with foreign keys to each\ntable part of the relationship.\n\n\nThe \nmanyToMany_\n construct can be used to fetch both, one, or no sides of a\nmany-to-many relationship.\n\n\nmanyToMany_\n\n  \n::\n \n(\n \nDatabase\n \nbe\n \ndb\n,\n \nTable\n \njoinThrough\n\n     \n,\n \nTable\n \nleft\n,\n \nTable\n \nright\n\n     \n,\n \nSql92SelectSanityCheck\n \nsyntax\n\n     \n,\n \nIsSql92SelectSyntax\n \nsyntax\n\n\n     \n,\n \nSqlEq\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n(\nPrimaryKey\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n     \n,\n \nSqlEq\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n(\nPrimaryKey\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n \n)\n\n  \n=\n \nDatabaseEntity\n \nbe\n \ndb\n \n(\nTableEntity\n \njoinThrough\n)\n\n  \n-\n \n(\njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n-\n \nPrimaryKey\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \n(\njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n-\n \nPrimaryKey\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n),\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n\n\n\n\n\nThis reads: for any database \ndb\n; tables \njoinThrough\n, \nleft\n, and \nright\n;\nand sane select syntax \nsyntax\n, where the primary keys of \nleft\n and \nright\n\nare comparable as value expressions and we have some way of extracting a primary\nkey of \nleft\n and \nright\n from \njoinThrough\n, associate all entries of \nleft\n\nwith those of \nright\n through \njoinThrough\n and return the results of \nleft\n and\n\nright\n.\n\n\nThe Chinook database associates multiple tracks with a playlist via the\n\nplaylist_track\n table. For example, to get all tracks from the playlists named\neither \"Movies\" or \"Music\".\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nmanyToMany_\n \n(\nplaylistTrack\n \nchinookDb\n)\n\n            \nplaylistTrackPlaylistId\n \nplaylistTrackTrackId\n\n\n            \n(\nfilter_\n \n(\n\\\np\n \n-\n \nplaylistName\n \np\n \n==.\n \njust_\n \n(\nval_\n \nMusic\n)\n \n||.\n\n                            \nplaylistName\n \np\n \n==.\n \njust_\n \n(\nval_\n \nMovies\n))\n\n                     \n(\nall_\n \n(\nplaylist\n \nchinookDb\n)))\n\n\n            \n(\nall_\n \n(\ntrack\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n \nPlaylistTrack\n \nAS\n \nt2\n \nON\n \n((\nt2\n.\nPlaylistId\n)\n=\n(\nt0\n.\nPlaylistId\n))\n\n\nAND\n \n((\nt2\n.\nTrackId\n)\n=\n(\nt1\n.\nTrackId\n))\n\n\nWHERE\n \n(\nCASE\n\n           \nWHEN\n \n((\nt0\n.\nName\n)\n \nIS\n \nNULL\n)\n\n                \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n           \nWHEN\n \n((\nt0\n.\nName\n)\n \nIS\n \nNULL\n)\n\n                \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n           \nELSE\n \n(\nt0\n.\nName\n)\n=\n(\n?\n)\n\n       \nEND\n)\n\n  \nOR\n \n(\nCASE\n\n          \nWHEN\n \n((\nt0\n.\nName\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nt0\n.\nName\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nt0\n.\nName\n)\n=\n(\n?\n)\n\n      \nEND\n);\n\n\n\n-- With values: [SQLText \nMusic\n,SQLInteger 1,SQLText \nMusic\n,SQLInteger 0,SQLText \nMusic\n,SQLText \nMovies\n,SQLInteger 1,SQLText \nMovies\n,SQLInteger 0,SQLText \nMovies\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n \nPlaylistTrack\n \nAS\n \nt2\n \nON\n \n((\nt2\n.\nPlaylistId\n)\n \n=\n \n(\nt0\n.\nPlaylistId\n))\n\n\nAND\n \n((\nt2\n.\nTrackId\n)\n \n=\n \n(\nt1\n.\nTrackId\n))\n\n\nWHERE\n \n((\nt0\n.\nName\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n       \nFROM\n \n(\nMusic\n))\n\n  \nOR\n \n((\nt0\n.\nName\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n      \nFROM\n \n(\nMovies\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nPlaylistId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt1\n`\n.\n`\nName\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt1\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt1\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres10\n`\n\n\nFROM\n \n`\nPlaylist\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n\n\nJOIN\n \n`\nPlaylistTrack\n`\n \nAS\n \n`\nt2\n`\n \nON\n \n((\n`\nt2\n`\n.\n`\nPlaylistId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nPlaylistId\n`\n))\n\n\nAND\n \n((\n`\nt2\n`\n.\n`\nTrackId\n`\n)\n \n=\n \n(\n`\nt1\n`\n.\n`\nTrackId\n`\n))\n\n\nWHERE\n \n(\nCASE\n\n           \nWHEN\n \n((\n`\nt0\n`\n.\n`\nName\n`\n)\n \nIS\n \nNULL\n)\n\n                \nAND\n \n((\nMusic\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n           \nWHEN\n \n((\n`\nt0\n`\n.\n`\nName\n`\n)\n \nIS\n \nNULL\n)\n\n                \nOR\n \n((\nMusic\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n           \nELSE\n \n(\n`\nt0\n`\n.\n`\nName\n`\n)\n \n=\n \n(\nMusic\n)\n\n       \nEND\n)\n\n  \nOR\n \n(\nCASE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nName\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nMovies\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nName\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nMovies\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nt0\n`\n.\n`\nName\n`\n)\n \n=\n \n(\nMovies\n)\n\n      \nEND\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nMany-to-many with arbitrary data\n\n\nSometimes you want to have additional data for each relationship. For this, use\n\nmanyToManyPassthrough_\n.\n\n\nmanyToManyPassthrough_\n\n  \n::\n \n(\n \nDatabase\n \nbe\n \ndb\n,\n \nTable\n \njoinThrough\n\n     \n,\n \nTable\n \nleft\n,\n \nTable\n \nright\n\n     \n,\n \nSql92SelectSanityCheck\n \nsyntax\n\n     \n,\n \nIsSql92SelectSyntax\n \nsyntax\n\n\n     \n,\n \nSqlEq\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n(\nPrimaryKey\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n     \n,\n \nSqlEq\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n(\nPrimaryKey\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n \n)\n\n  \n=\n \nDatabaseEntity\n \nbe\n \ndb\n \n(\nTableEntity\n \njoinThrough\n)\n\n  \n-\n \n(\njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n-\n \nPrimaryKey\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \n(\njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n-\n \nPrimaryKey\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\n \njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n\n                   \n,\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n\n                   \n,\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n\n\n\n\n\nUnder the hood \nmanyToMany_\n is defined simply as\n\n\nmanyToMany_\n \n=\n \nfmap\n \n(\n\\\n(\n_\n,\n \nleft\n,\n \nright\n)\n \n-\n \n(\nleft\n,\n \nright\n))\n \nmanyToManyPassthrough_\n\n\n\n\n\n\nDeclaring many-to-many relationships\n\n\nLike one-to-many relationships, beam allows you to extract commonly used\nmany-to-many relationships, via the \nManyToMany\n type.\n\n\nFor example, the playlist/track relationship above can be defined as follows\n\n\nplaylistTrackRelationship\n \n::\n \nManyToMany\n \nChinookDb\n \nPlaylistT\n \nTrackT\n\n\nplaylistTrackRelationshipu\n \n=\n\n  \nmanyToMany_\n \n(\nplaylistTrack\n \nchinookDb\n)\n \nplaylistTrackPlaylistId\n \nplaylistTrackTrackId\n\n\n\n\n\n\nAnd we can use it as expected:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nplaylistTrackRelationship\n\n    \n(\nfilter_\n \n(\n\\\np\n \n-\n \nplaylistName\n \np\n \n==.\n \njust_\n \n(\nval_\n \nMusic\n)\n \n||.\n\n                    \nplaylistName\n \np\n \n==.\n \njust_\n \n(\nval_\n \nMovies\n))\n\n             \n(\nall_\n \n(\nplaylist\n \nchinookDb\n)))\n\n\n    \n(\nall_\n \n(\ntrack\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n \nPlaylistTrack\n \nAS\n \nt2\n \nON\n \n((\nt2\n.\nPlaylistId\n)\n=\n(\nt0\n.\nPlaylistId\n))\n\n\nAND\n \n((\nt2\n.\nTrackId\n)\n=\n(\nt1\n.\nTrackId\n))\n\n\nWHERE\n \n(\nCASE\n\n           \nWHEN\n \n((\nt0\n.\nName\n)\n \nIS\n \nNULL\n)\n\n                \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n           \nWHEN\n \n((\nt0\n.\nName\n)\n \nIS\n \nNULL\n)\n\n                \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n           \nELSE\n \n(\nt0\n.\nName\n)\n=\n(\n?\n)\n\n       \nEND\n)\n\n  \nOR\n \n(\nCASE\n\n          \nWHEN\n \n((\nt0\n.\nName\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nt0\n.\nName\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nt0\n.\nName\n)\n=\n(\n?\n)\n\n      \nEND\n);\n\n\n\n-- With values: [SQLText \nMusic\n,SQLInteger 1,SQLText \nMusic\n,SQLInteger 0,SQLText \nMusic\n,SQLText \nMovies\n,SQLInteger 1,SQLText \nMovies\n,SQLInteger 0,SQLText \nMovies\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n \nPlaylistTrack\n \nAS\n \nt2\n \nON\n \n((\nt2\n.\nPlaylistId\n)\n \n=\n \n(\nt0\n.\nPlaylistId\n))\n\n\nAND\n \n((\nt2\n.\nTrackId\n)\n \n=\n \n(\nt1\n.\nTrackId\n))\n\n\nWHERE\n \n((\nt0\n.\nName\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n       \nFROM\n \n(\nMusic\n))\n\n  \nOR\n \n((\nt0\n.\nName\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n      \nFROM\n \n(\nMovies\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nPlaylistId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt1\n`\n.\n`\nName\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt1\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt1\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres10\n`\n\n\nFROM\n \n`\nPlaylist\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n\n\nJOIN\n \n`\nPlaylistTrack\n`\n \nAS\n \n`\nt2\n`\n \nON\n \n((\n`\nt2\n`\n.\n`\nPlaylistId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nPlaylistId\n`\n))\n\n\nAND\n \n((\n`\nt2\n`\n.\n`\nTrackId\n`\n)\n \n=\n \n(\n`\nt1\n`\n.\n`\nTrackId\n`\n))\n\n\nWHERE\n \n(\nCASE\n\n           \nWHEN\n \n((\n`\nt0\n`\n.\n`\nName\n`\n)\n \nIS\n \nNULL\n)\n\n                \nAND\n \n((\nMusic\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n           \nWHEN\n \n((\n`\nt0\n`\n.\n`\nName\n`\n)\n \nIS\n \nNULL\n)\n\n                \nOR\n \n((\nMusic\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n           \nELSE\n \n(\n`\nt0\n`\n.\n`\nName\n`\n)\n \n=\n \n(\nMusic\n)\n\n       \nEND\n)\n\n  \nOR\n \n(\nCASE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nName\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nMovies\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nName\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nMovies\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nt0\n`\n.\n`\nName\n`\n)\n \n=\n \n(\nMovies\n)\n\n      \nEND\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nManyToManyThrough\n is the equivalent for \nmanyToManyThrough_\n, except it takes\nanother table parameter for the 'through' table.\n\n\nArbitrary Joins\n\n\nJoins with arbitrary conditions can be specified using the \njoin_\n construct.\nFor example, \noneToMany_\n is implemented as\n\n\noneToMany_\n \nrel\n \ngetKey\n \ntbl\n \n=\n\n  \njoin_\n \nrel\n \n(\n\\\nrel\n \n-\n \ngetKey\n \nrel\n \n==.\n \npk\n \ntbl\n)\n\n\n\n\n\n\nThus, the invoice example above could be rewritten. For example, instead of\n\n\ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \noneToMany_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \ninvoiceLineInvoice\n \ni\n\n   \npure\n \n(\ni\n,\n \nln\n)\n\n\n\n\n\n\nWe could write\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \njoin_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \n(\n\\\nline\n \n-\n \ninvoiceLineInvoice\n \nline\n \n==.\n \nprimaryKey\n \ni\n)\n\n   \npure\n \n(\ni\n,\n \nln\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n=\n(\nt0\n.\nInvoiceId\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nInvoiceId\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nInvoiceDate\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingAddress\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCity\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingState\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCountry\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingPostalCode\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTotal\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceLineId\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nQuantity\n`\n \nAS\n \n`\nres13\n`\n\n\nFROM\n \n`\nInvoice\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n(\n`\nt1\n`\n.\n`\nInvoiceId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nInvoiceId\n`\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOuter joins\n\n\nLeft and right joins\n\n\nLeft joins with arbitrary conditions can be specified with the \nleftJoin_\n\nconstruct. \nleftJoin_\n takes an arbitrary query and a join condition. It\nassociates each result record with a record of the table given or a fully NULL\nrow of that table in case no row matches. For this reason, the result of\n\nleftJoin_\n has an extra \nNullable\n column tag, which converts each field into\nthe corresponding \nMaybe\n type.\n\n\n\n\nNote\n\n\nThe table parameter passed in as the join condition does not have a\n\nNullable\n column tag. The join condition should be written as if a\nconcrete row from that table exists.\n\n\n\n\nFor example, to get every artist along with their albums, but always including\nevery artist, use \nleftJoin_\n as follows.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nartist\n \n-\n \nall_\n \n(\nartist\n \nchinookDb\n)\n\n   \nalbum\n  \n-\n \nleftJoin_\n \n(\nall_\n \n(\nalbum\n \nchinookDb\n))\n \n(\n\\\nalbum\n \n-\n \nalbumArtist\n \nalbum\n \n==.\n \nprimaryKey\n \nartist\n)\n\n   \npure\n \n(\nartist\n,\n \nalbum\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nArtistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt1\n.\nArtistId\n \nAS\n \nres4\n\n\nFROM\n \nArtist\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nAlbum\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nArtistId\n)\n=\n(\nt0\n.\nArtistId\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nArtistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt1\n.\nArtistId\n \nAS\n \nres4\n\n\nFROM\n \nArtist\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nAlbum\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nArtistId\n)\n \n=\n \n(\nt0\n.\nArtistId\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nArtistId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt1\n`\n.\n`\nArtistId\n`\n \nAS\n \n`\nres4\n`\n\n\nFROM\n \n`\nArtist\n`\n \nAS\n \n`\nt0\n`\n\n\nLEFT\n \nJOIN\n \n`\nAlbum\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n(\n`\nt1\n`\n.\n`\nArtistId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nArtistId\n`\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nRight joins are not yet supported. They can always be rewritten as left joins.\nIf you have a compelling use case, please file an issue!\n\n\nHandling SQL \nNULL\ns\n\n\nNULL\n is a value that SQL treats as an 'unknown' value. Unfortunately, this can\ncause a lot of unexpected issues. Beam tries to normalize the handling of NULLs\nto some extent, but it ultimately cannot save you from the database. One thing\nyou can be sure of is that -- assuming your beam schema matches that of the\ndatabase -- any beam expression that does not yield a \nMaybe\n type cannot be\n\nNULL\n at run-time.\n\n\nAlso, beam treats equality between \nMaybe\n types correctly using the standard\n\n==.\n and \n/=.\n operators. This means that beam will sometimes generate obtuse\n\nCASE\n expressions. This is because beam's philosophy is that SQL operators be\nnamed after their equivalent Haskell ones, suffixed by a \n.\n, and that these\noperators should follow Haskell semantics.\n\n\nSometimes though, this care isn't necessary. When you are okay with SQL\nequality, you can use the \n(==?.)\n and \n(/=?.)\n operators. These work the same\nas the \n(==.)\n and \n(/=.)\n, except they return a \nSqlBool\n instead of\n\nBool\n. \nSqlBool\n can only occur as the result of a SQL expression, and it\ncannot be deserialized directly into Haskell on any backend. A \nSqlBool\n value\ncan contain \nTRUE\n, \nFALSE\n, and \nUNKNOWN\n (the third SQL boolean value). You\ncan marshal between \nSqlBool\n and \nBool\n using \nisTrue_\n, \nisFalse_\n, or\n\nisUnknown_\n to determine which value a \nSqlBool\n contains. The \nunknownAs_\n\nfunction takes a default Haskell \nBool\n and SQL expression returning\n\nSqlBool\n. It returns the given Haskell \nBool\n value in the case the SQL\nexpression is indeterminate.\n\n\nYou can also convert any expression returning \nBool\n to one returning \nSqlBool\n\nby using the \nsqlBool_\n function.\n\n\nThe various beam functions that deal with \nBool\n also have corresponding\nversions that operate on \nSqlBool\n. For example, whereas \nleftJoin_\n expects its\njoin condition to be a \nBool\n, the corresponding \nleftJoin_'\n (notice the prime)\nmethod takes a \nSqlBool\n. There are corresponding \nguard_'\n, \njoin_'\n, etc\nmethods. Boolean operators, such as \n(\n.)\n and \n(||.)\n, have \nSqlBool\n\nequivalents suffixed with \n?\n (\n(\n?.)\n and \n(||?.)\n for \nSqlBool\n \nAND\n and\n\nOR\n respectively).\n\n\nOne place where this can really bite is when generating \nON\n conditions. Many\nRDBMSes use a rather unintelligent means of choosing which indices to use, by\ndirectly matching on syntaxes. For example, postgres determines index usage by\ndirectly seeing if two columns are compared. If you wrap the comparison in the\n\nIS TRUE\n operator, the index is no longer used. In these cases, using the\nproper boolean handling can severely impact performance. For example, to get\nevery customer along with employees in their area, we can left join the customer\ntable with employees on their city.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nc\n \n-\n \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n   \ne\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n \n(\n\\\ne\n \n-\n \naddressCity\n \n(\nemployeeAddress\n \ne\n)\n \n==.\n \naddressCity\n \n(\ncustomerAddress\n \nc\n))\n\n   \npure\n \n(\nc\n,\n \ne\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres15\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres16\n,\n\n       \nt1\n.\nReportsTo\n \nAS\n \nres17\n,\n\n       \nt1\n.\nBirthDate\n \nAS\n \nres18\n,\n\n       \nt1\n.\nHireDate\n \nAS\n \nres19\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres20\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres21\n,\n\n       \nt1\n.\nState\n \nAS\n \nres22\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres24\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres25\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres26\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres27\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \nCASE\n\n                                    \nWHEN\n \n((\nt1\n.\nCity\n)\n \nIS\n \nNULL\n)\n\n                                         \nAND\n \n((\nt0\n.\nCity\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                    \nWHEN\n \n((\nt1\n.\nCity\n)\n \nIS\n \nNULL\n)\n\n                                         \nOR\n \n((\nt0\n.\nCity\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                    \nELSE\n \n(\nt1\n.\nCity\n)\n=\n(\nt0\n.\nCity\n)\n\n                                \nEND\n;\n\n\n\n-- With values: [SQLInteger 1,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres15\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres16\n,\n\n       \nt1\n.\nReportsTo\n \nAS\n \nres17\n,\n\n       \nt1\n.\nBirthDate\n \nAS\n \nres18\n,\n\n       \nt1\n.\nHireDate\n \nAS\n \nres19\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres20\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres21\n,\n\n       \nt1\n.\nState\n \nAS\n \nres22\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres24\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres25\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres26\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres27\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nCity\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n\nFROM\n \n(\nt0\n.\nCity\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nEmployeeId\n`\n \nAS\n \n`\nres13\n`\n,\n\n       \n`\nt1\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres14\n`\n,\n\n       \n`\nt1\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres15\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres16\n`\n,\n\n       \n`\nt1\n`\n.\n`\nReportsTo\n`\n \nAS\n \n`\nres17\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBirthDate\n`\n \nAS\n \n`\nres18\n`\n,\n\n       \n`\nt1\n`\n.\n`\nHireDate\n`\n \nAS\n \n`\nres19\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres20\n`\n,\n\n       \n`\nt1\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres21\n`\n,\n\n       \n`\nt1\n`\n.\n`\nState\n`\n \nAS\n \n`\nres22\n`\n,\n\n       \n`\nt1\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres23\n`\n,\n\n       \n`\nt1\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres24\n`\n,\n\n       \n`\nt1\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres25\n`\n,\n\n       \n`\nt1\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres26\n`\n,\n\n       \n`\nt1\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres27\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nLEFT\n \nJOIN\n \n`\nEmployee\n`\n \nAS\n \n`\nt1\n`\n \nON\n \nCASE\n\n                                    \nWHEN\n \n((\n`\nt1\n`\n.\n`\nCity\n`\n)\n \nIS\n \nNULL\n)\n\n                                         \nAND\n \n((\n`\nt0\n`\n.\n`\nCity\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n                                    \nWHEN\n \n((\n`\nt1\n`\n.\n`\nCity\n`\n)\n \nIS\n \nNULL\n)\n\n                                         \nOR\n \n((\n`\nt0\n`\n.\n`\nCity\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n                                    \nELSE\n \n(\n`\nt1\n`\n.\n`\nCity\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nCity\n`\n)\n\n                                \nEND\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that the join condition is not just a simple \n=\n. This will cause\npostgres to ignore any index on these columns. We can instead use \nleftJoin_'\n\nand \n==?.\n to be more direct.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nc\n \n-\n \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n   \ne\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n \n(\n\\\ne\n \n-\n \naddressCity\n \n(\nemployeeAddress\n \ne\n)\n \n==?.\n \naddressCity\n \n(\ncustomerAddress\n \nc\n))\n\n   \npure\n \n(\nc\n,\n \ne\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres15\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres16\n,\n\n       \nt1\n.\nReportsTo\n \nAS\n \nres17\n,\n\n       \nt1\n.\nBirthDate\n \nAS\n \nres18\n,\n\n       \nt1\n.\nHireDate\n \nAS\n \nres19\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres20\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres21\n,\n\n       \nt1\n.\nState\n \nAS\n \nres22\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres24\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres25\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres26\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres27\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nCity\n)\n=\n(\nt0\n.\nCity\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres15\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres16\n,\n\n       \nt1\n.\nReportsTo\n \nAS\n \nres17\n,\n\n       \nt1\n.\nBirthDate\n \nAS\n \nres18\n,\n\n       \nt1\n.\nHireDate\n \nAS\n \nres19\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres20\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres21\n,\n\n       \nt1\n.\nState\n \nAS\n \nres22\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres24\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres25\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres26\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres27\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nCity\n)\n \n=\n \n(\nt0\n.\nCity\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nEmployeeId\n`\n \nAS\n \n`\nres13\n`\n,\n\n       \n`\nt1\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres14\n`\n,\n\n       \n`\nt1\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres15\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTitle\n`\n \nAS\n \n`\nres16\n`\n,\n\n       \n`\nt1\n`\n.\n`\nReportsTo\n`\n \nAS\n \n`\nres17\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBirthDate\n`\n \nAS\n \n`\nres18\n`\n,\n\n       \n`\nt1\n`\n.\n`\nHireDate\n`\n \nAS\n \n`\nres19\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres20\n`\n,\n\n       \n`\nt1\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres21\n`\n,\n\n       \n`\nt1\n`\n.\n`\nState\n`\n \nAS\n \n`\nres22\n`\n,\n\n       \n`\nt1\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres23\n`\n,\n\n       \n`\nt1\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres24\n`\n,\n\n       \n`\nt1\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres25\n`\n,\n\n       \n`\nt1\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres26\n`\n,\n\n       \n`\nt1\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres27\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nLEFT\n \nJOIN\n \n`\nEmployee\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n(\n`\nt1\n`\n.\n`\nCity\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nCity\n`\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNow postgres will use an index.\n\n\nFull Outer joins\n\n\nOuter joins are supported with the \nouterJoin_\n function. \nouterJoin_\n takes two\nqueries and a join condition and returns a \nQ\n that represents the \nFULL OUTER\nJOIN\n of the two queries. Because either table may be nullable, the output of\nthe result has an additional \nNullable\n tag.\n\n\n\n\nNOTE\n\n\nOuter joins are only supported in backends whose SQL \nFROM\n syntax\nimplements \nIsSql92FromOuterJoinSyntax\n. Notably, this does not include\nSQLite.\n\n\n\n\nFor example, to get join all employees with customers with the same first name\nbut including all employees and customers, we can run the query\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nouterJoin_\n \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n \n(\n\\\n(\nemployee\n,\n \ncustomer\n)\n \n-\n \nemployeeFirstName\n \nemployee\n \n==.\n \ncustomerFirstName\n \ncustomer\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nEmployeeId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt0\n.\nReportsTo\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBirthDate\n \nAS\n \nres5\n,\n\n       \nt0\n.\nHireDate\n \nAS\n \nres6\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres7\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres8\n,\n\n       \nt0\n.\nState\n \nAS\n \nres9\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres10\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres11\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres12\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres13\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres14\n,\n\n       \nt1\n.\nCustomerId\n \nAS\n \nres15\n,\n\n       \nt1\n.\nFirstName\n \nAS\n \nres16\n,\n\n       \nt1\n.\nLastName\n \nAS\n \nres17\n,\n\n       \nt1\n.\nCompany\n \nAS\n \nres18\n,\n\n       \nt1\n.\nAddress\n \nAS\n \nres19\n,\n\n       \nt1\n.\nCity\n \nAS\n \nres20\n,\n\n       \nt1\n.\nState\n \nAS\n \nres21\n,\n\n       \nt1\n.\nCountry\n \nAS\n \nres22\n,\n\n       \nt1\n.\nPostalCode\n \nAS\n \nres23\n,\n\n       \nt1\n.\nPhone\n \nAS\n \nres24\n,\n\n       \nt1\n.\nFax\n \nAS\n \nres25\n,\n\n       \nt1\n.\nEmail\n \nAS\n \nres26\n,\n\n       \nt1\n.\nSupportRepId\n \nAS\n \nres27\n\n\nFROM\n \nEmployee\n \nAS\n \nt0\n\n\nFULL\n \nOUTER\n \nJOIN\n \nCustomer\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nFirstName\n)\n \n=\n \n(\nt1\n.\nFirstName\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nSubqueries\n\n\nSometimes you want to join against a \nsubquery\n rather than a table. For the\nmost part, beam will automatically figure out when certain queries need to be\nwritten using subqueries. For example, to join two result sets cointaining a SQL\nLIMIT, you would normally have to write both queries as subqueries. In beam, you\ncan write such queries as you'd expect. The library takes care of creating\nsubqueries as expected.\n\n\nFor example, the following query generates the code you'd expect.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ni\n \n-\n \nlimit_\n \n10\n \n$\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nline\n \n-\n \ninvoiceLines\n \ni\n\n   \npure\n \n(\ni\n,\n \nline\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n          \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n          \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n          \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n          \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n          \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n          \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n          \nt0\n.\nTotal\n \nAS\n \nres8\n\n   \nFROM\n \nInvoice\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n=\n(\nt0\n.\nres0\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n          \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n          \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n          \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n          \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n          \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n          \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n          \nt0\n.\nTotal\n \nAS\n \nres8\n\n   \nFROM\n \nInvoice\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nres0\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres4\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres5\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres6\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres7\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres8\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceLineId\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nQuantity\n`\n \nAS\n \n`\nres13\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \n`\nt0\n`\n.\n`\nInvoiceDate\n`\n \nAS\n \n`\nres2\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingAddress\n`\n \nAS\n \n`\nres3\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingCity\n`\n \nAS\n \n`\nres4\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingState\n`\n \nAS\n \n`\nres5\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingCountry\n`\n \nAS\n \n`\nres6\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingPostalCode\n`\n \nAS\n \n`\nres7\n`\n,\n\n          \n`\nt0\n`\n.\n`\nTotal\n`\n \nAS\n \n`\nres8\n`\n\n   \nFROM\n \n`\nInvoice\n`\n \nAS\n \n`\nt0\n`\n\n   \nLIMIT\n \n10\n)\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n(\n`\nt1\n`\n.\n`\nInvoiceId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nres0\n`\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nIf you need to (for efficiency for example), you can also generate subqueries\nexplicitly, using \nsubselect_\n. The \nsubselect_\n will force a new query to be\noutput in most cases. For simple queries, such as \nall_\n, \nsubselect_\n will have\nno effect.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Same as above, but with explicit sub select\n\n\ndo\n \ni\n \n-\n \nsubselect_\n \n$\n \nlimit_\n \n10\n \n$\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nline\n \n-\n \ninvoiceLines\n \ni\n\n   \npure\n \n(\ni\n,\n \nline\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n          \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n          \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n          \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n          \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n          \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n          \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n          \nt0\n.\nTotal\n \nAS\n \nres8\n\n   \nFROM\n \nInvoice\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n=\n(\nt0\n.\nres0\n);\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n          \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n          \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n          \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n          \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n          \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n          \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n          \nt0\n.\nTotal\n \nAS\n \nres8\n\n   \nFROM\n \nInvoice\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nres0\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres4\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres5\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres6\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres7\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres8\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceLineId\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres12\n`\n,\n\n       \n`\nt1\n`\n.\n`\nQuantity\n`\n \nAS\n \n`\nres13\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \n`\nt0\n`\n.\n`\nInvoiceDate\n`\n \nAS\n \n`\nres2\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingAddress\n`\n \nAS\n \n`\nres3\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingCity\n`\n \nAS\n \n`\nres4\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingState\n`\n \nAS\n \n`\nres5\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingCountry\n`\n \nAS\n \n`\nres6\n`\n,\n\n          \n`\nt0\n`\n.\n`\nBillingPostalCode\n`\n \nAS\n \n`\nres7\n`\n,\n\n          \n`\nt0\n`\n.\n`\nTotal\n`\n \nAS\n \n`\nres8\n`\n\n   \nFROM\n \n`\nInvoice\n`\n \nAS\n \n`\nt0\n`\n\n   \nLIMIT\n \n10\n)\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt1\n`\n \nON\n \n(\n`\nt1\n`\n.\n`\nInvoiceId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nres0\n`\n)", 
            "title": "Relationships"
        }, 
        {
            "location": "/user-guide/queries/relationships/#full-inner-joins", 
            "text": "Recall that the  Q  type is a monad. In many respects,  Q  operates like the\nlist monad. For those unfamiliar, the monadic bind operator for  []  is defined\nas  concatMap . Thus,  do   a   -   [ 1 , 2 , 3 ] \n    b   -   [ 4 , 5 , 6 ] \n    return   ( a ,   b )   is equivalent to  [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)] .  This operation is similar to the cartesian product from set theory or the  inner\njoin  from relational algebra. The  Q  monad fully supports this notion of join,\nand in fact, every other join is built off of this primitive.  For example, to get every row from the invoice table and every row from the\ninvoice line table, with no attention paid to any relationship between the two:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   all_   ( invoiceLine   chinookDb ) \n    pure   ( i ,   ln )  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  INNER   JOIN   InvoiceLine   AS   t1 ;  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  CROSS   JOIN   InvoiceLine   AS   t1  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` InvoiceId `   AS   ` res0 ` , \n        ` t0 ` . ` CustomerId `   AS   ` res1 ` , \n        ` t0 ` . ` InvoiceDate `   AS   ` res2 ` , \n        ` t0 ` . ` BillingAddress `   AS   ` res3 ` , \n        ` t0 ` . ` BillingCity `   AS   ` res4 ` , \n        ` t0 ` . ` BillingState `   AS   ` res5 ` , \n        ` t0 ` . ` BillingCountry `   AS   ` res6 ` , \n        ` t0 ` . ` BillingPostalCode `   AS   ` res7 ` , \n        ` t0 ` . ` Total `   AS   ` res8 ` , \n        ` t1 ` . ` InvoiceLineId `   AS   ` res9 ` , \n        ` t1 ` . ` InvoiceId `   AS   ` res10 ` , \n        ` t1 ` . ` TrackId `   AS   ` res11 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res12 ` , \n        ` t1 ` . ` Quantity `   AS   ` res13 `  FROM   ` Invoice `   AS   ` t0 `  JOIN   ` InvoiceLine `   AS   ` t1 `  \n\n         \n    \n         \n    \n                 \n                      Of course, most of the time you only want to fetch relevant rows. Going back to\nthe list monad example, suppose we only want to fetch pairs where the second\nnumber is less than or equal to twice the first. In Haskell, we'd use the guard  function.  do   a   -   [ 1 , 2 , 3 ] \n    b   -   [ 4 , 5 , 6 ] \n    guard   ( b   =   a   *   2 ) \n    return   ( a ,   b )   This would return  [(2,4),(3,4),(3,5)] .  Beam offers a similar function for the  Q  monad, named  guard_ . Note that\nwhereas the  Q  bind operator is the same as the Haskell monadic bind, the\ncorresponding  guard  function is not from  MonadZero , as it is in Haskell. The\ntechnical reason is that the argument to  guard_  in  Q  represents a SQL\nexpression returning a boolean, rather than a Haskell boolean itself.  Going back to our invoice line example above, we can fetch every invoice along\nwith only those invoice lines corresponding to that invoice.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   all_   ( invoiceLine   chinookDb ) \n    guard_   ( invoiceLineInvoice   ln   ` references_ `   i ) \n    pure   ( i ,   ln )  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  INNER   JOIN   InvoiceLine   AS   t1  WHERE   ( t1 . InvoiceId ) = ( t0 . InvoiceId );  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  CROSS   JOIN   InvoiceLine   AS   t1  WHERE   ( t1 . InvoiceId )   =   ( t0 . InvoiceId )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` InvoiceId `   AS   ` res0 ` , \n        ` t0 ` . ` CustomerId `   AS   ` res1 ` , \n        ` t0 ` . ` InvoiceDate `   AS   ` res2 ` , \n        ` t0 ` . ` BillingAddress `   AS   ` res3 ` , \n        ` t0 ` . ` BillingCity `   AS   ` res4 ` , \n        ` t0 ` . ` BillingState `   AS   ` res5 ` , \n        ` t0 ` . ` BillingCountry `   AS   ` res6 ` , \n        ` t0 ` . ` BillingPostalCode `   AS   ` res7 ` , \n        ` t0 ` . ` Total `   AS   ` res8 ` , \n        ` t1 ` . ` InvoiceLineId `   AS   ` res9 ` , \n        ` t1 ` . ` InvoiceId `   AS   ` res10 ` , \n        ` t1 ` . ` TrackId `   AS   ` res11 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res12 ` , \n        ` t1 ` . ` Quantity `   AS   ` res13 `  FROM   ` Invoice `   AS   ` t0 `  JOIN   ` InvoiceLine `   AS   ` t1 `  WHERE   ( ` t1 ` . ` InvoiceId ` )   =   ( ` t0 ` . ` InvoiceId ` )  \n\n         \n    \n         \n    \n                 \n                      Note that beam has floated the  guard_  expression into the  WHERE  clause,\nrather than the  ON  clause, This is fine for most inner joins on most database\nengines, as the query optimizer will execute both queries similarly. However,\nsome backends are more temperamental, so Beam offers several more idiomatic ways\nto express joins which more closely reflect the underlying SQL. In practice,\nmost users will use the methods below to express JOINs, but it is nevertheless\nimportant to understand that joining is fundamental to the structure of the  Q \nmoand.", 
            "title": "Full inner joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#one-to-many", 
            "text": "Beam supports querying for one-to-many joins. For example, to get every InvoiceLine  for each  Invoice , use the  oneToMany_  combinator.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   oneToMany_   ( invoiceLine   chinookDb )   invoiceLineInvoice   i \n    pure   ( i ,   ln )  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId ) = ( t0 . InvoiceId );  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId )   =   ( t0 . InvoiceId )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` InvoiceId `   AS   ` res0 ` , \n        ` t0 ` . ` CustomerId `   AS   ` res1 ` , \n        ` t0 ` . ` InvoiceDate `   AS   ` res2 ` , \n        ` t0 ` . ` BillingAddress `   AS   ` res3 ` , \n        ` t0 ` . ` BillingCity `   AS   ` res4 ` , \n        ` t0 ` . ` BillingState `   AS   ` res5 ` , \n        ` t0 ` . ` BillingCountry `   AS   ` res6 ` , \n        ` t0 ` . ` BillingPostalCode `   AS   ` res7 ` , \n        ` t0 ` . ` Total `   AS   ` res8 ` , \n        ` t1 ` . ` InvoiceLineId `   AS   ` res9 ` , \n        ` t1 ` . ` InvoiceId `   AS   ` res10 ` , \n        ` t1 ` . ` TrackId `   AS   ` res11 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res12 ` , \n        ` t1 ` . ` Quantity `   AS   ` res13 `  FROM   ` Invoice `   AS   ` t0 `  JOIN   ` InvoiceLine `   AS   ` t1 `   ON   ( ` t1 ` . ` InvoiceId ` )   =   ( ` t0 ` . ` InvoiceId ` )  \n\n         \n    \n         \n    \n                 \n                      Or, if you have an actual  Invoice  (called  oneInvoice ) and you want all the\nassociated  InvoiceLine s, you can use  val_  to convert  oneInvoice  to the SQL\nexpression level.  oneToMany_   ( invoiceLine   chinookDb )   invoiceLineInvoice   ( val_   oneInvoice )   If you find yourself repeating yourself constantly, you can define a helper.  invoiceLines_   ::   OneToMany   InvoiceT   InvoiceLineT  invoiceLines_   =   oneToMany_   ( invoiceLine   chinookDb )   invoiceLineInvoice   Then the above queries become  do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   invoiceLines_   i   and  invoiceLines   ( val_   i )   Notice that, instead of floating the join condition to the  WHERE  clause, beam\ngenerates an  INNER JOIN ... ON  expression. These statements are equivalent,\nalthough the  ON  expression is more idiomatic.", 
            "title": "One-to-many"
        }, 
        {
            "location": "/user-guide/queries/relationships/#nullable-columns", 
            "text": "If you have a nullable foreign key in your many table, you can use oneToManyOptional_  and  OneToManyOptional , respectively. For example,", 
            "title": "Nullable columns"
        }, 
        {
            "location": "/user-guide/queries/relationships/#one-to-one", 
            "text": "One to one relationships are a special case of one to many relationships, save\nfor a unique constraint on one column. Thus, there are no special constructs for\none-to-one relationships.  For convenience,  oneToOne_  and  OneToOne  are equivalent to  oneToMany_  and OneToMany . Additionally,  oneToMaybe_  and  OneToMaybe  correspond to oneToManyOptional_  and  OneToManyOptional .", 
            "title": "One-to-one"
        }, 
        {
            "location": "/user-guide/queries/relationships/#many-to-many", 
            "text": "Many to many relationships require a linking table, with foreign keys to each\ntable part of the relationship.  The  manyToMany_  construct can be used to fetch both, one, or no sides of a\nmany-to-many relationship.  manyToMany_ \n   ::   (   Database   be   db ,   Table   joinThrough \n      ,   Table   left ,   Table   right \n      ,   Sql92SelectSanityCheck   syntax \n      ,   IsSql92SelectSyntax   syntax \n\n      ,   SqlEq   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   ( PrimaryKey   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n      ,   SqlEq   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   ( PrimaryKey   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   ) \n   =   DatabaseEntity   be   db   ( TableEntity   joinThrough ) \n   -   ( joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   -   PrimaryKey   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   ( joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   -   PrimaryKey   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   ( left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   -   Q   syntax   db   s   ( right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   ( left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ),   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   This reads: for any database  db ; tables  joinThrough ,  left , and  right ;\nand sane select syntax  syntax , where the primary keys of  left  and  right \nare comparable as value expressions and we have some way of extracting a primary\nkey of  left  and  right  from  joinThrough , associate all entries of  left \nwith those of  right  through  joinThrough  and return the results of  left  and right .  The Chinook database associates multiple tracks with a playlist via the playlist_track  table. For example, to get all tracks from the playlists named\neither \"Movies\" or \"Music\".  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             manyToMany_   ( playlistTrack   chinookDb ) \n             playlistTrackPlaylistId   playlistTrackTrackId \n\n             ( filter_   ( \\ p   -   playlistName   p   ==.   just_   ( val_   Music )   ||. \n                             playlistName   p   ==.   just_   ( val_   Movies )) \n                      ( all_   ( playlist   chinookDb ))) \n\n             ( all_   ( track   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10  FROM   Playlist   AS   t0  INNER   JOIN   Track   AS   t1  INNER   JOIN   PlaylistTrack   AS   t2   ON   (( t2 . PlaylistId ) = ( t0 . PlaylistId ))  AND   (( t2 . TrackId ) = ( t1 . TrackId ))  WHERE   ( CASE \n            WHEN   (( t0 . Name )   IS   NULL ) \n                 AND   (( ? )   IS   NULL )   THEN   ? \n            WHEN   (( t0 . Name )   IS   NULL ) \n                 OR   (( ? )   IS   NULL )   THEN   ? \n            ELSE   ( t0 . Name ) = ( ? ) \n        END ) \n   OR   ( CASE \n           WHEN   (( t0 . Name )   IS   NULL ) \n                AND   (( ? )   IS   NULL )   THEN   ? \n           WHEN   (( t0 . Name )   IS   NULL ) \n                OR   (( ? )   IS   NULL )   THEN   ? \n           ELSE   ( t0 . Name ) = ( ? ) \n       END );  -- With values: [SQLText  Music ,SQLInteger 1,SQLText  Music ,SQLInteger 0,SQLText  Music ,SQLText  Movies ,SQLInteger 1,SQLText  Movies ,SQLInteger 0,SQLText  Movies ]  \n\n         \n    \n         \n             SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10  FROM   Playlist   AS   t0  CROSS   JOIN   Track   AS   t1  INNER   JOIN   PlaylistTrack   AS   t2   ON   (( t2 . PlaylistId )   =   ( t0 . PlaylistId ))  AND   (( t2 . TrackId )   =   ( t1 . TrackId ))  WHERE   (( t0 . Name )   IS   NOT   DISTINCT \n        FROM   ( Music )) \n   OR   (( t0 . Name )   IS   NOT   DISTINCT \n       FROM   ( Movies ))  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` PlaylistId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 ` , \n        ` t1 ` . ` TrackId `   AS   ` res2 ` , \n        ` t1 ` . ` Name `   AS   ` res3 ` , \n        ` t1 ` . ` AlbumId `   AS   ` res4 ` , \n        ` t1 ` . ` MediaTypeId `   AS   ` res5 ` , \n        ` t1 ` . ` GenreId `   AS   ` res6 ` , \n        ` t1 ` . ` Composer `   AS   ` res7 ` , \n        ` t1 ` . ` Milliseconds `   AS   ` res8 ` , \n        ` t1 ` . ` Bytes `   AS   ` res9 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res10 `  FROM   ` Playlist `   AS   ` t0 `  JOIN   ` Track `   AS   ` t1 `  JOIN   ` PlaylistTrack `   AS   ` t2 `   ON   (( ` t2 ` . ` PlaylistId ` )   =   ( ` t0 ` . ` PlaylistId ` ))  AND   (( ` t2 ` . ` TrackId ` )   =   ( ` t1 ` . ` TrackId ` ))  WHERE   ( CASE \n            WHEN   (( ` t0 ` . ` Name ` )   IS   NULL ) \n                 AND   (( Music )   IS   NULL )   THEN   TRUE \n            WHEN   (( ` t0 ` . ` Name ` )   IS   NULL ) \n                 OR   (( Music )   IS   NULL )   THEN   FALSE \n            ELSE   ( ` t0 ` . ` Name ` )   =   ( Music ) \n        END ) \n   OR   ( CASE \n           WHEN   (( ` t0 ` . ` Name ` )   IS   NULL ) \n                AND   (( Movies )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` t0 ` . ` Name ` )   IS   NULL ) \n                OR   (( Movies )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` t0 ` . ` Name ` )   =   ( Movies ) \n       END )", 
            "title": "Many-to-many"
        }, 
        {
            "location": "/user-guide/queries/relationships/#many-to-many-with-arbitrary-data", 
            "text": "Sometimes you want to have additional data for each relationship. For this, use manyToManyPassthrough_ .  manyToManyPassthrough_ \n   ::   (   Database   be   db ,   Table   joinThrough \n      ,   Table   left ,   Table   right \n      ,   Sql92SelectSanityCheck   syntax \n      ,   IsSql92SelectSyntax   syntax \n\n      ,   SqlEq   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   ( PrimaryKey   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n      ,   SqlEq   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   ( PrimaryKey   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   ) \n   =   DatabaseEntity   be   db   ( TableEntity   joinThrough ) \n   -   ( joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   -   PrimaryKey   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   ( joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   -   PrimaryKey   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   ( left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   ( right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   (   joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ) \n                    ,   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ) \n                    ,   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   Under the hood  manyToMany_  is defined simply as  manyToMany_   =   fmap   ( \\ ( _ ,   left ,   right )   -   ( left ,   right ))   manyToManyPassthrough_", 
            "title": "Many-to-many with arbitrary data"
        }, 
        {
            "location": "/user-guide/queries/relationships/#declaring-many-to-many-relationships", 
            "text": "Like one-to-many relationships, beam allows you to extract commonly used\nmany-to-many relationships, via the  ManyToMany  type.  For example, the playlist/track relationship above can be defined as follows  playlistTrackRelationship   ::   ManyToMany   ChinookDb   PlaylistT   TrackT  playlistTrackRelationshipu   = \n   manyToMany_   ( playlistTrack   chinookDb )   playlistTrackPlaylistId   playlistTrackTrackId   And we can use it as expected:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             playlistTrackRelationship \n     ( filter_   ( \\ p   -   playlistName   p   ==.   just_   ( val_   Music )   ||. \n                     playlistName   p   ==.   just_   ( val_   Movies )) \n              ( all_   ( playlist   chinookDb ))) \n\n     ( all_   ( track   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10  FROM   Playlist   AS   t0  INNER   JOIN   Track   AS   t1  INNER   JOIN   PlaylistTrack   AS   t2   ON   (( t2 . PlaylistId ) = ( t0 . PlaylistId ))  AND   (( t2 . TrackId ) = ( t1 . TrackId ))  WHERE   ( CASE \n            WHEN   (( t0 . Name )   IS   NULL ) \n                 AND   (( ? )   IS   NULL )   THEN   ? \n            WHEN   (( t0 . Name )   IS   NULL ) \n                 OR   (( ? )   IS   NULL )   THEN   ? \n            ELSE   ( t0 . Name ) = ( ? ) \n        END ) \n   OR   ( CASE \n           WHEN   (( t0 . Name )   IS   NULL ) \n                AND   (( ? )   IS   NULL )   THEN   ? \n           WHEN   (( t0 . Name )   IS   NULL ) \n                OR   (( ? )   IS   NULL )   THEN   ? \n           ELSE   ( t0 . Name ) = ( ? ) \n       END );  -- With values: [SQLText  Music ,SQLInteger 1,SQLText  Music ,SQLInteger 0,SQLText  Music ,SQLText  Movies ,SQLInteger 1,SQLText  Movies ,SQLInteger 0,SQLText  Movies ]  \n\n         \n    \n         \n             SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10  FROM   Playlist   AS   t0  CROSS   JOIN   Track   AS   t1  INNER   JOIN   PlaylistTrack   AS   t2   ON   (( t2 . PlaylistId )   =   ( t0 . PlaylistId ))  AND   (( t2 . TrackId )   =   ( t1 . TrackId ))  WHERE   (( t0 . Name )   IS   NOT   DISTINCT \n        FROM   ( Music )) \n   OR   (( t0 . Name )   IS   NOT   DISTINCT \n       FROM   ( Movies ))  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` PlaylistId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 ` , \n        ` t1 ` . ` TrackId `   AS   ` res2 ` , \n        ` t1 ` . ` Name `   AS   ` res3 ` , \n        ` t1 ` . ` AlbumId `   AS   ` res4 ` , \n        ` t1 ` . ` MediaTypeId `   AS   ` res5 ` , \n        ` t1 ` . ` GenreId `   AS   ` res6 ` , \n        ` t1 ` . ` Composer `   AS   ` res7 ` , \n        ` t1 ` . ` Milliseconds `   AS   ` res8 ` , \n        ` t1 ` . ` Bytes `   AS   ` res9 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res10 `  FROM   ` Playlist `   AS   ` t0 `  JOIN   ` Track `   AS   ` t1 `  JOIN   ` PlaylistTrack `   AS   ` t2 `   ON   (( ` t2 ` . ` PlaylistId ` )   =   ( ` t0 ` . ` PlaylistId ` ))  AND   (( ` t2 ` . ` TrackId ` )   =   ( ` t1 ` . ` TrackId ` ))  WHERE   ( CASE \n            WHEN   (( ` t0 ` . ` Name ` )   IS   NULL ) \n                 AND   (( Music )   IS   NULL )   THEN   TRUE \n            WHEN   (( ` t0 ` . ` Name ` )   IS   NULL ) \n                 OR   (( Music )   IS   NULL )   THEN   FALSE \n            ELSE   ( ` t0 ` . ` Name ` )   =   ( Music ) \n        END ) \n   OR   ( CASE \n           WHEN   (( ` t0 ` . ` Name ` )   IS   NULL ) \n                AND   (( Movies )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` t0 ` . ` Name ` )   IS   NULL ) \n                OR   (( Movies )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` t0 ` . ` Name ` )   =   ( Movies ) \n       END )  \n\n         \n    \n         \n    \n                 \n                      ManyToManyThrough  is the equivalent for  manyToManyThrough_ , except it takes\nanother table parameter for the 'through' table.", 
            "title": "Declaring many-to-many relationships"
        }, 
        {
            "location": "/user-guide/queries/relationships/#arbitrary-joins", 
            "text": "Joins with arbitrary conditions can be specified using the  join_  construct.\nFor example,  oneToMany_  is implemented as  oneToMany_   rel   getKey   tbl   = \n   join_   rel   ( \\ rel   -   getKey   rel   ==.   pk   tbl )   Thus, the invoice example above could be rewritten. For example, instead of  do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   oneToMany_   ( invoiceLine   chinookDb )   invoiceLineInvoice   i \n    pure   ( i ,   ln )   We could write  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   join_   ( invoiceLine   chinookDb )   ( \\ line   -   invoiceLineInvoice   line   ==.   primaryKey   i ) \n    pure   ( i ,   ln )  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId ) = ( t0 . InvoiceId );  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId )   =   ( t0 . InvoiceId )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` InvoiceId `   AS   ` res0 ` , \n        ` t0 ` . ` CustomerId `   AS   ` res1 ` , \n        ` t0 ` . ` InvoiceDate `   AS   ` res2 ` , \n        ` t0 ` . ` BillingAddress `   AS   ` res3 ` , \n        ` t0 ` . ` BillingCity `   AS   ` res4 ` , \n        ` t0 ` . ` BillingState `   AS   ` res5 ` , \n        ` t0 ` . ` BillingCountry `   AS   ` res6 ` , \n        ` t0 ` . ` BillingPostalCode `   AS   ` res7 ` , \n        ` t0 ` . ` Total `   AS   ` res8 ` , \n        ` t1 ` . ` InvoiceLineId `   AS   ` res9 ` , \n        ` t1 ` . ` InvoiceId `   AS   ` res10 ` , \n        ` t1 ` . ` TrackId `   AS   ` res11 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res12 ` , \n        ` t1 ` . ` Quantity `   AS   ` res13 `  FROM   ` Invoice `   AS   ` t0 `  JOIN   ` InvoiceLine `   AS   ` t1 `   ON   ( ` t1 ` . ` InvoiceId ` )   =   ( ` t0 ` . ` InvoiceId ` )", 
            "title": "Arbitrary Joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#outer-joins", 
            "text": "", 
            "title": "Outer joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#left-and-right-joins", 
            "text": "Left joins with arbitrary conditions can be specified with the  leftJoin_ \nconstruct.  leftJoin_  takes an arbitrary query and a join condition. It\nassociates each result record with a record of the table given or a fully NULL\nrow of that table in case no row matches. For this reason, the result of leftJoin_  has an extra  Nullable  column tag, which converts each field into\nthe corresponding  Maybe  type.   Note  The table parameter passed in as the join condition does not have a Nullable  column tag. The join condition should be written as if a\nconcrete row from that table exists.   For example, to get every artist along with their albums, but always including\nevery artist, use  leftJoin_  as follows.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   artist   -   all_   ( artist   chinookDb ) \n    album    -   leftJoin_   ( all_   ( album   chinookDb ))   ( \\ album   -   albumArtist   album   ==.   primaryKey   artist ) \n    pure   ( artist ,   album )  \n\n         \n    \n         \n             SELECT   t0 . ArtistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . AlbumId   AS   res2 , \n        t1 . Title   AS   res3 , \n        t1 . ArtistId   AS   res4  FROM   Artist   AS   t0  LEFT   JOIN   Album   AS   t1   ON   ( t1 . ArtistId ) = ( t0 . ArtistId );  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . ArtistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . AlbumId   AS   res2 , \n        t1 . Title   AS   res3 , \n        t1 . ArtistId   AS   res4  FROM   Artist   AS   t0  LEFT   JOIN   Album   AS   t1   ON   ( t1 . ArtistId )   =   ( t0 . ArtistId )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` ArtistId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 ` , \n        ` t1 ` . ` AlbumId `   AS   ` res2 ` , \n        ` t1 ` . ` Title `   AS   ` res3 ` , \n        ` t1 ` . ` ArtistId `   AS   ` res4 `  FROM   ` Artist `   AS   ` t0 `  LEFT   JOIN   ` Album `   AS   ` t1 `   ON   ( ` t1 ` . ` ArtistId ` )   =   ( ` t0 ` . ` ArtistId ` )  \n\n         \n    \n         \n    \n                 \n                      Right joins are not yet supported. They can always be rewritten as left joins.\nIf you have a compelling use case, please file an issue!", 
            "title": "Left and right joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#handling-sql-nulls", 
            "text": "NULL  is a value that SQL treats as an 'unknown' value. Unfortunately, this can\ncause a lot of unexpected issues. Beam tries to normalize the handling of NULLs\nto some extent, but it ultimately cannot save you from the database. One thing\nyou can be sure of is that -- assuming your beam schema matches that of the\ndatabase -- any beam expression that does not yield a  Maybe  type cannot be NULL  at run-time.  Also, beam treats equality between  Maybe  types correctly using the standard ==.  and  /=.  operators. This means that beam will sometimes generate obtuse CASE  expressions. This is because beam's philosophy is that SQL operators be\nnamed after their equivalent Haskell ones, suffixed by a  . , and that these\noperators should follow Haskell semantics.  Sometimes though, this care isn't necessary. When you are okay with SQL\nequality, you can use the  (==?.)  and  (/=?.)  operators. These work the same\nas the  (==.)  and  (/=.) , except they return a  SqlBool  instead of Bool .  SqlBool  can only occur as the result of a SQL expression, and it\ncannot be deserialized directly into Haskell on any backend. A  SqlBool  value\ncan contain  TRUE ,  FALSE , and  UNKNOWN  (the third SQL boolean value). You\ncan marshal between  SqlBool  and  Bool  using  isTrue_ ,  isFalse_ , or isUnknown_  to determine which value a  SqlBool  contains. The  unknownAs_ \nfunction takes a default Haskell  Bool  and SQL expression returning SqlBool . It returns the given Haskell  Bool  value in the case the SQL\nexpression is indeterminate.  You can also convert any expression returning  Bool  to one returning  SqlBool \nby using the  sqlBool_  function.  The various beam functions that deal with  Bool  also have corresponding\nversions that operate on  SqlBool . For example, whereas  leftJoin_  expects its\njoin condition to be a  Bool , the corresponding  leftJoin_'  (notice the prime)\nmethod takes a  SqlBool . There are corresponding  guard_' ,  join_' , etc\nmethods. Boolean operators, such as  ( .)  and  (||.) , have  SqlBool \nequivalents suffixed with  ?  ( ( ?.)  and  (||?.)  for  SqlBool   AND  and OR  respectively).  One place where this can really bite is when generating  ON  conditions. Many\nRDBMSes use a rather unintelligent means of choosing which indices to use, by\ndirectly matching on syntaxes. For example, postgres determines index usage by\ndirectly seeing if two columns are compared. If you wrap the comparison in the IS TRUE  operator, the index is no longer used. In these cases, using the\nproper boolean handling can severely impact performance. For example, to get\nevery customer along with employees in their area, we can left join the customer\ntable with employees on their city.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   c   -   all_   ( customer   chinookDb ) \n    e   -   leftJoin_   ( all_   ( employee   chinookDb ))   ( \\ e   -   addressCity   ( employeeAddress   e )   ==.   addressCity   ( customerAddress   c )) \n    pure   ( c ,   e )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12 , \n        t1 . EmployeeId   AS   res13 , \n        t1 . LastName   AS   res14 , \n        t1 . FirstName   AS   res15 , \n        t1 . Title   AS   res16 , \n        t1 . ReportsTo   AS   res17 , \n        t1 . BirthDate   AS   res18 , \n        t1 . HireDate   AS   res19 , \n        t1 . Address   AS   res20 , \n        t1 . City   AS   res21 , \n        t1 . State   AS   res22 , \n        t1 . Country   AS   res23 , \n        t1 . PostalCode   AS   res24 , \n        t1 . Phone   AS   res25 , \n        t1 . Fax   AS   res26 , \n        t1 . Email   AS   res27  FROM   Customer   AS   t0  LEFT   JOIN   Employee   AS   t1   ON   CASE \n                                     WHEN   (( t1 . City )   IS   NULL ) \n                                          AND   (( t0 . City )   IS   NULL )   THEN   ? \n                                     WHEN   (( t1 . City )   IS   NULL ) \n                                          OR   (( t0 . City )   IS   NULL )   THEN   ? \n                                     ELSE   ( t1 . City ) = ( t0 . City ) \n                                 END ;  -- With values: [SQLInteger 1,SQLInteger 0]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12 , \n        t1 . EmployeeId   AS   res13 , \n        t1 . LastName   AS   res14 , \n        t1 . FirstName   AS   res15 , \n        t1 . Title   AS   res16 , \n        t1 . ReportsTo   AS   res17 , \n        t1 . BirthDate   AS   res18 , \n        t1 . HireDate   AS   res19 , \n        t1 . Address   AS   res20 , \n        t1 . City   AS   res21 , \n        t1 . State   AS   res22 , \n        t1 . Country   AS   res23 , \n        t1 . PostalCode   AS   res24 , \n        t1 . Phone   AS   res25 , \n        t1 . Fax   AS   res26 , \n        t1 . Email   AS   res27  FROM   Customer   AS   t0  LEFT   JOIN   Employee   AS   t1   ON   ( t1 . City )   IS   NOT   DISTINCT  FROM   ( t0 . City )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 ` , \n        ` t1 ` . ` EmployeeId `   AS   ` res13 ` , \n        ` t1 ` . ` LastName `   AS   ` res14 ` , \n        ` t1 ` . ` FirstName `   AS   ` res15 ` , \n        ` t1 ` . ` Title `   AS   ` res16 ` , \n        ` t1 ` . ` ReportsTo `   AS   ` res17 ` , \n        ` t1 ` . ` BirthDate `   AS   ` res18 ` , \n        ` t1 ` . ` HireDate `   AS   ` res19 ` , \n        ` t1 ` . ` Address `   AS   ` res20 ` , \n        ` t1 ` . ` City `   AS   ` res21 ` , \n        ` t1 ` . ` State `   AS   ` res22 ` , \n        ` t1 ` . ` Country `   AS   ` res23 ` , \n        ` t1 ` . ` PostalCode `   AS   ` res24 ` , \n        ` t1 ` . ` Phone `   AS   ` res25 ` , \n        ` t1 ` . ` Fax `   AS   ` res26 ` , \n        ` t1 ` . ` Email `   AS   ` res27 `  FROM   ` Customer `   AS   ` t0 `  LEFT   JOIN   ` Employee `   AS   ` t1 `   ON   CASE \n                                     WHEN   (( ` t1 ` . ` City ` )   IS   NULL ) \n                                          AND   (( ` t0 ` . ` City ` )   IS   NULL )   THEN   TRUE \n                                     WHEN   (( ` t1 ` . ` City ` )   IS   NULL ) \n                                          OR   (( ` t0 ` . ` City ` )   IS   NULL )   THEN   FALSE \n                                     ELSE   ( ` t1 ` . ` City ` )   =   ( ` t0 ` . ` City ` ) \n                                 END  \n\n         \n    \n         \n    \n                 \n                      Notice that the join condition is not just a simple  = . This will cause\npostgres to ignore any index on these columns. We can instead use  leftJoin_' \nand  ==?.  to be more direct.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   c   -   all_   ( customer   chinookDb ) \n    e   -   leftJoin_   ( all_   ( employee   chinookDb ))   ( \\ e   -   addressCity   ( employeeAddress   e )   ==?.   addressCity   ( customerAddress   c )) \n    pure   ( c ,   e )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12 , \n        t1 . EmployeeId   AS   res13 , \n        t1 . LastName   AS   res14 , \n        t1 . FirstName   AS   res15 , \n        t1 . Title   AS   res16 , \n        t1 . ReportsTo   AS   res17 , \n        t1 . BirthDate   AS   res18 , \n        t1 . HireDate   AS   res19 , \n        t1 . Address   AS   res20 , \n        t1 . City   AS   res21 , \n        t1 . State   AS   res22 , \n        t1 . Country   AS   res23 , \n        t1 . PostalCode   AS   res24 , \n        t1 . Phone   AS   res25 , \n        t1 . Fax   AS   res26 , \n        t1 . Email   AS   res27  FROM   Customer   AS   t0  LEFT   JOIN   Employee   AS   t1   ON   ( t1 . City ) = ( t0 . City );  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12 , \n        t1 . EmployeeId   AS   res13 , \n        t1 . LastName   AS   res14 , \n        t1 . FirstName   AS   res15 , \n        t1 . Title   AS   res16 , \n        t1 . ReportsTo   AS   res17 , \n        t1 . BirthDate   AS   res18 , \n        t1 . HireDate   AS   res19 , \n        t1 . Address   AS   res20 , \n        t1 . City   AS   res21 , \n        t1 . State   AS   res22 , \n        t1 . Country   AS   res23 , \n        t1 . PostalCode   AS   res24 , \n        t1 . Phone   AS   res25 , \n        t1 . Fax   AS   res26 , \n        t1 . Email   AS   res27  FROM   Customer   AS   t0  LEFT   JOIN   Employee   AS   t1   ON   ( t1 . City )   =   ( t0 . City )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 ` , \n        ` t1 ` . ` EmployeeId `   AS   ` res13 ` , \n        ` t1 ` . ` LastName `   AS   ` res14 ` , \n        ` t1 ` . ` FirstName `   AS   ` res15 ` , \n        ` t1 ` . ` Title `   AS   ` res16 ` , \n        ` t1 ` . ` ReportsTo `   AS   ` res17 ` , \n        ` t1 ` . ` BirthDate `   AS   ` res18 ` , \n        ` t1 ` . ` HireDate `   AS   ` res19 ` , \n        ` t1 ` . ` Address `   AS   ` res20 ` , \n        ` t1 ` . ` City `   AS   ` res21 ` , \n        ` t1 ` . ` State `   AS   ` res22 ` , \n        ` t1 ` . ` Country `   AS   ` res23 ` , \n        ` t1 ` . ` PostalCode `   AS   ` res24 ` , \n        ` t1 ` . ` Phone `   AS   ` res25 ` , \n        ` t1 ` . ` Fax `   AS   ` res26 ` , \n        ` t1 ` . ` Email `   AS   ` res27 `  FROM   ` Customer `   AS   ` t0 `  LEFT   JOIN   ` Employee `   AS   ` t1 `   ON   ( ` t1 ` . ` City ` )   =   ( ` t0 ` . ` City ` )  \n\n         \n    \n         \n    \n                 \n                      Now postgres will use an index.", 
            "title": "Handling SQL NULLs"
        }, 
        {
            "location": "/user-guide/queries/relationships/#full-outer-joins", 
            "text": "Outer joins are supported with the  outerJoin_  function.  outerJoin_  takes two\nqueries and a join condition and returns a  Q  that represents the  FULL OUTER\nJOIN  of the two queries. Because either table may be nullable, the output of\nthe result has an additional  Nullable  tag.   NOTE  Outer joins are only supported in backends whose SQL  FROM  syntax\nimplements  IsSql92FromOuterJoinSyntax . Notably, this does not include\nSQLite.   For example, to get join all employees with customers with the same first name\nbut including all employees and customers, we can run the query  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             outerJoin_   ( all_   ( employee   chinookDb ))   ( all_   ( customer   chinookDb ))   ( \\ ( employee ,   customer )   -   employeeFirstName   employee   ==.   customerFirstName   customer )  \n\n         \n    \n         \n             SELECT   t0 . EmployeeId   AS   res0 , \n        t0 . LastName   AS   res1 , \n        t0 . FirstName   AS   res2 , \n        t0 . Title   AS   res3 , \n        t0 . ReportsTo   AS   res4 , \n        t0 . BirthDate   AS   res5 , \n        t0 . HireDate   AS   res6 , \n        t0 . Address   AS   res7 , \n        t0 . City   AS   res8 , \n        t0 . State   AS   res9 , \n        t0 . Country   AS   res10 , \n        t0 . PostalCode   AS   res11 , \n        t0 . Phone   AS   res12 , \n        t0 . Fax   AS   res13 , \n        t0 . Email   AS   res14 , \n        t1 . CustomerId   AS   res15 , \n        t1 . FirstName   AS   res16 , \n        t1 . LastName   AS   res17 , \n        t1 . Company   AS   res18 , \n        t1 . Address   AS   res19 , \n        t1 . City   AS   res20 , \n        t1 . State   AS   res21 , \n        t1 . Country   AS   res22 , \n        t1 . PostalCode   AS   res23 , \n        t1 . Phone   AS   res24 , \n        t1 . Fax   AS   res25 , \n        t1 . Email   AS   res26 , \n        t1 . SupportRepId   AS   res27  FROM   Employee   AS   t0  FULL   OUTER   JOIN   Customer   AS   t1   ON   ( t0 . FirstName )   =   ( t1 . FirstName )", 
            "title": "Full Outer joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#subqueries", 
            "text": "Sometimes you want to join against a  subquery  rather than a table. For the\nmost part, beam will automatically figure out when certain queries need to be\nwritten using subqueries. For example, to join two result sets cointaining a SQL\nLIMIT, you would normally have to write both queries as subqueries. In beam, you\ncan write such queries as you'd expect. The library takes care of creating\nsubqueries as expected.  For example, the following query generates the code you'd expect.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             do   i   -   limit_   10   $   all_   ( invoice   chinookDb ) \n    line   -   invoiceLines   i \n    pure   ( i ,   line )  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM \n   ( SELECT   t0 . InvoiceId   AS   res0 , \n           t0 . CustomerId   AS   res1 , \n           t0 . InvoiceDate   AS   res2 , \n           t0 . BillingAddress   AS   res3 , \n           t0 . BillingCity   AS   res4 , \n           t0 . BillingState   AS   res5 , \n           t0 . BillingCountry   AS   res6 , \n           t0 . BillingPostalCode   AS   res7 , \n           t0 . Total   AS   res8 \n    FROM   Invoice   AS   t0 \n    LIMIT   10 )   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId ) = ( t0 . res0 );  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM \n   ( SELECT   t0 . InvoiceId   AS   res0 , \n           t0 . CustomerId   AS   res1 , \n           t0 . InvoiceDate   AS   res2 , \n           t0 . BillingAddress   AS   res3 , \n           t0 . BillingCity   AS   res4 , \n           t0 . BillingState   AS   res5 , \n           t0 . BillingCountry   AS   res6 , \n           t0 . BillingPostalCode   AS   res7 , \n           t0 . Total   AS   res8 \n    FROM   Invoice   AS   t0 \n    LIMIT   10 )   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId )   =   ( t0 . res0 )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 ` , \n        ` t0 ` . ` res2 `   AS   ` res2 ` , \n        ` t0 ` . ` res3 `   AS   ` res3 ` , \n        ` t0 ` . ` res4 `   AS   ` res4 ` , \n        ` t0 ` . ` res5 `   AS   ` res5 ` , \n        ` t0 ` . ` res6 `   AS   ` res6 ` , \n        ` t0 ` . ` res7 `   AS   ` res7 ` , \n        ` t0 ` . ` res8 `   AS   ` res8 ` , \n        ` t1 ` . ` InvoiceLineId `   AS   ` res9 ` , \n        ` t1 ` . ` InvoiceId `   AS   ` res10 ` , \n        ` t1 ` . ` TrackId `   AS   ` res11 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res12 ` , \n        ` t1 ` . ` Quantity `   AS   ` res13 `  FROM \n   ( SELECT   ` t0 ` . ` InvoiceId `   AS   ` res0 ` , \n           ` t0 ` . ` CustomerId `   AS   ` res1 ` , \n           ` t0 ` . ` InvoiceDate `   AS   ` res2 ` , \n           ` t0 ` . ` BillingAddress `   AS   ` res3 ` , \n           ` t0 ` . ` BillingCity `   AS   ` res4 ` , \n           ` t0 ` . ` BillingState `   AS   ` res5 ` , \n           ` t0 ` . ` BillingCountry `   AS   ` res6 ` , \n           ` t0 ` . ` BillingPostalCode `   AS   ` res7 ` , \n           ` t0 ` . ` Total `   AS   ` res8 ` \n    FROM   ` Invoice `   AS   ` t0 ` \n    LIMIT   10 )   AS   ` t0 `  JOIN   ` InvoiceLine `   AS   ` t1 `   ON   ( ` t1 ` . ` InvoiceId ` )   =   ( ` t0 ` . ` res0 ` )  \n\n         \n    \n         \n    \n                 \n                      If you need to (for efficiency for example), you can also generate subqueries\nexplicitly, using  subselect_ . The  subselect_  will force a new query to be\noutput in most cases. For simple queries, such as  all_ ,  subselect_  will have\nno effect.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             -- Same as above, but with explicit sub select  do   i   -   subselect_   $   limit_   10   $   all_   ( invoice   chinookDb ) \n    line   -   invoiceLines   i \n    pure   ( i ,   line )  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM \n   ( SELECT   t0 . InvoiceId   AS   res0 , \n           t0 . CustomerId   AS   res1 , \n           t0 . InvoiceDate   AS   res2 , \n           t0 . BillingAddress   AS   res3 , \n           t0 . BillingCity   AS   res4 , \n           t0 . BillingState   AS   res5 , \n           t0 . BillingCountry   AS   res6 , \n           t0 . BillingPostalCode   AS   res7 , \n           t0 . Total   AS   res8 \n    FROM   Invoice   AS   t0 \n    LIMIT   10 )   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId ) = ( t0 . res0 );  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM \n   ( SELECT   t0 . InvoiceId   AS   res0 , \n           t0 . CustomerId   AS   res1 , \n           t0 . InvoiceDate   AS   res2 , \n           t0 . BillingAddress   AS   res3 , \n           t0 . BillingCity   AS   res4 , \n           t0 . BillingState   AS   res5 , \n           t0 . BillingCountry   AS   res6 , \n           t0 . BillingPostalCode   AS   res7 , \n           t0 . Total   AS   res8 \n    FROM   Invoice   AS   t0 \n    LIMIT   10 )   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId )   =   ( t0 . res0 )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 ` , \n        ` t0 ` . ` res2 `   AS   ` res2 ` , \n        ` t0 ` . ` res3 `   AS   ` res3 ` , \n        ` t0 ` . ` res4 `   AS   ` res4 ` , \n        ` t0 ` . ` res5 `   AS   ` res5 ` , \n        ` t0 ` . ` res6 `   AS   ` res6 ` , \n        ` t0 ` . ` res7 `   AS   ` res7 ` , \n        ` t0 ` . ` res8 `   AS   ` res8 ` , \n        ` t1 ` . ` InvoiceLineId `   AS   ` res9 ` , \n        ` t1 ` . ` InvoiceId `   AS   ` res10 ` , \n        ` t1 ` . ` TrackId `   AS   ` res11 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res12 ` , \n        ` t1 ` . ` Quantity `   AS   ` res13 `  FROM \n   ( SELECT   ` t0 ` . ` InvoiceId `   AS   ` res0 ` , \n           ` t0 ` . ` CustomerId `   AS   ` res1 ` , \n           ` t0 ` . ` InvoiceDate `   AS   ` res2 ` , \n           ` t0 ` . ` BillingAddress `   AS   ` res3 ` , \n           ` t0 ` . ` BillingCity `   AS   ` res4 ` , \n           ` t0 ` . ` BillingState `   AS   ` res5 ` , \n           ` t0 ` . ` BillingCountry `   AS   ` res6 ` , \n           ` t0 ` . ` BillingPostalCode `   AS   ` res7 ` , \n           ` t0 ` . ` Total `   AS   ` res8 ` \n    FROM   ` Invoice `   AS   ` t0 ` \n    LIMIT   10 )   AS   ` t0 `  JOIN   ` InvoiceLine `   AS   ` t1 `   ON   ( ` t1 ` . ` InvoiceId ` )   =   ( ` t0 ` . ` res0 ` )", 
            "title": "Subqueries"
        }, 
        {
            "location": "/user-guide/queries/aggregates/", 
            "text": "You can use the \naggregate_\n function to group your result set and compute\naggregates within the group. You can think of \naggregate_\n as a souped up\nversion of Haskell's \ngroupBy\n.\n\n\nYou use \naggregate_\n by specifying an underlying query to run and a function\nthat produces an aggregation projection. An aggregation projection is either a\nvalue of type \nQAgg syntax s a\n, a value of type \nQGroupExpr syntax s a\n, or a\ntuple of such values. Any \nQGenExpr\n that uses an aggregate function is\nautomatically assigned the \nQAgg syntax s a\n type. Any \nQGenExpr\n that contains\nthe \ngroup_\n combinator is given the type \nQGroupExpr\n.\n\n\nDuring query generation, the expressions of type \nQGroupExpr\n are added to the\n\nGROUP BY\n clause, and expressions of type \nQAgg\n are treated as aggregation to\nbe computed.\n\n\nThe result of the \naggregate_\n lifts all the \nQAgg\ns and \nQGroupExpr\ns to\n'regular' value-level \nQExpr\ns, so the result of \naggregate_\n can be used in\nexpressions as usual.\n\n\nSimple aggregate usage\n\n\nSuppose we wanted to count the number of genres in our database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\n_\n \n-\n \ncountAll_\n)\n \n(\nall_\n \n(\ngenre\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nGenre\n`\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nAdding a GROUP BY clause\n\n\nAbove, SQL used the default grouping, which puts all rows in one group. We can\nalso specify columns and expressions to group by. For example, if we wanted to\ncount the number of tracks for each genre, we can use the \ngroup_\n function to\ngroup by the genre.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n \n(\ngroup_\n \ngenre\n,\n \nas_\n \n@\nInt\n \n$\n \ncount_\n \n(\ntrackId\n \ntrack\n)))\n \n$\n \ndo\n\n  \ng\n \n-\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n\n  \nt\n \n-\n \ngenreTracks\n \ng\n\n  \npure\n \n(\ng\n,\n \nt\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nt1\n.\nTrackId\n)\n \nAS\n \nres2\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \nCASE\n\n                                 \nWHEN\n \n((\nt1\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                                      \nAND\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                 \nWHEN\n \n((\nt1\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                                      \nOR\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                 \nELSE\n \n(\nt1\n.\nGenreId\n)\n=\n(\nt0\n.\nGenreId\n)\n\n                             \nEND\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n;\n\n\n\n-- With values: [SQLInteger 1,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nt1\n.\nTrackId\n)\n \nAS\n \nres2\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nGenreId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n\nFROM\n \n(\nt0\n.\nGenreId\n)\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \nCOUNT\n(\n`\nt1\n`\n.\n`\nTrackId\n`\n)\n \nAS\n \n`\nres2\n`\n\n\nFROM\n \n`\nGenre\n`\n \nAS\n \n`\nt0\n`\n\n\nLEFT\n \nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n \nON\n \nCASE\n\n                                 \nWHEN\n \n((\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                                      \nAND\n \n((\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n                                 \nWHEN\n \n((\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                                      \nOR\n \n((\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n                                 \nELSE\n \n(\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n\n                             \nEND\n\n\nGROUP\n \nBY\n \n`\nt0\n`\n.\n`\nGenreId\n`\n,\n\n         \n`\nt0\n`\n.\n`\nName\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\ncount_\n can return any \nIntegral\n type. Adding the explicit \nas_ @Int\n above\nprevents an ambiguous type error.\n\n\n\n\nSQL compatibility\n\n\nAbove, we demonstrated the use of \ncount_\n and \ncountAll_\n which map to the\nappropriate SQL aggregates. Beam supports all of the other standard SQL92\naggregates.\n\n\nIn general, SQL aggregates are named similarly in beam and SQL. As usual, the\naggregate function in beam is suffixed by an underscore. For example, \nsum_\n\ncorresponds to the SQL aggregate \nSUM\n.\n\n\nSQL also allows you to specify set quantifiers for each aggregate. Beam supports\nthese as well. By convention, versions of aggregates that take in an optional\nset quantifier are suffixed by \nOver\n. For example \nSUM(DISTINCT x)\n can be\nwritten \nsumOver_ distinctInGroup_ x\n. The universally quantified version of\neach aggregate is obtained by using the \nallInGroup_\n quantifier. Thus, \nsum_ ==\nsumOver_ allInGroup_\n. Because \nALL\n is the default set quantifier, beam does\nnot typically generate it in queries. If, for some reason, you would like beam\nto be explicit about it, you can use the \nallInGroupExplicitly_\n quantifier.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n              \n(\n \ngroup_\n \ngenre\n\n              \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n              \n,\n \nfromMaybe_\n \n0\n \n(\nsumOver_\n \nallInGroupExplicitly_\n \n(\nfromMaybe_\n \n0\n \n(\ntrackMilliseconds\n \ntrack\n)))\n \n`\ndiv_\n`\n \n1000\n))\n \n$\n \ndo\n\n  \ng\n \n-\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n\n  \nt\n \n-\n \ngenreTracks\n \ng\n\n  \npure\n \n(\ng\n,\n \nt\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n       \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nCOALESCE\n(\nt1\n.\nMilliseconds\n,\n \n?\n)),\n \n?\n))\n \n/\n \n(\n?\n)\n \nAS\n \nres3\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \nCASE\n\n                                 \nWHEN\n \n((\nt1\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                                      \nAND\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                 \nWHEN\n \n((\nt1\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                                      \nOR\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                 \nELSE\n \n(\nt1\n.\nGenreId\n)\n=\n(\nt0\n.\nGenreId\n)\n\n                             \nEND\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n;\n\n\n\n-- With values: [SQLInteger 0,SQLInteger 0,SQLInteger 1000,SQLInteger 1,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n       \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nCOALESCE\n(\nt1\n.\nMilliseconds\n,\n \n0\n)),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nGenreId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n\nFROM\n \n(\nt0\n.\nGenreId\n)\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \nCOUNT\n(\nDISTINCT\n \n`\nt1\n`\n.\n`\nUnitPrice\n`\n)\n \nAS\n \n`\nres2\n`\n,\n\n       \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nCOALESCE\n(\n`\nt1\n`\n.\n`\nMilliseconds\n`\n,\n \n0\n)),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres3\n`\n\n\nFROM\n \n`\nGenre\n`\n \nAS\n \n`\nt0\n`\n\n\nLEFT\n \nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n \nON\n \nCASE\n\n                                 \nWHEN\n \n((\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                                      \nAND\n \n((\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n                                 \nWHEN\n \n((\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                                      \nOR\n \n((\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n                                 \nELSE\n \n(\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n\n                             \nEND\n\n\nGROUP\n \nBY\n \n`\nt0\n`\n.\n`\nGenreId\n`\n,\n\n         \n`\nt0\n`\n.\n`\nName\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\nMost Beam aggregates (\ncount_\n and \ncountAll_\n being an exception) return a\n\nMaybe\n value, because aggregating over no rows in SQL returns a \nNULL\n\nvalue. Use \nfromMaybe_\n or \ncoalesce_\n to supply a default value in this case.\n\n\n\n\nThe \nbeam-core\n library supports the standard SQL aggregation functions.\nIndividual backends are likely to support the full range of aggregates available\non that backend (if not, please send a bug report).\n\n\n\n\n\n\n\n\nSQL Aggregate\n\n\nRelevant standard\n\n\nUnquantified beam function\n\n\nQuantified beam function\n\n\n\n\n\n\n\n\n\n\nSUM\n\n\nSQL92\n\n\nsum_\n\n\nsumOver_\n\n\n\n\n\n\nMIN\n\n\nSQL92\n\n\nmin_\n\n\nminOver_\n\n\n\n\n\n\nMAX\n\n\nSQL92\n\n\nmax_\n\n\nmaxOver_\n\n\n\n\n\n\nAVG\n\n\nSQL92\n\n\navg_\n\n\navgOver_\n\n\n\n\n\n\nCOUNT(x)\n\n\nSQL92\n\n\ncount_\n\n\ncountOver_\n\n\n\n\n\n\nCOUNT(*)\n\n\nSQL92\n\n\ncountAll_\n\n\nN/A\n\n\n\n\n\n\nEVERY(x)\n\n\nSQL99\n\n\nevery_\n\n\neveryOver_\n\n\n\n\n\n\nANY(x)/SOME(x)\n\n\nSQL99\n\n\nany_\n, \nsome_\n\n\nanyOver_\n, \nsomeOver_\n\n\n\n\n\n\n\n\nThe \nHAVING\n clause\n\n\nSQL allows users to specify a \nHAVING\n condition to filter results based on the\ncomputed result of an aggregate. Beam fully supports \nHAVIVG\n clauses, but does\nnot use any special syntax. Simply use \nfilter_\n or \nguard_\n as usual, and beam\nwill add a \nHAVING\n clause if it forms legal SQL. Otherwise, beam will create a\nsubselect and add a \nWHERE\n clause. Either way, this is transparent to the user.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\nfilter_\n \n(\n\\\n(\ngenre\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n\naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n              \n(\n \ngroup_\n \ngenre\n\n              \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n              \n,\n \nfromMaybe_\n \n0\n \n(\nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n))\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n           \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n       \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n?\n))\n \n/\n \n(\n?\n)\n \nAS\n \nres3\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n\n\nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n?\n))\n \n/\n \n(\n?\n))\n=\n(\n?\n);\n\n\n\n-- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 0,SQLInteger 1000,SQLInteger 300000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n       \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n\n\nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n0\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \nCOUNT\n(\nDISTINCT\n \n`\nt1\n`\n.\n`\nUnitPrice\n`\n)\n \nAS\n \n`\nres2\n`\n,\n\n       \n(\nCOALESCE\n(\nSUM\n(\nALL\n \n`\nt1\n`\n.\n`\nMilliseconds\n`\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres3\n`\n\n\nFROM\n \n`\nGenre\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n\n\nGROUP\n \nBY\n \n`\nt0\n`\n.\n`\nGenreId\n`\n,\n\n         \n`\nt0\n`\n.\n`\nName\n`\n\n\nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \n`\nt1\n`\n.\n`\nMilliseconds\n`\n),\n \n0\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nBeam will also handle the \nfilter_\n correctly in the presence of more\ncomplicated queries. For example, we can now join our aggregate on genres back\nover tracks.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\nfilter_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n\ndo\n \n(\ngenre\n,\n \npriceCnt\n,\n \ntrackLength\n)\n \n-\n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n                          \n(\n \ngroup_\n \ngenre\n\n                          \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n                          \n,\n \nfromMaybe_\n \n0\n \n(\nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n))\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n            \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n   \ntrack\n \n-\n \ngenreTracks\n \ngenre\n\n   \npure\n \n(\ngenre\n,\n \ntrack\n,\n \npriceCnt\n,\n \ntrackLength\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n?\n))\n \n/\n \n(\n?\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n)\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \nCASE\n\n                                 \nWHEN\n \n((\nt1\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                                      \nAND\n \n((\nt0\n.\nres0\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                 \nWHEN\n \n((\nt1\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                                      \nOR\n \n((\nt0\n.\nres0\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                 \nELSE\n \n(\nt1\n.\nGenreId\n)\n=\n(\nt0\n.\nres0\n)\n\n                             \nEND\n\n\nWHERE\n \n(\nt0\n.\nres3\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 1,SQLInteger 0,SQLInteger 300000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n)\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nGenreId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n\nFROM\n \n(\nt0\n.\nres0\n)\n\n\nWHERE\n \n(\nt0\n.\nres3\n)\n \n=\n \n(\n300000\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt1\n`\n.\n`\nName\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt1\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt1\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \nCOUNT\n(\nDISTINCT\n \n`\nt1\n`\n.\n`\nUnitPrice\n`\n)\n \nAS\n \n`\nres2\n`\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \n`\nt1\n`\n.\n`\nMilliseconds\n`\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres3\n`\n\n   \nFROM\n \n`\nGenre\n`\n \nAS\n \n`\nt0\n`\n\n   \nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n\n   \nGROUP\n \nBY\n \n`\nt0\n`\n.\n`\nGenreId\n`\n,\n\n            \n`\nt0\n`\n.\n`\nName\n`\n)\n \nAS\n \n`\nt0\n`\n\n\nLEFT\n \nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n \nON\n \nCASE\n\n                                 \nWHEN\n \n((\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                                      \nAND\n \n((\n`\nt0\n`\n.\n`\nres0\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n                                 \nWHEN\n \n((\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                                      \nOR\n \n((\n`\nt0\n`\n.\n`\nres0\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n                                 \nELSE\n \n(\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nres0\n`\n)\n\n                             \nEND\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nres3\n`\n)\n \n=\n \n(\n300000\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe position of \nfilter_\n changes the code generated. Above, the \nfilter_\n\nproduced a \nWHERE\n clause on the outermost \nSELECT\n. If instead, we put the\n\nfilter_\n clause right outside the \naggregate_\n, beam will produce a \nHAVING\n clause instead.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\ndo\n \n(\ngenre\n,\n \npriceCnt\n,\n \ntrackLength\n)\n \n-\n\n            \nfilter_\n \n(\n\\\n(\ngenre\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n                          \n(\n \ngroup_\n \ngenre\n\n                          \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n                          \n,\n \nfromMaybe_\n \n0\n \n(\nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n))\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n            \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n   \ntrack\n \n-\n \ngenreTracks\n \ngenre\n\n   \npure\n \n(\ngenre\n,\n \ntrack\n,\n \npriceCnt\n,\n \ntrackLength\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n?\n))\n \n/\n \n(\n?\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n\n   \nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n?\n))\n \n/\n \n(\n?\n))\n=\n(\n?\n))\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \nCASE\n\n                                 \nWHEN\n \n((\nt1\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                                      \nAND\n \n((\nt0\n.\nres0\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                 \nWHEN\n \n((\nt1\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                                      \nOR\n \n((\nt0\n.\nres0\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n                                 \nELSE\n \n(\nt1\n.\nGenreId\n)\n=\n(\nt0\n.\nres0\n)\n\n                             \nEND\n;\n\n\n\n-- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 0,SQLInteger 1000,SQLInteger 300000,SQLInteger 1,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n\n   \nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n0\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n))\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nGenreId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n\nFROM\n \n(\nt0\n.\nres0\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt1\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt1\n`\n.\n`\nName\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt1\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt1\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt1\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt1\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt1\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt1\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \nCOUNT\n(\nDISTINCT\n \n`\nt1\n`\n.\n`\nUnitPrice\n`\n)\n \nAS\n \n`\nres2\n`\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \n`\nt1\n`\n.\n`\nMilliseconds\n`\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres3\n`\n\n   \nFROM\n \n`\nGenre\n`\n \nAS\n \n`\nt0\n`\n\n   \nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n\n   \nGROUP\n \nBY\n \n`\nt0\n`\n.\n`\nGenreId\n`\n,\n\n            \n`\nt0\n`\n.\n`\nName\n`\n\n   \nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \n`\nt1\n`\n.\n`\nMilliseconds\n`\n),\n \n0\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n))\n \nAS\n \n`\nt0\n`\n\n\nLEFT\n \nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n \nON\n \nCASE\n\n                                 \nWHEN\n \n((\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                                      \nAND\n \n((\n`\nt0\n`\n.\n`\nres0\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n                                 \nWHEN\n \n((\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                                      \nOR\n \n((\n`\nt0\n`\n.\n`\nres0\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n                                 \nELSE\n \n(\n`\nt1\n`\n.\n`\nGenreId\n`\n)\n \n=\n \n(\n`\nt0\n`\n.\n`\nres0\n`\n)\n\n                             \nEND\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nDue to the monadic structure, putting the filtered aggregate as the second\nclause in the JOIN causes the HAVING to be floated out, because the compiler\ncan't prove that the conditional expression only depends on the results of the\naggregate.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\ndo\n \ntrack_\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \n(\ngenre\n,\n \npriceCnt\n,\n \ntrackLength\n)\n \n-\n\n            \nfilter_\n \n(\n\\\n(\ngenre\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n                          \n(\n \ngroup_\n \ngenre\n\n                          \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n                          \n,\n \nfromMaybe_\n \n0\n \n(\nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n))\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n            \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n   \nguard_\n \n(\ntrackGenreId\n \ntrack_\n \n==.\n \njust_\n \n(\npk\n \ngenre\n))\n\n   \npure\n \n(\ngenre\n,\n \ntrack_\n,\n \npriceCnt\n,\n \ntrackLength\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nName\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt1\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt1\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n?\n))\n \n/\n \n(\n?\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n)\n \nAS\n \nt1\n\n\nWHERE\n \n((\nt1\n.\nres3\n)\n=\n(\n?\n))\n\n  \nAND\n \n(\nCASE\n\n           \nWHEN\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                \nAND\n \n((\nt1\n.\nres0\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n           \nWHEN\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n                \nOR\n \n((\nt1\n.\nres0\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n           \nELSE\n \n(\nt0\n.\nGenreId\n)\n=\n(\nt1\n.\nres0\n)\n\n       \nEND\n);\n\n\n\n-- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 300000,SQLInteger 1,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nName\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt1\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt1\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n)\n \nAS\n \nt1\n\n\nWHERE\n \n((\nt1\n.\nres3\n)\n \n=\n \n(\n300000\n))\n\n  \nAND\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n       \nFROM\n \n(\nt1\n.\nres0\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt1\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt1\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt1\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt1\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \nCOUNT\n(\nDISTINCT\n \n`\nt1\n`\n.\n`\nUnitPrice\n`\n)\n \nAS\n \n`\nres2\n`\n,\n\n          \n(\nCOALESCE\n(\nSUM\n(\nALL\n \n`\nt1\n`\n.\n`\nMilliseconds\n`\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres3\n`\n\n   \nFROM\n \n`\nGenre\n`\n \nAS\n \n`\nt0\n`\n\n   \nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n\n   \nGROUP\n \nBY\n \n`\nt0\n`\n.\n`\nGenreId\n`\n,\n\n            \n`\nt0\n`\n.\n`\nName\n`\n)\n \nAS\n \n`\nt1\n`\n\n\nWHERE\n \n((\n`\nt1\n`\n.\n`\nres3\n`\n)\n \n=\n \n(\n300000\n))\n\n  \nAND\n \n(\nCASE\n\n           \nWHEN\n \n((\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                \nAND\n \n((\n`\nt1\n`\n.\n`\nres0\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n           \nWHEN\n \n((\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n                \nOR\n \n((\n`\nt1\n`\n.\n`\nres0\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n           \nELSE\n \n(\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \n=\n \n(\n`\nt1\n`\n.\n`\nres0\n`\n)\n\n       \nEND\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou can prove to the compiler that the \nfilter_\n should generate a having by\nusing the \nsubselect_\n combinator.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\ndo\n \ntrack_\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \n(\ngenre\n,\n \npriceCnt\n,\n \ntrackLength\n)\n \n-\n\n            \nsubselect_\n \n$\n\n            \nfilter_\n \n(\n\\\n(\ngenre\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n                          \n(\n \ngroup_\n \ngenre\n\n                          \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n                          \n,\n \nfromMaybe_\n \n0\n \n(\nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n))\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n            \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n   \nguard_\n \n(\ntrackGenreId\n \ntrack_\n \n==.\n \njust_\n \n(\npk\n \ngenre\n))\n\n   \npure\n \n(\ngenre\n,\n \ntrack_\n,\n \npriceCnt\n,\n \ntrackLength\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nName\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt1\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt1\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n          \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n          \nt0\n.\nres3\n \nAS\n \nres3\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n             \nt0\n.\nName\n \nAS\n \nres1\n,\n\n             \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n             \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n?\n))\n \n/\n \n(\n?\n)\n \nAS\n \nres3\n\n      \nFROM\n \nGenre\n \nAS\n \nt0\n\n      \nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n      \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n               \nt0\n.\nName\n\n      \nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n?\n))\n \n/\n \n(\n?\n))\n=\n(\n?\n))\n \nAS\n \nt0\n)\n \nAS\n \nt1\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nt1\n.\nres0\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nt0\n.\nGenreId\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nt1\n.\nres0\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nt0\n.\nGenreId\n)\n=\n(\nt1\n.\nres0\n)\n\n      \nEND\n;\n\n\n\n-- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 0,SQLInteger 1000,SQLInteger 300000,SQLInteger 1,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nName\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt1\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt1\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n          \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n          \nt0\n.\nres3\n \nAS\n \nres3\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n             \nt0\n.\nName\n \nAS\n \nres1\n,\n\n             \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n             \n(\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n      \nFROM\n \nGenre\n \nAS\n \nt0\n\n      \nCROSS\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n      \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n               \nt0\n.\nName\n\n      \nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n),\n \n0\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n))\n \nAS\n \nt0\n)\n \nAS\n \nt1\n\n\nWHERE\n \n(\nt0\n.\nGenreId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n  \nFROM\n \n(\nt1\n.\nres0\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt1\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt1\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTrackId\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nMediaTypeId\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nComposer\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nMilliseconds\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBytes\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nUnitPrice\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt1\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt1\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\nJOIN\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n,\n\n          \n`\nt0\n`\n.\n`\nres2\n`\n \nAS\n \n`\nres2\n`\n,\n\n          \n`\nt0\n`\n.\n`\nres3\n`\n \nAS\n \n`\nres3\n`\n\n   \nFROM\n\n     \n(\nSELECT\n \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres0\n`\n,\n\n             \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n,\n\n             \nCOUNT\n(\nDISTINCT\n \n`\nt1\n`\n.\n`\nUnitPrice\n`\n)\n \nAS\n \n`\nres2\n`\n,\n\n             \n(\nCOALESCE\n(\nSUM\n(\nALL\n \n`\nt1\n`\n.\n`\nMilliseconds\n`\n),\n \n0\n))\n \n/\n \n(\n1000\n)\n \nAS\n \n`\nres3\n`\n\n      \nFROM\n \n`\nGenre\n`\n \nAS\n \n`\nt0\n`\n\n      \nJOIN\n \n`\nTrack\n`\n \nAS\n \n`\nt1\n`\n\n      \nGROUP\n \nBY\n \n`\nt0\n`\n.\n`\nGenreId\n`\n,\n\n               \n`\nt0\n`\n.\n`\nName\n`\n\n      \nHAVING\n \n((\nCOALESCE\n(\nSUM\n(\nALL\n \n`\nt1\n`\n.\n`\nMilliseconds\n`\n),\n \n0\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n))\n \nAS\n \n`\nt0\n`\n)\n \nAS\n \n`\nt1\n`\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n`\nt1\n`\n.\n`\nres0\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n`\nt1\n`\n.\n`\nres0\n`\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nt0\n`\n.\n`\nGenreId\n`\n)\n \n=\n \n(\n`\nt1\n`\n.\n`\nres0\n`\n)\n\n      \nEND", 
            "title": "Aggregates"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#simple-aggregate-usage", 
            "text": "Suppose we wanted to count the number of genres in our database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ _   -   countAll_ )   ( all_   ( genre   chinookDb ))  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   res0  FROM   Genre   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   res0  FROM   Genre   AS   t0  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   ` res0 `  FROM   ` Genre `   AS   ` t0 `", 
            "title": "Simple aggregate usage"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#adding-a-group-by-clause", 
            "text": "Above, SQL used the default grouping, which puts all rows in one group. We can\nalso specify columns and expressions to group by. For example, if we wanted to\ncount the number of tracks for each genre, we can use the  group_  function to\ngroup by the genre.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ ( genre ,   track )   -   ( group_   genre ,   as_   @ Int   $   count_   ( trackId   track )))   $   do \n   g   -   all_   ( genre   chinookDb ) \n   t   -   genreTracks   g \n   pure   ( g ,   t )  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( t1 . TrackId )   AS   res2  FROM   Genre   AS   t0  LEFT   JOIN   Track   AS   t1   ON   CASE \n                                  WHEN   (( t1 . GenreId )   IS   NULL ) \n                                       AND   (( t0 . GenreId )   IS   NULL )   THEN   ? \n                                  WHEN   (( t1 . GenreId )   IS   NULL ) \n                                       OR   (( t0 . GenreId )   IS   NULL )   THEN   ? \n                                  ELSE   ( t1 . GenreId ) = ( t0 . GenreId ) \n                              END  GROUP   BY   t0 . GenreId , \n          t0 . Name ;  -- With values: [SQLInteger 1,SQLInteger 0]  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( t1 . TrackId )   AS   res2  FROM   Genre   AS   t0  LEFT   JOIN   Track   AS   t1   ON   ( t1 . GenreId )   IS   NOT   DISTINCT  FROM   ( t0 . GenreId )  GROUP   BY   t0 . GenreId , \n          t0 . Name  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` GenreId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 ` , \n        COUNT ( ` t1 ` . ` TrackId ` )   AS   ` res2 `  FROM   ` Genre `   AS   ` t0 `  LEFT   JOIN   ` Track `   AS   ` t1 `   ON   CASE \n                                  WHEN   (( ` t1 ` . ` GenreId ` )   IS   NULL ) \n                                       AND   (( ` t0 ` . ` GenreId ` )   IS   NULL )   THEN   TRUE \n                                  WHEN   (( ` t1 ` . ` GenreId ` )   IS   NULL ) \n                                       OR   (( ` t0 ` . ` GenreId ` )   IS   NULL )   THEN   FALSE \n                                  ELSE   ( ` t1 ` . ` GenreId ` )   =   ( ` t0 ` . ` GenreId ` ) \n                              END  GROUP   BY   ` t0 ` . ` GenreId ` , \n          ` t0 ` . ` Name `  \n\n         \n    \n         \n    \n                 \n                       Tip  count_  can return any  Integral  type. Adding the explicit  as_ @Int  above\nprevents an ambiguous type error.", 
            "title": "Adding a GROUP BY clause"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#sql-compatibility", 
            "text": "Above, we demonstrated the use of  count_  and  countAll_  which map to the\nappropriate SQL aggregates. Beam supports all of the other standard SQL92\naggregates.  In general, SQL aggregates are named similarly in beam and SQL. As usual, the\naggregate function in beam is suffixed by an underscore. For example,  sum_ \ncorresponds to the SQL aggregate  SUM .  SQL also allows you to specify set quantifiers for each aggregate. Beam supports\nthese as well. By convention, versions of aggregates that take in an optional\nset quantifier are suffixed by  Over . For example  SUM(DISTINCT x)  can be\nwritten  sumOver_ distinctInGroup_ x . The universally quantified version of\neach aggregate is obtained by using the  allInGroup_  quantifier. Thus,  sum_ ==\nsumOver_ allInGroup_ . Because  ALL  is the default set quantifier, beam does\nnot typically generate it in queries. If, for some reason, you would like beam\nto be explicit about it, you can use the  allInGroupExplicitly_  quantifier.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ ( genre ,   track )   - \n               (   group_   genre \n               ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n               ,   fromMaybe_   0   ( sumOver_   allInGroupExplicitly_   ( fromMaybe_   0   ( trackMilliseconds   track )))   ` div_ `   1000 ))   $   do \n   g   -   all_   ( genre   chinookDb ) \n   t   -   genreTracks   g \n   pure   ( g ,   t )  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n        ( COALESCE ( SUM ( ALL   COALESCE ( t1 . Milliseconds ,   ? )),   ? ))   /   ( ? )   AS   res3  FROM   Genre   AS   t0  LEFT   JOIN   Track   AS   t1   ON   CASE \n                                  WHEN   (( t1 . GenreId )   IS   NULL ) \n                                       AND   (( t0 . GenreId )   IS   NULL )   THEN   ? \n                                  WHEN   (( t1 . GenreId )   IS   NULL ) \n                                       OR   (( t0 . GenreId )   IS   NULL )   THEN   ? \n                                  ELSE   ( t1 . GenreId ) = ( t0 . GenreId ) \n                              END  GROUP   BY   t0 . GenreId , \n          t0 . Name ;  -- With values: [SQLInteger 0,SQLInteger 0,SQLInteger 1000,SQLInteger 1,SQLInteger 0]  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n        ( COALESCE ( SUM ( ALL   COALESCE ( t1 . Milliseconds ,   0 )),   0 ))   /   ( 1000 )   AS   res3  FROM   Genre   AS   t0  LEFT   JOIN   Track   AS   t1   ON   ( t1 . GenreId )   IS   NOT   DISTINCT  FROM   ( t0 . GenreId )  GROUP   BY   t0 . GenreId , \n          t0 . Name  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` GenreId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 ` , \n        COUNT ( DISTINCT   ` t1 ` . ` UnitPrice ` )   AS   ` res2 ` , \n        ( COALESCE ( SUM ( ALL   COALESCE ( ` t1 ` . ` Milliseconds ` ,   0 )),   0 ))   /   ( 1000 )   AS   ` res3 `  FROM   ` Genre `   AS   ` t0 `  LEFT   JOIN   ` Track `   AS   ` t1 `   ON   CASE \n                                  WHEN   (( ` t1 ` . ` GenreId ` )   IS   NULL ) \n                                       AND   (( ` t0 ` . ` GenreId ` )   IS   NULL )   THEN   TRUE \n                                  WHEN   (( ` t1 ` . ` GenreId ` )   IS   NULL ) \n                                       OR   (( ` t0 ` . ` GenreId ` )   IS   NULL )   THEN   FALSE \n                                  ELSE   ( ` t1 ` . ` GenreId ` )   =   ( ` t0 ` . ` GenreId ` ) \n                              END  GROUP   BY   ` t0 ` . ` GenreId ` , \n          ` t0 ` . ` Name `  \n\n         \n    \n         \n    \n                 \n                       Tip  Most Beam aggregates ( count_  and  countAll_  being an exception) return a Maybe  value, because aggregating over no rows in SQL returns a  NULL \nvalue. Use  fromMaybe_  or  coalesce_  to supply a default value in this case.   The  beam-core  library supports the standard SQL aggregation functions.\nIndividual backends are likely to support the full range of aggregates available\non that backend (if not, please send a bug report).     SQL Aggregate  Relevant standard  Unquantified beam function  Quantified beam function      SUM  SQL92  sum_  sumOver_    MIN  SQL92  min_  minOver_    MAX  SQL92  max_  maxOver_    AVG  SQL92  avg_  avgOver_    COUNT(x)  SQL92  count_  countOver_    COUNT(*)  SQL92  countAll_  N/A    EVERY(x)  SQL99  every_  everyOver_    ANY(x)/SOME(x)  SQL99  any_ ,  some_  anyOver_ ,  someOver_", 
            "title": "SQL compatibility"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#the-having-clause", 
            "text": "SQL allows users to specify a  HAVING  condition to filter results based on the\ncomputed result of an aggregate. Beam fully supports  HAVIVG  clauses, but does\nnot use any special syntax. Simply use  filter_  or  guard_  as usual, and beam\nwill add a  HAVING  clause if it forms legal SQL. Otherwise, beam will create a\nsubselect and add a  WHERE  clause. Either way, this is transparent to the user.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  filter_   ( \\ ( genre ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $  aggregate_   ( \\ ( genre ,   track )   - \n               (   group_   genre \n               ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n               ,   fromMaybe_   0   ( sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track ))   ` div_ `   1000   ))   $ \n            ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n        ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   ? ))   /   ( ? )   AS   res3  FROM   Genre   AS   t0  INNER   JOIN   Track   AS   t1  GROUP   BY   t0 . GenreId , \n          t0 . Name  HAVING   (( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   ? ))   /   ( ? )) = ( ? );  -- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 0,SQLInteger 1000,SQLInteger 300000]  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n        ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   0 ))   /   ( 1000 )   AS   res3  FROM   Genre   AS   t0  CROSS   JOIN   Track   AS   t1  GROUP   BY   t0 . GenreId , \n          t0 . Name  HAVING   (( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   0 ))   /   ( 1000 ))   =   ( 300000 )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` GenreId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 ` , \n        COUNT ( DISTINCT   ` t1 ` . ` UnitPrice ` )   AS   ` res2 ` , \n        ( COALESCE ( SUM ( ALL   ` t1 ` . ` Milliseconds ` ),   0 ))   /   ( 1000 )   AS   ` res3 `  FROM   ` Genre `   AS   ` t0 `  JOIN   ` Track `   AS   ` t1 `  GROUP   BY   ` t0 ` . ` GenreId ` , \n          ` t0 ` . ` Name `  HAVING   (( COALESCE ( SUM ( ALL   ` t1 ` . ` Milliseconds ` ),   0 ))   /   ( 1000 ))   =   ( 300000 )  \n\n         \n    \n         \n    \n                 \n                      Beam will also handle the  filter_  correctly in the presence of more\ncomplicated queries. For example, we can now join our aggregate on genres back\nover tracks.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  filter_   ( \\ ( genre ,   track ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $  do   ( genre ,   priceCnt ,   trackLength )   - \n             aggregate_   ( \\ ( genre ,   track )   - \n                           (   group_   genre \n                           ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n                           ,   fromMaybe_   0   ( sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track ))   ` div_ `   1000   ))   $ \n             ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb )) \n    track   -   genreTracks   genre \n    pure   ( genre ,   track ,   priceCnt ,   trackLength )  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10 , \n        t0 . res2   AS   res11 , \n        t0 . res3   AS   res12  FROM \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   ? ))   /   ( ? )   AS   res3 \n    FROM   Genre   AS   t0 \n    INNER   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name )   AS   t0  LEFT   JOIN   Track   AS   t1   ON   CASE \n                                  WHEN   (( t1 . GenreId )   IS   NULL ) \n                                       AND   (( t0 . res0 )   IS   NULL )   THEN   ? \n                                  WHEN   (( t1 . GenreId )   IS   NULL ) \n                                       OR   (( t0 . res0 )   IS   NULL )   THEN   ? \n                                  ELSE   ( t1 . GenreId ) = ( t0 . res0 ) \n                              END  WHERE   ( t0 . res3 ) = ( ? );  -- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 1,SQLInteger 0,SQLInteger 300000]  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10 , \n        t0 . res2   AS   res11 , \n        t0 . res3   AS   res12  FROM \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   0 ))   /   ( 1000 )   AS   res3 \n    FROM   Genre   AS   t0 \n    CROSS   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name )   AS   t0  LEFT   JOIN   Track   AS   t1   ON   ( t1 . GenreId )   IS   NOT   DISTINCT  FROM   ( t0 . res0 )  WHERE   ( t0 . res3 )   =   ( 300000 )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 ` , \n        ` t1 ` . ` TrackId `   AS   ` res2 ` , \n        ` t1 ` . ` Name `   AS   ` res3 ` , \n        ` t1 ` . ` AlbumId `   AS   ` res4 ` , \n        ` t1 ` . ` MediaTypeId `   AS   ` res5 ` , \n        ` t1 ` . ` GenreId `   AS   ` res6 ` , \n        ` t1 ` . ` Composer `   AS   ` res7 ` , \n        ` t1 ` . ` Milliseconds `   AS   ` res8 ` , \n        ` t1 ` . ` Bytes `   AS   ` res9 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res10 ` , \n        ` t0 ` . ` res2 `   AS   ` res11 ` , \n        ` t0 ` . ` res3 `   AS   ` res12 `  FROM \n   ( SELECT   ` t0 ` . ` GenreId `   AS   ` res0 ` , \n           ` t0 ` . ` Name `   AS   ` res1 ` , \n           COUNT ( DISTINCT   ` t1 ` . ` UnitPrice ` )   AS   ` res2 ` , \n           ( COALESCE ( SUM ( ALL   ` t1 ` . ` Milliseconds ` ),   0 ))   /   ( 1000 )   AS   ` res3 ` \n    FROM   ` Genre `   AS   ` t0 ` \n    JOIN   ` Track `   AS   ` t1 ` \n    GROUP   BY   ` t0 ` . ` GenreId ` , \n             ` t0 ` . ` Name ` )   AS   ` t0 `  LEFT   JOIN   ` Track `   AS   ` t1 `   ON   CASE \n                                  WHEN   (( ` t1 ` . ` GenreId ` )   IS   NULL ) \n                                       AND   (( ` t0 ` . ` res0 ` )   IS   NULL )   THEN   TRUE \n                                  WHEN   (( ` t1 ` . ` GenreId ` )   IS   NULL ) \n                                       OR   (( ` t0 ` . ` res0 ` )   IS   NULL )   THEN   FALSE \n                                  ELSE   ( ` t1 ` . ` GenreId ` )   =   ( ` t0 ` . ` res0 ` ) \n                              END  WHERE   ( ` t0 ` . ` res3 ` )   =   ( 300000 )  \n\n         \n    \n         \n    \n                 \n                      The position of  filter_  changes the code generated. Above, the  filter_ \nproduced a  WHERE  clause on the outermost  SELECT . If instead, we put the filter_  clause right outside the  aggregate_ , beam will produce a  HAVING  clause instead.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  do   ( genre ,   priceCnt ,   trackLength )   - \n             filter_   ( \\ ( genre ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $ \n             aggregate_   ( \\ ( genre ,   track )   - \n                           (   group_   genre \n                           ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n                           ,   fromMaybe_   0   ( sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track ))   ` div_ `   1000   ))   $ \n             ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb )) \n    track   -   genreTracks   genre \n    pure   ( genre ,   track ,   priceCnt ,   trackLength )  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10 , \n        t0 . res2   AS   res11 , \n        t0 . res3   AS   res12  FROM \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   ? ))   /   ( ? )   AS   res3 \n    FROM   Genre   AS   t0 \n    INNER   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name \n    HAVING   (( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   ? ))   /   ( ? )) = ( ? ))   AS   t0  LEFT   JOIN   Track   AS   t1   ON   CASE \n                                  WHEN   (( t1 . GenreId )   IS   NULL ) \n                                       AND   (( t0 . res0 )   IS   NULL )   THEN   ? \n                                  WHEN   (( t1 . GenreId )   IS   NULL ) \n                                       OR   (( t0 . res0 )   IS   NULL )   THEN   ? \n                                  ELSE   ( t1 . GenreId ) = ( t0 . res0 ) \n                              END ;  -- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 0,SQLInteger 1000,SQLInteger 300000,SQLInteger 1,SQLInteger 0]  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10 , \n        t0 . res2   AS   res11 , \n        t0 . res3   AS   res12  FROM \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   0 ))   /   ( 1000 )   AS   res3 \n    FROM   Genre   AS   t0 \n    CROSS   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name \n    HAVING   (( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   0 ))   /   ( 1000 ))   =   ( 300000 ))   AS   t0  LEFT   JOIN   Track   AS   t1   ON   ( t1 . GenreId )   IS   NOT   DISTINCT  FROM   ( t0 . res0 )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 ` , \n        ` t1 ` . ` TrackId `   AS   ` res2 ` , \n        ` t1 ` . ` Name `   AS   ` res3 ` , \n        ` t1 ` . ` AlbumId `   AS   ` res4 ` , \n        ` t1 ` . ` MediaTypeId `   AS   ` res5 ` , \n        ` t1 ` . ` GenreId `   AS   ` res6 ` , \n        ` t1 ` . ` Composer `   AS   ` res7 ` , \n        ` t1 ` . ` Milliseconds `   AS   ` res8 ` , \n        ` t1 ` . ` Bytes `   AS   ` res9 ` , \n        ` t1 ` . ` UnitPrice `   AS   ` res10 ` , \n        ` t0 ` . ` res2 `   AS   ` res11 ` , \n        ` t0 ` . ` res3 `   AS   ` res12 `  FROM \n   ( SELECT   ` t0 ` . ` GenreId `   AS   ` res0 ` , \n           ` t0 ` . ` Name `   AS   ` res1 ` , \n           COUNT ( DISTINCT   ` t1 ` . ` UnitPrice ` )   AS   ` res2 ` , \n           ( COALESCE ( SUM ( ALL   ` t1 ` . ` Milliseconds ` ),   0 ))   /   ( 1000 )   AS   ` res3 ` \n    FROM   ` Genre `   AS   ` t0 ` \n    JOIN   ` Track `   AS   ` t1 ` \n    GROUP   BY   ` t0 ` . ` GenreId ` , \n             ` t0 ` . ` Name ` \n    HAVING   (( COALESCE ( SUM ( ALL   ` t1 ` . ` Milliseconds ` ),   0 ))   /   ( 1000 ))   =   ( 300000 ))   AS   ` t0 `  LEFT   JOIN   ` Track `   AS   ` t1 `   ON   CASE \n                                  WHEN   (( ` t1 ` . ` GenreId ` )   IS   NULL ) \n                                       AND   (( ` t0 ` . ` res0 ` )   IS   NULL )   THEN   TRUE \n                                  WHEN   (( ` t1 ` . ` GenreId ` )   IS   NULL ) \n                                       OR   (( ` t0 ` . ` res0 ` )   IS   NULL )   THEN   FALSE \n                                  ELSE   ( ` t1 ` . ` GenreId ` )   =   ( ` t0 ` . ` res0 ` ) \n                              END  \n\n         \n    \n         \n    \n                 \n                      Due to the monadic structure, putting the filtered aggregate as the second\nclause in the JOIN causes the HAVING to be floated out, because the compiler\ncan't prove that the conditional expression only depends on the results of the\naggregate.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  do   track_   -   all_   ( track   chinookDb ) \n    ( genre ,   priceCnt ,   trackLength )   - \n             filter_   ( \\ ( genre ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $ \n             aggregate_   ( \\ ( genre ,   track )   - \n                           (   group_   genre \n                           ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n                           ,   fromMaybe_   0   ( sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track ))   ` div_ `   1000   ))   $ \n             ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb )) \n    guard_   ( trackGenreId   track_   ==.   just_   ( pk   genre )) \n    pure   ( genre ,   track_ ,   priceCnt ,   trackLength )  \n\n         \n    \n         \n             SELECT   t1 . res0   AS   res0 , \n        t1 . res1   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . Name   AS   res3 , \n        t0 . AlbumId   AS   res4 , \n        t0 . MediaTypeId   AS   res5 , \n        t0 . GenreId   AS   res6 , \n        t0 . Composer   AS   res7 , \n        t0 . Milliseconds   AS   res8 , \n        t0 . Bytes   AS   res9 , \n        t0 . UnitPrice   AS   res10 , \n        t1 . res2   AS   res11 , \n        t1 . res3   AS   res12  FROM   Track   AS   t0  INNER   JOIN \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   ? ))   /   ( ? )   AS   res3 \n    FROM   Genre   AS   t0 \n    INNER   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name )   AS   t1  WHERE   (( t1 . res3 ) = ( ? )) \n   AND   ( CASE \n            WHEN   (( t0 . GenreId )   IS   NULL ) \n                 AND   (( t1 . res0 )   IS   NULL )   THEN   ? \n            WHEN   (( t0 . GenreId )   IS   NULL ) \n                 OR   (( t1 . res0 )   IS   NULL )   THEN   ? \n            ELSE   ( t0 . GenreId ) = ( t1 . res0 ) \n        END );  -- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 300000,SQLInteger 1,SQLInteger 0]  \n\n         \n    \n         \n             SELECT   t1 . res0   AS   res0 , \n        t1 . res1   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . Name   AS   res3 , \n        t0 . AlbumId   AS   res4 , \n        t0 . MediaTypeId   AS   res5 , \n        t0 . GenreId   AS   res6 , \n        t0 . Composer   AS   res7 , \n        t0 . Milliseconds   AS   res8 , \n        t0 . Bytes   AS   res9 , \n        t0 . UnitPrice   AS   res10 , \n        t1 . res2   AS   res11 , \n        t1 . res3   AS   res12  FROM   Track   AS   t0  CROSS   JOIN \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   0 ))   /   ( 1000 )   AS   res3 \n    FROM   Genre   AS   t0 \n    CROSS   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name )   AS   t1  WHERE   (( t1 . res3 )   =   ( 300000 )) \n   AND   (( t0 . GenreId )   IS   NOT   DISTINCT \n        FROM   ( t1 . res0 ))  \n\n         \n    \n         \n             SELECT   ` t1 ` . ` res0 `   AS   ` res0 ` , \n        ` t1 ` . ` res1 `   AS   ` res1 ` , \n        ` t0 ` . ` TrackId `   AS   ` res2 ` , \n        ` t0 ` . ` Name `   AS   ` res3 ` , \n        ` t0 ` . ` AlbumId `   AS   ` res4 ` , \n        ` t0 ` . ` MediaTypeId `   AS   ` res5 ` , \n        ` t0 ` . ` GenreId `   AS   ` res6 ` , \n        ` t0 ` . ` Composer `   AS   ` res7 ` , \n        ` t0 ` . ` Milliseconds `   AS   ` res8 ` , \n        ` t0 ` . ` Bytes `   AS   ` res9 ` , \n        ` t0 ` . ` UnitPrice `   AS   ` res10 ` , \n        ` t1 ` . ` res2 `   AS   ` res11 ` , \n        ` t1 ` . ` res3 `   AS   ` res12 `  FROM   ` Track `   AS   ` t0 `  JOIN \n   ( SELECT   ` t0 ` . ` GenreId `   AS   ` res0 ` , \n           ` t0 ` . ` Name `   AS   ` res1 ` , \n           COUNT ( DISTINCT   ` t1 ` . ` UnitPrice ` )   AS   ` res2 ` , \n           ( COALESCE ( SUM ( ALL   ` t1 ` . ` Milliseconds ` ),   0 ))   /   ( 1000 )   AS   ` res3 ` \n    FROM   ` Genre `   AS   ` t0 ` \n    JOIN   ` Track `   AS   ` t1 ` \n    GROUP   BY   ` t0 ` . ` GenreId ` , \n             ` t0 ` . ` Name ` )   AS   ` t1 `  WHERE   (( ` t1 ` . ` res3 ` )   =   ( 300000 )) \n   AND   ( CASE \n            WHEN   (( ` t0 ` . ` GenreId ` )   IS   NULL ) \n                 AND   (( ` t1 ` . ` res0 ` )   IS   NULL )   THEN   TRUE \n            WHEN   (( ` t0 ` . ` GenreId ` )   IS   NULL ) \n                 OR   (( ` t1 ` . ` res0 ` )   IS   NULL )   THEN   FALSE \n            ELSE   ( ` t0 ` . ` GenreId ` )   =   ( ` t1 ` . ` res0 ` ) \n        END )  \n\n         \n    \n         \n    \n                 \n                      You can prove to the compiler that the  filter_  should generate a having by\nusing the  subselect_  combinator.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  do   track_   -   all_   ( track   chinookDb ) \n    ( genre ,   priceCnt ,   trackLength )   - \n             subselect_   $ \n             filter_   ( \\ ( genre ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $ \n             aggregate_   ( \\ ( genre ,   track )   - \n                           (   group_   genre \n                           ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n                           ,   fromMaybe_   0   ( sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track ))   ` div_ `   1000   ))   $ \n             ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb )) \n    guard_   ( trackGenreId   track_   ==.   just_   ( pk   genre )) \n    pure   ( genre ,   track_ ,   priceCnt ,   trackLength )  \n\n         \n    \n         \n             SELECT   t1 . res0   AS   res0 , \n        t1 . res1   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . Name   AS   res3 , \n        t0 . AlbumId   AS   res4 , \n        t0 . MediaTypeId   AS   res5 , \n        t0 . GenreId   AS   res6 , \n        t0 . Composer   AS   res7 , \n        t0 . Milliseconds   AS   res8 , \n        t0 . Bytes   AS   res9 , \n        t0 . UnitPrice   AS   res10 , \n        t1 . res2   AS   res11 , \n        t1 . res3   AS   res12  FROM   Track   AS   t0  INNER   JOIN \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 , \n           t0 . res2   AS   res2 , \n           t0 . res3   AS   res3 \n    FROM \n      ( SELECT   t0 . GenreId   AS   res0 , \n              t0 . Name   AS   res1 , \n              COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n              ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   ? ))   /   ( ? )   AS   res3 \n       FROM   Genre   AS   t0 \n       INNER   JOIN   Track   AS   t1 \n       GROUP   BY   t0 . GenreId , \n                t0 . Name \n       HAVING   (( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   ? ))   /   ( ? )) = ( ? ))   AS   t0 )   AS   t1  WHERE   CASE \n           WHEN   (( t0 . GenreId )   IS   NULL ) \n                AND   (( t1 . res0 )   IS   NULL )   THEN   ? \n           WHEN   (( t0 . GenreId )   IS   NULL ) \n                OR   (( t1 . res0 )   IS   NULL )   THEN   ? \n           ELSE   ( t0 . GenreId ) = ( t1 . res0 ) \n       END ;  -- With values: [SQLInteger 0,SQLInteger 1000,SQLInteger 0,SQLInteger 1000,SQLInteger 300000,SQLInteger 1,SQLInteger 0]  \n\n         \n    \n         \n             SELECT   t1 . res0   AS   res0 , \n        t1 . res1   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . Name   AS   res3 , \n        t0 . AlbumId   AS   res4 , \n        t0 . MediaTypeId   AS   res5 , \n        t0 . GenreId   AS   res6 , \n        t0 . Composer   AS   res7 , \n        t0 . Milliseconds   AS   res8 , \n        t0 . Bytes   AS   res9 , \n        t0 . UnitPrice   AS   res10 , \n        t1 . res2   AS   res11 , \n        t1 . res3   AS   res12  FROM   Track   AS   t0  CROSS   JOIN \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 , \n           t0 . res2   AS   res2 , \n           t0 . res3   AS   res3 \n    FROM \n      ( SELECT   t0 . GenreId   AS   res0 , \n              t0 . Name   AS   res1 , \n              COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n              ( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   0 ))   /   ( 1000 )   AS   res3 \n       FROM   Genre   AS   t0 \n       CROSS   JOIN   Track   AS   t1 \n       GROUP   BY   t0 . GenreId , \n                t0 . Name \n       HAVING   (( COALESCE ( SUM ( ALL   t1 . Milliseconds ),   0 ))   /   ( 1000 ))   =   ( 300000 ))   AS   t0 )   AS   t1  WHERE   ( t0 . GenreId )   IS   NOT   DISTINCT \n   FROM   ( t1 . res0 )  \n\n         \n    \n         \n             SELECT   ` t1 ` . ` res0 `   AS   ` res0 ` , \n        ` t1 ` . ` res1 `   AS   ` res1 ` , \n        ` t0 ` . ` TrackId `   AS   ` res2 ` , \n        ` t0 ` . ` Name `   AS   ` res3 ` , \n        ` t0 ` . ` AlbumId `   AS   ` res4 ` , \n        ` t0 ` . ` MediaTypeId `   AS   ` res5 ` , \n        ` t0 ` . ` GenreId `   AS   ` res6 ` , \n        ` t0 ` . ` Composer `   AS   ` res7 ` , \n        ` t0 ` . ` Milliseconds `   AS   ` res8 ` , \n        ` t0 ` . ` Bytes `   AS   ` res9 ` , \n        ` t0 ` . ` UnitPrice `   AS   ` res10 ` , \n        ` t1 ` . ` res2 `   AS   ` res11 ` , \n        ` t1 ` . ` res3 `   AS   ` res12 `  FROM   ` Track `   AS   ` t0 `  JOIN \n   ( SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n           ` t0 ` . ` res1 `   AS   ` res1 ` , \n           ` t0 ` . ` res2 `   AS   ` res2 ` , \n           ` t0 ` . ` res3 `   AS   ` res3 ` \n    FROM \n      ( SELECT   ` t0 ` . ` GenreId `   AS   ` res0 ` , \n              ` t0 ` . ` Name `   AS   ` res1 ` , \n              COUNT ( DISTINCT   ` t1 ` . ` UnitPrice ` )   AS   ` res2 ` , \n              ( COALESCE ( SUM ( ALL   ` t1 ` . ` Milliseconds ` ),   0 ))   /   ( 1000 )   AS   ` res3 ` \n       FROM   ` Genre `   AS   ` t0 ` \n       JOIN   ` Track `   AS   ` t1 ` \n       GROUP   BY   ` t0 ` . ` GenreId ` , \n                ` t0 ` . ` Name ` \n       HAVING   (( COALESCE ( SUM ( ALL   ` t1 ` . ` Milliseconds ` ),   0 ))   /   ( 1000 ))   =   ( 300000 ))   AS   ` t0 ` )   AS   ` t1 `  WHERE   CASE \n           WHEN   (( ` t0 ` . ` GenreId ` )   IS   NULL ) \n                AND   (( ` t1 ` . ` res0 ` )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` t0 ` . ` GenreId ` )   IS   NULL ) \n                OR   (( ` t1 ` . ` res0 ` )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` t0 ` . ` GenreId ` )   =   ( ` t1 ` . ` res0 ` ) \n       END", 
            "title": "The HAVING clause"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/", 
            "text": "SQL lets you combine the results of multiple \nSELECT\n statements using the\n\nUNION\n, \nINTERSECT\n, and \nEXCEPT\n clauses.\n\n\nSQL Set operations\n\n\nThe SQL Set operations are provided as the \nunion_\n, \nintersect_\n, and \nexcept_\n\nfunctions. SQL also allows an optional \nALL\n clause to be specified with each of\nthese. Beam implements these as \nunionAll_\n, \nintersectAll_\n, and \nexceptAll_\n\nrespectively. Each combinator takes two queries as arguments. The results of\nboth queries will be combined accordingly. The returned type is the same as the\ntype of both query arguments, which must be the same.\n\n\nFor example, suppose we wanted the first and last names of both customers and\nemployees.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ncustomerNames\n \n=\n\n      \nfmap\n \n(\n\\\nc\n \n-\n \n(\ncustomerFirstName\n \nc\n,\n \ncustomerLastName\n \nc\n))\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeNames\n \n=\n\n      \nfmap\n \n(\n\\\ne\n \n-\n \n(\nemployeeFirstName\n \ne\n,\n \nemployeeLastName\n \ne\n))\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n\nin\n \nunion_\n \ncustomerNames\n \nemployeeNames\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nUNION\n\n\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n\n\nFROM\n \nEmployee\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n)\n\n\nUNION\n\n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nEmployee\n \nAS\n \nt0\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres1\n`\n\n   \nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n   \nUNION\n \nSELECT\n \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres0\n`\n,\n\n                \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres1\n`\n\n   \nFROM\n \n`\nEmployee\n`\n \nAS\n \n`\nt0\n`\n)\n \nAS\n \n`\nt0\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nCombining arbitrary set expressions\n\n\nSuppose we wanted all employee and customer first names that were also customer\nlast names but not also employee last names. We could use \nUNION\n to combine the\nresults of a query over the first names of employees and customers, and an\n\nEXCEPT\n to get all customer last names that were not employee ones. Finally, an\n\nINTERSECT\n would give us the result we want. The beam query language allows\nthis and many popular backends do as well, but standard SQL makes it difficult\nto express. Beam has decided to go with the most common implement solution,\nwhich is to allow such nesting. This simplifies the API design.\n\n\nOn backends which allow such nesting (like Postgres), the query is translated\ndirectly. On backends that do not (like SQLite), an appropriate subselect is\ngenerated.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ncustomerFirstNames\n \n=\n\n      \nfmap\n \ncustomerFirstName\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeFirstNames\n \n=\n\n      \nfmap\n \nemployeeFirstName\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n    \ncustomerLastNames\n \n=\n\n      \nfmap\n \ncustomerLastName\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeLastNames\n \n=\n\n      \nfmap\n \nemployeeLastName\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n\nin\n \n(\ncustomerFirstNames\n \n`\nunion_\n`\nemployeeFirstNames\n)\n \n`\nintersect_\n`\n\n   \n(\ncustomerLastNames\n \n`\nexcept_\n`\n \nemployeeLastNames\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nUNION\n \nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n\n   \nFROM\n \nEmployee\n \nAS\n \nt0\n)\n \nAS\n \nt0\n \nINTERSECT\n\n\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nLastName\n \nAS\n \nres0\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nEXCEPT\n \nSELECT\n \nt0\n.\nLastName\n \nAS\n \nres0\n\n   \nFROM\n \nEmployee\n \nAS\n \nt0\n)\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(\n\n   \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n\n    \nFROM\n \nCustomer\n \nAS\n \nt0\n)\n\n \nUNION\n\n   \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n\n    \nFROM\n \nEmployee\n \nAS\n \nt0\n))\n \nINTERSECT\n \n(\n\n                                           \n(\nSELECT\n \nt0\n.\nLastName\n \nAS\n \nres0\n\n                                            \nFROM\n \nCustomer\n \nAS\n \nt0\n)\n\n                                         \nEXCEPT\n\n                                           \n(\nSELECT\n \nt0\n.\nLastName\n \nAS\n \nres0\n\n                                            \nFROM\n \nEmployee\n \nAS\n \nt0\n))\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nLIMIT\n/\nOFFSET\n and set operations\n\n\nThe \nLIMIT\n and \nOFFSET\n clauses generated by \nlimit_\n and \noffset_\n apply to\nthe entire result of the set operation. Beam will correctly generate the query\nyou specify, placing the \nLIMIT\n and \nOFFSET\n at the appropriate point. If\nnecessary, it will also generate a sub select to preserve the meaning of the\nquery.\n\n\nFor example, to get the second ten full names in common.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ncustomerNames\n \n=\n\n      \nfmap\n \n(\n\\\nc\n \n-\n \n(\ncustomerFirstName\n \nc\n,\n \ncustomerLastName\n \nc\n))\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeNames\n \n=\n\n      \nfmap\n \n(\n\\\ne\n \n-\n \n(\nemployeeFirstName\n \ne\n,\n \nemployeeLastName\n \ne\n))\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n\nin\n \nlimit_\n \n10\n \n(\nunion_\n \ncustomerNames\n \nemployeeNames\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nUNION\n\n\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n\n\nFROM\n \nEmployee\n \nAS\n \nt0\n\n\nLIMIT\n \n10\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n)\n\n\nUNION\n\n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nEmployee\n \nAS\n \nt0\n)\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres1\n`\n\n   \nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n   \nUNION\n \nSELECT\n \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres0\n`\n,\n\n                \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres1\n`\n\n   \nFROM\n \n`\nEmployee\n`\n \nAS\n \n`\nt0\n`\n)\n \nAS\n \n`\nt0\n`\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nIf we only wanted the union of the first 10 names of each.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ncustomerNames\n \n=\n\n      \nfmap\n \n(\n\\\nc\n \n-\n \n(\ncustomerFirstName\n \nc\n,\n \ncustomerLastName\n \nc\n))\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeNames\n \n=\n\n      \nfmap\n \n(\n\\\ne\n \n-\n \n(\nemployeeFirstName\n \ne\n,\n \nemployeeLastName\n \ne\n))\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n\nin\n \nunion_\n \n(\nlimit_\n \n10\n \ncustomerNames\n)\n \n(\nlimit_\n \n10\n \nemployeeNames\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nUNION\n\n\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nEmployee\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n             \nt0\n.\nLastName\n \nAS\n \nres1\n\n      \nFROM\n \nCustomer\n \nAS\n \nt0\n\n      \nLIMIT\n \n10\n)\n \nAS\n \nt0\n)\n\n\nUNION\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n             \nt0\n.\nLastName\n \nAS\n \nres1\n\n      \nFROM\n \nEmployee\n \nAS\n \nt0\n\n      \nLIMIT\n \n10\n)\n \nAS\n \nt0\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n\n\nFROM\n\n  \n(\nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n          \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n\n   \nFROM\n\n     \n(\nSELECT\n \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres0\n`\n,\n\n             \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres1\n`\n\n      \nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n      \nLIMIT\n \n10\n)\n \nAS\n \n`\nt0\n`\n\n   \nUNION\n \nSELECT\n \n`\nt0\n`\n.\n`\nres0\n`\n \nAS\n \n`\nres0\n`\n,\n\n                \n`\nt0\n`\n.\n`\nres1\n`\n \nAS\n \n`\nres1\n`\n\n   \nFROM\n\n     \n(\nSELECT\n \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres0\n`\n,\n\n             \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres1\n`\n\n      \nFROM\n \n`\nEmployee\n`\n \nAS\n \n`\nt0\n`\n\n      \nLIMIT\n \n10\n)\n \nAS\n \n`\nt0\n`\n)\n \nAS\n \n`\nt0\n`", 
            "title": "Combining queries"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#sql-set-operations", 
            "text": "The SQL Set operations are provided as the  union_ ,  intersect_ , and  except_ \nfunctions. SQL also allows an optional  ALL  clause to be specified with each of\nthese. Beam implements these as  unionAll_ ,  intersectAll_ , and  exceptAll_ \nrespectively. Each combinator takes two queries as arguments. The results of\nboth queries will be combined accordingly. The returned type is the same as the\ntype of both query arguments, which must be the same.  For example, suppose we wanted the first and last names of both customers and\nemployees.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             let   customerNames   = \n       fmap   ( \\ c   -   ( customerFirstName   c ,   customerLastName   c )) \n            ( all_   ( customer   chinookDb )) \n     employeeNames   = \n       fmap   ( \\ e   -   ( employeeFirstName   e ,   employeeLastName   e )) \n            ( all_   ( employee   chinookDb ))  in   union_   customerNames   employeeNames  \n\n         \n    \n         \n             SELECT   t0 . FirstName   AS   res0 , \n        t0 . LastName   AS   res1  FROM   Customer   AS   t0  UNION  SELECT   t0 . FirstName   AS   res0 , \n        t0 . LastName   AS   res1  FROM   Employee   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n                ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Customer   AS   t0 )  UNION \n   ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Employee   AS   t0 )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 `  FROM \n   ( SELECT   ` t0 ` . ` FirstName `   AS   ` res0 ` , \n           ` t0 ` . ` LastName `   AS   ` res1 ` \n    FROM   ` Customer `   AS   ` t0 ` \n    UNION   SELECT   ` t0 ` . ` FirstName `   AS   ` res0 ` , \n                 ` t0 ` . ` LastName `   AS   ` res1 ` \n    FROM   ` Employee `   AS   ` t0 ` )   AS   ` t0 `", 
            "title": "SQL Set operations"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#combining-arbitrary-set-expressions", 
            "text": "Suppose we wanted all employee and customer first names that were also customer\nlast names but not also employee last names. We could use  UNION  to combine the\nresults of a query over the first names of employees and customers, and an EXCEPT  to get all customer last names that were not employee ones. Finally, an INTERSECT  would give us the result we want. The beam query language allows\nthis and many popular backends do as well, but standard SQL makes it difficult\nto express. Beam has decided to go with the most common implement solution,\nwhich is to allow such nesting. This simplifies the API design.  On backends which allow such nesting (like Postgres), the query is translated\ndirectly. On backends that do not (like SQLite), an appropriate subselect is\ngenerated.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   customerFirstNames   = \n       fmap   customerFirstName \n            ( all_   ( customer   chinookDb )) \n     employeeFirstNames   = \n       fmap   employeeFirstName \n            ( all_   ( employee   chinookDb )) \n     customerLastNames   = \n       fmap   customerLastName \n            ( all_   ( customer   chinookDb )) \n     employeeLastNames   = \n       fmap   employeeLastName \n            ( all_   ( employee   chinookDb ))  in   ( customerFirstNames   ` union_ ` employeeFirstNames )   ` intersect_ ` \n    ( customerLastNames   ` except_ `   employeeLastNames )  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0  FROM \n   ( SELECT   t0 . FirstName   AS   res0 \n    FROM   Customer   AS   t0 \n    UNION   SELECT   t0 . FirstName   AS   res0 \n    FROM   Employee   AS   t0 )   AS   t0   INTERSECT  SELECT   t0 . res0   AS   res0  FROM \n   ( SELECT   t0 . LastName   AS   res0 \n    FROM   Customer   AS   t0 \n    EXCEPT   SELECT   t0 . LastName   AS   res0 \n    FROM   Employee   AS   t0 )   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n             ( \n    ( SELECT   t0 . FirstName   AS   res0 \n     FROM   Customer   AS   t0 ) \n  UNION \n    ( SELECT   t0 . FirstName   AS   res0 \n     FROM   Employee   AS   t0 ))   INTERSECT   ( \n                                            ( SELECT   t0 . LastName   AS   res0 \n                                             FROM   Customer   AS   t0 ) \n                                          EXCEPT \n                                            ( SELECT   t0 . LastName   AS   res0 \n                                             FROM   Employee   AS   t0 ))", 
            "title": "Combining arbitrary set expressions"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#limitoffset-and-set-operations", 
            "text": "The  LIMIT  and  OFFSET  clauses generated by  limit_  and  offset_  apply to\nthe entire result of the set operation. Beam will correctly generate the query\nyou specify, placing the  LIMIT  and  OFFSET  at the appropriate point. If\nnecessary, it will also generate a sub select to preserve the meaning of the\nquery.  For example, to get the second ten full names in common.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             let   customerNames   = \n       fmap   ( \\ c   -   ( customerFirstName   c ,   customerLastName   c )) \n            ( all_   ( customer   chinookDb )) \n     employeeNames   = \n       fmap   ( \\ e   -   ( employeeFirstName   e ,   employeeLastName   e )) \n            ( all_   ( employee   chinookDb ))  in   limit_   10   ( union_   customerNames   employeeNames )  \n\n         \n    \n         \n             SELECT   t0 . FirstName   AS   res0 , \n        t0 . LastName   AS   res1  FROM   Customer   AS   t0  UNION  SELECT   t0 . FirstName   AS   res0 , \n        t0 . LastName   AS   res1  FROM   Employee   AS   t0  LIMIT   10 ;  -- With values: []  \n\n         \n    \n         \n                ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Customer   AS   t0 )  UNION \n   ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Employee   AS   t0 )  LIMIT   10  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 `  FROM \n   ( SELECT   ` t0 ` . ` FirstName `   AS   ` res0 ` , \n           ` t0 ` . ` LastName `   AS   ` res1 ` \n    FROM   ` Customer `   AS   ` t0 ` \n    UNION   SELECT   ` t0 ` . ` FirstName `   AS   ` res0 ` , \n                 ` t0 ` . ` LastName `   AS   ` res1 ` \n    FROM   ` Employee `   AS   ` t0 ` )   AS   ` t0 `  LIMIT   10  \n\n         \n    \n         \n    \n                 \n                      If we only wanted the union of the first 10 names of each.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             let   customerNames   = \n       fmap   ( \\ c   -   ( customerFirstName   c ,   customerLastName   c )) \n            ( all_   ( customer   chinookDb )) \n     employeeNames   = \n       fmap   ( \\ e   -   ( employeeFirstName   e ,   employeeLastName   e )) \n            ( all_   ( employee   chinookDb ))  in   union_   ( limit_   10   customerNames )   ( limit_   10   employeeNames )  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1  FROM \n   ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Customer   AS   t0 \n    LIMIT   10 )   AS   t0  UNION  SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1  FROM \n   ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Employee   AS   t0 \n    LIMIT   10 )   AS   t0 ;  -- With values: []  \n\n         \n    \n         \n                ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 \n    FROM \n      ( SELECT   t0 . FirstName   AS   res0 , \n              t0 . LastName   AS   res1 \n       FROM   Customer   AS   t0 \n       LIMIT   10 )   AS   t0 )  UNION \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 \n    FROM \n      ( SELECT   t0 . FirstName   AS   res0 , \n              t0 . LastName   AS   res1 \n       FROM   Employee   AS   t0 \n       LIMIT   10 )   AS   t0 )  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n        ` t0 ` . ` res1 `   AS   ` res1 `  FROM \n   ( SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n           ` t0 ` . ` res1 `   AS   ` res1 ` \n    FROM \n      ( SELECT   ` t0 ` . ` FirstName `   AS   ` res0 ` , \n              ` t0 ` . ` LastName `   AS   ` res1 ` \n       FROM   ` Customer `   AS   ` t0 ` \n       LIMIT   10 )   AS   ` t0 ` \n    UNION   SELECT   ` t0 ` . ` res0 `   AS   ` res0 ` , \n                 ` t0 ` . ` res1 `   AS   ` res1 ` \n    FROM \n      ( SELECT   ` t0 ` . ` FirstName `   AS   ` res0 ` , \n              ` t0 ` . ` LastName `   AS   ` res1 ` \n       FROM   ` Employee `   AS   ` t0 ` \n       LIMIT   10 )   AS   ` t0 ` )   AS   ` t0 `", 
            "title": "LIMIT/OFFSET and set operations"
        }, 
        {
            "location": "/user-guide/queries/window-functions/", 
            "text": "Window functions allow you to calculate aggregates over portions of your result\nset. They are defined in SQL2003. Some databases use the alternative\nnomenclature \nanalytic functions\n. They are expressed in SQL with the \nOVER\n\nclause. The\n\nPostgres documentation\n\noffers a good overview of window functions.\n\n\nThe \nwithWindow_\n function\n\n\nWhen you want to add windows to a query, use the \nwithWindow_\n function to\nintroduce your frames, and compute the projection. You may notice that this is a\ndeparture from SQL syntax, where you can define window expressions inline. Beam\nseeks to be type-safe. Queries with window functions follow slightly different\nrules. Wrapping such a query with a special function allows beam to enforce\nthese rules.\n\n\nFor example, to get each invoice along with the average invoice total by each\ncustomer, use \nwithWindow_\n as follows.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithWindow_\n \n(\n\\\ni\n \n-\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \nnoOrder_\n \nnoBounds_\n)\n\n            \n(\n\\\ni\n \nw\n \n-\n \n(\ni\n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nover_\n`\n \nw\n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nAVG\n(\nt0\n.\nTotal\n)\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n)\n \nAS\n \nres9\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOr to get each invoice along with the ranking of each invoice by total per\ncustomer \nand\n the overall ranking,\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithWindow_\n \n(\n\\\ni\n \n-\n \n(\n \nframe_\n \nnoPartition_\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceTotal\n \ni\n)))\n \nnoBounds_\n\n                   \n,\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceTotal\n \ni\n)))\n \nnoBounds_\n \n))\n\n            \n(\n\\\ni\n \n(\nallInvoices\n,\n \ncustomerInvoices\n)\n \n-\n \n(\ni\n,\n \nrank_\n \n`\nover_\n`\n \nallInvoices\n,\n \nrank_\n \n`\nover_\n`\n \ncustomerInvoices\n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nRANK\n()\n \nOVER\n \n(\n\n                    \nORDER\n \nBY\n \nt0\n.\nTotal\n \nASC\n)\n \nAS\n \nres9\n,\n\n                   \nRANK\n()\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n\n                                \nORDER\n \nBY\n \nt0\n.\nTotal\n \nASC\n)\n \nAS\n \nres10\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nrank_\n is only available in backends that implement the optional SQL2003\nT611 feature \"Elementary OLAP operations\". Beam syntaxes that implement this\nfunctionality implement the\n\nIsSql2003ExpressionElementaryOLAPOperationsSyntax\n type class.\n\n\n\n\nNotice that aggregates over the result of the window expression work as you'd\nexpect. Beam automatically generates a subquery once a query has been windowed.\nFor example, to get the sum of the totals of the invoices, by rank.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \norderBy_\n \n(\n\\\n(\nrank\n,\n \n_\n)\n \n-\n \nasc_\n \nrank\n)\n \n$\n\n\naggregate_\n \n(\n\\\n(\ni\n,\n \nrank\n)\n \n-\n \n(\ngroup_\n \nrank\n,\n \nsum_\n \n$\n \ninvoiceTotal\n \ni\n))\n \n$\n\n\nwithWindow_\n \n(\n\\\ni\n \n-\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceTotal\n \ni\n)))\n \nnoBounds_\n)\n\n            \n(\n\\\ni\n \nw\n \n-\n \n(\ni\n,\n \nrank_\n \n`\nover_\n`\n \nw\n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres9\n \nAS\n \nres0\n,\n\n       \nSUM\n(\nt0\n.\nres8\n)\n \nAS\n \nres1\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n          \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n          \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n          \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n          \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n          \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n          \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n          \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n          \nRANK\n()\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n\n                       \nORDER\n \nBY\n \nt0\n.\nTotal\n \nASC\n)\n \nAS\n \nres9\n\n   \nFROM\n \nInvoice\n \nAS\n \nt0\n)\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nres9\n\n\nORDER\n \nBY\n \nt0\n.\nres9\n \nASC\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nMore examples\n\n\nWindows and aggregates can be combined freely. For example, suppose\nyou wanted to find, for each album, the single genre that represented\nmost of the tracks on that album.\n\n\nWe can begin by finding the number of tracks in a given genre on a\ngiven album using \ncountAll_\n and \naggregate_\n, like so\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                  \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                  \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n\nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nAlbumId\n,\n\n         \nt0\n.\nGenreId\n;\n\n\n\n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nAlbumId\n,\n\n         \nt0\n.\nGenreId\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nAlbumId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nGenreId\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \nCOUNT\n(\n*\n)\n \nAS\n \n`\nres2\n`\n\n\nFROM\n \n`\nTrack\n`\n \nAS\n \n`\nt0\n`\n\n\nGROUP\n \nBY\n \n`\nt0\n`\n.\n`\nAlbumId\n`\n,\n\n         \n`\nt0\n`\n.\n`\nGenreId\n`\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNow, we want to find, for each album, which genre has the most\ntracks. We can do this by windowing over the album ID.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                     \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\nin\n \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n               \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                   \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n   \nalbumGenreCnts\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n,\n\n       \nMAX\n(\nCOUNT\n(\n*\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nAlbumId\n)\n \nAS\n \nres3\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nAlbumId\n,\n\n         \nt0\n.\nGenreId\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe're almost there. Now, our query returns tuples of\n\n\n\n\nan album ID,\n\n\na genre ID,\n\n\nthe number of tracks in that genre for that album, and\n\n\nthe number of tracks for the genre with the most tracks in that album\n\n\n\n\nTo get just the genre with the most tracks, we have to find the genres\nwher the number of tracks (#3) matches #4. We can do this using\n\nfilter_\n. Because \nmax_\n can return \nNULL\n if there are no items in\nthe window, we use \nfilter_'\n and the nullable ordering operators.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                     \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n    \nwithMaxCounts\n \n=\n \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n                                \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                                    \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n                    \nalbumGenreCnts\n\n\nin\n \nfilter_\n \n(\n\\\n(\n_\n,\n \n_\n,\n \ntrackCnt\n,\n \nmaxTrackCntPerAlbum\n)\n \n-\n \njust_\n \ntrackCnt\n \n==?.\n \nmaxTrackCntPerAlbum\n)\n \nwithMaxCounts\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nGenreId\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n,\n\n          \nMAX\n(\nCOUNT\n(\n*\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nAlbumId\n)\n \nAS\n \nres3\n\n   \nFROM\n \nTrack\n \nAS\n \nt0\n\n   \nGROUP\n \nBY\n \nt0\n.\nAlbumId\n,\n\n            \nt0\n.\nGenreId\n)\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nres2\n)\n \n=\n \n(\nt0\n.\nres3\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nFrame syntax\n\n\nThe \nframe_\n function takes a partition, ordering, and bounds parameter, all of\nwhich are optional. To specify no partition, use \nnoPartition_\n. For no\nordering, use \nnoOrder_\n. For no bounds, use \nnoBounds_\n.\n\n\nTo specify a partition, use \npartitionBy_\n with an expression or a tuple of\nexpressions. To specify an ordering use \norderPartitionBy_\n with an ordering\nexpression or a tuple of ordering expressions. Ordering expressions are scalar\nexpressions passed to either \nasc_\n or \ndesc_\n. Finally, to specify bounds, use\n\nbounds_\n or \nfromBound_\n. \nfromBound_\n starts the window at the specified\nposition, which can be \nunbounded_\n (the default) to include all rows seen thus\nfar. \nbounds_\n lets you specify an optional ending bound, which can be \nNothing\n\n(the default), \nJust unbounded_\n (the semantic default, but producing an\nexplicit bound syntactically), or \nJust (nrows_ x)\n, where \nx\n is an integer\nexpression, specifying the number of rows before or after to include in the\ncalculation.\n\n\nThe following query illustrates some of these features. Along with each invoice, it returns\n\n\n\n\nThe average total of all invoices, given by the frame with no partition, ordering, and bounds.\n\n\nThe average total of all invoices, by customer.\n\n\nThe rank of each invoice over all the rows, when ordered by total.\n\n\nThe average of the totals of the invoices starting at the two immediately\n  preceding and ending with the two immediately succeeding invoices, when\n  ordered by date.\n\n\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithWindow_\n \n(\n\\\ni\n \n-\n \n(\n \nframe_\n \nnoPartition_\n \nnoOrder_\n \nnoBounds_\n\n                   \n,\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \nnoOrder_\n \nnoBounds_\n\n                   \n,\n \nframe_\n \nnoPartition_\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceTotal\n \ni\n)))\n \nnoBounds_\n\n                   \n,\n \nframe_\n \nnoPartition_\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceDate\n \ni\n)))\n \n(\nbounds_\n \n(\nnrows_\n \n2\n)\n \n(\nJust\n \n(\nnrows_\n \n2\n)))))\n\n            \n(\n\\\ni\n \n(\nallRows_\n,\n \nsameCustomer_\n,\n \ntotals_\n,\n \nfourInvoicesAround_\n)\n \n-\n\n                 \n(\n \ni\n\n                 \n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nover_\n`\n \nallRows_\n\n                 \n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nover_\n`\n \nsameCustomer_\n\n                 \n,\n \nrank_\n \n`\nover_\n`\n \ntotals_\n\n                 \n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nover_\n`\n \nfourInvoicesAround_\n \n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nAVG\n(\nt0\n.\nTotal\n)\n \nOVER\n \n()\n \nAS\n \nres9\n,\n\n                              \nAVG\n(\nt0\n.\nTotal\n)\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n)\n \nAS\n \nres10\n,\n\n                                                     \nRANK\n()\n \nOVER\n \n(\n\n                                                                  \nORDER\n \nBY\n \nt0\n.\nTotal\n \nASC\n)\n \nAS\n \nres11\n,\n\n                                                                 \nAVG\n(\nt0\n.\nTotal\n)\n \nOVER\n \n(\n\n                                                                                         \nORDER\n \nBY\n \nt0\n.\nInvoiceDate\n \nASC\n \nROWS\n \nBETWEEN\n \n2\n \nPRECEDING\n \nAND\n \n2\n \nFOLLOWING\n)\n \nAS\n \nres12\n\n\nFROM\n \nInvoice\n \nAS\n \nt0", 
            "title": "Window functions"
        }, 
        {
            "location": "/user-guide/queries/window-functions/#the-withwindow_-function", 
            "text": "When you want to add windows to a query, use the  withWindow_  function to\nintroduce your frames, and compute the projection. You may notice that this is a\ndeparture from SQL syntax, where you can define window expressions inline. Beam\nseeks to be type-safe. Queries with window functions follow slightly different\nrules. Wrapping such a query with a special function allows beam to enforce\nthese rules.  For example, to get each invoice along with the average invoice total by each\ncustomer, use  withWindow_  as follows.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             withWindow_   ( \\ i   -   frame_   ( partitionBy_   ( invoiceCustomer   i ))   noOrder_   noBounds_ ) \n             ( \\ i   w   -   ( i ,   avg_   ( invoiceTotal   i )   ` over_ `   w )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        AVG ( t0 . Total )   OVER   ( PARTITION   BY   t0 . CustomerId )   AS   res9  FROM   Invoice   AS   t0  \n\n         \n    \n         \n    \n                 \n                      Or to get each invoice along with the ranking of each invoice by total per\ncustomer  and  the overall ranking,  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             withWindow_   ( \\ i   -   (   frame_   noPartition_   ( orderPartitionBy_   ( asc_   ( invoiceTotal   i )))   noBounds_ \n                    ,   frame_   ( partitionBy_   ( invoiceCustomer   i ))   ( orderPartitionBy_   ( asc_   ( invoiceTotal   i )))   noBounds_   )) \n             ( \\ i   ( allInvoices ,   customerInvoices )   -   ( i ,   rank_   ` over_ `   allInvoices ,   rank_   ` over_ `   customerInvoices )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        RANK ()   OVER   ( \n                     ORDER   BY   t0 . Total   ASC )   AS   res9 , \n                    RANK ()   OVER   ( PARTITION   BY   t0 . CustomerId \n                                 ORDER   BY   t0 . Total   ASC )   AS   res10  FROM   Invoice   AS   t0  \n\n         \n    \n         \n    \n                 \n                       Note  rank_  is only available in backends that implement the optional SQL2003\nT611 feature \"Elementary OLAP operations\". Beam syntaxes that implement this\nfunctionality implement the IsSql2003ExpressionElementaryOLAPOperationsSyntax  type class.   Notice that aggregates over the result of the window expression work as you'd\nexpect. Beam automatically generates a subquery once a query has been windowed.\nFor example, to get the sum of the totals of the invoices, by rank.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             orderBy_   ( \\ ( rank ,   _ )   -   asc_   rank )   $  aggregate_   ( \\ ( i ,   rank )   -   ( group_   rank ,   sum_   $   invoiceTotal   i ))   $  withWindow_   ( \\ i   -   frame_   ( partitionBy_   ( invoiceCustomer   i ))   ( orderPartitionBy_   ( asc_   ( invoiceTotal   i )))   noBounds_ ) \n             ( \\ i   w   -   ( i ,   rank_   ` over_ `   w )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . res9   AS   res0 , \n        SUM ( t0 . res8 )   AS   res1  FROM \n   ( SELECT   t0 . InvoiceId   AS   res0 , \n           t0 . CustomerId   AS   res1 , \n           t0 . InvoiceDate   AS   res2 , \n           t0 . BillingAddress   AS   res3 , \n           t0 . BillingCity   AS   res4 , \n           t0 . BillingState   AS   res5 , \n           t0 . BillingCountry   AS   res6 , \n           t0 . BillingPostalCode   AS   res7 , \n           t0 . Total   AS   res8 , \n           RANK ()   OVER   ( PARTITION   BY   t0 . CustomerId \n                        ORDER   BY   t0 . Total   ASC )   AS   res9 \n    FROM   Invoice   AS   t0 )   AS   t0  GROUP   BY   t0 . res9  ORDER   BY   t0 . res9   ASC", 
            "title": "The withWindow_ function"
        }, 
        {
            "location": "/user-guide/queries/window-functions/#more-examples", 
            "text": "Windows and aggregates can be combined freely. For example, suppose\nyou wanted to find, for each album, the single genre that represented\nmost of the tracks on that album.  We can begin by finding the number of tracks in a given genre on a\ngiven album using  countAll_  and  aggregate_ , like so  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                   ,   group_   ( trackGenreId   t ) \n                   ,   as_   @ Int   countAll_   ))   $  all_   ( track   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . AlbumId   AS   res0 , \n        t0 . GenreId   AS   res1 , \n        COUNT ( * )   AS   res2  FROM   Track   AS   t0  GROUP   BY   t0 . AlbumId , \n          t0 . GenreId ;  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . AlbumId   AS   res0 , \n        t0 . GenreId   AS   res1 , \n        COUNT ( * )   AS   res2  FROM   Track   AS   t0  GROUP   BY   t0 . AlbumId , \n          t0 . GenreId  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` AlbumId `   AS   ` res0 ` , \n        ` t0 ` . ` GenreId `   AS   ` res1 ` , \n        COUNT ( * )   AS   ` res2 `  FROM   ` Track `   AS   ` t0 `  GROUP   BY   ` t0 ` . ` AlbumId ` , \n          ` t0 ` . ` GenreId `  \n\n         \n    \n         \n    \n                 \n                      Now, we want to find, for each album, which genre has the most\ntracks. We can do this by windowing over the album ID.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                 ,   group_   ( trackGenreId   t ) \n                                 ,   as_   @ Int   countAll_   ))   $ \n                      all_   ( track   chinookDb )  in   withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                    ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n    albumGenreCnts  \n\n         \n    \n         \n             SELECT   t0 . AlbumId   AS   res0 , \n        t0 . GenreId   AS   res1 , \n        COUNT ( * )   AS   res2 , \n        MAX ( COUNT ( * ))   OVER   ( PARTITION   BY   t0 . AlbumId )   AS   res3  FROM   Track   AS   t0  GROUP   BY   t0 . AlbumId , \n          t0 . GenreId  \n\n         \n    \n         \n    \n                 \n                      We're almost there. Now, our query returns tuples of   an album ID,  a genre ID,  the number of tracks in that genre for that album, and  the number of tracks for the genre with the most tracks in that album   To get just the genre with the most tracks, we have to find the genres\nwher the number of tracks (#3) matches #4. We can do this using filter_ . Because  max_  can return  NULL  if there are no items in\nthe window, we use  filter_'  and the nullable ordering operators.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                 ,   group_   ( trackGenreId   t ) \n                                 ,   as_   @ Int   countAll_   ))   $ \n                      all_   ( track   chinookDb ) \n\n     withMaxCounts   =   withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                                 ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                                     ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n                     albumGenreCnts  in   filter_   ( \\ ( _ ,   _ ,   trackCnt ,   maxTrackCntPerAlbum )   -   just_   trackCnt   ==?.   maxTrackCntPerAlbum )   withMaxCounts  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3  FROM \n   ( SELECT   t0 . AlbumId   AS   res0 , \n           t0 . GenreId   AS   res1 , \n           COUNT ( * )   AS   res2 , \n           MAX ( COUNT ( * ))   OVER   ( PARTITION   BY   t0 . AlbumId )   AS   res3 \n    FROM   Track   AS   t0 \n    GROUP   BY   t0 . AlbumId , \n             t0 . GenreId )   AS   t0  WHERE   ( t0 . res2 )   =   ( t0 . res3 )", 
            "title": "More examples"
        }, 
        {
            "location": "/user-guide/queries/window-functions/#frame-syntax", 
            "text": "The  frame_  function takes a partition, ordering, and bounds parameter, all of\nwhich are optional. To specify no partition, use  noPartition_ . For no\nordering, use  noOrder_ . For no bounds, use  noBounds_ .  To specify a partition, use  partitionBy_  with an expression or a tuple of\nexpressions. To specify an ordering use  orderPartitionBy_  with an ordering\nexpression or a tuple of ordering expressions. Ordering expressions are scalar\nexpressions passed to either  asc_  or  desc_ . Finally, to specify bounds, use bounds_  or  fromBound_ .  fromBound_  starts the window at the specified\nposition, which can be  unbounded_  (the default) to include all rows seen thus\nfar.  bounds_  lets you specify an optional ending bound, which can be  Nothing \n(the default),  Just unbounded_  (the semantic default, but producing an\nexplicit bound syntactically), or  Just (nrows_ x) , where  x  is an integer\nexpression, specifying the number of rows before or after to include in the\ncalculation.  The following query illustrates some of these features. Along with each invoice, it returns   The average total of all invoices, given by the frame with no partition, ordering, and bounds.  The average total of all invoices, by customer.  The rank of each invoice over all the rows, when ordered by total.  The average of the totals of the invoices starting at the two immediately\n  preceding and ending with the two immediately succeeding invoices, when\n  ordered by date.   \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             withWindow_   ( \\ i   -   (   frame_   noPartition_   noOrder_   noBounds_ \n                    ,   frame_   ( partitionBy_   ( invoiceCustomer   i ))   noOrder_   noBounds_ \n                    ,   frame_   noPartition_   ( orderPartitionBy_   ( asc_   ( invoiceTotal   i )))   noBounds_ \n                    ,   frame_   noPartition_   ( orderPartitionBy_   ( asc_   ( invoiceDate   i )))   ( bounds_   ( nrows_   2 )   ( Just   ( nrows_   2 ))))) \n             ( \\ i   ( allRows_ ,   sameCustomer_ ,   totals_ ,   fourInvoicesAround_ )   - \n                  (   i \n                  ,   avg_   ( invoiceTotal   i )   ` over_ `   allRows_ \n                  ,   avg_   ( invoiceTotal   i )   ` over_ `   sameCustomer_ \n                  ,   rank_   ` over_ `   totals_ \n                  ,   avg_   ( invoiceTotal   i )   ` over_ `   fourInvoicesAround_   )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        AVG ( t0 . Total )   OVER   ()   AS   res9 , \n                               AVG ( t0 . Total )   OVER   ( PARTITION   BY   t0 . CustomerId )   AS   res10 , \n                                                      RANK ()   OVER   ( \n                                                                   ORDER   BY   t0 . Total   ASC )   AS   res11 , \n                                                                  AVG ( t0 . Total )   OVER   ( \n                                                                                          ORDER   BY   t0 . InvoiceDate   ASC   ROWS   BETWEEN   2   PRECEDING   AND   2   FOLLOWING )   AS   res12  FROM   Invoice   AS   t0", 
            "title": "Frame syntax"
        }, 
        {
            "location": "/user-guide/queries/advanced-features/", 
            "text": "This page documents other advanced features that beam supports across backends\nthat support them.\n\n\nSQL2003 T611: Elementary OLAP operations\n\n\nThis optional SQL2003 feature allows attaching arbitrary \nFILTER (WHERE ..)\n\nclauses to aggregates. During querying only rows matching the given expression\nare included in computing the aggregate. This can often be simulated in other\ndatabases by an appropriate \nCASE\n expression, but beam will not do this\ntranslation.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\ni\n \n-\n \n(\ngroup_\n \n(\ninvoiceCustomer\n \ni\n),\n \nas_\n \n@\nInt\n \n$\n \ncountAll_\n \n`\nfilterWhere_\n`\n \n(\ninvoiceTotal\n \ni\n \n.\n \n500\n),\n \nas_\n \n@\nInt\n \n$\n \ncountAll_\n \n`\nfilterWhere_\n`\n \n(\ninvoiceTotal\n \ni\n \n.\n \n100\n)))\n \n$\n\n\nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nCOUNT\n(\n*\n)\n \nFILTER\n \n(\n\n                        \nWHERE\n \n(\nt0\n.\nTotal\n)\n \n \n(\n500.0\n))\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\n*\n)\n \nFILTER\n \n(\n\n                        \nWHERE\n \n(\nt0\n.\nTotal\n)\n \n \n(\n100.0\n))\n \nAS\n \nres2\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nCustomerId\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThese combine as you'd expect with window functions. For example, to return each\ninvoice along with the average total of all invoices by the same customer where\nthe invoice was billed to an address in Los Angeles,\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithWindow_\n \n(\n\\\ni\n \n-\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \nnoOrder_\n \nnoBounds_\n)\n\n            \n(\n\\\ni\n \nw\n \n-\n \n(\ni\n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nfilterWhere_\n`\n \n(\naddressCity\n \n(\ninvoiceBillingAddress\n \ni\n)\n \n==.\n \njust_\n \nLos Angeles\n)\n \n`\nover_\n`\n \nw\n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nAVG\n(\nt0\n.\nTotal\n)\n \nFILTER\n \n(\n\n                                 \nWHERE\n \n(\nt0\n.\nBillingCity\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n                                   \nFROM\n \n(\nLos Angeles\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n)\n \nAS\n \nres9\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nDanger\"\n\n\nFILTER (WHERE ..)\n must be applied directly to a SQL aggregate function,\nbut this isn't enforced at compile time. This may be fixed in a later\nversion of beam.\n\n\n\n\nThis extension also provides various window functions for SQL. The only one beam\ncurrently implements is \nRANK()\n via the \nrank_\n function. Contributions are\nappreciated!\n\n\nNull Ordering\n\n\nThis optional SQL2003 feature allows nulls to appear before or after non-null\nvalues in the sort ordering.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_\n \n10\n \n$\n\n\norderBy_\n \n(\n\\\ne\n \n-\n \n(\nasc_\n \n(\naddressState\n \n(\nemployeeAddress\n \ne\n)),\n \nnullsLast_\n \n(\ndesc_\n \n(\naddressCity\n \n(\nemployeeAddress\n \ne\n)))))\n \n$\n\n\nall_\n \n(\nemployee\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nEmployeeId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt0\n.\nReportsTo\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBirthDate\n \nAS\n \nres5\n,\n\n       \nt0\n.\nHireDate\n \nAS\n \nres6\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres7\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres8\n,\n\n       \nt0\n.\nState\n \nAS\n \nres9\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres10\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres11\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres12\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres13\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres14\n\n\nFROM\n \nEmployee\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nState\n \nASC\n,\n\n         \nt0\n.\nCity\n \nDESC\n \nNULLS\n \nLAST\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nSQL2003 T612: Advanced OLAP operations\n\n\nThis provides both the \nPERCENT_RANK()\n and \nCUME_DIST()\n functions as\n\npercentRank_\n and \ncumeDist_\n respectively.", 
            "title": "Advanced features"
        }, 
        {
            "location": "/user-guide/queries/advanced-features/#sql2003-t611-elementary-olap-operations", 
            "text": "This optional SQL2003 feature allows attaching arbitrary  FILTER (WHERE ..) \nclauses to aggregates. During querying only rows matching the given expression\nare included in computing the aggregate. This can often be simulated in other\ndatabases by an appropriate  CASE  expression, but beam will not do this\ntranslation.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ i   -   ( group_   ( invoiceCustomer   i ),   as_   @ Int   $   countAll_   ` filterWhere_ `   ( invoiceTotal   i   .   500 ),   as_   @ Int   $   countAll_   ` filterWhere_ `   ( invoiceTotal   i   .   100 )))   $  all_   ( invoice   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        COUNT ( * )   FILTER   ( \n                         WHERE   ( t0 . Total )     ( 500.0 ))   AS   res1 , \n        COUNT ( * )   FILTER   ( \n                         WHERE   ( t0 . Total )     ( 100.0 ))   AS   res2  FROM   Invoice   AS   t0  GROUP   BY   t0 . CustomerId  \n\n         \n    \n         \n    \n                 \n                      These combine as you'd expect with window functions. For example, to return each\ninvoice along with the average total of all invoices by the same customer where\nthe invoice was billed to an address in Los Angeles,  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             withWindow_   ( \\ i   -   frame_   ( partitionBy_   ( invoiceCustomer   i ))   noOrder_   noBounds_ ) \n             ( \\ i   w   -   ( i ,   avg_   ( invoiceTotal   i )   ` filterWhere_ `   ( addressCity   ( invoiceBillingAddress   i )   ==.   just_   Los Angeles )   ` over_ `   w )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        AVG ( t0 . Total )   FILTER   ( \n                                  WHERE   ( t0 . BillingCity )   IS   NOT   DISTINCT \n                                    FROM   ( Los Angeles ))   OVER   ( PARTITION   BY   t0 . CustomerId )   AS   res9  FROM   Invoice   AS   t0  \n\n         \n    \n         \n    \n                 \n                       Danger\"  FILTER (WHERE ..)  must be applied directly to a SQL aggregate function,\nbut this isn't enforced at compile time. This may be fixed in a later\nversion of beam.   This extension also provides various window functions for SQL. The only one beam\ncurrently implements is  RANK()  via the  rank_  function. Contributions are\nappreciated!", 
            "title": "SQL2003 T611: Elementary OLAP operations"
        }, 
        {
            "location": "/user-guide/queries/advanced-features/#null-ordering", 
            "text": "This optional SQL2003 feature allows nulls to appear before or after non-null\nvalues in the sort ordering.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             limit_   10   $  orderBy_   ( \\ e   -   ( asc_   ( addressState   ( employeeAddress   e )),   nullsLast_   ( desc_   ( addressCity   ( employeeAddress   e )))))   $  all_   ( employee   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . EmployeeId   AS   res0 , \n        t0 . LastName   AS   res1 , \n        t0 . FirstName   AS   res2 , \n        t0 . Title   AS   res3 , \n        t0 . ReportsTo   AS   res4 , \n        t0 . BirthDate   AS   res5 , \n        t0 . HireDate   AS   res6 , \n        t0 . Address   AS   res7 , \n        t0 . City   AS   res8 , \n        t0 . State   AS   res9 , \n        t0 . Country   AS   res10 , \n        t0 . PostalCode   AS   res11 , \n        t0 . Phone   AS   res12 , \n        t0 . Fax   AS   res13 , \n        t0 . Email   AS   res14  FROM   Employee   AS   t0  ORDER   BY   t0 . State   ASC , \n          t0 . City   DESC   NULLS   LAST  LIMIT   10", 
            "title": "Null Ordering"
        }, 
        {
            "location": "/user-guide/queries/advanced-features/#sql2003-t612-advanced-olap-operations", 
            "text": "This provides both the  PERCENT_RANK()  and  CUME_DIST()  functions as percentRank_  and  cumeDist_  respectively.", 
            "title": "SQL2003 T612: Advanced OLAP operations"
        }, 
        {
            "location": "/user-guide/queries/common-table-expressions/", 
            "text": "Common table expressions are a SQL99 feature that allow you to reuse common\nsubqueries in your queries. There is often no semantic difference between CTEs\nand reusing Beam queries, but backends sometimes have optimizations that will\nonly fire when using CTEs. Common table expressions are also necessary to write\n\nrecursive\n queries.\n\n\nLet's start with an example\n\n\nCommon table expressions are complicated, so let's start with an example.\n\n\nIn the \nwindow function\n section, we saw how to\nfind the genre representing the most tracks in a particular album.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                     \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n    \nwithMaxCounts\n \n=\n \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n                                \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                                    \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n                    \nalbumGenreCnts\n\n\nin\n \nfilter_\n \n(\n\\\n(\n_\n,\n \n_\n,\n \ntrackCnt\n,\n \nmaxTrackCntPerAlbum\n)\n \n-\n \njust_\n \ntrackCnt\n \n==?.\n \nmaxTrackCntPerAlbum\n)\n \nwithMaxCounts\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nGenreId\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n,\n\n          \nMAX\n(\nCOUNT\n(\n*\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nAlbumId\n)\n \nAS\n \nres3\n\n   \nFROM\n \nTrack\n \nAS\n \nt0\n\n   \nGROUP\n \nBY\n \nt0\n.\nAlbumId\n,\n\n            \nt0\n.\nGenreId\n)\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nres2\n)\n \n=\n \n(\nt0\n.\nres3\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNow, suppose that, instead of the album and genre ids, we wanted the names,\nalong with the name of the artist who produced the album. We can do this by just\njoining over the above\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                     \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n    \nwithMaxCounts\n \n=\n \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n                                \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                                    \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n                    \nalbumGenreCnts\n\n\n    \nalbumAndRepresentativeGenres\n \n=\n \nfilter_\n \n(\n\\\n(\n_\n,\n \n_\n,\n \ntrackCnt\n,\n \nmaxTrackCntPerAlbum\n)\n \n-\n \njust_\n \ntrackCnt\n \n==?.\n \nmaxTrackCntPerAlbum\n)\n \nwithMaxCounts\n\n\n\nin\n \ndo\n\n  \n(\nalbumId\n,\n \ngenreId\n,\n \n_\n,\n \n_\n)\n \n-\n \nalbumAndRepresentativeGenres\n\n\n  \ngenre_\n \n-\n \njoin_\n \n(\ngenre\n \nchinookDb\n)\n \n(\n\\\ng\n \n-\n \ngenreId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \ng\n))\n\n  \nalbum_\n \n-\n \njoin_\n \n(\nalbum\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \na\n))\n\n\n  \nartistName\n \n-\n \nfmap\n \nartistName\n \n$\n\n                \njoin_\n \n(\nartist\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumArtist\n \nalbum_\n \n`\nreferences_\n`\n \na\n)\n\n\n  \npure\n \n(\n \nartistName\n,\n \nalbumTitle\n \nalbum_\n,\n \ngenreName\n \ngenre_\n \n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt3\n.\nName\n \nAS\n \nres0\n,\n\n       \nt2\n.\nTitle\n \nAS\n \nres1\n,\n\n       \nt1\n.\nName\n \nAS\n \nres2\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nGenreId\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n,\n\n          \nMAX\n(\nCOUNT\n(\n*\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nAlbumId\n)\n \nAS\n \nres3\n\n   \nFROM\n \nTrack\n \nAS\n \nt0\n\n   \nGROUP\n \nBY\n \nt0\n.\nAlbumId\n,\n\n            \nt0\n.\nGenreId\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nGenre\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nres1\n)\n \n=\n \n(\nt1\n.\nGenreId\n)\n\n\nINNER\n \nJOIN\n \nAlbum\n \nAS\n \nt2\n \nON\n \n(\nt0\n.\nres0\n)\n \n=\n \n(\nt2\n.\nAlbumId\n)\n\n\nINNER\n \nJOIN\n \nArtist\n \nAS\n \nt3\n \nON\n \n(\nt2\n.\nArtistId\n)\n \n=\n \n(\nt3\n.\nArtistId\n)\n\n\nWHERE\n \n(\nt0\n.\nres2\n)\n \n=\n \n(\nt0\n.\nres3\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nBecause we're using Beam, and Beam is just Haskell, we are free to compose\nqueries arbitrarily, and get the right results. However, the generated SQL is a\nbit dense, and some backends may not optimize it well. Moreover, if we plan on\nusing \nalbumAndRepresentativeGenres\n more than once, then we'd like to express\nthis syntactically, rather than repeating the query wherever we need it. In\nother words, we want to be able to signal the concept of re-use to the database\nsystem.\n\n\nThe \nselectWith\n function\n\n\nWe can rewrite the above query using common table expressions. Firstly, we'll\nhave to tell Beam that we want to write a \nSELECT\n statement with a \nWITH\n\nexpression. We can do this by using \nselectWith\n instead of\n\nselect\n. \nselectWith\n takes one argument, which is a monadic action returning a\nquery. The monad expected is the \nWith\n monad from\n\nDatabase.Beam.Query.CTE\n. Within this monad, bindings represent queries we\nwould like bound at the top-level.\n\n\nSo, let's start building our query using \nselectWith\n. We'll want to return a\nlist, so we'll use \nrunSelectReturningList\n.\n\n\nrunSelectReturningList\n \n$\n \nselectWith\n \n$\n \ndo\n\n\n\n\n\n\nBinding subqueries with \nselecting\n\n\nNow, we're in the \nWith\n monad, so we can start binding common table\nexpressions. We can bind multiple different types of results here. On all\nbackends that support CTEs, you can bind the results of \nSELECT\n, but in some\nbackends, you can bind the results of \nINSERT\n, \nDELETE\n, \nUPDATE\n, etc.\n\n\nIn our case, we would like to bind the results of a \nSELECT\n statement, so we\ncan use the \nselecting\n function. This function takes a query (represented by a\nvalue of type \nQ\n) and returns a \nReusableQ\n, which is a query value that can be\nre-used elsewhere.\n\n\nA \nReusableQ\n is parameterized by three paramaters\n\n\ndata\n \nReusableQ\n \nbe\n \ndb\n \nres\n\n\n\n\n\n\n\n\nbe\n -- This is the backend that the query is in. For example, \nPostgres\n for\n  \nbeam-postgres\n or \nSqlite\n for \nbeam-sqlite\n.\n\n\ndb\n -- This is the type of the database the query is written over\n\n\nres\n -- This is the type of each row returned by the query.\n\n\n\n\nNotice that \nReusableQ\n has no scoping parameter like regular \nQ\n\nexpressions. This is because \nReusableQ\n values can be rescoped at any\nlevel. We'll get to this in the next section.\n\n\nWe can introduce the \nalbumAndRepresentativeGenres\n query into the \nWith\n monad\nusing \nselecting\n.\n\n\n  \nalbumAndRepresentativeGenres\n \n-\n\n    \nselecting\n \n$\n\n    \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                    \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                    \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                         \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n        \nwithMaxCounts\n \n=\n \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n                                    \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                                        \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n                        \nalbumGenreCnts\n\n    \nin\n \nfilter_\n \n(\n\\\n(\n_\n,\n \n_\n,\n \ntrackCnt\n,\n \nmaxTrackCntPerAlbum\n)\n \n-\n \njust_\n \ntrackCnt\n \n==?.\n \nmaxTrackCntPerAlbum\n)\n \nwithMaxCounts\n\n\n\n\n\n\nUsing the query with \nreuse\n\n\nNow that we have taken that query out of scope, we'll need the ability to refer\nto its result. Queries are in the \nQ\n monad, but \nalbumAndRepresentativeGenres\n\nhas type \nReusableQ\n. In order to use the value in the \nQ\n monad, we can use the\n\nreuse\n function. This utility function ensures that the query is able to be\nused at any nesting level.\n\n\nAlso note that since we're in the \nWith\n monad, we'll need to inject our query\ninto that using \npure\n.\n\n\n  \npure\n \n$\n \ndo\n\n    \n(\nalbumId\n@\n(\nAlbumId\n \nalbumIdColumn\n),\n \ngenreId\n,\n \n_\n,\n \n_\n)\n \n-\n\n       \nreuse\n \nalbumGenreCountQ\n\n    \ngenre_\n \n-\n \njoin_\n \n(\ngenre\n \nchinookDb\n)\n \n(\n\\\ng\n \n-\n \ngenreId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \ng\n))\n\n    \nalbum_\n \n-\n \njoin_\n \n(\nalbum\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \na\n))\n\n    \nartist_\n \n-\n \njoin_\n \n(\nartist\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumArtist\n \nalbum_\n \n`\nreferences_\n`\n \na\n)\n\n\n    \npure\n \n(\n \nartistName\n \nartist_\n,\n \nalbumTitle\n \nalbum_\n,\n \ngenreName\n \ngenre_\n \n)\n\n\n\n\n\n\nPhew! Putting all of that together, and executing, we get...\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nvoid\n \n$\n \nrunSelectReturningList\n \n$\n \nselectWith\n \n$\n \ndo\n\n  \nalbumAndRepresentativeGenres\n \n-\n\n    \nselecting\n \n$\n\n    \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                    \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                    \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                         \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n        \nwithMaxCounts\n \n=\n \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n                                    \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                                        \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n                        \nalbumGenreCnts\n\n    \nin\n \nfilter_\n \n(\n\\\n(\n_\n,\n \n_\n,\n \ntrackCnt\n,\n \nmaxTrackCntPerAlbum\n)\n \n-\n \njust_\n \ntrackCnt\n \n==?.\n \nmaxTrackCntPerAlbum\n)\n \nwithMaxCounts\n\n\n  \npure\n \n$\n \ndo\n\n    \n(\nalbumId\n,\n \ngenreId\n,\n \n_\n,\n \n_\n)\n \n-\n\n       \nreuse\n \nalbumAndRepresentativeGenres\n\n    \ngenre_\n \n-\n \njoin_\n \n(\ngenre\n \nchinookDb\n)\n \n(\n\\\ng\n \n-\n \ngenreId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \ng\n))\n\n    \nalbum_\n \n-\n \njoin_\n \n(\nalbum\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \na\n))\n\n    \nartist_\n \n-\n \njoin_\n \n(\nartist\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumArtist\n \nalbum_\n \n`\nreferences_\n`\n \na\n)\n\n\n    \npure\n \n(\n \nartistName\n \nartist_\n,\n \nalbumTitle\n \nalbum_\n,\n \ngenreName\n \ngenre_\n \n)\n\n\n\n\n        \n\n    \n        \n\n            \nWITH\n \ncte0\n(\nres0\n,\n\n            \nres1\n,\n\n            \nres2\n,\n\n            \nres3\n)\n \nAS\n\n  \n(\nSELECT\n \ncte0_0\n.\nres0\n \nAS\n \nres0\n,\n\n          \ncte0_0\n.\nres1\n \nAS\n \nres1\n,\n\n          \ncte0_0\n.\nres2\n \nAS\n \nres2\n,\n\n          \ncte0_0\n.\nres3\n \nAS\n \nres3\n\n   \nFROM\n\n     \n(\nSELECT\n \ncte0_0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n             \ncte0_0\n.\nGenreId\n \nAS\n \nres1\n,\n\n             \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n,\n\n             \nMAX\n(\nCOUNT\n(\n*\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \ncte0_0\n.\nAlbumId\n)\n \nAS\n \nres3\n\n      \nFROM\n \nTrack\n \nAS\n \ncte0_0\n\n      \nGROUP\n \nBY\n \ncte0_0\n.\nAlbumId\n,\n\n               \ncte0_0\n.\nGenreId\n)\n \nAS\n \ncte0_0\n\n   \nWHERE\n \n(\ncte0_0\n.\nres2\n)\n \n=\n \n(\ncte0_0\n.\nres3\n))\n\n\nSELECT\n \nt3\n.\nName\n \nAS\n \nres0\n,\n\n       \nt2\n.\nTitle\n \nAS\n \nres1\n,\n\n       \nt1\n.\nName\n \nAS\n \nres2\n\n\nFROM\n \ncte0\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nGenre\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nres1\n)\n \n=\n \n(\nt1\n.\nGenreId\n)\n\n\nINNER\n \nJOIN\n \nAlbum\n \nAS\n \nt2\n \nON\n \n(\nt0\n.\nres0\n)\n \n=\n \n(\nt2\n.\nAlbumId\n)\n\n\nINNER\n \nJOIN\n \nArtist\n \nAS\n \nt3\n \nON\n \n(\nt2\n.\nArtistId\n)\n \n=\n \n(\nt3\n.\nArtistId\n);\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nRefining our query\n\n\nNotice that the \nfilter_'\n condition on the common table expression resulted in\na nasty subselect. We can get rid of that by introducing the \nfilter_'\n in the\nouter query.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nvoid\n \n$\n \nrunSelectReturningList\n \n$\n \nselectWith\n \n$\n \ndo\n\n  \nalbumAndRepresentativeGenres\n \n-\n\n    \nselecting\n \n$\n\n    \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                    \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                    \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                         \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n    \nin\n \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n                   \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                       \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n       \nalbumGenreCnts\n\n\n  \npure\n \n$\n \ndo\n\n    \n(\nalbumId\n,\n \ngenreId\n,\n \n_\n,\n \n_\n)\n \n-\n\n       \nfilter_\n \n(\n\\\n(\n_\n,\n \n_\n,\n \ntrackCnt\n,\n \nmaxTrackCntInAlbum\n)\n \n-\n\n                     \njust_\n \ntrackCnt\n \n==?.\n \nmaxTrackCntInAlbum\n)\n \n$\n\n       \nreuse\n \nalbumAndRepresentativeGenres\n\n    \ngenre_\n \n-\n \njoin_\n \n(\ngenre\n \nchinookDb\n)\n \n(\n\\\ng\n \n-\n \ngenreId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \ng\n))\n\n    \nalbum_\n \n-\n \njoin_\n \n(\nalbum\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \na\n))\n\n    \nartist_\n \n-\n \njoin_\n \n(\nartist\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumArtist\n \nalbum_\n \n`\nreferences_\n`\n \na\n)\n\n\n    \npure\n \n(\n \nartistName\n \nartist_\n,\n \nalbumTitle\n \nalbum_\n,\n \ngenreName\n \ngenre_\n \n)\n\n\n\n\n        \n\n    \n        \n\n            \nWITH\n \ncte0\n(\nres0\n,\n\n            \nres1\n,\n\n            \nres2\n,\n\n            \nres3\n)\n \nAS\n\n  \n(\nSELECT\n \ncte0_0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \ncte0_0\n.\nGenreId\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n,\n\n          \nMAX\n(\nCOUNT\n(\n*\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \ncte0_0\n.\nAlbumId\n)\n \nAS\n \nres3\n\n   \nFROM\n \nTrack\n \nAS\n \ncte0_0\n\n   \nGROUP\n \nBY\n \ncte0_0\n.\nAlbumId\n,\n\n            \ncte0_0\n.\nGenreId\n)\n\n\nSELECT\n \nt3\n.\nName\n \nAS\n \nres0\n,\n\n       \nt2\n.\nTitle\n \nAS\n \nres1\n,\n\n       \nt1\n.\nName\n \nAS\n \nres2\n\n\nFROM\n \ncte0\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nGenre\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nres1\n)\n \n=\n \n(\nt1\n.\nGenreId\n)\n\n\nINNER\n \nJOIN\n \nAlbum\n \nAS\n \nt2\n \nON\n \n(\nt0\n.\nres0\n)\n \n=\n \n(\nt2\n.\nAlbumId\n)\n\n\nINNER\n \nJOIN\n \nArtist\n \nAS\n \nt3\n \nON\n \n(\nt2\n.\nArtistId\n)\n \n=\n \n(\nt3\n.\nArtistId\n)\n\n\nWHERE\n \n(\nt0\n.\nres2\n)\n \n=\n \n(\nt0\n.\nres3\n);\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nTo demonstrate that we can still use all beam's features, let's only return\nresults for albums with tracks of more than one genre. We can do this by using a\nquantified comparison operator on the album id column, and a subquery to find\nall albums with more than one genre.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nvoid\n \n$\n \nrunSelectReturningList\n \n$\n \nselectWith\n \n$\n \ndo\n\n  \nalbumAndRepresentativeGenres\n \n-\n\n    \nselecting\n \n$\n\n    \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                    \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                    \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                         \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n    \nin\n \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n                   \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                       \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n       \nalbumGenreCnts\n\n\n  \npure\n \n$\n \ndo\n\n    \n(\nalbumId\n@\n(\nAlbumId\n \nalbumIdColumn\n),\n \ngenreId\n,\n \n_\n,\n \n_\n)\n \n-\n\n       \nfilter_\n \n(\n\\\n(\n_\n,\n \n_\n,\n \ntrackCnt\n,\n \nmaxTrackCntInAlbum\n)\n \n-\n\n                     \njust_\n \ntrackCnt\n \n==?.\n \nmaxTrackCntInAlbum\n)\n \n$\n\n       \nreuse\n \nalbumAndRepresentativeGenres\n\n    \ngenre_\n \n-\n \njoin_\n \n(\ngenre\n \nchinookDb\n)\n \n(\n\\\ng\n \n-\n \ngenreId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \ng\n))\n\n    \nalbum_\n \n-\n \njoin_\n \n(\nalbum\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \na\n))\n\n    \nartist_\n \n-\n \njoin_\n \n(\nartist\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumArtist\n \nalbum_\n \n`\nreferences_\n`\n \na\n)\n\n\n    \n-- Filter out all albums with tracks of only one genre\n\n    \nguard_\n \n(\nalbumIdColumn\n \n==*.\n\n             \nanyOf_\n \n(\norderBy_\n \nasc_\n \n$\n \nfmap\n \n(\n\\\n(\nAlbumId\n \nalbumIdRaw\n,\n \n_\n)\n \n-\n \nalbumIdRaw\n)\n \n$\n\n                     \nfilter_\n \n(\n\\\n(\n_\n,\n \ngenreCntByAlbum\n)\n \n-\n \ngenreCntByAlbum\n \n.\n \n1\n)\n \n$\n\n                     \naggregate_\n \n(\n\\\nt\n \n-\n \nlet\n \nGenreId\n \ngenreId\n \n=\n \ntrackGenreId\n \nt\n\n                                       \nin\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                          \n,\n \nas_\n \n@\nInt\n \n(\ncountOver_\n \ndistinctInGroup_\n \ngenreId\n)))\n \n$\n\n                     \nall_\n \n(\ntrack\n \nchinookDb\n)))\n\n\n    \npure\n \n(\n \nartistName\n \nartist_\n,\n \nalbumTitle\n \nalbum_\n,\n \ngenreName\n \ngenre_\n \n)\n\n\n\n\n        \n\n    \n        \n\n            \nWITH\n \ncte0\n(\nres0\n,\n\n            \nres1\n,\n\n            \nres2\n,\n\n            \nres3\n)\n \nAS\n\n  \n(\nSELECT\n \ncte0_0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \ncte0_0\n.\nGenreId\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n,\n\n          \nMAX\n(\nCOUNT\n(\n*\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \ncte0_0\n.\nAlbumId\n)\n \nAS\n \nres3\n\n   \nFROM\n \nTrack\n \nAS\n \ncte0_0\n\n   \nGROUP\n \nBY\n \ncte0_0\n.\nAlbumId\n,\n\n            \ncte0_0\n.\nGenreId\n)\n\n\nSELECT\n \nt3\n.\nName\n \nAS\n \nres0\n,\n\n       \nt2\n.\nTitle\n \nAS\n \nres1\n,\n\n       \nt1\n.\nName\n \nAS\n \nres2\n\n\nFROM\n \ncte0\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nGenre\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nres1\n)\n \n=\n \n(\nt1\n.\nGenreId\n)\n\n\nINNER\n \nJOIN\n \nAlbum\n \nAS\n \nt2\n \nON\n \n(\nt0\n.\nres0\n)\n \n=\n \n(\nt2\n.\nAlbumId\n)\n\n\nINNER\n \nJOIN\n \nArtist\n \nAS\n \nt3\n \nON\n \n(\nt2\n.\nArtistId\n)\n \n=\n \n(\nt3\n.\nArtistId\n)\n\n\nWHERE\n \n((\nt0\n.\nres2\n)\n \n=\n \n(\nt0\n.\nres3\n))\n\n  \nAND\n \n((\nt0\n.\nres0\n)\n \n=\n \nANY\n\n         \n(\nSELECT\n \nsub_t0\n.\nAlbumId\n \nAS\n \nres0\n\n          \nFROM\n \nTrack\n \nAS\n \nsub_t0\n\n          \nGROUP\n \nBY\n \nsub_t0\n.\nAlbumId\n\n          \nHAVING\n \n(\nCOUNT\n(\nDISTINCT\n \nsub_t0\n.\nGenreId\n))\n \n \n(\n1\n)\n\n          \nORDER\n \nBY\n \nsub_t0\n.\nAlbumId\n \nASC\n));\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nwithout CTEs,\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nlet\n \nalbumGenreCnts\n \n=\n \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                   \n,\n \ngroup_\n \n(\ntrackGenreId\n \nt\n)\n\n                                   \n,\n \nas_\n \n@\nInt\n \ncountAll_\n \n))\n \n$\n\n                        \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n       \nalbumAndRepresentativeGenres\n \n=\n\n         \nwithWindow_\n \n(\n\\\n(\nalbumId\n,\n \n_\n,\n \n_\n)\n \n-\n \nframe_\n \n(\npartitionBy_\n \nalbumId\n)\n \nnoOrder_\n \nnoBounds_\n)\n\n                     \n(\n\\\n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n)\n \nalbumWindow\n \n-\n\n                         \n(\nalbumId\n,\n \ngenreId\n,\n \ntrackCnt\n,\n \nmax_\n \ntrackCnt\n \n`\nover_\n`\n \nalbumWindow\n))\n \n$\n\n           \nalbumGenreCnts\n\n\n\n   \n(\nalbumId\n@\n(\nAlbumId\n \nalbumIdColumn\n),\n \ngenreId\n,\n \n_\n,\n \n_\n)\n \n-\n\n      \nfilter_\n \n(\n\\\n(\n_\n,\n \n_\n,\n \ntrackCnt\n,\n \nmaxTrackCntInAlbum\n)\n \n-\n\n                    \njust_\n \ntrackCnt\n \n==?.\n \nmaxTrackCntInAlbum\n)\n \n$\n\n      \nalbumAndRepresentativeGenres\n\n   \ngenre_\n \n-\n \njoin_\n \n(\ngenre\n \nchinookDb\n)\n \n(\n\\\ng\n \n-\n \ngenreId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \ng\n))\n\n   \nalbum_\n \n-\n \njoin_\n \n(\nalbum\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumId\n \n==?.\n \njust_\n \n(\nprimaryKey\n \na\n))\n\n   \nartist_\n \n-\n \njoin_\n \n(\nartist\n \nchinookDb\n)\n \n(\n\\\na\n \n-\n \nalbumArtist\n \nalbum_\n \n`\nreferences_\n`\n \na\n)\n\n\n   \n-- Filter out all albums with tracks of only one genre\n\n   \nguard_\n \n(\nalbumIdColumn\n \n==*.\n\n            \nanyOf_\n \n(\norderBy_\n \nasc_\n \n$\n \nfmap\n \n(\n\\\n(\nAlbumId\n \nalbumIdRaw\n,\n \n_\n)\n \n-\n \nalbumIdRaw\n)\n \n$\n\n                    \nfilter_\n \n(\n\\\n(\n_\n,\n \ngenreCntByAlbum\n)\n \n-\n \ngenreCntByAlbum\n \n.\n \n1\n)\n \n$\n\n                    \naggregate_\n \n(\n\\\nt\n \n-\n \nlet\n \nGenreId\n \ngenreId\n \n=\n \ntrackGenreId\n \nt\n\n                                      \nin\n \n(\n \ngroup_\n \n(\ntrackAlbumId\n \nt\n)\n\n                                         \n,\n \nas_\n \n@\nInt\n \n(\ncountOver_\n \ndistinctInGroup_\n \ngenreId\n)))\n \n$\n\n                    \nall_\n \n(\ntrack\n \nchinookDb\n)))\n\n\n   \npure\n \n(\n \nartistName\n \nartist_\n,\n \nalbumTitle\n \nalbum_\n,\n \ngenreName\n \ngenre_\n \n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt3\n.\nName\n \nAS\n \nres0\n,\n\n       \nt2\n.\nTitle\n \nAS\n \nres1\n,\n\n       \nt1\n.\nName\n \nAS\n \nres2\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nGenreId\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres2\n,\n\n          \nMAX\n(\nCOUNT\n(\n*\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nAlbumId\n)\n \nAS\n \nres3\n\n   \nFROM\n \nTrack\n \nAS\n \nt0\n\n   \nGROUP\n \nBY\n \nt0\n.\nAlbumId\n,\n\n            \nt0\n.\nGenreId\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nGenre\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nres1\n)\n \n=\n \n(\nt1\n.\nGenreId\n)\n\n\nINNER\n \nJOIN\n \nAlbum\n \nAS\n \nt2\n \nON\n \n(\nt0\n.\nres0\n)\n \n=\n \n(\nt2\n.\nAlbumId\n)\n\n\nINNER\n \nJOIN\n \nArtist\n \nAS\n \nt3\n \nON\n \n(\nt2\n.\nArtistId\n)\n \n=\n \n(\nt3\n.\nArtistId\n)\n\n\nWHERE\n \n((\nt0\n.\nres2\n)\n \n=\n \n(\nt0\n.\nres3\n))\n\n  \nAND\n \n((\nt0\n.\nres0\n)\n \n=\n \nANY\n\n         \n(\nSELECT\n \nsub_t0\n.\nAlbumId\n \nAS\n \nres0\n\n          \nFROM\n \nTrack\n \nAS\n \nsub_t0\n\n          \nGROUP\n \nBY\n \nsub_t0\n.\nAlbumId\n\n          \nHAVING\n \n(\nCOUNT\n(\nDISTINCT\n \nsub_t0\n.\nGenreId\n))\n \n \n(\n1\n)\n\n          \nORDER\n \nBY\n \nsub_t0\n.\nAlbumId\n \nASC\n))\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nReusing queries multiple times\n\n\nSuppose we wanted to ask the question, \"which albums have tracks under the same\ngenre?\". One easy way of doing this is to do multiple self-joins.\n\n\nWe can also use a common table expression.\n\n\nLet's call albums \nA\n and \nB\n \"genre-related\" if \nA\n and \nB\n contain at least\none track under the same genre. Then, the queries above answer if \nA\n and \nB\n\nare \"genre-related\". A natural extension of the question above then is \"Which\nalbums are genre-related to the same album?\". For example, suppose \nA\n has Jazz\nand Rock tracks, \nB\n has Rock and Country tracks, and \nC\n has Country and Blues\ntracks. Then, \n(A, B)\n and \n(B, C)\n will both be results of the query above, but\n\n(A, C)\n will not. We can output tuples like \n(A, C)\n by self-joining on the\nresults of the same CTE.\n\n\nRecursive queries\n\n\nOkay, so the next natural extension is to extend this relation by relating any\ntwo albums \nA\n and \nD\n where there exist \nB\n and \nC\n such that \nA\n is related to\n\nB\n, \nB\n is related to \nC\n, and \nC\n is related to \nD\n. We can keep extending\nthis query forever, but the queries above require that we specify all lengths\nwe're interested in. Conceptually, we could express in Haskell an infinite query:\n\n\nHowever, the query generator will loop when serializing this query, because\ndatabase systems don't operate on laziness they way Haskell does!\n\n\nTo solve this, some RDBMS systems offer \"recursive\" queries \n1\n. The canonical\nexample of a recursive query is the Fibonacci sequence:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nvoid\n \n$\n \nrunSelectReturningList\n \n$\n \nselectWith\n \n$\n \ndo\n\n  \nrec\n \nfib\n \n-\n \nselecting\n \n(\npure\n \n(\nas_\n \n@\nInt\n \n0\n,\n \nas_\n \n@\nInt\n \n1\n)\n \n`\nunion_\n`\n\n                        \n(\ndo\n \n(\na\n,\n \nb\n)\n \n-\n \nreuse\n \nfib\n\n                            \nguard_\n \n(\nb\n \n.\n \n1000\n)\n\n                            \npure\n \n(\nb\n,\n \na\n \n+\n \nb\n)))\n\n  \npure\n \n(\nreuse\n \nfib\n)\n\n\n\n\n        \n\n    \n        \n\n            \nWITH\n \nRECURSIVE\n \ncte0\n(\nres0\n,\n\n                      \nres1\n)\n \nAS\n \n(\n\n                                    \n(\nSELECT\n \n0\n \nAS\n \nres0\n,\n\n                                            \n1\n \nAS\n \nres1\n)\n\n                                  \nUNION\n\n                                    \n(\nSELECT\n \ncte0_0\n.\nres1\n \nAS\n \nres0\n,\n\n                                            \n(\ncte0_0\n.\nres0\n)\n \n+\n \n(\ncte0_0\n.\nres1\n)\n \nAS\n \nres1\n\n                                     \nFROM\n \ncte0\n \nAS\n \ncte0_0\n\n                                     \nWHERE\n \n(\ncte0_0\n.\nres1\n)\n \n \n(\n1000\n)))\n\n\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n\n\nFROM\n \ncte0\n \nAS\n \nt0\n;\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\n\n\n\n\n\n\n\"Recursive\" here is in quotes, because this is not true, general recursion,\n   but rather iteration. Still the term \"recursive\" has stuck around, so Beam\n   adopts the convention.", 
            "title": "Common table expressions"
        }, 
        {
            "location": "/user-guide/queries/common-table-expressions/#lets-start-with-an-example", 
            "text": "Common table expressions are complicated, so let's start with an example.  In the  window function  section, we saw how to\nfind the genre representing the most tracks in a particular album.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                 ,   group_   ( trackGenreId   t ) \n                                 ,   as_   @ Int   countAll_   ))   $ \n                      all_   ( track   chinookDb ) \n\n     withMaxCounts   =   withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                                 ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                                     ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n                     albumGenreCnts  in   filter_   ( \\ ( _ ,   _ ,   trackCnt ,   maxTrackCntPerAlbum )   -   just_   trackCnt   ==?.   maxTrackCntPerAlbum )   withMaxCounts  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3  FROM \n   ( SELECT   t0 . AlbumId   AS   res0 , \n           t0 . GenreId   AS   res1 , \n           COUNT ( * )   AS   res2 , \n           MAX ( COUNT ( * ))   OVER   ( PARTITION   BY   t0 . AlbumId )   AS   res3 \n    FROM   Track   AS   t0 \n    GROUP   BY   t0 . AlbumId , \n             t0 . GenreId )   AS   t0  WHERE   ( t0 . res2 )   =   ( t0 . res3 )  \n\n         \n    \n         \n    \n                 \n                      Now, suppose that, instead of the album and genre ids, we wanted the names,\nalong with the name of the artist who produced the album. We can do this by just\njoining over the above  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                 ,   group_   ( trackGenreId   t ) \n                                 ,   as_   @ Int   countAll_   ))   $ \n                      all_   ( track   chinookDb ) \n\n     withMaxCounts   =   withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                                 ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                                     ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n                     albumGenreCnts \n\n     albumAndRepresentativeGenres   =   filter_   ( \\ ( _ ,   _ ,   trackCnt ,   maxTrackCntPerAlbum )   -   just_   trackCnt   ==?.   maxTrackCntPerAlbum )   withMaxCounts  in   do \n   ( albumId ,   genreId ,   _ ,   _ )   -   albumAndRepresentativeGenres \n\n   genre_   -   join_   ( genre   chinookDb )   ( \\ g   -   genreId   ==?.   just_   ( primaryKey   g )) \n   album_   -   join_   ( album   chinookDb )   ( \\ a   -   albumId   ==?.   just_   ( primaryKey   a )) \n\n   artistName   -   fmap   artistName   $ \n                 join_   ( artist   chinookDb )   ( \\ a   -   albumArtist   album_   ` references_ `   a ) \n\n   pure   (   artistName ,   albumTitle   album_ ,   genreName   genre_   )  \n\n         \n    \n         \n             SELECT   t3 . Name   AS   res0 , \n        t2 . Title   AS   res1 , \n        t1 . Name   AS   res2  FROM \n   ( SELECT   t0 . AlbumId   AS   res0 , \n           t0 . GenreId   AS   res1 , \n           COUNT ( * )   AS   res2 , \n           MAX ( COUNT ( * ))   OVER   ( PARTITION   BY   t0 . AlbumId )   AS   res3 \n    FROM   Track   AS   t0 \n    GROUP   BY   t0 . AlbumId , \n             t0 . GenreId )   AS   t0  INNER   JOIN   Genre   AS   t1   ON   ( t0 . res1 )   =   ( t1 . GenreId )  INNER   JOIN   Album   AS   t2   ON   ( t0 . res0 )   =   ( t2 . AlbumId )  INNER   JOIN   Artist   AS   t3   ON   ( t2 . ArtistId )   =   ( t3 . ArtistId )  WHERE   ( t0 . res2 )   =   ( t0 . res3 )  \n\n         \n    \n         \n    \n                 \n                      Because we're using Beam, and Beam is just Haskell, we are free to compose\nqueries arbitrarily, and get the right results. However, the generated SQL is a\nbit dense, and some backends may not optimize it well. Moreover, if we plan on\nusing  albumAndRepresentativeGenres  more than once, then we'd like to express\nthis syntactically, rather than repeating the query wherever we need it. In\nother words, we want to be able to signal the concept of re-use to the database\nsystem.", 
            "title": "Let's start with an example"
        }, 
        {
            "location": "/user-guide/queries/common-table-expressions/#the-selectwith-function", 
            "text": "We can rewrite the above query using common table expressions. Firstly, we'll\nhave to tell Beam that we want to write a  SELECT  statement with a  WITH \nexpression. We can do this by using  selectWith  instead of select .  selectWith  takes one argument, which is a monadic action returning a\nquery. The monad expected is the  With  monad from Database.Beam.Query.CTE . Within this monad, bindings represent queries we\nwould like bound at the top-level.  So, let's start building our query using  selectWith . We'll want to return a\nlist, so we'll use  runSelectReturningList .  runSelectReturningList   $   selectWith   $   do", 
            "title": "The selectWith function"
        }, 
        {
            "location": "/user-guide/queries/common-table-expressions/#binding-subqueries-with-selecting", 
            "text": "Now, we're in the  With  monad, so we can start binding common table\nexpressions. We can bind multiple different types of results here. On all\nbackends that support CTEs, you can bind the results of  SELECT , but in some\nbackends, you can bind the results of  INSERT ,  DELETE ,  UPDATE , etc.  In our case, we would like to bind the results of a  SELECT  statement, so we\ncan use the  selecting  function. This function takes a query (represented by a\nvalue of type  Q ) and returns a  ReusableQ , which is a query value that can be\nre-used elsewhere.  A  ReusableQ  is parameterized by three paramaters  data   ReusableQ   be   db   res    be  -- This is the backend that the query is in. For example,  Postgres  for\n   beam-postgres  or  Sqlite  for  beam-sqlite .  db  -- This is the type of the database the query is written over  res  -- This is the type of each row returned by the query.   Notice that  ReusableQ  has no scoping parameter like regular  Q \nexpressions. This is because  ReusableQ  values can be rescoped at any\nlevel. We'll get to this in the next section.  We can introduce the  albumAndRepresentativeGenres  query into the  With  monad\nusing  selecting .     albumAndRepresentativeGenres   - \n     selecting   $ \n     let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                     ,   group_   ( trackGenreId   t ) \n                                     ,   as_   @ Int   countAll_   ))   $ \n                          all_   ( track   chinookDb ) \n\n         withMaxCounts   =   withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                                     ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                                         ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n                         albumGenreCnts \n     in   filter_   ( \\ ( _ ,   _ ,   trackCnt ,   maxTrackCntPerAlbum )   -   just_   trackCnt   ==?.   maxTrackCntPerAlbum )   withMaxCounts", 
            "title": "Binding subqueries with selecting"
        }, 
        {
            "location": "/user-guide/queries/common-table-expressions/#using-the-query-with-reuse", 
            "text": "Now that we have taken that query out of scope, we'll need the ability to refer\nto its result. Queries are in the  Q  monad, but  albumAndRepresentativeGenres \nhas type  ReusableQ . In order to use the value in the  Q  monad, we can use the reuse  function. This utility function ensures that the query is able to be\nused at any nesting level.  Also note that since we're in the  With  monad, we'll need to inject our query\ninto that using  pure .     pure   $   do \n     ( albumId @ ( AlbumId   albumIdColumn ),   genreId ,   _ ,   _ )   - \n        reuse   albumGenreCountQ \n     genre_   -   join_   ( genre   chinookDb )   ( \\ g   -   genreId   ==?.   just_   ( primaryKey   g )) \n     album_   -   join_   ( album   chinookDb )   ( \\ a   -   albumId   ==?.   just_   ( primaryKey   a )) \n     artist_   -   join_   ( artist   chinookDb )   ( \\ a   -   albumArtist   album_   ` references_ `   a ) \n\n     pure   (   artistName   artist_ ,   albumTitle   album_ ,   genreName   genre_   )   Phew! Putting all of that together, and executing, we get...  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             void   $   runSelectReturningList   $   selectWith   $   do \n   albumAndRepresentativeGenres   - \n     selecting   $ \n     let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                     ,   group_   ( trackGenreId   t ) \n                                     ,   as_   @ Int   countAll_   ))   $ \n                          all_   ( track   chinookDb ) \n\n         withMaxCounts   =   withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                                     ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                                         ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n                         albumGenreCnts \n     in   filter_   ( \\ ( _ ,   _ ,   trackCnt ,   maxTrackCntPerAlbum )   -   just_   trackCnt   ==?.   maxTrackCntPerAlbum )   withMaxCounts \n\n   pure   $   do \n     ( albumId ,   genreId ,   _ ,   _ )   - \n        reuse   albumAndRepresentativeGenres \n     genre_   -   join_   ( genre   chinookDb )   ( \\ g   -   genreId   ==?.   just_   ( primaryKey   g )) \n     album_   -   join_   ( album   chinookDb )   ( \\ a   -   albumId   ==?.   just_   ( primaryKey   a )) \n     artist_   -   join_   ( artist   chinookDb )   ( \\ a   -   albumArtist   album_   ` references_ `   a ) \n\n     pure   (   artistName   artist_ ,   albumTitle   album_ ,   genreName   genre_   )  \n\n         \n    \n         \n             WITH   cte0 ( res0 , \n             res1 , \n             res2 , \n             res3 )   AS \n   ( SELECT   cte0_0 . res0   AS   res0 , \n           cte0_0 . res1   AS   res1 , \n           cte0_0 . res2   AS   res2 , \n           cte0_0 . res3   AS   res3 \n    FROM \n      ( SELECT   cte0_0 . AlbumId   AS   res0 , \n              cte0_0 . GenreId   AS   res1 , \n              COUNT ( * )   AS   res2 , \n              MAX ( COUNT ( * ))   OVER   ( PARTITION   BY   cte0_0 . AlbumId )   AS   res3 \n       FROM   Track   AS   cte0_0 \n       GROUP   BY   cte0_0 . AlbumId , \n                cte0_0 . GenreId )   AS   cte0_0 \n    WHERE   ( cte0_0 . res2 )   =   ( cte0_0 . res3 ))  SELECT   t3 . Name   AS   res0 , \n        t2 . Title   AS   res1 , \n        t1 . Name   AS   res2  FROM   cte0   AS   t0  INNER   JOIN   Genre   AS   t1   ON   ( t0 . res1 )   =   ( t1 . GenreId )  INNER   JOIN   Album   AS   t2   ON   ( t0 . res0 )   =   ( t2 . AlbumId )  INNER   JOIN   Artist   AS   t3   ON   ( t2 . ArtistId )   =   ( t3 . ArtistId );", 
            "title": "Using the query with reuse"
        }, 
        {
            "location": "/user-guide/queries/common-table-expressions/#refining-our-query", 
            "text": "Notice that the  filter_'  condition on the common table expression resulted in\na nasty subselect. We can get rid of that by introducing the  filter_'  in the\nouter query.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             void   $   runSelectReturningList   $   selectWith   $   do \n   albumAndRepresentativeGenres   - \n     selecting   $ \n     let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                     ,   group_   ( trackGenreId   t ) \n                                     ,   as_   @ Int   countAll_   ))   $ \n                          all_   ( track   chinookDb ) \n\n     in   withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                    ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                        ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n        albumGenreCnts \n\n   pure   $   do \n     ( albumId ,   genreId ,   _ ,   _ )   - \n        filter_   ( \\ ( _ ,   _ ,   trackCnt ,   maxTrackCntInAlbum )   - \n                      just_   trackCnt   ==?.   maxTrackCntInAlbum )   $ \n        reuse   albumAndRepresentativeGenres \n     genre_   -   join_   ( genre   chinookDb )   ( \\ g   -   genreId   ==?.   just_   ( primaryKey   g )) \n     album_   -   join_   ( album   chinookDb )   ( \\ a   -   albumId   ==?.   just_   ( primaryKey   a )) \n     artist_   -   join_   ( artist   chinookDb )   ( \\ a   -   albumArtist   album_   ` references_ `   a ) \n\n     pure   (   artistName   artist_ ,   albumTitle   album_ ,   genreName   genre_   )  \n\n         \n    \n         \n             WITH   cte0 ( res0 , \n             res1 , \n             res2 , \n             res3 )   AS \n   ( SELECT   cte0_0 . AlbumId   AS   res0 , \n           cte0_0 . GenreId   AS   res1 , \n           COUNT ( * )   AS   res2 , \n           MAX ( COUNT ( * ))   OVER   ( PARTITION   BY   cte0_0 . AlbumId )   AS   res3 \n    FROM   Track   AS   cte0_0 \n    GROUP   BY   cte0_0 . AlbumId , \n             cte0_0 . GenreId )  SELECT   t3 . Name   AS   res0 , \n        t2 . Title   AS   res1 , \n        t1 . Name   AS   res2  FROM   cte0   AS   t0  INNER   JOIN   Genre   AS   t1   ON   ( t0 . res1 )   =   ( t1 . GenreId )  INNER   JOIN   Album   AS   t2   ON   ( t0 . res0 )   =   ( t2 . AlbumId )  INNER   JOIN   Artist   AS   t3   ON   ( t2 . ArtistId )   =   ( t3 . ArtistId )  WHERE   ( t0 . res2 )   =   ( t0 . res3 );  \n\n         \n    \n         \n    \n                 \n                      To demonstrate that we can still use all beam's features, let's only return\nresults for albums with tracks of more than one genre. We can do this by using a\nquantified comparison operator on the album id column, and a subquery to find\nall albums with more than one genre.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             void   $   runSelectReturningList   $   selectWith   $   do \n   albumAndRepresentativeGenres   - \n     selecting   $ \n     let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                     ,   group_   ( trackGenreId   t ) \n                                     ,   as_   @ Int   countAll_   ))   $ \n                          all_   ( track   chinookDb ) \n\n     in   withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                    ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                        ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n        albumGenreCnts \n\n   pure   $   do \n     ( albumId @ ( AlbumId   albumIdColumn ),   genreId ,   _ ,   _ )   - \n        filter_   ( \\ ( _ ,   _ ,   trackCnt ,   maxTrackCntInAlbum )   - \n                      just_   trackCnt   ==?.   maxTrackCntInAlbum )   $ \n        reuse   albumAndRepresentativeGenres \n     genre_   -   join_   ( genre   chinookDb )   ( \\ g   -   genreId   ==?.   just_   ( primaryKey   g )) \n     album_   -   join_   ( album   chinookDb )   ( \\ a   -   albumId   ==?.   just_   ( primaryKey   a )) \n     artist_   -   join_   ( artist   chinookDb )   ( \\ a   -   albumArtist   album_   ` references_ `   a ) \n\n     -- Filter out all albums with tracks of only one genre \n     guard_   ( albumIdColumn   ==*. \n              anyOf_   ( orderBy_   asc_   $   fmap   ( \\ ( AlbumId   albumIdRaw ,   _ )   -   albumIdRaw )   $ \n                      filter_   ( \\ ( _ ,   genreCntByAlbum )   -   genreCntByAlbum   .   1 )   $ \n                      aggregate_   ( \\ t   -   let   GenreId   genreId   =   trackGenreId   t \n                                        in   (   group_   ( trackAlbumId   t ) \n                                           ,   as_   @ Int   ( countOver_   distinctInGroup_   genreId )))   $ \n                      all_   ( track   chinookDb ))) \n\n     pure   (   artistName   artist_ ,   albumTitle   album_ ,   genreName   genre_   )  \n\n         \n    \n         \n             WITH   cte0 ( res0 , \n             res1 , \n             res2 , \n             res3 )   AS \n   ( SELECT   cte0_0 . AlbumId   AS   res0 , \n           cte0_0 . GenreId   AS   res1 , \n           COUNT ( * )   AS   res2 , \n           MAX ( COUNT ( * ))   OVER   ( PARTITION   BY   cte0_0 . AlbumId )   AS   res3 \n    FROM   Track   AS   cte0_0 \n    GROUP   BY   cte0_0 . AlbumId , \n             cte0_0 . GenreId )  SELECT   t3 . Name   AS   res0 , \n        t2 . Title   AS   res1 , \n        t1 . Name   AS   res2  FROM   cte0   AS   t0  INNER   JOIN   Genre   AS   t1   ON   ( t0 . res1 )   =   ( t1 . GenreId )  INNER   JOIN   Album   AS   t2   ON   ( t0 . res0 )   =   ( t2 . AlbumId )  INNER   JOIN   Artist   AS   t3   ON   ( t2 . ArtistId )   =   ( t3 . ArtistId )  WHERE   (( t0 . res2 )   =   ( t0 . res3 )) \n   AND   (( t0 . res0 )   =   ANY \n          ( SELECT   sub_t0 . AlbumId   AS   res0 \n           FROM   Track   AS   sub_t0 \n           GROUP   BY   sub_t0 . AlbumId \n           HAVING   ( COUNT ( DISTINCT   sub_t0 . GenreId ))     ( 1 ) \n           ORDER   BY   sub_t0 . AlbumId   ASC ));  \n\n         \n    \n         \n    \n                 \n                      without CTEs,  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do   let   albumGenreCnts   =   aggregate_   ( \\ t   -   (   group_   ( trackAlbumId   t ) \n                                    ,   group_   ( trackGenreId   t ) \n                                    ,   as_   @ Int   countAll_   ))   $ \n                         all_   ( track   chinookDb ) \n\n        albumAndRepresentativeGenres   = \n          withWindow_   ( \\ ( albumId ,   _ ,   _ )   -   frame_   ( partitionBy_   albumId )   noOrder_   noBounds_ ) \n                      ( \\ ( albumId ,   genreId ,   trackCnt )   albumWindow   - \n                          ( albumId ,   genreId ,   trackCnt ,   max_   trackCnt   ` over_ `   albumWindow ))   $ \n            albumGenreCnts \n\n\n    ( albumId @ ( AlbumId   albumIdColumn ),   genreId ,   _ ,   _ )   - \n       filter_   ( \\ ( _ ,   _ ,   trackCnt ,   maxTrackCntInAlbum )   - \n                     just_   trackCnt   ==?.   maxTrackCntInAlbum )   $ \n       albumAndRepresentativeGenres \n    genre_   -   join_   ( genre   chinookDb )   ( \\ g   -   genreId   ==?.   just_   ( primaryKey   g )) \n    album_   -   join_   ( album   chinookDb )   ( \\ a   -   albumId   ==?.   just_   ( primaryKey   a )) \n    artist_   -   join_   ( artist   chinookDb )   ( \\ a   -   albumArtist   album_   ` references_ `   a ) \n\n    -- Filter out all albums with tracks of only one genre \n    guard_   ( albumIdColumn   ==*. \n             anyOf_   ( orderBy_   asc_   $   fmap   ( \\ ( AlbumId   albumIdRaw ,   _ )   -   albumIdRaw )   $ \n                     filter_   ( \\ ( _ ,   genreCntByAlbum )   -   genreCntByAlbum   .   1 )   $ \n                     aggregate_   ( \\ t   -   let   GenreId   genreId   =   trackGenreId   t \n                                       in   (   group_   ( trackAlbumId   t ) \n                                          ,   as_   @ Int   ( countOver_   distinctInGroup_   genreId )))   $ \n                     all_   ( track   chinookDb ))) \n\n    pure   (   artistName   artist_ ,   albumTitle   album_ ,   genreName   genre_   )  \n\n         \n    \n         \n             SELECT   t3 . Name   AS   res0 , \n        t2 . Title   AS   res1 , \n        t1 . Name   AS   res2  FROM \n   ( SELECT   t0 . AlbumId   AS   res0 , \n           t0 . GenreId   AS   res1 , \n           COUNT ( * )   AS   res2 , \n           MAX ( COUNT ( * ))   OVER   ( PARTITION   BY   t0 . AlbumId )   AS   res3 \n    FROM   Track   AS   t0 \n    GROUP   BY   t0 . AlbumId , \n             t0 . GenreId )   AS   t0  INNER   JOIN   Genre   AS   t1   ON   ( t0 . res1 )   =   ( t1 . GenreId )  INNER   JOIN   Album   AS   t2   ON   ( t0 . res0 )   =   ( t2 . AlbumId )  INNER   JOIN   Artist   AS   t3   ON   ( t2 . ArtistId )   =   ( t3 . ArtistId )  WHERE   (( t0 . res2 )   =   ( t0 . res3 )) \n   AND   (( t0 . res0 )   =   ANY \n          ( SELECT   sub_t0 . AlbumId   AS   res0 \n           FROM   Track   AS   sub_t0 \n           GROUP   BY   sub_t0 . AlbumId \n           HAVING   ( COUNT ( DISTINCT   sub_t0 . GenreId ))     ( 1 ) \n           ORDER   BY   sub_t0 . AlbumId   ASC ))", 
            "title": "Refining our query"
        }, 
        {
            "location": "/user-guide/queries/common-table-expressions/#reusing-queries-multiple-times", 
            "text": "Suppose we wanted to ask the question, \"which albums have tracks under the same\ngenre?\". One easy way of doing this is to do multiple self-joins.  We can also use a common table expression.  Let's call albums  A  and  B  \"genre-related\" if  A  and  B  contain at least\none track under the same genre. Then, the queries above answer if  A  and  B \nare \"genre-related\". A natural extension of the question above then is \"Which\nalbums are genre-related to the same album?\". For example, suppose  A  has Jazz\nand Rock tracks,  B  has Rock and Country tracks, and  C  has Country and Blues\ntracks. Then,  (A, B)  and  (B, C)  will both be results of the query above, but (A, C)  will not. We can output tuples like  (A, C)  by self-joining on the\nresults of the same CTE.", 
            "title": "Reusing queries multiple times"
        }, 
        {
            "location": "/user-guide/queries/common-table-expressions/#recursive-queries", 
            "text": "Okay, so the next natural extension is to extend this relation by relating any\ntwo albums  A  and  D  where there exist  B  and  C  such that  A  is related to B ,  B  is related to  C , and  C  is related to  D . We can keep extending\nthis query forever, but the queries above require that we specify all lengths\nwe're interested in. Conceptually, we could express in Haskell an infinite query:  However, the query generator will loop when serializing this query, because\ndatabase systems don't operate on laziness they way Haskell does!  To solve this, some RDBMS systems offer \"recursive\" queries  1 . The canonical\nexample of a recursive query is the Fibonacci sequence:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             void   $   runSelectReturningList   $   selectWith   $   do \n   rec   fib   -   selecting   ( pure   ( as_   @ Int   0 ,   as_   @ Int   1 )   ` union_ ` \n                         ( do   ( a ,   b )   -   reuse   fib \n                             guard_   ( b   .   1000 ) \n                             pure   ( b ,   a   +   b ))) \n   pure   ( reuse   fib )  \n\n         \n    \n         \n             WITH   RECURSIVE   cte0 ( res0 , \n                       res1 )   AS   ( \n                                     ( SELECT   0   AS   res0 , \n                                             1   AS   res1 ) \n                                   UNION \n                                     ( SELECT   cte0_0 . res1   AS   res0 , \n                                             ( cte0_0 . res0 )   +   ( cte0_0 . res1 )   AS   res1 \n                                      FROM   cte0   AS   cte0_0 \n                                      WHERE   ( cte0_0 . res1 )     ( 1000 )))  SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1  FROM   cte0   AS   t0 ;  \n\n         \n    \n         \n    \n                 \n                          \"Recursive\" here is in quotes, because this is not true, general recursion,\n   but rather iteration. Still the term \"recursive\" has stuck around, so Beam\n   adopts the convention.", 
            "title": "Recursive queries"
        }, 
        {
            "location": "/user-guide/extensibility/", 
            "text": "The \nbeam-core\n library and respective backends strive to expose the full power\nof each underlying database. If a particular feature is missing, please feel\nfree to file a bug report on the GitHub issue tracker.\n\n\nHowever, in the meantime, beam offers a few options to inject raw SQL into your\nqueries. Of course, beam cannot predict types of expressions and queries that\nwere not created with its combinators, so \ncaveat emptor\n.\n\n\nCustom expressions\n\n\nIf you'd like to write an expression that beam currently does not support, you\ncan use the \ncustomExpr_\n function. Your backend's syntax must implement the\n\nIsSqlCustomExpressionSyntax\n type class. \ncustomExpr_\n takes a function of\narity \nn\n and \nn\n arguments, which must all be \nQGenExpr\ns with the same thread\nparameter. The expressions may be from different contexts (i.e., you can pass an\naggregate and scalar into the same \ncustomExpr_\n).\n\n\nThe function supplied must return a string-like expression that it can build\nusing provided \nIsString\n and \nMonoid\n instances. The type of the expression is\nopaque to the user. The function's arguments will have the same type as the\nreturn type. Thus, they can be embedded into the returned expression using\n\nmappend\n. The arguments will be properly parenthesized and can be inserted\nwhole into the final expression. You will likely need to explicitly supply a\nresult type using the \nas_\n function.\n\n\nFor example, below, we use \ncustomExpr_\n to access the \nregr_intercept\n and\n\nregr_slope\n functions in postgres.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \nas_\n \n@\nDouble\n \n@\nQAggregateContext\n \n$\n \ncustomExpr_\n \n(\n\\\nbytes\n \nms\n \n-\n \nregr_intercept(\n \n \nbytes\n \n \n, \n \n \nms\n \n \n)\n)\n \n(\ntrackBytes\n \nt\n)\n \n(\ntrackMilliseconds\n \nt\n)\n\n                  \n,\n \nas_\n \n@\nDouble\n \n@\nQAggregateContext\n \n$\n \ncustomExpr_\n \n(\n\\\nbytes\n \nms\n \n-\n \nregr_slope(\n \n \nbytes\n \n \n, \n \n \nms\n \n \n)\n)\n \n(\ntrackBytes\n \nt\n)\n \n(\ntrackMilliseconds\n \nt\n)\n \n))\n \n$\n\n\nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nregr_intercept\n((\nt0\n.\nBytes\n),\n \n(\nt0\n.\nMilliseconds\n))\n \nAS\n \nres0\n,\n\n       \nregr_slope\n((\nt0\n.\nBytes\n),\n \n(\nt0\n.\nMilliseconds\n))\n \nAS\n \nres1\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nCustom queries (i.e., embedding arbitrary expressions into \nQ\n) is currently\nbeing planned, but not implemented.", 
            "title": "Custom queries"
        }, 
        {
            "location": "/user-guide/extensibility/#custom-expressions", 
            "text": "If you'd like to write an expression that beam currently does not support, you\ncan use the  customExpr_  function. Your backend's syntax must implement the IsSqlCustomExpressionSyntax  type class.  customExpr_  takes a function of\narity  n  and  n  arguments, which must all be  QGenExpr s with the same thread\nparameter. The expressions may be from different contexts (i.e., you can pass an\naggregate and scalar into the same  customExpr_ ).  The function supplied must return a string-like expression that it can build\nusing provided  IsString  and  Monoid  instances. The type of the expression is\nopaque to the user. The function's arguments will have the same type as the\nreturn type. Thus, they can be embedded into the returned expression using mappend . The arguments will be properly parenthesized and can be inserted\nwhole into the final expression. You will likely need to explicitly supply a\nresult type using the  as_  function.  For example, below, we use  customExpr_  to access the  regr_intercept  and regr_slope  functions in postgres.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ t   -   (   as_   @ Double   @ QAggregateContext   $   customExpr_   ( \\ bytes   ms   -   regr_intercept(     bytes     ,      ms     ) )   ( trackBytes   t )   ( trackMilliseconds   t ) \n                   ,   as_   @ Double   @ QAggregateContext   $   customExpr_   ( \\ bytes   ms   -   regr_slope(     bytes     ,      ms     ) )   ( trackBytes   t )   ( trackMilliseconds   t )   ))   $  all_   ( track   chinookDb )  \n\n         \n    \n         \n             SELECT   regr_intercept (( t0 . Bytes ),   ( t0 . Milliseconds ))   AS   res0 , \n        regr_slope (( t0 . Bytes ),   ( t0 . Milliseconds ))   AS   res1  FROM   Track   AS   t0  \n\n         \n    \n         \n    \n                 \n                       Note  Custom queries (i.e., embedding arbitrary expressions into  Q ) is currently\nbeing planned, but not implemented.", 
            "title": "Custom expressions"
        }, 
        {
            "location": "/user-guide/manipulation/insert/", 
            "text": "SQL \nINSERT\n expressions allow you to insert rows in the database.\n\n\nThere is a lot of variety in how you can provide new data, and Beam supports all\nstandard ways.\n\n\nThe \ninsert\n function from \nDatabase.Beam.Query\n can be used to insert rows into\na particular table. \ninsert\n takes a table and a source of values, represented\nby \nSqlInsertValues\n, and returns a \nSqlInsert\n object that can be run in a\n\nMonadBeam\n with \nrunInsert\n.\n\n\nThe \nSqlInsertValues\n type takes two type parameters. The first is the\nunderlying database syntax, and the second is the shape of the data it carries,\nspecified as a beam table type. For example, a source of values in Postgres that\ncan be inserted in the Chinook customers table would have the type\n\nSqlInsertValues PgInsertValuesSyntax CustomerT\n. This abstracts over where\nthose values actually are. The values may be explicit haskell values,\nexpressions returning customers, a query returning customers, or something\nelse. Either way, they can all be used in the same way with the \ninsert\n\nfunction.\n\n\nInserting explicit new values\n\n\nIf you have a record of explicit Haskell values, use the \ninsertValues\n\nfunction. For example, to insert a new playlist into our chinook database\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunInsert\n \n$\n \ninsert\n \n(\nplaylist\n \nchinookDb\n)\n \n$\n\n  \ninsertValues\n \n[\n \nPlaylist\n \n700\n \n(\nJust\n \nMy New Playlist\n)\n\n               \n,\n \nPlaylist\n \n701\n \n(\nJust\n \nAnother Playlist\n)\n\n               \n,\n \nPlaylist\n \n702\n \n(\nJust\n \nLook... more playlists\n)\n \n]\n\n\n\ninsertedPlaylists\n \n-\n\n  \nrunSelectReturningList\n \n$\n\n  \nselect\n \n$\n \nfilter_\n \n(\n\\\np\n \n-\n \nplaylistId\n \np\n \n=.\n \n700\n)\n \n$\n\n  \nall_\n \n(\nplaylist\n \nchinookDb\n)\n\n\n\nputStrLn\n \nInserted playlists:\n\n\nforM_\n \ninsertedPlaylists\n \n$\n \n\\\np\n \n-\n\n  \nputStrLn\n \n(\nshow\n \np\n)\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nPlaylist\n(\nPlaylistId\n,\n\n                       \nName\n)\n\n\nVALUES\n \n(\n?\n,\n\n        \n?\n),\n \n(\n?\n,\n\n             \n?\n),\n \n(\n?\n,\n\n                  \n?\n);\n\n\n\n-- With values: [SQLInteger 700,SQLText \nMy New Playlist\n,SQLInteger 701,SQLText \nAnother Playlist\n,SQLInteger 702,SQLText \nLook... more playlists\n];\n\n\n\nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nPlaylistId\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLInteger 700];\n\n\n-- Output: Inserted playlists:\n\n\n-- Output: Playlist {playlistId = 700, playlistName = Just \nMy New Playlist\n}\n\n\n-- Output: Playlist {playlistId = 701, playlistName = Just \nAnother Playlist\n}\n\n\n-- Output: Playlist {playlistId = 702, playlistName = Just \nLook... more playlists\n}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nPlaylist\n(\nPlaylistId\n,\n\n                       \nName\n)\n\n\nVALUES\n \n(\n700\n,\n\n        \nMy New Playlist\n),\n \n(\n701\n,\n\n                             \nAnother Playlist\n),\n \n(\n702\n,\n\n                                                   \nLook... more playlists\n);\n\n\n\n\nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nPlaylistId\n)\n \n=\n \n(\n700\n);\n\n\n\n-- Output: Inserted playlists:\n\n\n-- Output: Playlist {playlistId = 700, playlistName = Just \nMy New Playlist\n}\n\n\n-- Output: Playlist {playlistId = 701, playlistName = Just \nAnother Playlist\n}\n\n\n-- Output: Playlist {playlistId = 702, playlistName = Just \nLook... more playlists\n}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \n`\nPlaylist\n`\n(\n`\nPlaylistId\n`\n,\n \n`\nName\n`\n)\n\n\nVALUES\n \n(\n700\n,\n\n        \nMy New Playlist\n),\n \n(\n701\n,\n\n                             \nAnother Playlist\n),\n \n(\n702\n,\n\n                                                   \nLook... more playlists\n);\n\n\n\n\nSELECT\n \n`\nt0\n`\n.\n`\nPlaylistId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n\n\nFROM\n \n`\nPlaylist\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nPlaylistId\n`\n)\n \n=\n \n(\n700\n);\n\n\n\n-- Output: Inserted playlists:\n\n\n-- Output: Playlist {playlistId = 700, playlistName = Just \nMy New Playlist\n}\n\n\n-- Output: Playlist {playlistId = 701, playlistName = Just \nAnother Playlist\n}\n\n\n-- Output: Playlist {playlistId = 702, playlistName = Just \nLook... more playlists\n}\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nInserting calculated values\n\n\nInserting explicit values is all well and good, but sometimes we want to defer\nsome processing to the database. For example, perhaps we want to create a new\ninvoice and use the current time as the invoice date. We could grab the current\ntime using \ngetCurrentTime\n and then use this to construct an explicit Haskell\nvalue, but this may cause synchronization issues for our application. To do\nthis, beam allows us to specify arbitrary expressions as a source of values\nusing the \ninsertExpressions\n function.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunInsert\n \n$\n \ninsert\n \n(\ninvoice\n \nchinookDb\n)\n \n$\n\n  \ninsertExpressions\n \n[\n \nInvoice\n \n(\nval_\n \n800\n)\n \n(\nCustomerId\n \n(\nval_\n \n1\n))\n \ncurrentTimestamp_\n\n                              \n(\nval_\n \n(\nAddress\n \n(\nJust\n \n123 My Street\n)\n \n(\nJust\n \nBuenos Noches\n)\n \n(\nJust\n \nRio\n)\n \n(\nJust\n \nMozambique\n)\n \n(\nJust\n \nABCDEF\n)))\n\n                              \n(\nval_\n \n1000\n)\n \n]\n\n\n\nJust\n \nnewInvoice\n \n-\n\n  \nrunSelectReturningOne\n \n$\n\n  \nlookup_\n \n(\ninvoice\n \nchinookDb\n)\n \n(\nInvoiceId\n \n800\n)\n\n\n\nputStrLn\n \n(\nInserted invoice: \n \n++\n \nshow\n \nnewInvoice\n)\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nInvoice\n(\nInvoiceId\n,\n\n                      \nCustomerId\n,\n\n                      \nInvoiceDate\n,\n\n                      \nBillingAddress\n,\n\n                      \nBillingCity\n,\n\n                      \nBillingState\n,\n\n                      \nBillingCountry\n,\n\n                      \nBillingPostalCode\n,\n\n                      \nTotal\n)\n\n\nVALUES\n \n(\n?\n,\n\n        \n?\n,\n\n        \nCURRENT_TIMESTAMP\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n);\n\n\n\n-- With values: [SQLInteger 800,SQLInteger 1,SQLText \n123 My Street\n,SQLText \nBuenos Noches\n,SQLText \nRio\n,SQLText \nMozambique\n,SQLText \nABCDEF\n,SQLText \n1000.0\n];\n\n\n\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nInvoiceId\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLInteger 800];\n\n\n-- Output: Inserted invoice: Invoice {invoiceId = SqlSerial {unSerial = 800}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 17:22:39, invoiceBillingAddress = Address {address = Just \n123 My Street\n, addressCity = Just \nBuenos Noches\n, addressState = Just \nRio\n, addressCountry = Just \nMozambique\n, addressPostalCode = Just \nABCDEF\n}, invoiceTotal = 1000.0}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nInvoice\n(\nInvoiceId\n,\n\n                      \nCustomerId\n,\n\n                      \nInvoiceDate\n,\n\n                      \nBillingAddress\n,\n\n                      \nBillingCity\n,\n\n                      \nBillingState\n,\n\n                      \nBillingCountry\n,\n\n                      \nBillingPostalCode\n,\n\n                      \nTotal\n)\n\n\nVALUES\n \n(\n800\n,\n\n        \n1\n,\n\n        \nCURRENT_TIMESTAMP\n,\n\n        \n123 My Street\n,\n\n        \nBuenos Noches\n,\n\n        \nRio\n,\n\n        \nMozambique\n,\n\n        \nABCDEF\n,\n\n        \n1000.0\n);\n\n\n\n\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nInvoiceId\n)\n \n=\n \n(\n800\n);\n\n\n\n-- Output: Inserted invoice: Invoice {invoiceId = SqlSerial {unSerial = 800}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 10:22:42.74249, invoiceBillingAddress = Address {address = Just \n123 My Street\n, addressCity = Just \nBuenos Noches\n, addressState = Just \nRio\n, addressCountry = Just \nMozambique\n, addressPostalCode = Just \nABCDEF\n}, invoiceTotal = 1000.0}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \n`\nInvoice\n`\n(\n`\nInvoiceId\n`\n,\n \n`\nCustomerId\n`\n,\n \n`\nInvoiceDate\n`\n,\n \n`\nBillingAddress\n`\n,\n \n`\nBillingCity\n`\n,\n \n`\nBillingState\n`\n,\n \n`\nBillingCountry\n`\n,\n \n`\nBillingPostalCode\n`\n,\n \n`\nTotal\n`\n)\n\n\nVALUES\n \n(\n800\n,\n\n        \n1\n,\n\n        \nCURRENT_TIMESTAMP\n,\n\n        \n123 My Street\n,\n\n        \nBuenos Noches\n,\n\n        \nRio\n,\n\n        \nMozambique\n,\n\n        \nABCDEF\n,\n\n        \n1000\n.\n0\n);\n\n\n\n\nSELECT\n \n`\nt0\n`\n.\n`\nInvoiceId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nInvoiceDate\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingAddress\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCity\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingState\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingCountry\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nBillingPostalCode\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nTotal\n`\n \nAS\n \n`\nres8\n`\n\n\nFROM\n \n`\nInvoice\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nInvoiceId\n`\n)\n \n=\n \n(\n800\n);\n\n\n\n-- Output: Inserted invoice: Invoice {invoiceId = SqlSerial {unSerial = 800}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 10:22:47, invoiceBillingAddress = Address {address = Just \n123 My Street\n, addressCity = Just \nBuenos Noches\n, addressState = Just \nRio\n, addressCountry = Just \nMozambique\n, addressPostalCode = Just \nABCDEF\n}, invoiceTotal = 1000.0}\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\ninsertExpressions\n is strictly more general than \ninsertValues\n. We can turn\nany \ninsertValues\n to an \ninsertExpressions\n by running every table value\nthrough the \nval_\n function to convert a Haskell literal to an expression.\n\n\nFor example, we can write the playlist example above as\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunInsert\n \n$\n \ninsert\n \n(\nplaylist\n \nchinookDb\n)\n \n$\n\n  \ninsertExpressions\n \n[\n \nval_\n \n$\n \nPlaylist\n \n700\n \n(\nJust\n \nMy New Playlist\n)\n\n                    \n,\n \nval_\n \n$\n \nPlaylist\n \n701\n \n(\nJust\n \nAnother Playlist\n)\n\n                    \n,\n \nval_\n \n$\n \nPlaylist\n \n702\n \n(\nJust\n \nLook... more playlists\n)\n \n]\n\n\n\ninsertedPlaylists\n \n-\n\n  \nrunSelectReturningList\n \n$\n\n  \nselect\n \n$\n \nfilter_\n \n(\n\\\np\n \n-\n \nplaylistId\n \np\n \n=.\n \n700\n)\n \n$\n\n  \nall_\n \n(\nplaylist\n \nchinookDb\n)\n\n\n\nputStrLn\n \nInserted playlists:\n\n\nforM_\n \ninsertedPlaylists\n \n$\n \n\\\np\n \n-\n\n  \nputStrLn\n \n(\nshow\n \np\n)\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nPlaylist\n(\nPlaylistId\n,\n\n                       \nName\n)\n\n\nVALUES\n \n(\n?\n,\n\n        \n?\n),\n \n(\n?\n,\n\n             \n?\n),\n \n(\n?\n,\n\n                  \n?\n);\n\n\n\n-- With values: [SQLInteger 700,SQLText \nMy New Playlist\n,SQLInteger 701,SQLText \nAnother Playlist\n,SQLInteger 702,SQLText \nLook... more playlists\n];\n\n\n\nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nPlaylistId\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLInteger 700];\n\n\n-- Output: Inserted playlists:\n\n\n-- Output: Playlist {playlistId = 700, playlistName = Just \nMy New Playlist\n}\n\n\n-- Output: Playlist {playlistId = 701, playlistName = Just \nAnother Playlist\n}\n\n\n-- Output: Playlist {playlistId = 702, playlistName = Just \nLook... more playlists\n}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nPlaylist\n(\nPlaylistId\n,\n\n                       \nName\n)\n\n\nVALUES\n \n(\n700\n,\n\n        \nMy New Playlist\n),\n \n(\n701\n,\n\n                             \nAnother Playlist\n),\n \n(\n702\n,\n\n                                                   \nLook... more playlists\n);\n\n\n\n\nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nPlaylistId\n)\n \n=\n \n(\n700\n);\n\n\n\n-- Output: Inserted playlists:\n\n\n-- Output: Playlist {playlistId = 700, playlistName = Just \nMy New Playlist\n}\n\n\n-- Output: Playlist {playlistId = 701, playlistName = Just \nAnother Playlist\n}\n\n\n-- Output: Playlist {playlistId = 702, playlistName = Just \nLook... more playlists\n}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \n`\nPlaylist\n`\n(\n`\nPlaylistId\n`\n,\n \n`\nName\n`\n)\n\n\nVALUES\n \n(\n700\n,\n\n        \nMy New Playlist\n),\n \n(\n701\n,\n\n                             \nAnother Playlist\n),\n \n(\n702\n,\n\n                                                   \nLook... more playlists\n);\n\n\n\n\nSELECT\n \n`\nt0\n`\n.\n`\nPlaylistId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nName\n`\n \nAS\n \n`\nres1\n`\n\n\nFROM\n \n`\nPlaylist\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nPlaylistId\n`\n)\n \n=\n \n(\n700\n);\n\n\n\n-- Output: Inserted playlists:\n\n\n-- Output: Playlist {playlistId = 700, playlistName = Just \nMy New Playlist\n}\n\n\n-- Output: Playlist {playlistId = 701, playlistName = Just \nAnother Playlist\n}\n\n\n-- Output: Playlist {playlistId = 702, playlistName = Just \nLook... more playlists\n}\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOne common use of \ninsertExpressions_\n is when adding new rows to tables where\none field needs to be set to the default value. For example, auto-incrementing\nkeys or random UUIDs are a common way to assign primary keys to rows. You can\nuse \ninsertExpressions_\n using the \ndefault_\n expression for each column that\nyou want to use the default value for.\n\n\nFor example, the query below adds a new invoice asking the database to assign a\nnew id.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunInsert\n \n$\n \ninsert\n \n(\ninvoice\n \nchinookDb\n)\n \n$\n\n  \ninsertExpressions\n \n[\n \nInvoice\n \ndefault_\n \n-- Ask the database to give us a default id\n\n                              \n(\nval_\n \n(\nCustomerId\n \n1\n))\n \ncurrentTimestamp_\n\n                              \n(\nval_\n \n(\nAddress\n \n(\nJust\n \n123 My Street\n)\n \n(\nJust\n \nBuenos Noches\n)\n \n(\nJust\n \nRio\n)\n \n(\nJust\n \nMozambique\n)\n \n(\nJust\n \nABCDEF\n)))\n\n                              \n(\nval_\n \n1000\n)\n \n]\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nInvoice\n(\nInvoiceId\n,\n\n                      \nCustomerId\n,\n\n                      \nInvoiceDate\n,\n\n                      \nBillingAddress\n,\n\n                      \nBillingCity\n,\n\n                      \nBillingState\n,\n\n                      \nBillingCountry\n,\n\n                      \nBillingPostalCode\n,\n\n                      \nTotal\n)\n\n\nVALUES\n \n(\nDEFAULT\n,\n\n        \n1\n,\n\n        \nCURRENT_TIMESTAMP\n,\n\n        \n123 My Street\n,\n\n        \nBuenos Noches\n,\n\n        \nRio\n,\n\n        \nMozambique\n,\n\n        \nABCDEF\n,\n\n        \n1000.0\n);\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \n`\nInvoice\n`\n(\n`\nInvoiceId\n`\n,\n \n`\nCustomerId\n`\n,\n \n`\nInvoiceDate\n`\n,\n \n`\nBillingAddress\n`\n,\n \n`\nBillingCity\n`\n,\n \n`\nBillingState\n`\n,\n \n`\nBillingCountry\n`\n,\n \n`\nBillingPostalCode\n`\n,\n \n`\nTotal\n`\n)\n\n\nVALUES\n \n(\nDEFAULT\n,\n\n        \n1\n,\n\n        \nCURRENT_TIMESTAMP\n,\n\n        \n123 My Street\n,\n\n        \nBuenos Noches\n,\n\n        \nRio\n,\n\n        \nMozambique\n,\n\n        \nABCDEF\n,\n\n        \n1000\n.\n0\n);\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nWarning\n\n\nSQLite is a great little backend, but it doesn't support some standard SQL\nfeatures, like the \nDEFAULT\n keyword in inserts. You can retrieve the same\nfunctionality by only inserting into a subset of columns. See the section on\n\nthat\n below.\n\n\n\n\nRetrieving the rows inserted\n\n\nHowever, now we have no way of knowing \nwhat\n value the database\nassigned. Unfortunately, there is no database-agnostic solution to this\nproblem. However, it's a common enough use case that beam provides a\nbackend-agnostic way for some backends. Backends that provide this functionality\nprovide an instance of \nMonadBeamInsertReturning\n. In order to use this class,\nyou'll need to explicitly import\n\nDatabase.Beam.Backend.SQL.BeamExtensions\n. Below, we've imported this module\nqualified.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n[\nnewInvoice\n]\n \n-\n\n  \nBeamExtensions\n.\nrunInsertReturningList\n \n$\n \ninsert\n \n(\ninvoice\n \nchinookDb\n)\n \n$\n\n  \ninsertExpressions\n \n[\n \nInvoice\n \ndefault_\n \n-- Ask the database to give us a default id\n\n                              \n(\nval_\n \n(\nCustomerId\n \n1\n))\n \ncurrentTimestamp_\n\n                              \n(\nval_\n \n(\nAddress\n \n(\nJust\n \n123 My Street\n)\n \n(\nJust\n \nBuenos Noches\n)\n \n(\nJust\n \nRio\n)\n \n(\nJust\n \nMozambique\n)\n \n(\nJust\n \nABCDEF\n)))\n\n                              \n(\nval_\n \n1000\n)\n \n]\n\n\n\nputStrLn\n \n(\nWe inserted a new invoice, and the result was \n \n++\n \nshow\n \nnewInvoice\n)\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nInvoice\n(\nCustomerId\n,\n\n                      \nInvoiceDate\n,\n\n                      \nBillingAddress\n,\n\n                      \nBillingCity\n,\n\n                      \nBillingState\n,\n\n                      \nBillingCountry\n,\n\n                      \nBillingPostalCode\n,\n\n                      \nTotal\n)\n\n\nVALUES\n \n(\n?\n,\n\n        \nCURRENT_TIMESTAMP\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n);\n\n\n\n-- With values: [SQLInteger 1,SQLText \n123 My Street\n,SQLText \nBuenos Noches\n,SQLText \nRio\n,SQLText \nMozambique\n,SQLText \nABCDEF\n,SQLText \n1000.0\n];\n\n\n-- Output: We inserted a new invoice, and the result was Invoice {invoiceId = SqlSerial {unSerial = 413}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 17:23:11, invoiceBillingAddress = Address {address = Just \n123 My Street\n, addressCity = Just \nBuenos Noches\n, addressState = Just \nRio\n, addressCountry = Just \nMozambique\n, addressPostalCode = Just \nABCDEF\n}, invoiceTotal = 1000.0}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nInvoice\n(\nInvoiceId\n,\n\n                      \nCustomerId\n,\n\n                      \nInvoiceDate\n,\n\n                      \nBillingAddress\n,\n\n                      \nBillingCity\n,\n\n                      \nBillingState\n,\n\n                      \nBillingCountry\n,\n\n                      \nBillingPostalCode\n,\n\n                      \nTotal\n)\n\n\nVALUES\n \n(\nDEFAULT\n,\n\n        \n1\n,\n\n        \nCURRENT_TIMESTAMP\n,\n\n        \n123 My Street\n,\n\n        \nBuenos Noches\n,\n\n        \nRio\n,\n\n        \nMozambique\n,\n\n        \nABCDEF\n,\n\n        \n1000.0\n)\n \nRETURNING\n \nInvoiceId\n,\n\n                            \nCustomerId\n,\n\n                            \nInvoiceDate\n,\n\n                            \nBillingAddress\n,\n\n                            \nBillingCity\n,\n\n                            \nBillingState\n,\n\n                            \nBillingCountry\n,\n\n                            \nBillingPostalCode\n,\n\n                            \nTotal\n;\n\n\n\n-- Output: We inserted a new invoice, and the result was Invoice {invoiceId = SqlSerial {unSerial = 814}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 10:23:14.615668, invoiceBillingAddress = Address {address = Just \n123 My Street\n, addressCity = Just \nBuenos Noches\n, addressState = Just \nRio\n, addressCountry = Just \nMozambique\n, addressPostalCode = Just \nABCDEF\n}, invoiceTotal = 1000.0}\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe pattern match on the single \nnewInvoice\n is safe, even though its\npartial. In general, you can expect the same amount of rows returned as\nspecified in your \nSqlInsertValues\n. If you know what this is statically, then\nyou can feel free to pattern match directly. Otherwise (if you used\n\ninsertFrom\n, for example), you'll need to handle the possibility that nothing\nwas inserted.\n\n\n\n\nNote\n\n\nAlthough SQLite has no support for the \nDEFAULT\n clause,\n\nMonadBeamInsertReturning\n in \nbeam-sqlite\n inserts rows one at a time and\nwill detect usage of the \nDEFAULT\n keyword. The beam authors consider this\nokay. While most beam statements are guaranteed to translate directly to the\nunderlying DBMS system, \nrunInsertReturningList\n is explicitly marked as\nemulated functionality.\n\n\n\n\nInserting from the result of a \nSELECT\n statement\n\n\nSometimes you want to use existing data to insert values. For example, perhaps\nwe want to give every customer their own playlist, titled \"\n's playlist\".\n\n\nWe can use the \ninsertFrom\n function to make a \nSqlInsertValues\n corresponding\nto the result of a query. Make sure to return a projection with the same 'shape'\nas your data. If not, you'll get a compile time error.\n\n\nFor example, to create the playlists as above\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunInsert\n \n$\n \ninsert\n \n(\nplaylist\n \nchinookDb\n)\n \n$\n\n  \ninsertFrom\n \n$\n \ndo\n\n    \nc\n \n-\n \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n    \npure\n \n(\nPlaylist\n \n(\ncustomerId\n \nc\n \n+\n \n1000\n)\n \n(\njust_\n \n(\nconcat_\n \n[\n \ncustomerFirstName\n \nc\n,\n \ns Playlist\n \n])))\n\n\n\nplaylists\n \n-\n \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \nlimit_\n \n10\n \n$\n\n             \norderBy_\n \n(\n\\\np\n \n-\n \nasc_\n \n(\nplaylistId\n \np\n))\n \n$\n\n             \nfilter_\n \n(\n\\\np\n \n-\n \nplaylistId\n \np\n \n=.\n \n1000\n)\n \n$\n\n             \nall_\n \n(\nplaylist\n \nchinookDb\n)\n\n\n\nputStrLn\n \nInserted playlists\n\n\nforM_\n \nplaylists\n \n$\n \n\\\nplaylist\n \n-\n\n  \nputStrLn\n \n(\n  - \n \n++\n \nshow\n \nplaylist\n)\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nPlaylist\n(\nPlaylistId\n,\n\n                       \nName\n)\n\n\nSELECT\n \n(\nt0\n.\nCustomerId\n)\n \n+\n \n(\n?\n)\n \nAS\n \nres0\n,\n\n       \n(\nt0\n.\nFirstName\n \n||\n \n(\n?\n))\n \nAS\n \nres1\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n;\n\n\n\n-- With values: [SQLInteger 1000,SQLText \ns Playlist\n];\n\n\n\nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nPlaylistId\n)\n=\n(\n?\n)\n\n\nORDER\n \nBY\n \nt0\n.\nPlaylistId\n \nASC\n\n\nLIMIT\n \n10\n;\n\n\n\n-- With values: [SQLInteger 1000];\n\n\n-- Output: Inserted playlists\n\n\n-- Output:   - Playlist {playlistId = 1001, playlistName = Just \nLu\\237s\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1002, playlistName = Just \nLeonie\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1003, playlistName = Just \nFran\\231ois\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1004, playlistName = Just \nBj\\248rn\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1005, playlistName = Just \nFranti\\353ek\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1006, playlistName = Just \nHelena\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1007, playlistName = Just \nAstrid\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1008, playlistName = Just \nDaan\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1009, playlistName = Just \nKara\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1010, playlistName = Just \nEduardo\ns Playlist\n}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nPlaylist\n(\nPlaylistId\n,\n\n                       \nName\n)\n\n\nSELECT\n \n(\nt0\n.\nCustomerId\n)\n \n+\n \n(\n1000\n)\n \nAS\n \nres0\n,\n\n       \nCONCAT\n(\nt0\n.\nFirstName\n,\n \ns Playlist\n)\n \nAS\n \nres1\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n;\n\n\n\n\nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nPlaylistId\n)\n \n=\n \n(\n1000\n)\n\n\nORDER\n \nBY\n \nt0\n.\nPlaylistId\n \nASC\n\n\nLIMIT\n \n10\n;\n\n\n\n-- Output: Inserted playlists\n\n\n-- Output:   - Playlist {playlistId = 1001, playlistName = Just \nLu\\237s\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1002, playlistName = Just \nLeonie\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1003, playlistName = Just \nFran\\231ois\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1004, playlistName = Just \nBj\\345rn\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1005, playlistName = Just \nFranti\\154ek\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1006, playlistName = Just \nHelena\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1007, playlistName = Just \nAstrid\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1008, playlistName = Just \nDaan\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1009, playlistName = Just \nKara\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1010, playlistName = Just \nEduardo\ns Playlist\n}\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \n`\nPlaylist\n`\n(\n`\nPlaylistId\n`\n,\n \n`\nName\n`\n)\n\n\nSELECT\n \n(\n`\nt0\n`\n.\n`\nCustomerId\n`\n)\n \n+\n \n(\n1000\n)\n \nAS\n \n`\nres0\n`\n,\n\n       \nCONCAT\n(\n`\nt0\n`\n.\n`\nFirstName\n`\n,\n \n\\\ns\n \nPlaylist\n) AS `res1`\n\n\nFROM `Customer` AS `t0`;\n\n\n\n\nSELECT `t0`.`PlaylistId` AS `res0`,\n\n\n       `t0`.`Name` AS `res1`\n\n\nFROM `Playlist` AS `t0`\n\n\nWHERE (`t0`.`PlaylistId`) \n= (1000)\n\n\nORDER BY `t0`.`PlaylistId` ASC\n\n\nLIMIT 10;\n\n\n\n-- Output: Inserted playlists\n\n\n-- Output:   - Playlist {playlistId = 1001, playlistName = Just \nLu\\237s\ns\n \nPlaylist\n}\n\n\n-- Output:   - Playlist {playlistId = 1002, playlistName = Just \nLeonie\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1003, playlistName = Just \nFran\\231ois\ns\n \nPlaylist\n}\n\n\n-- Output:   - Playlist {playlistId = 1004, playlistName = Just \nBj\n\\\n248\nrn\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1005, playlistName = Just \nFranti\\353ek\ns\n \nPlaylist\n}\n\n\n-- Output:   - Playlist {playlistId = 1006, playlistName = Just \nHelena\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1007, playlistName = Just \nAstrid\ns\n \nPlaylist\n}\n\n\n-- Output:   - Playlist {playlistId = 1008, playlistName = Just \nDaan\ns Playlist\n}\n\n\n-- Output:   - Playlist {playlistId = 1009, playlistName = Just \nKara\ns\n \nPlaylist\n}\n\n\n-- Output:   - Playlist {playlistId = 1010, playlistName = Just \nEduardo\ns\n \nPlaylist\n}\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nChoosing a subset of columns\n\n\nAbove, we used the \ndefault_\n clause to set a column to a default\nvalue. Unfortunately, not all backends support \ndefault_\n (SQLite being a\nnotable exception). Moreover, some \nINSERT\n forms simply can't use \ndefault_\n,\nsuch as \ninsertFrom_\n (you can't return \ndefault_\n from a query). The standard\nSQL tool used in these cases is limiting the inserted data to specific\ncolumns. For example, suppose we want to insert new invoices for every customer\nwith today's date. We can use the \ninsertOnly\n function to project which field's\nare being inserted.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunInsert\n \n$\n\n  \ninsertOnly\n \n(\ninvoice\n \nchinookDb\n)\n\n             \n(\n\\\ni\n \n-\n \n(\n \ninvoiceCustomer\n \ni\n,\n \ninvoiceDate\n \ni\n,\n \ninvoiceBillingAddress\n \ni\n,\n \ninvoiceTotal\n \ni\n \n)\n \n)\n \n$\n\n  \ninsertFrom\n \n$\n \ndo\n\n    \nc\n \n-\n \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n    \n-- We\nll just charge each customer $10 to be mean!\n\n    \npure\n \n(\nprimaryKey\n \nc\n,\n \ncurrentTimestamp_\n,\n \ncustomerAddress\n \nc\n,\n \nas_\n \n@\nScientific\n \n$\n \nval_\n \n10\n)\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nInvoice\n(\nCustomerId\n,\n\n                      \nInvoiceDate\n,\n\n                      \nBillingAddress\n,\n\n                      \nBillingCity\n,\n\n                      \nBillingState\n,\n\n                      \nBillingCountry\n,\n\n                      \nBillingPostalCode\n,\n\n                      \nTotal\n)\n\n\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nCURRENT_TIMESTAMP\n \nAS\n \nres1\n,\n\n                            \nt0\n.\nAddress\n \nAS\n \nres2\n,\n\n                            \nt0\n.\nCity\n \nAS\n \nres3\n,\n\n                            \nt0\n.\nState\n \nAS\n \nres4\n,\n\n                            \nt0\n.\nCountry\n \nAS\n \nres5\n,\n\n                            \nt0\n.\nPostalCode\n \nAS\n \nres6\n,\n\n                            \n?\n \nAS\n \nres7\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n;\n\n\n\n-- With values: [SQLText \n10.0\n];\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nInvoice\n(\nCustomerId\n,\n\n                      \nInvoiceDate\n,\n\n                      \nBillingAddress\n,\n\n                      \nBillingCity\n,\n\n                      \nBillingState\n,\n\n                      \nBillingCountry\n,\n\n                      \nBillingPostalCode\n,\n\n                      \nTotal\n)\n\n\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nCURRENT_TIMESTAMP\n \nAS\n \nres1\n,\n\n                            \nt0\n.\nAddress\n \nAS\n \nres2\n,\n\n                            \nt0\n.\nCity\n \nAS\n \nres3\n,\n\n                            \nt0\n.\nState\n \nAS\n \nres4\n,\n\n                            \nt0\n.\nCountry\n \nAS\n \nres5\n,\n\n                            \nt0\n.\nPostalCode\n \nAS\n \nres6\n,\n\n                            \n10.0\n \nAS\n \nres7\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n;\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \n`\nInvoice\n`\n(\n`\nCustomerId\n`\n,\n \n`\nInvoiceDate\n`\n,\n \n`\nBillingAddress\n`\n,\n \n`\nBillingCity\n`\n,\n \n`\nBillingState\n`\n,\n \n`\nBillingCountry\n`\n,\n \n`\nBillingPostalCode\n`\n,\n \n`\nTotal\n`\n)\n\n\nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \nCURRENT_TIMESTAMP\n \nAS\n \n`\nres1\n`\n,\n\n                            \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres2\n`\n,\n\n                            \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres3\n`\n,\n\n                            \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres4\n`\n,\n\n                            \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres5\n`\n,\n\n                            \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres6\n`\n,\n\n                            \n10\n.\n0\n \nAS\n \n`\nres7\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n;\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nInserting nothing\n\n\nOftentimes, the values to be inserted are generated automatically by some\nHaskell function, and you just insert the resulting list. Sometimes, these lists\nmay be empty. If you blindly translated this into SQL, you'd end up with\n\nINSERT\ns with empty \nVALUE\n clauses, which are illegal. Beam actually handles\nthis gracefully. If a \nSqlInsertValues\n has no rows to insert, the \nSqlInsert\n\nreturned by \ninsert\n will know that it is empty. Running this \nSqlInsert\n\nresults in nothing being sent to the database, which you can verify below.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nsuperComplicatedAction\n \n=\n \npure\n \n[]\n \n-- Hopefully, you\nre more creative!\n\n\n\nvaluesToInsert\n \n-\n \nsuperComplicatedAction\n\n\n\nputStrLn\n \nThe following runInsert will send no commands to the database\n\n\nrunInsert\n \n$\n \ninsert\n \n(\nplaylist\n \nchinookDb\n)\n \n$\n\n  \ninsertValues\n \nvaluesToInsert\n\n\nputStrLn\n \nSee! I told you!\n\n\n\n\n        \n\n    \n        \n\n            \n-- Output: The following runInsert will send no commands to the database\n\n\n-- Output: See! I told you!\n\n\n\n\n        \n\n    \n        \n\n            \n-- Output: The following runInsert will send no commands to the database\n\n\n-- Output: See! I told you!\n\n\n\n\n        \n\n    \n        \n\n            \n-- Output: The following runInsert will send no commands to the database\n\n\n-- Output: See! I told you!", 
            "title": "INSERT"
        }, 
        {
            "location": "/user-guide/manipulation/insert/#inserting-explicit-new-values", 
            "text": "If you have a record of explicit Haskell values, use the  insertValues \nfunction. For example, to insert a new playlist into our chinook database  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             runInsert   $   insert   ( playlist   chinookDb )   $ \n   insertValues   [   Playlist   700   ( Just   My New Playlist ) \n                ,   Playlist   701   ( Just   Another Playlist ) \n                ,   Playlist   702   ( Just   Look... more playlists )   ]  insertedPlaylists   - \n   runSelectReturningList   $ \n   select   $   filter_   ( \\ p   -   playlistId   p   =.   700 )   $ \n   all_   ( playlist   chinookDb )  putStrLn   Inserted playlists:  forM_   insertedPlaylists   $   \\ p   - \n   putStrLn   ( show   p )  \n\n         \n    \n         \n             INSERT   INTO   Playlist ( PlaylistId , \n                        Name )  VALUES   ( ? , \n         ? ),   ( ? , \n              ? ),   ( ? , \n                   ? );  -- With values: [SQLInteger 700,SQLText  My New Playlist ,SQLInteger 701,SQLText  Another Playlist ,SQLInteger 702,SQLText  Look... more playlists ];  SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1  FROM   Playlist   AS   t0  WHERE   ( t0 . PlaylistId ) = ( ? );  -- With values: [SQLInteger 700];  -- Output: Inserted playlists:  -- Output: Playlist {playlistId = 700, playlistName = Just  My New Playlist }  -- Output: Playlist {playlistId = 701, playlistName = Just  Another Playlist }  -- Output: Playlist {playlistId = 702, playlistName = Just  Look... more playlists }  \n\n         \n    \n         \n             INSERT   INTO   Playlist ( PlaylistId , \n                        Name )  VALUES   ( 700 , \n         My New Playlist ),   ( 701 , \n                              Another Playlist ),   ( 702 , \n                                                    Look... more playlists );  SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1  FROM   Playlist   AS   t0  WHERE   ( t0 . PlaylistId )   =   ( 700 );  -- Output: Inserted playlists:  -- Output: Playlist {playlistId = 700, playlistName = Just  My New Playlist }  -- Output: Playlist {playlistId = 701, playlistName = Just  Another Playlist }  -- Output: Playlist {playlistId = 702, playlistName = Just  Look... more playlists }  \n\n         \n    \n         \n             INSERT   INTO   ` Playlist ` ( ` PlaylistId ` ,   ` Name ` )  VALUES   ( 700 , \n         My New Playlist ),   ( 701 , \n                              Another Playlist ),   ( 702 , \n                                                    Look... more playlists );  SELECT   ` t0 ` . ` PlaylistId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 `  FROM   ` Playlist `   AS   ` t0 `  WHERE   ( ` t0 ` . ` PlaylistId ` )   =   ( 700 );  -- Output: Inserted playlists:  -- Output: Playlist {playlistId = 700, playlistName = Just  My New Playlist }  -- Output: Playlist {playlistId = 701, playlistName = Just  Another Playlist }  -- Output: Playlist {playlistId = 702, playlistName = Just  Look... more playlists }", 
            "title": "Inserting explicit new values"
        }, 
        {
            "location": "/user-guide/manipulation/insert/#inserting-calculated-values", 
            "text": "Inserting explicit values is all well and good, but sometimes we want to defer\nsome processing to the database. For example, perhaps we want to create a new\ninvoice and use the current time as the invoice date. We could grab the current\ntime using  getCurrentTime  and then use this to construct an explicit Haskell\nvalue, but this may cause synchronization issues for our application. To do\nthis, beam allows us to specify arbitrary expressions as a source of values\nusing the  insertExpressions  function.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             runInsert   $   insert   ( invoice   chinookDb )   $ \n   insertExpressions   [   Invoice   ( val_   800 )   ( CustomerId   ( val_   1 ))   currentTimestamp_ \n                               ( val_   ( Address   ( Just   123 My Street )   ( Just   Buenos Noches )   ( Just   Rio )   ( Just   Mozambique )   ( Just   ABCDEF ))) \n                               ( val_   1000 )   ]  Just   newInvoice   - \n   runSelectReturningOne   $ \n   lookup_   ( invoice   chinookDb )   ( InvoiceId   800 )  putStrLn   ( Inserted invoice:    ++   show   newInvoice )  \n\n         \n    \n         \n             INSERT   INTO   Invoice ( InvoiceId , \n                       CustomerId , \n                       InvoiceDate , \n                       BillingAddress , \n                       BillingCity , \n                       BillingState , \n                       BillingCountry , \n                       BillingPostalCode , \n                       Total )  VALUES   ( ? , \n         ? , \n         CURRENT_TIMESTAMP , \n         ? , \n         ? , \n         ? , \n         ? , \n         ? , \n         ? );  -- With values: [SQLInteger 800,SQLInteger 1,SQLText  123 My Street ,SQLText  Buenos Noches ,SQLText  Rio ,SQLText  Mozambique ,SQLText  ABCDEF ,SQLText  1000.0 ];  SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8  FROM   Invoice   AS   t0  WHERE   ( t0 . InvoiceId ) = ( ? );  -- With values: [SQLInteger 800];  -- Output: Inserted invoice: Invoice {invoiceId = SqlSerial {unSerial = 800}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 17:22:39, invoiceBillingAddress = Address {address = Just  123 My Street , addressCity = Just  Buenos Noches , addressState = Just  Rio , addressCountry = Just  Mozambique , addressPostalCode = Just  ABCDEF }, invoiceTotal = 1000.0}  \n\n         \n    \n         \n             INSERT   INTO   Invoice ( InvoiceId , \n                       CustomerId , \n                       InvoiceDate , \n                       BillingAddress , \n                       BillingCity , \n                       BillingState , \n                       BillingCountry , \n                       BillingPostalCode , \n                       Total )  VALUES   ( 800 , \n         1 , \n         CURRENT_TIMESTAMP , \n         123 My Street , \n         Buenos Noches , \n         Rio , \n         Mozambique , \n         ABCDEF , \n         1000.0 );  SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8  FROM   Invoice   AS   t0  WHERE   ( t0 . InvoiceId )   =   ( 800 );  -- Output: Inserted invoice: Invoice {invoiceId = SqlSerial {unSerial = 800}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 10:22:42.74249, invoiceBillingAddress = Address {address = Just  123 My Street , addressCity = Just  Buenos Noches , addressState = Just  Rio , addressCountry = Just  Mozambique , addressPostalCode = Just  ABCDEF }, invoiceTotal = 1000.0}  \n\n         \n    \n         \n             INSERT   INTO   ` Invoice ` ( ` InvoiceId ` ,   ` CustomerId ` ,   ` InvoiceDate ` ,   ` BillingAddress ` ,   ` BillingCity ` ,   ` BillingState ` ,   ` BillingCountry ` ,   ` BillingPostalCode ` ,   ` Total ` )  VALUES   ( 800 , \n         1 , \n         CURRENT_TIMESTAMP , \n         123 My Street , \n         Buenos Noches , \n         Rio , \n         Mozambique , \n         ABCDEF , \n         1000 . 0 );  SELECT   ` t0 ` . ` InvoiceId `   AS   ` res0 ` , \n        ` t0 ` . ` CustomerId `   AS   ` res1 ` , \n        ` t0 ` . ` InvoiceDate `   AS   ` res2 ` , \n        ` t0 ` . ` BillingAddress `   AS   ` res3 ` , \n        ` t0 ` . ` BillingCity `   AS   ` res4 ` , \n        ` t0 ` . ` BillingState `   AS   ` res5 ` , \n        ` t0 ` . ` BillingCountry `   AS   ` res6 ` , \n        ` t0 ` . ` BillingPostalCode `   AS   ` res7 ` , \n        ` t0 ` . ` Total `   AS   ` res8 `  FROM   ` Invoice `   AS   ` t0 `  WHERE   ( ` t0 ` . ` InvoiceId ` )   =   ( 800 );  -- Output: Inserted invoice: Invoice {invoiceId = SqlSerial {unSerial = 800}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 10:22:47, invoiceBillingAddress = Address {address = Just  123 My Street , addressCity = Just  Buenos Noches , addressState = Just  Rio , addressCountry = Just  Mozambique , addressPostalCode = Just  ABCDEF }, invoiceTotal = 1000.0}  \n\n         \n    \n         \n    \n                 \n                      insertExpressions  is strictly more general than  insertValues . We can turn\nany  insertValues  to an  insertExpressions  by running every table value\nthrough the  val_  function to convert a Haskell literal to an expression.  For example, we can write the playlist example above as  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             runInsert   $   insert   ( playlist   chinookDb )   $ \n   insertExpressions   [   val_   $   Playlist   700   ( Just   My New Playlist ) \n                     ,   val_   $   Playlist   701   ( Just   Another Playlist ) \n                     ,   val_   $   Playlist   702   ( Just   Look... more playlists )   ]  insertedPlaylists   - \n   runSelectReturningList   $ \n   select   $   filter_   ( \\ p   -   playlistId   p   =.   700 )   $ \n   all_   ( playlist   chinookDb )  putStrLn   Inserted playlists:  forM_   insertedPlaylists   $   \\ p   - \n   putStrLn   ( show   p )  \n\n         \n    \n         \n             INSERT   INTO   Playlist ( PlaylistId , \n                        Name )  VALUES   ( ? , \n         ? ),   ( ? , \n              ? ),   ( ? , \n                   ? );  -- With values: [SQLInteger 700,SQLText  My New Playlist ,SQLInteger 701,SQLText  Another Playlist ,SQLInteger 702,SQLText  Look... more playlists ];  SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1  FROM   Playlist   AS   t0  WHERE   ( t0 . PlaylistId ) = ( ? );  -- With values: [SQLInteger 700];  -- Output: Inserted playlists:  -- Output: Playlist {playlistId = 700, playlistName = Just  My New Playlist }  -- Output: Playlist {playlistId = 701, playlistName = Just  Another Playlist }  -- Output: Playlist {playlistId = 702, playlistName = Just  Look... more playlists }  \n\n         \n    \n         \n             INSERT   INTO   Playlist ( PlaylistId , \n                        Name )  VALUES   ( 700 , \n         My New Playlist ),   ( 701 , \n                              Another Playlist ),   ( 702 , \n                                                    Look... more playlists );  SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1  FROM   Playlist   AS   t0  WHERE   ( t0 . PlaylistId )   =   ( 700 );  -- Output: Inserted playlists:  -- Output: Playlist {playlistId = 700, playlistName = Just  My New Playlist }  -- Output: Playlist {playlistId = 701, playlistName = Just  Another Playlist }  -- Output: Playlist {playlistId = 702, playlistName = Just  Look... more playlists }  \n\n         \n    \n         \n             INSERT   INTO   ` Playlist ` ( ` PlaylistId ` ,   ` Name ` )  VALUES   ( 700 , \n         My New Playlist ),   ( 701 , \n                              Another Playlist ),   ( 702 , \n                                                    Look... more playlists );  SELECT   ` t0 ` . ` PlaylistId `   AS   ` res0 ` , \n        ` t0 ` . ` Name `   AS   ` res1 `  FROM   ` Playlist `   AS   ` t0 `  WHERE   ( ` t0 ` . ` PlaylistId ` )   =   ( 700 );  -- Output: Inserted playlists:  -- Output: Playlist {playlistId = 700, playlistName = Just  My New Playlist }  -- Output: Playlist {playlistId = 701, playlistName = Just  Another Playlist }  -- Output: Playlist {playlistId = 702, playlistName = Just  Look... more playlists }  \n\n         \n    \n         \n    \n                 \n                      One common use of  insertExpressions_  is when adding new rows to tables where\none field needs to be set to the default value. For example, auto-incrementing\nkeys or random UUIDs are a common way to assign primary keys to rows. You can\nuse  insertExpressions_  using the  default_  expression for each column that\nyou want to use the default value for.  For example, the query below adds a new invoice asking the database to assign a\nnew id.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             runInsert   $   insert   ( invoice   chinookDb )   $ \n   insertExpressions   [   Invoice   default_   -- Ask the database to give us a default id \n                               ( val_   ( CustomerId   1 ))   currentTimestamp_ \n                               ( val_   ( Address   ( Just   123 My Street )   ( Just   Buenos Noches )   ( Just   Rio )   ( Just   Mozambique )   ( Just   ABCDEF ))) \n                               ( val_   1000 )   ]  \n\n         \n    \n         \n             INSERT   INTO   Invoice ( InvoiceId , \n                       CustomerId , \n                       InvoiceDate , \n                       BillingAddress , \n                       BillingCity , \n                       BillingState , \n                       BillingCountry , \n                       BillingPostalCode , \n                       Total )  VALUES   ( DEFAULT , \n         1 , \n         CURRENT_TIMESTAMP , \n         123 My Street , \n         Buenos Noches , \n         Rio , \n         Mozambique , \n         ABCDEF , \n         1000.0 );  \n\n         \n    \n         \n             INSERT   INTO   ` Invoice ` ( ` InvoiceId ` ,   ` CustomerId ` ,   ` InvoiceDate ` ,   ` BillingAddress ` ,   ` BillingCity ` ,   ` BillingState ` ,   ` BillingCountry ` ,   ` BillingPostalCode ` ,   ` Total ` )  VALUES   ( DEFAULT , \n         1 , \n         CURRENT_TIMESTAMP , \n         123 My Street , \n         Buenos Noches , \n         Rio , \n         Mozambique , \n         ABCDEF , \n         1000 . 0 );  \n\n         \n    \n         \n    \n                 \n                       Warning  SQLite is a great little backend, but it doesn't support some standard SQL\nfeatures, like the  DEFAULT  keyword in inserts. You can retrieve the same\nfunctionality by only inserting into a subset of columns. See the section on that  below.", 
            "title": "Inserting calculated values"
        }, 
        {
            "location": "/user-guide/manipulation/insert/#retrieving-the-rows-inserted", 
            "text": "However, now we have no way of knowing  what  value the database\nassigned. Unfortunately, there is no database-agnostic solution to this\nproblem. However, it's a common enough use case that beam provides a\nbackend-agnostic way for some backends. Backends that provide this functionality\nprovide an instance of  MonadBeamInsertReturning . In order to use this class,\nyou'll need to explicitly import Database.Beam.Backend.SQL.BeamExtensions . Below, we've imported this module\nqualified.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             [ newInvoice ]   - \n   BeamExtensions . runInsertReturningList   $   insert   ( invoice   chinookDb )   $ \n   insertExpressions   [   Invoice   default_   -- Ask the database to give us a default id \n                               ( val_   ( CustomerId   1 ))   currentTimestamp_ \n                               ( val_   ( Address   ( Just   123 My Street )   ( Just   Buenos Noches )   ( Just   Rio )   ( Just   Mozambique )   ( Just   ABCDEF ))) \n                               ( val_   1000 )   ]  putStrLn   ( We inserted a new invoice, and the result was    ++   show   newInvoice )  \n\n         \n    \n         \n             INSERT   INTO   Invoice ( CustomerId , \n                       InvoiceDate , \n                       BillingAddress , \n                       BillingCity , \n                       BillingState , \n                       BillingCountry , \n                       BillingPostalCode , \n                       Total )  VALUES   ( ? , \n         CURRENT_TIMESTAMP , \n         ? , \n         ? , \n         ? , \n         ? , \n         ? , \n         ? );  -- With values: [SQLInteger 1,SQLText  123 My Street ,SQLText  Buenos Noches ,SQLText  Rio ,SQLText  Mozambique ,SQLText  ABCDEF ,SQLText  1000.0 ];  -- Output: We inserted a new invoice, and the result was Invoice {invoiceId = SqlSerial {unSerial = 413}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 17:23:11, invoiceBillingAddress = Address {address = Just  123 My Street , addressCity = Just  Buenos Noches , addressState = Just  Rio , addressCountry = Just  Mozambique , addressPostalCode = Just  ABCDEF }, invoiceTotal = 1000.0}  \n\n         \n    \n         \n             INSERT   INTO   Invoice ( InvoiceId , \n                       CustomerId , \n                       InvoiceDate , \n                       BillingAddress , \n                       BillingCity , \n                       BillingState , \n                       BillingCountry , \n                       BillingPostalCode , \n                       Total )  VALUES   ( DEFAULT , \n         1 , \n         CURRENT_TIMESTAMP , \n         123 My Street , \n         Buenos Noches , \n         Rio , \n         Mozambique , \n         ABCDEF , \n         1000.0 )   RETURNING   InvoiceId , \n                             CustomerId , \n                             InvoiceDate , \n                             BillingAddress , \n                             BillingCity , \n                             BillingState , \n                             BillingCountry , \n                             BillingPostalCode , \n                             Total ;  -- Output: We inserted a new invoice, and the result was Invoice {invoiceId = SqlSerial {unSerial = 814}, invoiceCustomer = CustomerId 1, invoiceDate = 2019-03-19 10:23:14.615668, invoiceBillingAddress = Address {address = Just  123 My Street , addressCity = Just  Buenos Noches , addressState = Just  Rio , addressCountry = Just  Mozambique , addressPostalCode = Just  ABCDEF }, invoiceTotal = 1000.0}  \n\n         \n    \n         \n    \n                 \n                      The pattern match on the single  newInvoice  is safe, even though its\npartial. In general, you can expect the same amount of rows returned as\nspecified in your  SqlInsertValues . If you know what this is statically, then\nyou can feel free to pattern match directly. Otherwise (if you used insertFrom , for example), you'll need to handle the possibility that nothing\nwas inserted.   Note  Although SQLite has no support for the  DEFAULT  clause, MonadBeamInsertReturning  in  beam-sqlite  inserts rows one at a time and\nwill detect usage of the  DEFAULT  keyword. The beam authors consider this\nokay. While most beam statements are guaranteed to translate directly to the\nunderlying DBMS system,  runInsertReturningList  is explicitly marked as\nemulated functionality.", 
            "title": "Retrieving the rows inserted"
        }, 
        {
            "location": "/user-guide/manipulation/insert/#inserting-from-the-result-of-a-select-statement", 
            "text": "Sometimes you want to use existing data to insert values. For example, perhaps\nwe want to give every customer their own playlist, titled \" 's playlist\".  We can use the  insertFrom  function to make a  SqlInsertValues  corresponding\nto the result of a query. Make sure to return a projection with the same 'shape'\nas your data. If not, you'll get a compile time error.  For example, to create the playlists as above  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             runInsert   $   insert   ( playlist   chinookDb )   $ \n   insertFrom   $   do \n     c   -   all_   ( customer   chinookDb ) \n     pure   ( Playlist   ( customerId   c   +   1000 )   ( just_   ( concat_   [   customerFirstName   c ,   s Playlist   ])))  playlists   -   runSelectReturningList   $   select   $   limit_   10   $ \n              orderBy_   ( \\ p   -   asc_   ( playlistId   p ))   $ \n              filter_   ( \\ p   -   playlistId   p   =.   1000 )   $ \n              all_   ( playlist   chinookDb )  putStrLn   Inserted playlists  forM_   playlists   $   \\ playlist   - \n   putStrLn   (   -    ++   show   playlist )  \n\n         \n    \n         \n             INSERT   INTO   Playlist ( PlaylistId , \n                        Name )  SELECT   ( t0 . CustomerId )   +   ( ? )   AS   res0 , \n        ( t0 . FirstName   ||   ( ? ))   AS   res1  FROM   Customer   AS   t0 ;  -- With values: [SQLInteger 1000,SQLText  s Playlist ];  SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1  FROM   Playlist   AS   t0  WHERE   ( t0 . PlaylistId ) = ( ? )  ORDER   BY   t0 . PlaylistId   ASC  LIMIT   10 ;  -- With values: [SQLInteger 1000];  -- Output: Inserted playlists  -- Output:   - Playlist {playlistId = 1001, playlistName = Just  Lu\\237s s Playlist }  -- Output:   - Playlist {playlistId = 1002, playlistName = Just  Leonie s Playlist }  -- Output:   - Playlist {playlistId = 1003, playlistName = Just  Fran\\231ois s Playlist }  -- Output:   - Playlist {playlistId = 1004, playlistName = Just  Bj\\248rn s Playlist }  -- Output:   - Playlist {playlistId = 1005, playlistName = Just  Franti\\353ek s Playlist }  -- Output:   - Playlist {playlistId = 1006, playlistName = Just  Helena s Playlist }  -- Output:   - Playlist {playlistId = 1007, playlistName = Just  Astrid s Playlist }  -- Output:   - Playlist {playlistId = 1008, playlistName = Just  Daan s Playlist }  -- Output:   - Playlist {playlistId = 1009, playlistName = Just  Kara s Playlist }  -- Output:   - Playlist {playlistId = 1010, playlistName = Just  Eduardo s Playlist }  \n\n         \n    \n         \n             INSERT   INTO   Playlist ( PlaylistId , \n                        Name )  SELECT   ( t0 . CustomerId )   +   ( 1000 )   AS   res0 , \n        CONCAT ( t0 . FirstName ,   s Playlist )   AS   res1  FROM   Customer   AS   t0 ;  SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1  FROM   Playlist   AS   t0  WHERE   ( t0 . PlaylistId )   =   ( 1000 )  ORDER   BY   t0 . PlaylistId   ASC  LIMIT   10 ;  -- Output: Inserted playlists  -- Output:   - Playlist {playlistId = 1001, playlistName = Just  Lu\\237s s Playlist }  -- Output:   - Playlist {playlistId = 1002, playlistName = Just  Leonie s Playlist }  -- Output:   - Playlist {playlistId = 1003, playlistName = Just  Fran\\231ois s Playlist }  -- Output:   - Playlist {playlistId = 1004, playlistName = Just  Bj\\345rn s Playlist }  -- Output:   - Playlist {playlistId = 1005, playlistName = Just  Franti\\154ek s Playlist }  -- Output:   - Playlist {playlistId = 1006, playlistName = Just  Helena s Playlist }  -- Output:   - Playlist {playlistId = 1007, playlistName = Just  Astrid s Playlist }  -- Output:   - Playlist {playlistId = 1008, playlistName = Just  Daan s Playlist }  -- Output:   - Playlist {playlistId = 1009, playlistName = Just  Kara s Playlist }  -- Output:   - Playlist {playlistId = 1010, playlistName = Just  Eduardo s Playlist }  \n\n         \n    \n         \n             INSERT   INTO   ` Playlist ` ( ` PlaylistId ` ,   ` Name ` )  SELECT   ( ` t0 ` . ` CustomerId ` )   +   ( 1000 )   AS   ` res0 ` , \n        CONCAT ( ` t0 ` . ` FirstName ` ,   \\ s   Playlist ) AS `res1`  FROM `Customer` AS `t0`;  SELECT `t0`.`PlaylistId` AS `res0`,         `t0`.`Name` AS `res1`  FROM `Playlist` AS `t0`  WHERE (`t0`.`PlaylistId`)  = (1000)  ORDER BY `t0`.`PlaylistId` ASC  LIMIT 10;  -- Output: Inserted playlists  -- Output:   - Playlist {playlistId = 1001, playlistName = Just  Lu\\237s s   Playlist }  -- Output:   - Playlist {playlistId = 1002, playlistName = Just  Leonie s Playlist }  -- Output:   - Playlist {playlistId = 1003, playlistName = Just  Fran\\231ois s   Playlist }  -- Output:   - Playlist {playlistId = 1004, playlistName = Just  Bj \\ 248 rn s Playlist }  -- Output:   - Playlist {playlistId = 1005, playlistName = Just  Franti\\353ek s   Playlist }  -- Output:   - Playlist {playlistId = 1006, playlistName = Just  Helena s Playlist }  -- Output:   - Playlist {playlistId = 1007, playlistName = Just  Astrid s   Playlist }  -- Output:   - Playlist {playlistId = 1008, playlistName = Just  Daan s Playlist }  -- Output:   - Playlist {playlistId = 1009, playlistName = Just  Kara s   Playlist }  -- Output:   - Playlist {playlistId = 1010, playlistName = Just  Eduardo s   Playlist }", 
            "title": "Inserting from the result of a SELECT statement"
        }, 
        {
            "location": "/user-guide/manipulation/insert/#choosing-a-subset-of-columns", 
            "text": "Above, we used the  default_  clause to set a column to a default\nvalue. Unfortunately, not all backends support  default_  (SQLite being a\nnotable exception). Moreover, some  INSERT  forms simply can't use  default_ ,\nsuch as  insertFrom_  (you can't return  default_  from a query). The standard\nSQL tool used in these cases is limiting the inserted data to specific\ncolumns. For example, suppose we want to insert new invoices for every customer\nwith today's date. We can use the  insertOnly  function to project which field's\nare being inserted.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             runInsert   $ \n   insertOnly   ( invoice   chinookDb ) \n              ( \\ i   -   (   invoiceCustomer   i ,   invoiceDate   i ,   invoiceBillingAddress   i ,   invoiceTotal   i   )   )   $ \n   insertFrom   $   do \n     c   -   all_   ( customer   chinookDb ) \n\n     -- We ll just charge each customer $10 to be mean! \n     pure   ( primaryKey   c ,   currentTimestamp_ ,   customerAddress   c ,   as_   @ Scientific   $   val_   10 )  \n\n         \n    \n         \n             INSERT   INTO   Invoice ( CustomerId , \n                       InvoiceDate , \n                       BillingAddress , \n                       BillingCity , \n                       BillingState , \n                       BillingCountry , \n                       BillingPostalCode , \n                       Total )  SELECT   t0 . CustomerId   AS   res0 , \n        CURRENT_TIMESTAMP   AS   res1 , \n                             t0 . Address   AS   res2 , \n                             t0 . City   AS   res3 , \n                             t0 . State   AS   res4 , \n                             t0 . Country   AS   res5 , \n                             t0 . PostalCode   AS   res6 , \n                             ?   AS   res7  FROM   Customer   AS   t0 ;  -- With values: [SQLText  10.0 ];  \n\n         \n    \n         \n             INSERT   INTO   Invoice ( CustomerId , \n                       InvoiceDate , \n                       BillingAddress , \n                       BillingCity , \n                       BillingState , \n                       BillingCountry , \n                       BillingPostalCode , \n                       Total )  SELECT   t0 . CustomerId   AS   res0 , \n        CURRENT_TIMESTAMP   AS   res1 , \n                             t0 . Address   AS   res2 , \n                             t0 . City   AS   res3 , \n                             t0 . State   AS   res4 , \n                             t0 . Country   AS   res5 , \n                             t0 . PostalCode   AS   res6 , \n                             10.0   AS   res7  FROM   Customer   AS   t0 ;  \n\n         \n    \n         \n             INSERT   INTO   ` Invoice ` ( ` CustomerId ` ,   ` InvoiceDate ` ,   ` BillingAddress ` ,   ` BillingCity ` ,   ` BillingState ` ,   ` BillingCountry ` ,   ` BillingPostalCode ` ,   ` Total ` )  SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        CURRENT_TIMESTAMP   AS   ` res1 ` , \n                             ` t0 ` . ` Address `   AS   ` res2 ` , \n                             ` t0 ` . ` City `   AS   ` res3 ` , \n                             ` t0 ` . ` State `   AS   ` res4 ` , \n                             ` t0 ` . ` Country `   AS   ` res5 ` , \n                             ` t0 ` . ` PostalCode `   AS   ` res6 ` , \n                             10 . 0   AS   ` res7 `  FROM   ` Customer `   AS   ` t0 ` ;", 
            "title": "Choosing a subset of columns"
        }, 
        {
            "location": "/user-guide/manipulation/insert/#inserting-nothing", 
            "text": "Oftentimes, the values to be inserted are generated automatically by some\nHaskell function, and you just insert the resulting list. Sometimes, these lists\nmay be empty. If you blindly translated this into SQL, you'd end up with INSERT s with empty  VALUE  clauses, which are illegal. Beam actually handles\nthis gracefully. If a  SqlInsertValues  has no rows to insert, the  SqlInsert \nreturned by  insert  will know that it is empty. Running this  SqlInsert \nresults in nothing being sent to the database, which you can verify below.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             let   superComplicatedAction   =   pure   []   -- Hopefully, you re more creative!  valuesToInsert   -   superComplicatedAction  putStrLn   The following runInsert will send no commands to the database  runInsert   $   insert   ( playlist   chinookDb )   $ \n   insertValues   valuesToInsert  putStrLn   See! I told you!  \n\n         \n    \n         \n             -- Output: The following runInsert will send no commands to the database  -- Output: See! I told you!  \n\n         \n    \n         \n             -- Output: The following runInsert will send no commands to the database  -- Output: See! I told you!  \n\n         \n    \n         \n             -- Output: The following runInsert will send no commands to the database  -- Output: See! I told you!", 
            "title": "Inserting nothing"
        }, 
        {
            "location": "/user-guide/manipulation/update/", 
            "text": "SQL \nUPDATE\n expressions allow you to update rows in the database.\n\n\nBeam supplies two functions to update a row in a beam database.\n\n\nSaving entire rows\n\n\nThe \nsave\n function allows you to save entire rows to a database. It generates a\n\nSET\n clause that sets the value of every non-primary-key column and a \nWHERE\n\nclause that matches on the primary key.\n\n\nFor example, suppose we have a customer object representing Mark Philips\n\n\nlet\n \nc\n \n::\n \nCustomer\n\n    \nc\n \n=\n \nCustomer\n \n14\n \nMark\n \nPhilips\n \n(\nJust\n \nTelus\n)\n\n                 \n(\nAddress\n \n(\nJust\n \n8210 111 ST NW\n)\n \n(\nJust\n \nEdmonton\n)\n \n(\nJust\n \nAB\n)\n\n                          \n(\nJust\n \nCanada\n)\n \n(\nJust\n \nT6G 2C7\n))\n\n                 \n(\nJust\n \n+1 (780) 434-4554\n)\n\n                 \n(\nJust\n \n+1 (780) 434-5565\n)\n\n                 \nmphilips12@shaw.ca\n \n(\nEmployeeKey\n \n(\nJust\n \n5\n))\n\n\n\n\n\n\nMark's phone number recently changed and we'd like to update the database based\non our new customer object. We can use Haskell record update syntax to easily\nsave the entire row.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nJust\n \nc\n \n-\n \nrunSelectReturningOne\n \n$\n \nlookup_\n \n(\ncustomer\n \nchinookDb\n)\n \n(\nCustomerId\n \n14\n)\n\n\nputStrLn\n \n(\nOld phone number is \n \n++\n \nshow\n \n(\ncustomerPhone\n \nc\n))\n\n\n\nrunUpdate\n \n$\n\n  \nsave\n \n(\ncustomer\n \nchinookDb\n)\n\n       \n(\nc\n \n{\n \ncustomerPhone\n \n=\n \nJust\n \n+1 (123) 456-7890\n \n})\n\n\n\nJust\n \nc\n \n-\n \nrunSelectReturningOne\n \n$\n \nlookup_\n \n(\ncustomer\n \nchinookDb\n)\n \n(\nCustomerId\n \n14\n)\n\n\nputStrLn\n \n(\nNew phone number is \n \n++\n \nshow\n \n(\ncustomerPhone\n \nc\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCustomerId\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLInteger 14];\n\n\n-- Output: Old phone number is Just \n+1 (780) 434-4554\n\n\n\nUPDATE\n \nCustomer\n\n\nSET\n \nFirstName\n=?\n,\n\n    \nLastName\n=?\n,\n\n    \nCompany\n=?\n,\n\n    \nAddress\n=?\n,\n\n    \nCity\n=?\n,\n\n    \nState\n=?\n,\n\n    \nCountry\n=?\n,\n\n    \nPostalCode\n=?\n,\n\n    \nPhone\n=?\n,\n\n    \nFax\n=?\n,\n\n    \nEmail\n=?\n,\n\n    \nSupportRepId\n=?\n\n\nWHERE\n \n(\n?\n)\n=\n(\nCustomerId\n);\n\n\n\n-- With values: [SQLText \nMark\n,SQLText \nPhilips\n,SQLText \nTelus\n,SQLText \n8210 111 ST NW\n,SQLText \nEdmonton\n,SQLText \nAB\n,SQLText \nCanada\n,SQLText \nT6G 2C7\n,SQLText \n+1 (123) 456-7890\n,SQLText \n+1 (780) 434-5565\n,SQLText \nmphilips12@shaw.ca\n,SQLInteger 5,SQLInteger 14];\n\n\n\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCustomerId\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLInteger 14];\n\n\n-- Output: New phone number is Just \n+1 (123) 456-7890\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCustomerId\n)\n \n=\n \n(\n14\n);\n\n\n\n-- Output: Old phone number is Just \n+1 (780) 434-4554\n\n\n\nUPDATE\n \nCustomer\n\n\nSET\n \nFirstName\n=\nMark\n,\n\n    \nLastName\n=\nPhilips\n,\n\n    \nCompany\n=\nTelus\n,\n\n    \nAddress\n=\n8210 111 ST NW\n,\n\n    \nCity\n=\nEdmonton\n,\n\n    \nState\n=\nAB\n,\n\n    \nCountry\n=\nCanada\n,\n\n    \nPostalCode\n=\nT6G 2C7\n,\n\n    \nPhone\n=\n+1 (123) 456-7890\n,\n\n    \nFax\n=\n+1 (780) 434-5565\n,\n\n    \nEmail\n=\nmphilips12@shaw.ca\n,\n\n    \nSupportRepId\n=\n5\n\n\nWHERE\n \n(\n14\n)\n \n=\n \n(\nCustomerId\n);\n\n\n\n\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCustomerId\n)\n \n=\n \n(\n14\n);\n\n\n\n-- Output: New phone number is Just \n+1 (123) 456-7890\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nCustomerId\n`\n)\n \n=\n \n(\n14\n);\n\n\n\n-- Output: Old phone number is Just \n+1 (780) 434-4554\n\n\n\nUPDATE\n \n`\nCustomer\n`\n\n\nSET\n \n`\nFirstName\n`=\nMark\n,\n\n    \n`\nLastName\n`=\nPhilips\n,\n\n    \n`\nCompany\n`=\nTelus\n,\n\n    \n`\nAddress\n`=\n8210 111 ST NW\n,\n\n    \n`\nCity\n`=\nEdmonton\n,\n\n    \n`\nState\n`=\nAB\n,\n\n    \n`\nCountry\n`=\nCanada\n,\n\n    \n`\nPostalCode\n`=\nT6G 2C7\n,\n\n    \n`\nPhone\n`=\n+1 (123) 456-7890\n,\n\n    \n`\nFax\n`=\n+1 (780) 434-5565\n,\n\n    \n`\nEmail\n`=\nmphilips12@shaw.ca\n,\n\n    \n`\nSupportRepId\n`=\n5\n\n\nWHERE\n \n(\n14\n)\n \n=\n \n(\n`\nCustomerId\n`\n);\n\n\n\n\nSELECT\n \n`\nt0\n`\n.\n`\nCustomerId\n`\n \nAS\n \n`\nres0\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFirstName\n`\n \nAS\n \n`\nres1\n`\n,\n\n       \n`\nt0\n`\n.\n`\nLastName\n`\n \nAS\n \n`\nres2\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCompany\n`\n \nAS\n \n`\nres3\n`\n,\n\n       \n`\nt0\n`\n.\n`\nAddress\n`\n \nAS\n \n`\nres4\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCity\n`\n \nAS\n \n`\nres5\n`\n,\n\n       \n`\nt0\n`\n.\n`\nState\n`\n \nAS\n \n`\nres6\n`\n,\n\n       \n`\nt0\n`\n.\n`\nCountry\n`\n \nAS\n \n`\nres7\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPostalCode\n`\n \nAS\n \n`\nres8\n`\n,\n\n       \n`\nt0\n`\n.\n`\nPhone\n`\n \nAS\n \n`\nres9\n`\n,\n\n       \n`\nt0\n`\n.\n`\nFax\n`\n \nAS\n \n`\nres10\n`\n,\n\n       \n`\nt0\n`\n.\n`\nEmail\n`\n \nAS\n \n`\nres11\n`\n,\n\n       \n`\nt0\n`\n.\n`\nSupportRepId\n`\n \nAS\n \n`\nres12\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \n(\n`\nt0\n`\n.\n`\nCustomerId\n`\n)\n \n=\n \n(\n14\n);\n\n\n\n-- Output: New phone number is Just \n+1 (123) 456-7890\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe \nsave\n function generates a value of type \nSqlUpdate syntax CustomerT\n,\nwhere \nsyntax\n is the type of the appropriate backend syntax\n(\nSqliteCommandSyntax\n for \nbeam-sqlite\n and \nPgCommandSyntax\n for\n\nbeam-postgres\n). Like \nselect\n and the \nrunSelect*\n functions, we use the\n\nrunUpdate\n function to run the command against the database\n\n\nFine-grained updates\n\n\nWhile \nsave\n is useful when many fields may have changed, often times you only\nwant to update a few columns. Moreover, if you have several large columns, using\n\nsave\n may end up sending huge pieces of data to the database. The SQL \nUPDATE\n\nsyntax allows you to set or modify each column individually and to even\ncalculate a new value based off the result of an expression.\n\n\nThe beam \nupdate\n function exposes this functionality. \nupdate\n takes\na table, a set of assignments (which can be combined monoidally), and\na boolean expression, and returns a \nSqlUpdate\n.\n\n\nFor example, suppose Canada and the USA became one country and we needed to\nupdate all customer addresses to reflect that.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nJust\n \ncanadianCount\n \n-\n\n  \nrunSelectReturningOne\n \n$\n \nselect\n \n$\n\n  \naggregate_\n \n(\n\\\n_\n \n-\n \nas_\n \n@\nInt\n \ncountAll_\n)\n \n$\n\n  \nfilter_\n \n(\n\\\nc\n \n-\n \naddressCountry\n \n(\ncustomerAddress\n \nc\n)\n \n==.\n \nval_\n \n(\nJust\n \nCanada\n))\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\nJust\n \nusaCount\n \n-\n\n  \nrunSelectReturningOne\n \n$\n \nselect\n \n$\n\n  \naggregate_\n \n(\n\\\n_\n \n-\n \nas_\n \n@\nInt\n \ncountAll_\n)\n \n$\n\n  \nfilter_\n \n(\n\\\nc\n \n-\n \naddressCountry\n \n(\ncustomerAddress\n \nc\n)\n \n==.\n \nval_\n \n(\nJust\n \nUSA\n))\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\nputStrLn\n \n(\nBefore, there were \n \n++\n \nshow\n \ncanadianCount\n \n++\n \n addresses in Canada and \n \n++\n \nshow\n \nusaCount\n \n++\n \n in the USA.\n)\n\n\n\n-- This is the important part!\n\n\nrunUpdate\n \n$\n \nupdate\n \n(\ncustomer\n \nchinookDb\n)\n\n                   \n(\n\\\nc\n \n-\n \naddressCountry\n \n(\ncustomerAddress\n \nc\n)\n \n-.\n \nval_\n \n(\nJust\n \nUSA\n))\n\n                   \n(\n\\\nc\n \n-\n \naddressCountry\n \n(\ncustomerAddress\n \nc\n)\n \n==.\n \nval_\n \n(\nJust\n \nCanada\n))\n\n\n\nJust\n \ncanadianCount\n \n-\n\n  \nrunSelectReturningOne\n \n$\n \nselect\n \n$\n\n  \naggregate_\n \n(\n\\\n_\n \n-\n \nas_\n \n@\nInt\n \ncountAll_\n)\n \n$\n\n  \nfilter_\n \n(\n\\\nc\n \n-\n \naddressCountry\n \n(\ncustomerAddress\n \nc\n)\n \n==.\n \nval_\n \n(\nJust\n \nCanada\n))\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\nJust\n \nusaCount\n \n-\n\n  \nrunSelectReturningOne\n \n$\n \nselect\n \n$\n\n  \naggregate_\n \n(\n\\\n_\n \n-\n \nas_\n \n@\nInt\n \ncountAll_\n)\n \n$\n\n  \nfilter_\n \n(\n\\\nc\n \n-\n \naddressCountry\n \n(\ncustomerAddress\n \nc\n)\n \n==.\n \nval_\n \n(\nJust\n \nUSA\n))\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\nputStrLn\n \n(\nNow, there are \n \n++\n \nshow\n \ncanadianCount\n \n++\n \n addresses in Canada and \n \n++\n \nshow\n \nusaCount\n \n++\n \n in the USA.\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\nt0\n.\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nt0\n.\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nt0\n.\nCountry\n)\n=\n(\n?\n)\n\n      \nEND\n;\n\n\n\n-- With values: [SQLText \nCanada\n,SQLInteger 1,SQLText \nCanada\n,SQLInteger 0,SQLText \nCanada\n];\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\nt0\n.\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nt0\n.\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nt0\n.\nCountry\n)\n=\n(\n?\n)\n\n      \nEND\n;\n\n\n\n-- With values: [SQLText \nUSA\n,SQLInteger 1,SQLText \nUSA\n,SQLInteger 0,SQLText \nUSA\n];\n\n\n-- Output: Before, there were 8 addresses in Canada and 13 in the USA.\n\n\n\nUPDATE\n \nCustomer\n\n\nSET\n \nCountry\n=?\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nCountry\n)\n=\n(\n?\n)\n\n      \nEND\n;\n\n\n\n-- With values: [SQLText \nUSA\n,SQLText \nCanada\n,SQLInteger 1,SQLText \nCanada\n,SQLInteger 0,SQLText \nCanada\n];\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\nt0\n.\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nt0\n.\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nt0\n.\nCountry\n)\n=\n(\n?\n)\n\n      \nEND\n;\n\n\n\n-- With values: [SQLText \nCanada\n,SQLInteger 1,SQLText \nCanada\n,SQLInteger 0,SQLText \nCanada\n];\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\nt0\n.\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nWHEN\n \n((\nt0\n.\nCountry\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\n?\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \n?\n\n          \nELSE\n \n(\nt0\n.\nCountry\n)\n=\n(\n?\n)\n\n      \nEND\n;\n\n\n\n-- With values: [SQLText \nUSA\n,SQLInteger 1,SQLText \nUSA\n,SQLInteger 0,SQLText \nUSA\n];\n\n\n-- Output: Now, there are 0 addresses in Canada and 21 in the USA.\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCountry\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n  \nFROM\n \n(\nCanada\n);\n\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCountry\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n  \nFROM\n \n(\nUSA\n);\n\n\n\n-- Output: Before, there were 8 addresses in Canada and 13 in the USA.\n\n\n\nUPDATE\n \nCustomer\n\n\nSET\n \nCountry\n=\nUSA\n\n\nWHERE\n \n(\nCountry\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n  \nFROM\n \n(\nCanada\n);\n\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCountry\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n  \nFROM\n \n(\nCanada\n);\n\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nCountry\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n  \nFROM\n \n(\nUSA\n);\n\n\n\n-- Output: Now, there are 0 addresses in Canada and 21 in the USA.\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nCanada\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nCanada\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \n=\n \n(\nCanada\n)\n\n      \nEND\n;\n\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nUSA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nUSA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \n=\n \n(\nUSA\n)\n\n      \nEND\n;\n\n\n\n-- Output: Before, there were 8 addresses in Canada and 13 in the USA.\n\n\n\nUPDATE\n \n`\nCustomer\n`\n\n\nSET\n \n`\nCountry\n`=\nUSA\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nCanada\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nCanada\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nCountry\n`\n)\n \n=\n \n(\nCanada\n)\n\n      \nEND\n;\n\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nCanada\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nCanada\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \n=\n \n(\nCanada\n)\n\n      \nEND\n;\n\n\n\n\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nCustomer\n`\n \nAS\n \n`\nt0\n`\n\n\nWHERE\n \nCASE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nAND\n \n((\nUSA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nTRUE\n\n          \nWHEN\n \n((\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \nIS\n \nNULL\n)\n\n               \nOR\n \n((\nUSA\n)\n \nIS\n \nNULL\n)\n \nTHEN\n \nFALSE\n\n          \nELSE\n \n(\n`\nt0\n`\n.\n`\nCountry\n`\n)\n \n=\n \n(\nUSA\n)\n\n      \nEND\n;\n\n\n\n-- Output: Now, there are 0 addresses in Canada and 21 in the USA.\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can update columns based on their old value as well, using the \ncurrent_\n\nfunction. For example, suppose we wanted to fudge our sales data a bit and double\nquantity of every line item.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nJust\n \ntotalLineItems\n \n-\n\n  \nrunSelectReturningOne\n \n$\n \nselect\n \n$\n\n  \naggregate_\n \n(\n\\\nln\n \n-\n \nsum_\n \n(\ninvoiceLineQuantity\n \nln\n))\n \n$\n\n  \nall_\n \n(\ninvoiceLine\n \nchinookDb\n)\n\n\nputStrLn\n \n(\nBefore, we had \n \n++\n \nshow\n \ntotalLineItems\n \n++\n \n total products sold\n\\n\n)\n\n\n\nrunUpdate\n \n$\n \nupdate\n \n(\ninvoiceLine\n \nchinookDb\n)\n\n                   \n(\n\\\nln\n \n-\n \ninvoiceLineQuantity\n \nln\n \n-.\n \ncurrent_\n \n(\ninvoiceLineQuantity\n \nln\n)\n \n*\n \n2\n)\n\n                   \n(\n\\\n_\n \n-\n \nval_\n \nTrue\n)\n\n\n\nJust\n \ntotalLineItems\n \n-\n\n  \nrunSelectReturningOne\n \n$\n \nselect\n \n$\n\n  \naggregate_\n \n(\n\\\nln\n \n-\n \nsum_\n \n(\ninvoiceLineQuantity\n \nln\n))\n \n$\n\n  \nall_\n \n(\ninvoiceLine\n \nchinookDb\n)\n\n\nputStrLn\n \n(\nWith a few simple lines, we\nve double our sales figure to \n \n++\n \nshow\n \ntotalLineItems\n \n++\n \n products sold!\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nSUM\n(\nt0\n.\nQuantity\n)\n \nAS\n \nres0\n\n\nFROM\n \nInvoiceLine\n \nAS\n \nt0\n;\n\n\n\n-- With values: [];\n\n\n-- Output: Before, we had Just 2240 total products sold\n\n\n\nUPDATE\n \nInvoiceLine\n\n\nSET\n \nQuantity\n=\n(\nQuantity\n)\n \n*\n \n(\n?\n)\n\n\nWHERE\n \n?\n;\n\n\n\n-- With values: [SQLInteger 2,SQLInteger 1];\n\n\n\nSELECT\n \nSUM\n(\nt0\n.\nQuantity\n)\n \nAS\n \nres0\n\n\nFROM\n \nInvoiceLine\n \nAS\n \nt0\n;\n\n\n\n-- With values: [];\n\n\n-- Output: With a few simple lines, we\nve double our sales figure to Just 4480 products sold!\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nSUM\n(\nt0\n.\nQuantity\n)\n \nAS\n \nres0\n\n\nFROM\n \nInvoiceLine\n \nAS\n \nt0\n;\n\n\n\n-- Output: Before, we had Just 2240 total products sold\n\n\n\nUPDATE\n \nInvoiceLine\n\n\nSET\n \nQuantity\n=\n(\nQuantity\n)\n \n*\n \n(\n2\n)\n\n\nWHERE\n \ntrue\n;\n\n\n\n\nSELECT\n \nSUM\n(\nt0\n.\nQuantity\n)\n \nAS\n \nres0\n\n\nFROM\n \nInvoiceLine\n \nAS\n \nt0\n;\n\n\n\n-- Output: With a few simple lines, we\nve double our sales figure to Just 4480 products sold!\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nSUM\n(\n`\nt0\n`\n.\n`\nQuantity\n`\n)\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt0\n`\n;\n\n\n\n-- Output: Before, we had Just 2240 total products sold\n\n\n\nUPDATE\n \n`\nInvoiceLine\n`\n\n\nSET\n \n`\nQuantity\n`=\n(\n`\nQuantity\n`\n)\n \n*\n \n(\n2\n)\n\n\nWHERE\n \nTRUE\n;\n\n\n\n\nSELECT\n \nSUM\n(\n`\nt0\n`\n.\n`\nQuantity\n`\n)\n \nAS\n \n`\nres0\n`\n\n\nFROM\n \n`\nInvoiceLine\n`\n \nAS\n \n`\nt0\n`\n;\n\n\n\n-- Output: With a few simple lines, we\nve double our sales figure to Just 4480 products sold!\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nAmazing! A few simple lines, and we've doubled our sales -- beam is awesome!", 
            "title": "UPDATE"
        }, 
        {
            "location": "/user-guide/manipulation/update/#saving-entire-rows", 
            "text": "The  save  function allows you to save entire rows to a database. It generates a SET  clause that sets the value of every non-primary-key column and a  WHERE \nclause that matches on the primary key.  For example, suppose we have a customer object representing Mark Philips  let   c   ::   Customer \n     c   =   Customer   14   Mark   Philips   ( Just   Telus ) \n                  ( Address   ( Just   8210 111 ST NW )   ( Just   Edmonton )   ( Just   AB ) \n                           ( Just   Canada )   ( Just   T6G 2C7 )) \n                  ( Just   +1 (780) 434-4554 ) \n                  ( Just   +1 (780) 434-5565 ) \n                  mphilips12@shaw.ca   ( EmployeeKey   ( Just   5 ))   Mark's phone number recently changed and we'd like to update the database based\non our new customer object. We can use Haskell record update syntax to easily\nsave the entire row.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             Just   c   -   runSelectReturningOne   $   lookup_   ( customer   chinookDb )   ( CustomerId   14 )  putStrLn   ( Old phone number is    ++   show   ( customerPhone   c ))  runUpdate   $ \n   save   ( customer   chinookDb ) \n        ( c   {   customerPhone   =   Just   +1 (123) 456-7890   })  Just   c   -   runSelectReturningOne   $   lookup_   ( customer   chinookDb )   ( CustomerId   14 )  putStrLn   ( New phone number is    ++   show   ( customerPhone   c ))  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . CustomerId ) = ( ? );  -- With values: [SQLInteger 14];  -- Output: Old phone number is Just  +1 (780) 434-4554  UPDATE   Customer  SET   FirstName =? , \n     LastName =? , \n     Company =? , \n     Address =? , \n     City =? , \n     State =? , \n     Country =? , \n     PostalCode =? , \n     Phone =? , \n     Fax =? , \n     Email =? , \n     SupportRepId =?  WHERE   ( ? ) = ( CustomerId );  -- With values: [SQLText  Mark ,SQLText  Philips ,SQLText  Telus ,SQLText  8210 111 ST NW ,SQLText  Edmonton ,SQLText  AB ,SQLText  Canada ,SQLText  T6G 2C7 ,SQLText  +1 (123) 456-7890 ,SQLText  +1 (780) 434-5565 ,SQLText  mphilips12@shaw.ca ,SQLInteger 5,SQLInteger 14];  SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . CustomerId ) = ( ? );  -- With values: [SQLInteger 14];  -- Output: New phone number is Just  +1 (123) 456-7890  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . CustomerId )   =   ( 14 );  -- Output: Old phone number is Just  +1 (780) 434-4554  UPDATE   Customer  SET   FirstName = Mark , \n     LastName = Philips , \n     Company = Telus , \n     Address = 8210 111 ST NW , \n     City = Edmonton , \n     State = AB , \n     Country = Canada , \n     PostalCode = T6G 2C7 , \n     Phone = +1 (123) 456-7890 , \n     Fax = +1 (780) 434-5565 , \n     Email = mphilips12@shaw.ca , \n     SupportRepId = 5  WHERE   ( 14 )   =   ( CustomerId );  SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . CustomerId )   =   ( 14 );  -- Output: New phone number is Just  +1 (123) 456-7890  \n\n         \n    \n         \n             SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ( ` t0 ` . ` CustomerId ` )   =   ( 14 );  -- Output: Old phone number is Just  +1 (780) 434-4554  UPDATE   ` Customer `  SET   ` FirstName `= Mark , \n     ` LastName `= Philips , \n     ` Company `= Telus , \n     ` Address `= 8210 111 ST NW , \n     ` City `= Edmonton , \n     ` State `= AB , \n     ` Country `= Canada , \n     ` PostalCode `= T6G 2C7 , \n     ` Phone `= +1 (123) 456-7890 , \n     ` Fax `= +1 (780) 434-5565 , \n     ` Email `= mphilips12@shaw.ca , \n     ` SupportRepId `= 5  WHERE   ( 14 )   =   ( ` CustomerId ` );  SELECT   ` t0 ` . ` CustomerId `   AS   ` res0 ` , \n        ` t0 ` . ` FirstName `   AS   ` res1 ` , \n        ` t0 ` . ` LastName `   AS   ` res2 ` , \n        ` t0 ` . ` Company `   AS   ` res3 ` , \n        ` t0 ` . ` Address `   AS   ` res4 ` , \n        ` t0 ` . ` City `   AS   ` res5 ` , \n        ` t0 ` . ` State `   AS   ` res6 ` , \n        ` t0 ` . ` Country `   AS   ` res7 ` , \n        ` t0 ` . ` PostalCode `   AS   ` res8 ` , \n        ` t0 ` . ` Phone `   AS   ` res9 ` , \n        ` t0 ` . ` Fax `   AS   ` res10 ` , \n        ` t0 ` . ` Email `   AS   ` res11 ` , \n        ` t0 ` . ` SupportRepId `   AS   ` res12 `  FROM   ` Customer `   AS   ` t0 `  WHERE   ( ` t0 ` . ` CustomerId ` )   =   ( 14 );  -- Output: New phone number is Just  +1 (123) 456-7890  \n\n         \n    \n         \n    \n                 \n                      The  save  function generates a value of type  SqlUpdate syntax CustomerT ,\nwhere  syntax  is the type of the appropriate backend syntax\n( SqliteCommandSyntax  for  beam-sqlite  and  PgCommandSyntax  for beam-postgres ). Like  select  and the  runSelect*  functions, we use the runUpdate  function to run the command against the database", 
            "title": "Saving entire rows"
        }, 
        {
            "location": "/user-guide/manipulation/update/#fine-grained-updates", 
            "text": "While  save  is useful when many fields may have changed, often times you only\nwant to update a few columns. Moreover, if you have several large columns, using save  may end up sending huge pieces of data to the database. The SQL  UPDATE \nsyntax allows you to set or modify each column individually and to even\ncalculate a new value based off the result of an expression.  The beam  update  function exposes this functionality.  update  takes\na table, a set of assignments (which can be combined monoidally), and\na boolean expression, and returns a  SqlUpdate .  For example, suppose Canada and the USA became one country and we needed to\nupdate all customer addresses to reflect that.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             Just   canadianCount   - \n   runSelectReturningOne   $   select   $ \n   aggregate_   ( \\ _   -   as_   @ Int   countAll_ )   $ \n   filter_   ( \\ c   -   addressCountry   ( customerAddress   c )   ==.   val_   ( Just   Canada ))   $ \n   all_   ( customer   chinookDb )  Just   usaCount   - \n   runSelectReturningOne   $   select   $ \n   aggregate_   ( \\ _   -   as_   @ Int   countAll_ )   $ \n   filter_   ( \\ c   -   addressCountry   ( customerAddress   c )   ==.   val_   ( Just   USA ))   $ \n   all_   ( customer   chinookDb )  putStrLn   ( Before, there were    ++   show   canadianCount   ++    addresses in Canada and    ++   show   usaCount   ++    in the USA. )  -- This is the important part!  runUpdate   $   update   ( customer   chinookDb ) \n                    ( \\ c   -   addressCountry   ( customerAddress   c )   -.   val_   ( Just   USA )) \n                    ( \\ c   -   addressCountry   ( customerAddress   c )   ==.   val_   ( Just   Canada ))  Just   canadianCount   - \n   runSelectReturningOne   $   select   $ \n   aggregate_   ( \\ _   -   as_   @ Int   countAll_ )   $ \n   filter_   ( \\ c   -   addressCountry   ( customerAddress   c )   ==.   val_   ( Just   Canada ))   $ \n   all_   ( customer   chinookDb )  Just   usaCount   - \n   runSelectReturningOne   $   select   $ \n   aggregate_   ( \\ _   -   as_   @ Int   countAll_ )   $ \n   filter_   ( \\ c   -   addressCountry   ( customerAddress   c )   ==.   val_   ( Just   USA ))   $ \n   all_   ( customer   chinookDb )  putStrLn   ( Now, there are    ++   show   canadianCount   ++    addresses in Canada and    ++   show   usaCount   ++    in the USA. )  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   res0  FROM   Customer   AS   t0  WHERE   CASE \n           WHEN   (( t0 . Country )   IS   NULL ) \n                AND   (( ? )   IS   NULL )   THEN   ? \n           WHEN   (( t0 . Country )   IS   NULL ) \n                OR   (( ? )   IS   NULL )   THEN   ? \n           ELSE   ( t0 . Country ) = ( ? ) \n       END ;  -- With values: [SQLText  Canada ,SQLInteger 1,SQLText  Canada ,SQLInteger 0,SQLText  Canada ];  SELECT   COUNT ( * )   AS   res0  FROM   Customer   AS   t0  WHERE   CASE \n           WHEN   (( t0 . Country )   IS   NULL ) \n                AND   (( ? )   IS   NULL )   THEN   ? \n           WHEN   (( t0 . Country )   IS   NULL ) \n                OR   (( ? )   IS   NULL )   THEN   ? \n           ELSE   ( t0 . Country ) = ( ? ) \n       END ;  -- With values: [SQLText  USA ,SQLInteger 1,SQLText  USA ,SQLInteger 0,SQLText  USA ];  -- Output: Before, there were 8 addresses in Canada and 13 in the USA.  UPDATE   Customer  SET   Country =?  WHERE   CASE \n           WHEN   (( Country )   IS   NULL ) \n                AND   (( ? )   IS   NULL )   THEN   ? \n           WHEN   (( Country )   IS   NULL ) \n                OR   (( ? )   IS   NULL )   THEN   ? \n           ELSE   ( Country ) = ( ? ) \n       END ;  -- With values: [SQLText  USA ,SQLText  Canada ,SQLInteger 1,SQLText  Canada ,SQLInteger 0,SQLText  Canada ];  SELECT   COUNT ( * )   AS   res0  FROM   Customer   AS   t0  WHERE   CASE \n           WHEN   (( t0 . Country )   IS   NULL ) \n                AND   (( ? )   IS   NULL )   THEN   ? \n           WHEN   (( t0 . Country )   IS   NULL ) \n                OR   (( ? )   IS   NULL )   THEN   ? \n           ELSE   ( t0 . Country ) = ( ? ) \n       END ;  -- With values: [SQLText  Canada ,SQLInteger 1,SQLText  Canada ,SQLInteger 0,SQLText  Canada ];  SELECT   COUNT ( * )   AS   res0  FROM   Customer   AS   t0  WHERE   CASE \n           WHEN   (( t0 . Country )   IS   NULL ) \n                AND   (( ? )   IS   NULL )   THEN   ? \n           WHEN   (( t0 . Country )   IS   NULL ) \n                OR   (( ? )   IS   NULL )   THEN   ? \n           ELSE   ( t0 . Country ) = ( ? ) \n       END ;  -- With values: [SQLText  USA ,SQLInteger 1,SQLText  USA ,SQLInteger 0,SQLText  USA ];  -- Output: Now, there are 0 addresses in Canada and 21 in the USA.  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   res0  FROM   Customer   AS   t0  WHERE   ( t0 . Country )   IS   NOT   DISTINCT \n   FROM   ( Canada );  SELECT   COUNT ( * )   AS   res0  FROM   Customer   AS   t0  WHERE   ( t0 . Country )   IS   NOT   DISTINCT \n   FROM   ( USA );  -- Output: Before, there were 8 addresses in Canada and 13 in the USA.  UPDATE   Customer  SET   Country = USA  WHERE   ( Country )   IS   NOT   DISTINCT \n   FROM   ( Canada );  SELECT   COUNT ( * )   AS   res0  FROM   Customer   AS   t0  WHERE   ( t0 . Country )   IS   NOT   DISTINCT \n   FROM   ( Canada );  SELECT   COUNT ( * )   AS   res0  FROM   Customer   AS   t0  WHERE   ( t0 . Country )   IS   NOT   DISTINCT \n   FROM   ( USA );  -- Output: Now, there are 0 addresses in Canada and 21 in the USA.  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   ` res0 `  FROM   ` Customer `   AS   ` t0 `  WHERE   CASE \n           WHEN   (( ` t0 ` . ` Country ` )   IS   NULL ) \n                AND   (( Canada )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` t0 ` . ` Country ` )   IS   NULL ) \n                OR   (( Canada )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` t0 ` . ` Country ` )   =   ( Canada ) \n       END ;  SELECT   COUNT ( * )   AS   ` res0 `  FROM   ` Customer `   AS   ` t0 `  WHERE   CASE \n           WHEN   (( ` t0 ` . ` Country ` )   IS   NULL ) \n                AND   (( USA )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` t0 ` . ` Country ` )   IS   NULL ) \n                OR   (( USA )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` t0 ` . ` Country ` )   =   ( USA ) \n       END ;  -- Output: Before, there were 8 addresses in Canada and 13 in the USA.  UPDATE   ` Customer `  SET   ` Country `= USA  WHERE   CASE \n           WHEN   (( ` Country ` )   IS   NULL ) \n                AND   (( Canada )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` Country ` )   IS   NULL ) \n                OR   (( Canada )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` Country ` )   =   ( Canada ) \n       END ;  SELECT   COUNT ( * )   AS   ` res0 `  FROM   ` Customer `   AS   ` t0 `  WHERE   CASE \n           WHEN   (( ` t0 ` . ` Country ` )   IS   NULL ) \n                AND   (( Canada )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` t0 ` . ` Country ` )   IS   NULL ) \n                OR   (( Canada )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` t0 ` . ` Country ` )   =   ( Canada ) \n       END ;  SELECT   COUNT ( * )   AS   ` res0 `  FROM   ` Customer `   AS   ` t0 `  WHERE   CASE \n           WHEN   (( ` t0 ` . ` Country ` )   IS   NULL ) \n                AND   (( USA )   IS   NULL )   THEN   TRUE \n           WHEN   (( ` t0 ` . ` Country ` )   IS   NULL ) \n                OR   (( USA )   IS   NULL )   THEN   FALSE \n           ELSE   ( ` t0 ` . ` Country ` )   =   ( USA ) \n       END ;  -- Output: Now, there are 0 addresses in Canada and 21 in the USA.  \n\n         \n    \n         \n    \n                 \n                      We can update columns based on their old value as well, using the  current_ \nfunction. For example, suppose we wanted to fudge our sales data a bit and double\nquantity of every line item.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite \n         \n    \n         \n             Postgres \n         \n    \n         \n             Mysql \n         \n    \n         \n    \n         \n            \n         \n             Just   totalLineItems   - \n   runSelectReturningOne   $   select   $ \n   aggregate_   ( \\ ln   -   sum_   ( invoiceLineQuantity   ln ))   $ \n   all_   ( invoiceLine   chinookDb )  putStrLn   ( Before, we had    ++   show   totalLineItems   ++    total products sold \\n )  runUpdate   $   update   ( invoiceLine   chinookDb ) \n                    ( \\ ln   -   invoiceLineQuantity   ln   -.   current_   ( invoiceLineQuantity   ln )   *   2 ) \n                    ( \\ _   -   val_   True )  Just   totalLineItems   - \n   runSelectReturningOne   $   select   $ \n   aggregate_   ( \\ ln   -   sum_   ( invoiceLineQuantity   ln ))   $ \n   all_   ( invoiceLine   chinookDb )  putStrLn   ( With a few simple lines, we ve double our sales figure to    ++   show   totalLineItems   ++    products sold! )  \n\n         \n    \n         \n             SELECT   SUM ( t0 . Quantity )   AS   res0  FROM   InvoiceLine   AS   t0 ;  -- With values: [];  -- Output: Before, we had Just 2240 total products sold  UPDATE   InvoiceLine  SET   Quantity = ( Quantity )   *   ( ? )  WHERE   ? ;  -- With values: [SQLInteger 2,SQLInteger 1];  SELECT   SUM ( t0 . Quantity )   AS   res0  FROM   InvoiceLine   AS   t0 ;  -- With values: [];  -- Output: With a few simple lines, we ve double our sales figure to Just 4480 products sold!  \n\n         \n    \n         \n             SELECT   SUM ( t0 . Quantity )   AS   res0  FROM   InvoiceLine   AS   t0 ;  -- Output: Before, we had Just 2240 total products sold  UPDATE   InvoiceLine  SET   Quantity = ( Quantity )   *   ( 2 )  WHERE   true ;  SELECT   SUM ( t0 . Quantity )   AS   res0  FROM   InvoiceLine   AS   t0 ;  -- Output: With a few simple lines, we ve double our sales figure to Just 4480 products sold!  \n\n         \n    \n         \n             SELECT   SUM ( ` t0 ` . ` Quantity ` )   AS   ` res0 `  FROM   ` InvoiceLine `   AS   ` t0 ` ;  -- Output: Before, we had Just 2240 total products sold  UPDATE   ` InvoiceLine `  SET   ` Quantity `= ( ` Quantity ` )   *   ( 2 )  WHERE   TRUE ;  SELECT   SUM ( ` t0 ` . ` Quantity ` )   AS   ` res0 `  FROM   ` InvoiceLine `   AS   ` t0 ` ;  -- Output: With a few simple lines, we ve double our sales figure to Just 4480 products sold!  \n\n         \n    \n         \n    \n                 \n                      Amazing! A few simple lines, and we've doubled our sales -- beam is awesome!", 
            "title": "Fine-grained updates"
        }, 
        {
            "location": "/user-guide/manipulation/delete/", 
            "text": "SQL \nDELETE\n expressions allow you to remove rows from a database.\n\n\nThe \ndelete\n function from \nDatabase.Beam.Query\n can be used to delete\nrows from a particular table. The function takes a table and a\ncondition for the \nWHERE\n clause. The function returns a \nSqlDelete\n\nobject that can be run in \nMonadBeam\n with \nrunDelete\n.\n\n\nFor example, to delete any customer, whose first name is Emilio.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n            \nMysql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunDelete\n \n$\n \ndelete\n \n(\ncustomer\n \nchinookDb\n)\n\n  \n(\n\\\nc\n \n-\n \ncustomerFirstName\n \nc\n \n==.\n \nEmilio\n)\n\n\n\n\n        \n\n    \n        \n\n            \nDELETE\n\n\nFROM\n \nCustomer\n\n\nWHERE\n \n(\nFirstName\n)\n=\n(\n?\n);\n\n\n\n-- With values: [SQLText \nEmilio\n];\n\n\n\n\n        \n\n    \n        \n\n            \nDELETE\n\n\nFROM\n \nCustomer\n \nAS\n \ndelete_target\n\n\nWHERE\n \n(\ndelete_target\n.\nFirstName\n)\n \n=\n \n(\nEmilio\n);\n\n\n\n\n        \n\n    \n        \n\n            \nDELETE\n\n\nFROM\n \n`\nCustomer\n`\n\n\nWHERE\n \n(\n`\nFirstName\n`\n)\n \n=\n \n(\nEmilio\n);\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nDELETE\n is fairly simple compared to the other manipulation commands,\nso that's really all there is to it. Expressions for the \nWHERE\n\nclause can be arbitrarily complex, assuming your backend supports it.\n\n\nFor example, to delete any invoice with more than five invoice lines\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nrunDelete\n \n$\n \ndelete\n \n(\ninvoice\n \nchinookDb\n)\n\n  \n(\n\\\ni\n \n-\n \n5\n \n.\n \nsubquery_\n \n(\naggregate_\n \n(\n\\\n_\n \n-\n \ncountAll_\n)\n \n$\n\n                         \ninvoiceLines\n \ni\n))\n\n\n\n\n        \n\n    \n        \n\n            \nDELETE\n\n\nFROM\n \nInvoice\n\n\nWHERE\n \n(\n?\n)\n(\n\n             \n(\nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n              \nFROM\n \nInvoiceLine\n \nAS\n \nt0\n\n              \nWHERE\n \n(\nt0\n.\nInvoiceId\n)\n=\n(\nInvoiceId\n)));\n\n\n\n-- With values: [SQLInteger 5];\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nThe example above was only given for SQLite because it violates a\nforeign key constraint in the underlying database, and other\nbackends are more pedantic", 
            "title": "DELETE"
        }, 
        {
            "location": "/schema-guide/migrations/", 
            "text": "In the User Guide we saw how to declare a schema for an already created database\nand use it to perform queries. Beam can also manage a database schema based on\nHaskell datatypes you feed it.\n\n\nThe migrations framework is meant to be a robust and modular way of\nmanaging schema changes. It is an optional part of beam provided in\nthe \nbeam-migrate\n package.\n\n\nInstall the migrations framework by running.\n\n\n$ cabal install beam-migrate\n\n# or\n\n$ stack install beam-migrate\n\n\n\n\n\nBasic concepts\n\n\nIn the user guide, we saw how we can use \ndefaultDbSettings\n to generate default\nmetadata that can be used to access the database. This default metadata is\nenough to query, but not enough for \nbeam-migrate\n. \nbeam-migrate\n offers the\n\ndefaultMigratableDbSettings\n function, which annotates the database schema with\nadditional information. Whereas \ndefaultDbSettings\n yields a value of type\n\nDatabaseSettings be db\n, \ndefaultMigratableDbSettings\n yields a value of type\n\nCheckedDatabaseSettings be db\n. You can recover a \nDatabaseSettings be db\n from\na \nCheckedDatabaseSettings be db\n value by applying the \nunCheckDatabase\n\nfunction.\n\n\nThe \nCheckedDatabaseSettings\n value contains the original \nDatabaseSettings\n\nalong with a series of \npredicates\n. Each \npredicate\n describes one aspect of\nthe database. As far as \nbeam-migrate\n is concerned, each database schema is\nfully specified by the set of predicates that apply to it. \nbeam-migrate\n calls\nthis the \nchecked type\n of the database.\n\n\nFor example, a database schema that consists of one table named \ntable\n with no\nfields is represented uniquely by the \nchecked type\n of \n[TableExistsPredicate\n\"table\"]\n. If you add a field \nfield1\n of type \nINT\n to the table, then the\nchecked type becomes \n[TableExistsPredicate \"table\", TableHasColumn \"table\"\n\"field1\" intType]\n.\n\n\n\n\nNote\n\n\nThe types are a bit more complicated than what they appear. In particular, a\npredicate can be of any type that satisfies the \nDatabasePredicate\n type\nclass. The predicates can be stored in a list because they are wrapped in\nthe \nSomeDatabasePredicate\n GADT that holds the type class instance as well.\n\n\n\n\nUsage modes\n\n\nbeam-migrate\n can be used as a library or a command-line tool in \nmanaged\n or\n\nunmanaged\n mode.\n\n\nThe \nbeam-migrate\n library\n\n\nThe \nbeam-migrate\n library provides syntax definitions for common SQL DDL tasks.\nIt also provides types for expressing migrations as transformations of one or\nmore schemas to another. \nbeam-migrate\n offers a built-in way to apply these\nmigrations to a production database, running only those migrations that are\nnecessary. You can also directly interpret the \nbeam-migrate\n DSL to hook your\nHaskell migrations into your own system.\n\n\nbeam-migrate\n is described in more detail in the \nbeam-migrate\n migrations\nguide\n\n\nThe \nbeam-migrate\n tool\n\n\nThere is an optional \nbeam-migrate\n command line tool, available in the\n\nbeam-migrate-cli\n package.\n\n\nThe \nbeam-migrate\n tool can generate a beam schema from a pre-existing database,\nmanage migrations for several production databases, automatically generate\nmigrations between two schemas, and much more. It is rather opinionated, and is\ndescribed in more detail in the \nbeam-migrate\n CLI guide\n\n\nAutomatic migration generation\n\n\nGiven two \nCheckedDatabaseSettings\n values, \nbeam-migrate\n can generate a set of\nSQL steps that will transform one schema to another. The generation of such\nsteps is an exceedingly difficult problem in general. \nbeam-migrate\n can\nautomatically handle most common cases, but it will not always succeed. In this\ncase, it can present to you a list of steps it thinks are best as well as what\nremains to be solved.\n\n\nThe migration generation is implemented as a proof search in linear logic\n1\n. In\nparticular, \nbeam-migrate\n views a migration as a linear logic proof of the form\n\na \u22b8 b\n, where \na\n is the set of predicates of the original schema and \nb\n is\nthe set of predicates in the target schema. \nbeam-migrate\n ships with a set of\ndefault proof steps. Backends can add to these steps for backend-specific\npredicates.\n\n\n\n\nNote\n\n\nAt this time, Haskell does not allow the expression of linear programs (this\nwill change with the introduction of linear types). Thus, migrations written\nin Haskell are not checked by GHC for linear-ness, but \nbeam-migrate\n will\nvalidate such migrations at run-time to the best of its ability.\n\n\n\n\nThe migration prover may not be able to find a migration in a sufficiently short\nperiod of time. \nbeam-migrate\n's algorithm is designed to terminate, but this\nmay take a while. Additionally, the prover will not automatically generate steps\nfor some migrations. For example, \nbeam-migrate\n will never rename a table\nwithout explicit instructions.\n\n\nAdvantages of checked migrations\n\n\nUnlike other database migration frameworks, the checking process allows\n\nbeam-migrate\n to be sure that the migration you specify will result in the\ndatabase type you want. Also, checked migrations allow the programmer to verify\nthat the database they are accessing indeed matches what their schema expects.\n\n\n\n\n\n\n\n\n\n\nLinear logic is a type of logic first described by Jean-Yves Gerard. In\nparticular, it constrains the weakening and strengthening rules of classical\nlogic. Intuitively, you can think of it as forcing the rule that each\nassumption is used exactly once to produce the result. Read\nmore \non Wikipedia\n.", 
            "title": "The Migrations Framework"
        }, 
        {
            "location": "/schema-guide/migrations/#basic-concepts", 
            "text": "In the user guide, we saw how we can use  defaultDbSettings  to generate default\nmetadata that can be used to access the database. This default metadata is\nenough to query, but not enough for  beam-migrate .  beam-migrate  offers the defaultMigratableDbSettings  function, which annotates the database schema with\nadditional information. Whereas  defaultDbSettings  yields a value of type DatabaseSettings be db ,  defaultMigratableDbSettings  yields a value of type CheckedDatabaseSettings be db . You can recover a  DatabaseSettings be db  from\na  CheckedDatabaseSettings be db  value by applying the  unCheckDatabase \nfunction.  The  CheckedDatabaseSettings  value contains the original  DatabaseSettings \nalong with a series of  predicates . Each  predicate  describes one aspect of\nthe database. As far as  beam-migrate  is concerned, each database schema is\nfully specified by the set of predicates that apply to it.  beam-migrate  calls\nthis the  checked type  of the database.  For example, a database schema that consists of one table named  table  with no\nfields is represented uniquely by the  checked type  of  [TableExistsPredicate\n\"table\"] . If you add a field  field1  of type  INT  to the table, then the\nchecked type becomes  [TableExistsPredicate \"table\", TableHasColumn \"table\"\n\"field1\" intType] .   Note  The types are a bit more complicated than what they appear. In particular, a\npredicate can be of any type that satisfies the  DatabasePredicate  type\nclass. The predicates can be stored in a list because they are wrapped in\nthe  SomeDatabasePredicate  GADT that holds the type class instance as well.", 
            "title": "Basic concepts"
        }, 
        {
            "location": "/schema-guide/migrations/#usage-modes", 
            "text": "beam-migrate  can be used as a library or a command-line tool in  managed  or unmanaged  mode.", 
            "title": "Usage modes"
        }, 
        {
            "location": "/schema-guide/migrations/#the-beam-migrate-library", 
            "text": "The  beam-migrate  library provides syntax definitions for common SQL DDL tasks.\nIt also provides types for expressing migrations as transformations of one or\nmore schemas to another.  beam-migrate  offers a built-in way to apply these\nmigrations to a production database, running only those migrations that are\nnecessary. You can also directly interpret the  beam-migrate  DSL to hook your\nHaskell migrations into your own system.  beam-migrate  is described in more detail in the  beam-migrate  migrations\nguide", 
            "title": "The beam-migrate library"
        }, 
        {
            "location": "/schema-guide/migrations/#the-beam-migrate-tool", 
            "text": "There is an optional  beam-migrate  command line tool, available in the beam-migrate-cli  package.  The  beam-migrate  tool can generate a beam schema from a pre-existing database,\nmanage migrations for several production databases, automatically generate\nmigrations between two schemas, and much more. It is rather opinionated, and is\ndescribed in more detail in the  beam-migrate  CLI guide", 
            "title": "The beam-migrate tool"
        }, 
        {
            "location": "/schema-guide/migrations/#automatic-migration-generation", 
            "text": "Given two  CheckedDatabaseSettings  values,  beam-migrate  can generate a set of\nSQL steps that will transform one schema to another. The generation of such\nsteps is an exceedingly difficult problem in general.  beam-migrate  can\nautomatically handle most common cases, but it will not always succeed. In this\ncase, it can present to you a list of steps it thinks are best as well as what\nremains to be solved.  The migration generation is implemented as a proof search in linear logic 1 . In\nparticular,  beam-migrate  views a migration as a linear logic proof of the form a \u22b8 b , where  a  is the set of predicates of the original schema and  b  is\nthe set of predicates in the target schema.  beam-migrate  ships with a set of\ndefault proof steps. Backends can add to these steps for backend-specific\npredicates.   Note  At this time, Haskell does not allow the expression of linear programs (this\nwill change with the introduction of linear types). Thus, migrations written\nin Haskell are not checked by GHC for linear-ness, but  beam-migrate  will\nvalidate such migrations at run-time to the best of its ability.   The migration prover may not be able to find a migration in a sufficiently short\nperiod of time.  beam-migrate 's algorithm is designed to terminate, but this\nmay take a while. Additionally, the prover will not automatically generate steps\nfor some migrations. For example,  beam-migrate  will never rename a table\nwithout explicit instructions.", 
            "title": "Automatic migration generation"
        }, 
        {
            "location": "/schema-guide/migrations/#advantages-of-checked-migrations", 
            "text": "Unlike other database migration frameworks, the checking process allows beam-migrate  to be sure that the migration you specify will result in the\ndatabase type you want. Also, checked migrations allow the programmer to verify\nthat the database they are accessing indeed matches what their schema expects.      Linear logic is a type of logic first described by Jean-Yves Gerard. In\nparticular, it constrains the weakening and strengthening rules of classical\nlogic. Intuitively, you can think of it as forcing the rule that each\nassumption is used exactly once to produce the result. Read\nmore  on Wikipedia .", 
            "title": "Advantages of checked migrations"
        }, 
        {
            "location": "/schema-guide/tool/", 
            "text": "Tool", 
            "title": "The beam-migrate tool"
        }, 
        {
            "location": "/schema-guide/library/", 
            "text": "supported", 
            "title": "The beam-migrate library"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/", 
            "text": "The \nbeam-postgres\n backend is the most feature complete SQL backend for beam.\nThe Postgres RDBMS supports most of the standards beam follows, so you can\nusually expect most queries to simply work. Additionally, \nbeam-postgres\n is\npart of the standard Beam distribution, and so upgrades are applied\nperiodically, and new functions are added to achieve feature-parity with the\nlatest Postgres stable\n\n\nPostgres-specific data types\n\n\nPostgres has several data types not available from \nbeam-core\n. The\n\nbeam-postgres\n library provides several types and functions to make working\nwith these easier.\n\n\nThe \ntsvector\n and \ntsquery\n types\n\n\nThe \ntsvector\n and \ntsquery\n types form the basis of full-text search\nin Postgres. They correspond to the haskell types \nTsVector\n and\n\nTsQuery\n, which are just newtype-wrappers over \nByteString\n.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \npure\n \n(\nPg\n.\ntoTsVector\n \n(\nJust\n \nPg\n.\nenglish\n)\n \n(\nas_\n \n@\nString\n \n(\nval_\n \nThe quick brown fox jumps over the lazy dog\n)))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nto_tsvector\n(\nenglish\n,\n \nThe quick brown fox jumps over the lazy dog\n)\n \nAS\n \nres0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nPostgres extensions\n\n\nSELECT\n locking clause\n\n\nPostgres allows you to explicitly lock rows retrieved during a select\nusing the \nlocking\nclause\n.\n\n\nBeam supports most of the Postgres locking clause. However, there are some\ninvariants that are currently not checked at compile time. For example, Postgres\ndoes not allow locking clauses with queries that use \nUNION\n, \nEXCEPT\n, or\n\nINTERSECT\n or those with aggregates. Since all these queries have the same type\nin Beam, we cannot catch these errors at compile-time. Current guidance is to\nonly use the locking clause in top-level queries that you know to be\nsafe.\n\n\nThe following example finds all customers living in Dublin, and requests a \nROW\nSHARE\n lock for each row. This prevents concurrent updates from updating these\nrows until the current transaction is complete.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nPg\n.\nlockingAllTablesFor_\n \nPg\n.\nPgSelectLockingStrengthShare\n \nNothing\n \n$\n\n  \nfilter_\n \n(\n\\\nc\n \n-\n \nfromMaybe_\n \n \n(\naddressCity\n \n(\ncustomerAddress\n \nc\n))\n \n==.\n \nDublin\n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nCOALESCE\n(\nt0\n.\nCity\n,\n \n))\n \n=\n \n(\nDublin\n)\n\n  \nFOR\n \nSHARE\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNow, suppose we want to update these rows, so we'll want to lock them for an update.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nPg\n.\nlockingAllTablesFor_\n \nPg\n.\nPgSelectLockingStrengthUpdate\n \nNothing\n \n$\n\n  \nfilter_\n \n(\n\\\nc\n \n-\n \nfromMaybe_\n \n \n(\naddressCity\n \n(\ncustomerAddress\n \nc\n))\n \n==.\n \nDublin\n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nCOALESCE\n(\nt0\n.\nCity\n,\n \n))\n \n=\n \n(\nDublin\n)\n\n  \nFOR\n\n  \nUPDATE\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nHowever, because there may be a lot of customers in Dublin that we'd like to\nupdate, this may block for a long time. Perhaps, we'd only like to lock rows\nthat aren't already locked. This is inconsistent in general, but we do not\nalways care.  Postgres offers the \nSKIP LOCKED\n clause for this\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nPg\n.\nlockingAllTablesFor_\n \nPg\n.\nPgSelectLockingStrengthUpdate\n \n(\nJust\n \nPg\n.\nPgSelectLockingOptionsSkipLocked\n)\n \n$\n\n  \nfilter_\n \n(\n\\\nc\n \n-\n \nfromMaybe_\n \n \n(\naddressCity\n \n(\ncustomerAddress\n \nc\n))\n \n==.\n \nDublin\n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nCOALESCE\n(\nt0\n.\nCity\n,\n \n))\n \n=\n \n(\nDublin\n)\n\n  \nFOR\n\n  \nUPDATE\n \nSKIP\n \nLOCKED\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOr, if we do care, and don't want to wait anyway, we can ask Postgres to fail\nearly instead of blocking, using \nNO WAIT\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nPg\n.\nlockingAllTablesFor_\n \nPg\n.\nPgSelectLockingStrengthUpdate\n \n(\nJust\n \nPg\n.\nPgSelectLockingOptionsNoWait\n)\n \n$\n\n  \nfilter_\n \n(\n\\\nc\n \n-\n \nfromMaybe_\n \n \n(\naddressCity\n \n(\ncustomerAddress\n \nc\n))\n \n==.\n \nDublin\n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nCOALESCE\n(\nt0\n.\nCity\n,\n \n))\n \n=\n \n(\nDublin\n)\n\n  \nFOR\n\n  \nUPDATE\n \nNOWAIT\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can also specify the locking clauses when \nJOIN\ning. Suppose we want to get\nall customers who live in London \nand\n have a support rep who lives in Paris,\nand skipping rows that we can't lock.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nPg\n.\nlockingAllTablesFor_\n \nPg\n.\nPgSelectLockingStrengthShare\n \n(\nJust\n \nPg\n.\nPgSelectLockingOptionsSkipLocked\n)\n \n$\n\n  \ndo\n \ncustomer\n \n-\n \nfilter_\n \n(\n\\\nc\n \n-\n \nfromMaybe_\n \n \n(\naddressCity\n \n(\ncustomerAddress\n \nc\n))\n \n==.\n \nLondon\n)\n \n$\n\n                 \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n     \nemployee\n \n-\n \njoin_\n \n(\nemployee\n \nchinookDb\n)\n\n                       \n(\n\\\ne\n \n-\n \nfromMaybe_\n \n \n(\naddressCity\n \n(\nemployeeAddress\n \ne\n))\n \n==.\n \nParis\n \n.\n\n                              \njust_\n \n(\npk\n \ne\n)\n \n==.\n \ncustomerSupportRep\n \ncustomer\n)\n\n     \npure\n \n(\ncustomerFirstName\n \ncustomer\n,\n \ncustomerLastName\n \ncustomer\n,\n \npk\n \nemployee\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres2\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n \nON\n \n((\nCOALESCE\n(\nt1\n.\nCity\n,\n \n))\n \n=\n \n(\nParis\n))\n\n\nAND\n \n((\nt1\n.\nEmployeeId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n     \nFROM\n \n(\nt0\n.\nSupportRepId\n))\n\n\nWHERE\n \n(\nCOALESCE\n(\nt0\n.\nCity\n,\n \n))\n \n=\n \n(\nLondon\n)\n\n  \nFOR\n \nSHARE\n \nSKIP\n \nLOCKED\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou may notice that this query will lock rows in both the customers and\nemployees table. This may not be what you want. You can also specify which\ntables to lock by using the \nlockingFor_\n function. This requires you to specify\nwhich locks you want to hold by returning them from your query. For example, to\nlock only the customers table\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nPg\n.\nlockingFor_\n \nPg\n.\nPgSelectLockingStrengthShare\n \n(\nJust\n \nPg\n.\nPgSelectLockingOptionsSkipLocked\n)\n \n$\n\n  \ndo\n \n(\ncustomerLock\n,\n \ncustomer\n)\n \n-\n \nPg\n.\nlocked_\n \n(\ncustomer\n \nchinookDb\n)\n\n     \nguard_\n \n(\nfromMaybe_\n \n \n(\naddressCity\n \n(\ncustomerAddress\n \ncustomer\n))\n \n==.\n \nLondon\n)\n\n     \nemployee\n \n-\n \nfilter_\n \n(\n\\\ne\n \n-\n \nfromMaybe_\n \n \n(\naddressCity\n \n(\nemployeeAddress\n \ne\n))\n \n==.\n \nParis\n \n.\n\n                                \njust_\n \n(\npk\n \ne\n)\n \n==.\n \ncustomerSupportRep\n \ncustomer\n)\n \n$\n\n                 \nall_\n \n(\nemployee\n \nchinookDb\n)\n\n     \npure\n \n((\ncustomerFirstName\n \ncustomer\n,\n \ncustomerLastName\n \ncustomer\n,\n \npk\n \nemployee\n)\n \n`\nPg\n.\nwithLocks_\n`\n \ncustomerLock\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres2\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n\n\nWHERE\n \n((\nCOALESCE\n(\nt0\n.\nCity\n,\n \n))\n \n=\n \n(\nLondon\n))\n\n  \nAND\n \n(((\nCOALESCE\n(\nt1\n.\nCity\n,\n \n))\n \n=\n \n(\nParis\n))\n\n       \nAND\n \n((\nt1\n.\nEmployeeId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n            \nFROM\n \n(\nt0\n.\nSupportRepId\n)))\n\n  \nFOR\n \nSHARE\n \nOF\n \nt0\n \nSKIP\n \nLOCKED\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nIn order to use the explicit locking clause, you need to use the \nlocked_\n\nfunction to get a reference to a lock for a particular table. This forces the\nlocked table to be part of the join, which is a requirement for the Postgres\nlocking clause. You can think of \nlocked_\n as exactly like \nall_\n, except it\nreturns a table lock as the first return value.\n\n\n\n\nTip\n\n\nLocks can be combined monoidally, using \nmappend\n or \n(\n)\n. You can use this\nto lock multiple tables, by passing the result of \nmappend\n to \nwithLocks_\n.\n\n\nIf you return \nmempty\n as the first argument, then this recovers the standard\nbehavior of locking all tables.\n\n\n\n\nlockingFor_\n is the most general locking combinator. You can recover the same\nbehavior as \nlockingAllTablesFor_\n by using the \nlockAll_\n function.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nPg\n.\nlockingFor_\n \nPg\n.\nPgSelectLockingStrengthShare\n \n(\nJust\n \nPg\n.\nPgSelectLockingOptionsSkipLocked\n)\n \n$\n\n  \ndo\n \n(\ncustomerLock\n,\n \ncustomer\n)\n \n-\n \nPg\n.\nlocked_\n \n(\ncustomer\n \nchinookDb\n)\n\n     \nguard_\n \n(\nfromMaybe_\n \n \n(\naddressCity\n \n(\ncustomerAddress\n \ncustomer\n))\n \n==.\n \nLondon\n)\n\n     \nemployee\n \n-\n \nfilter_\n \n(\n\\\ne\n \n-\n \nfromMaybe_\n \n \n(\naddressCity\n \n(\nemployeeAddress\n \ne\n))\n \n==.\n \nParis\n \n.\n\n                                \njust_\n \n(\npk\n \ne\n)\n \n==.\n \ncustomerSupportRep\n \ncustomer\n)\n \n$\n\n                 \nall_\n \n(\nemployee\n \nchinookDb\n)\n\n     \npure\n \n(\nPg\n.\nlockAll_\n \n(\ncustomerFirstName\n \ncustomer\n,\n \ncustomerLastName\n \ncustomer\n,\n \npk\n \nemployee\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nEmployeeId\n \nAS\n \nres2\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nCROSS\n \nJOIN\n \nEmployee\n \nAS\n \nt1\n\n\nWHERE\n \n((\nCOALESCE\n(\nt0\n.\nCity\n,\n \n))\n \n=\n \n(\nLondon\n))\n\n  \nAND\n \n(((\nCOALESCE\n(\nt1\n.\nCity\n,\n \n))\n \n=\n \n(\nParis\n))\n\n       \nAND\n \n((\nt1\n.\nEmployeeId\n)\n \nIS\n \nNOT\n \nDISTINCT\n\n            \nFROM\n \n(\nt0\n.\nSupportRepId\n)))\n\n  \nFOR\n \nSHARE\n \nSKIP\n \nLOCKED\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\nTable locks have the type \nPgLockedTables s\n, where \ns\n is the thread\nparameter, as described\n\nhere\n\n\n\n\nDISTINCT ON\n support\n\n\nPostgres supports the \nDISTINCT ON\n clause with selects to return distinct\nresults based on a particular key. The \nbeam-postgres\n package provides the\n\npgNubBy_\n function to use this feature.\n\n\nFor example, to get an arbitrary customer from each distinct area code\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nPg\n.\npgNubBy_\n \n(\naddressPostalCode\n \n.\n \ncustomerAddress\n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nDISTINCT\n \nON\n \n(\nt0\n.\nPostalCode\n)\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n                   \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n                   \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n                   \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n                   \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n                   \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n                   \nt0\n.\nState\n \nAS\n \nres6\n,\n\n                   \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n                   \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n                   \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n                   \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n                   \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n                   \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nAggregates\n\n\nstring_agg\n\n\nThe Postgres \nstring_agg\n aggregate combines all column values in a group\nseparated by a given separator. \nbeam-postgres\n provides \npgStringAgg\n and\n\npgStringAggOver\n to use the unquantified and quantified versions of the\n\nstring_agg\n aggregate appropriately.\n\n\nFor example, to put together a list of all cities in all the postal codes we have for customers,\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\nc\n \n-\n \n(\n \ngroup_\n \n(\naddressPostalCode\n \n(\ncustomerAddress\n \nc\n))\n\n                  \n,\n \nPg\n.\npgStringAgg\n \n(\ncoalesce_\n \n[\naddressCity\n \n(\ncustomerAddress\n \nc\n)]\n \n)\n \n,\n)\n \n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nPostalCode\n \nAS\n \nres0\n,\n\n       \nstring_agg\n(\nCOALESCE\n(\nt0\n.\nCity\n,\n \n),\n \n,\n)\n \nAS\n \nres1\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nPostalCode\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe above will include one city multiple times if its shared by multiple customers.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\nc\n \n-\n \n(\n \ngroup_\n \n(\naddressPostalCode\n \n(\ncustomerAddress\n \nc\n))\n\n                  \n,\n \nPg\n.\npgStringAggOver\n \ndistinctInGroup_\n \n(\ncoalesce_\n \n[\naddressCity\n \n(\ncustomerAddress\n \nc\n)]\n \n)\n \n,\n)\n \n)\n \n$\n\n  \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nPostalCode\n \nAS\n \nres0\n,\n\n       \nstring_agg\n(\nDISTINCT\n \nCOALESCE\n(\nt0\n.\nCity\n,\n \n),\n \n,\n)\n \nAS\n \nres1\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nPostalCode\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nON CONFLICT\n\n\nBeam supports \nON CONFLICT\n statements in a Postgres-specific version of\n\ninsert\n. The code below uses the following imports to ensure the correct \ninsert\n is used:\n\n\nimport\n \nDatabase.Beam\n \nhiding\n \n(\ninsert\n)\n\n\nimport\n \nqualified\n \nDatabase.Beam.Postgres\n \nas\n \nPg\n\n\n\n\n\n\nThe 3rd argument of the \ninsert\n from \nDatabase.Beam.Postgres\n allows\nyou to specify an \nON CONFLICT\n clause. You can use\n\nonConflictDefault\n in order to recover the standard behavior.\n\n\ninsert\n \n::\n \nDatabaseEntity\n \nPostgres\n \ndb\n \n(\nTableEntity\n \ntable\n)\n\n       \n-\n \nSqlInsertValues\n \nPgInsertValuesSyntax\n \ntable\n\n       \n-\n \nPgInsertOnConflict\n \ntable\n\n       \n-\n \nSqlInsert\n \nPgInsertSyntax\n\n\n\n\n\n\nAn explicit \nON CONFLICT\n statement requires to specify the indexes\nwhich are conflicting and an action to take when a conflict is\ndiscovered. The \nonConflict\n function allows you to specify these\nparts of the \nON CONFLICT\n clause.\n\n\nonConflict\n \n::\n \nBeamable\n \ntbl\n\n           \n=\n \nPgInsertOnConflictTarget\n \ntbl\n\n           \n-\n \nPgConflictAction\n \ntbl\n\n           \n-\n \nPgInsertOnConflict\n \ntbl\n\n\n\n\n\n\nActing on any conflict\n\n\nThe \nanyConflict\n value causes the action to be executed when any\nindex or constraint is violated by the specified \nINSERT\n. The\nfollowing example causes any conflicting update to be ignored. This\ncould be useful if you want to upsert rows into a database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- import qualified Database.Beam.Postgres as Pg\n\n\nlet\n\n  \nnewCustomer\n \n=\n \nCustomer\n \n42\n \nJohn\n \nDoe\n \nNothing\n \n(\nAddress\n \n(\nJust\n \nStreet\n)\n \n(\nJust\n \nCity\n)\n \n(\nJust\n \nState\n)\n \nNothing\n \nNothing\n)\n \nNothing\n \nNothing\n \njohn.doe@johndoe.com\n \nnothing_\n\n\n\nrunInsert\n \n$\n\n  \nPg\n.\ninsert\n \n(\ncustomer\n \nchinookDb\n)\n \n(\ninsertValues\n \n[\nnewCustomer\n])\n \n$\n\n    \nPg\n.\nonConflict\n\n      \nPg\n.\nanyConflict\n\n      \nPg\n.\nonConflictDoNothing\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nCustomer\n(\nCustomerId\n,\n\n                       \nFirstName\n,\n\n                       \nLastName\n,\n\n                       \nCompany\n,\n\n                       \nAddress\n,\n\n                       \nCity\n,\n\n                       \nState\n,\n\n                       \nCountry\n,\n\n                       \nPostalCode\n,\n\n                       \nPhone\n,\n\n                       \nFax\n,\n\n                       \nEmail\n,\n\n                       \nSupportRepId\n)\n\n\nVALUES\n \n(\n42\n,\n\n        \nJohn\n,\n\n        \nDoe\n,\n\n        \nnull\n,\n\n        \nStreet\n,\n\n        \nCity\n,\n\n        \nState\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \njohn.doe@johndoe.com\n,\n\n        \nnull\n)\n \nON\n \nCONFLICT\n \nDO\n \nNOTHING\n;\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nActing only on certain conflicts\n\n\nSometimes you only want to perform an action if a certain constraint\nis violated.  If the conflicting index or constraint is on a field,\nyou can specify the fields with the function \nconflictingFields\n.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- import qualified Database.Beam.Postgres as Pg\n\n\nlet\n\n  \nnewCustomer\n \n=\n \nCustomer\n \n42\n \nJohn\n \nDoe\n \nNothing\n \n(\nAddress\n \n(\nJust\n \nStreet\n)\n \n(\nJust\n \nCity\n)\n \n(\nJust\n \nState\n)\n \nNothing\n \nNothing\n)\n \nNothing\n \nNothing\n \njohn.doe@johndoe.com\n \nnothing_\n\n\n\nrunInsert\n \n$\n\n  \nPg\n.\ninsert\n \n(\ncustomer\n \nchinookDb\n)\n \n(\ninsertValues\n \n[\nnewCustomer\n])\n \n$\n\n    \nPg\n.\nonConflict\n\n      \n(\nPg\n.\nconflictingFields\n \nprimaryKey\n)\n\n      \nPg\n.\nonConflictSetAll\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nCustomer\n(\nCustomerId\n,\n\n                       \nFirstName\n,\n\n                       \nLastName\n,\n\n                       \nCompany\n,\n\n                       \nAddress\n,\n\n                       \nCity\n,\n\n                       \nState\n,\n\n                       \nCountry\n,\n\n                       \nPostalCode\n,\n\n                       \nPhone\n,\n\n                       \nFax\n,\n\n                       \nEmail\n,\n\n                       \nSupportRepId\n)\n\n\nVALUES\n \n(\n42\n,\n\n        \nJohn\n,\n\n        \nDoe\n,\n\n        \nnull\n,\n\n        \nStreet\n,\n\n        \nCity\n,\n\n        \nState\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \njohn.doe@johndoe.com\n,\n\n        \nnull\n)\n \nON\n \nCONFLICT\n \n(\nCustomerId\n)\n \nDO\n\n\nUPDATE\n\n\nSET\n \nCustomerId\n=\n(\nexcluded\n.\nCustomerId\n),\n\n    \nFirstName\n=\n(\nexcluded\n.\nFirstName\n),\n\n    \nLastName\n=\n(\nexcluded\n.\nLastName\n),\n\n    \nCompany\n=\n(\nexcluded\n.\nCompany\n),\n\n    \nAddress\n=\n(\nexcluded\n.\nAddress\n),\n\n    \nCity\n=\n(\nexcluded\n.\nCity\n),\n\n    \nState\n=\n(\nexcluded\n.\nState\n),\n\n    \nCountry\n=\n(\nexcluded\n.\nCountry\n),\n\n    \nPostalCode\n=\n(\nexcluded\n.\nPostalCode\n),\n\n    \nPhone\n=\n(\nexcluded\n.\nPhone\n),\n\n    \nFax\n=\n(\nexcluded\n.\nFax\n),\n\n    \nEmail\n=\n(\nexcluded\n.\nEmail\n),\n\n    \nSupportRepId\n=\n(\nexcluded\n.\nSupportRepId\n);\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\nTo specify a conflict on the primary keys, use \nconflictingField primaryKey\n.\n\n\n\n\nIf the conflict target is an index, use \nconflictingConstraint\n, and supply the name of the constraint\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- import qualified Database.Beam.Postgres as Pg\n\n\nlet\n\n  \nnewCustomer\n \n=\n \nCustomer\n \n42\n \nJohn\n \nDoe\n \nNothing\n \n(\nAddress\n \n(\nJust\n \nStreet\n)\n \n(\nJust\n \nCity\n)\n \n(\nJust\n \nState\n)\n \nNothing\n \nNothing\n)\n \nNothing\n \nNothing\n \njohn.doe@johndoe.com\n \nnothing_\n\n\n\nrunInsert\n \n$\n\n  \nPg\n.\ninsert\n \n(\ncustomer\n \nchinookDb\n)\n \n(\ninsertValues\n \n[\nnewCustomer\n])\n \n$\n\n    \nPg\n.\nonConflict\n\n      \n(\nPg\n.\nconflictingConstraint\n \nPK_Customer\n)\n\n      \nPg\n.\nonConflictSetAll\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nCustomer\n(\nCustomerId\n,\n\n                       \nFirstName\n,\n\n                       \nLastName\n,\n\n                       \nCompany\n,\n\n                       \nAddress\n,\n\n                       \nCity\n,\n\n                       \nState\n,\n\n                       \nCountry\n,\n\n                       \nPostalCode\n,\n\n                       \nPhone\n,\n\n                       \nFax\n,\n\n                       \nEmail\n,\n\n                       \nSupportRepId\n)\n\n\nVALUES\n \n(\n42\n,\n\n        \nJohn\n,\n\n        \nDoe\n,\n\n        \nnull\n,\n\n        \nStreet\n,\n\n        \nCity\n,\n\n        \nState\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \njohn.doe@johndoe.com\n,\n\n        \nnull\n)\n \nON\n \nCONFLICT\n \nON\n \nCONSTRAINT\n \nPK_Customer\n \nDO\n\n\nUPDATE\n\n\nSET\n \nCustomerId\n=\n(\nexcluded\n.\nCustomerId\n),\n\n    \nFirstName\n=\n(\nexcluded\n.\nFirstName\n),\n\n    \nLastName\n=\n(\nexcluded\n.\nLastName\n),\n\n    \nCompany\n=\n(\nexcluded\n.\nCompany\n),\n\n    \nAddress\n=\n(\nexcluded\n.\nAddress\n),\n\n    \nCity\n=\n(\nexcluded\n.\nCity\n),\n\n    \nState\n=\n(\nexcluded\n.\nState\n),\n\n    \nCountry\n=\n(\nexcluded\n.\nCountry\n),\n\n    \nPostalCode\n=\n(\nexcluded\n.\nPostalCode\n),\n\n    \nPhone\n=\n(\nexcluded\n.\nPhone\n),\n\n    \nFax\n=\n(\nexcluded\n.\nFax\n),\n\n    \nEmail\n=\n(\nexcluded\n.\nEmail\n),\n\n    \nSupportRepId\n=\n(\nexcluded\n.\nSupportRepId\n);\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nSpecifying actions\n\n\nOften times, you do not want to update every field on a conflict. For\nexample, for upserts, you rarely want to update the primary key. The\nfunction \nonConflictUpdateInstead\n allows you to restrict which fields\nare updated in the case of a conflict. The required function argument\nis a projection of which fields ought to be updated.\n\n\nIn the example below, we insert a new row, but if a row with the given\nprimary key already exists, we update \nonly\n the first and last name.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- import qualified Database.Beam.Postgres as Pg\n\n\nlet\n\n  \nnewCustomer\n \n=\n \nCustomer\n \n42\n \nJohn\n \nDoe\n \nNothing\n \n(\nAddress\n \n(\nJust\n \nStreet\n)\n \n(\nJust\n \nCity\n)\n \n(\nJust\n \nState\n)\n \nNothing\n \nNothing\n)\n \nNothing\n \nNothing\n \njohn.doe@johndoe.com\n \nnothing_\n\n\n\nrunInsert\n \n$\n\n  \nPg\n.\ninsert\n \n(\ncustomer\n \nchinookDb\n)\n \n(\ninsertValues\n \n[\nnewCustomer\n])\n \n$\n\n    \nPg\n.\nonConflict\n\n      \n(\nPg\n.\nconflictingFields\n \nprimaryKey\n)\n\n      \n(\nPg\n.\nonConflictUpdateInstead\n\n         \n(\n\\\nc\n \n-\n \n(\n \ncustomerFirstName\n \nc\n\n                \n,\n \ncustomerLastName\n \nc\n \n)))\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nCustomer\n(\nCustomerId\n,\n\n                       \nFirstName\n,\n\n                       \nLastName\n,\n\n                       \nCompany\n,\n\n                       \nAddress\n,\n\n                       \nCity\n,\n\n                       \nState\n,\n\n                       \nCountry\n,\n\n                       \nPostalCode\n,\n\n                       \nPhone\n,\n\n                       \nFax\n,\n\n                       \nEmail\n,\n\n                       \nSupportRepId\n)\n\n\nVALUES\n \n(\n42\n,\n\n        \nJohn\n,\n\n        \nDoe\n,\n\n        \nnull\n,\n\n        \nStreet\n,\n\n        \nCity\n,\n\n        \nState\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \njohn.doe@johndoe.com\n,\n\n        \nnull\n)\n \nON\n \nCONFLICT\n \n(\nCustomerId\n)\n \nDO\n\n\nUPDATE\n\n\nSET\n \nFirstName\n=\n(\nexcluded\n.\nFirstName\n),\n\n    \nLastName\n=\n(\nexcluded\n.\nLastName\n);\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou can also specify a more specific update, using the\n\nonConflictUpdateSet\n function. This is the most general form of the\npostgres \nON CONFLICT\n action. The \nexcluded\n table is provided as the\nsecond argument. The syntax of the updates is similar to that of\n\nupdate\n.\n\n\nIn the following example, we append the old first name to the new\nfirst name and replace the old last name.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- import qualified Database.Beam.Postgres as Pg\n\n\nlet\n\n  \nnewCustomer\n \n=\n \nCustomer\n \n42\n \nJohn\n \nDoe\n \nNothing\n \n(\nAddress\n \n(\nJust\n \nStreet\n)\n \n(\nJust\n \nCity\n)\n \n(\nJust\n \nState\n)\n \nNothing\n \nNothing\n)\n \nNothing\n \nNothing\n \njohn.doe@johndoe.com\n \nnothing_\n\n\n\nrunInsert\n \n$\n\n  \nPg\n.\ninsert\n \n(\ncustomer\n \nchinookDb\n)\n \n(\ninsertValues\n \n[\nnewCustomer\n])\n \n$\n\n    \nPg\n.\nonConflict\n\n      \n(\nPg\n.\nconflictingFields\n \nprimaryKey\n)\n\n      \n(\nPg\n.\nonConflictUpdateSet\n\n        \n-- tbl is the old row, tblExcluded is the row proposed for insertion\n\n        \n(\n\\\ntbl\n \ntblExcluded\n \n-\n \nmconcat\n\n          \n[\n \ncustomerFirstName\n \ntbl\n \n-.\n \nconcat_\n \n[\n \ncurrent_\n \n(\ncustomerFirstName\n \ntbl\n),\n  \ncustomerFirstName\n \ntblExcluded\n \n]\n\n          \n,\n \ncustomerLastName\n \ntbl\n \n-.\n \ncustomerLastName\n \ntblExcluded\n \n]\n\n        \n)\n\n      \n)\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nCustomer\n(\nCustomerId\n,\n\n                       \nFirstName\n,\n\n                       \nLastName\n,\n\n                       \nCompany\n,\n\n                       \nAddress\n,\n\n                       \nCity\n,\n\n                       \nState\n,\n\n                       \nCountry\n,\n\n                       \nPostalCode\n,\n\n                       \nPhone\n,\n\n                       \nFax\n,\n\n                       \nEmail\n,\n\n                       \nSupportRepId\n)\n\n\nVALUES\n \n(\n42\n,\n\n        \nJohn\n,\n\n        \nDoe\n,\n\n        \nnull\n,\n\n        \nStreet\n,\n\n        \nCity\n,\n\n        \nState\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \nnull\n,\n\n        \njohn.doe@johndoe.com\n,\n\n        \nnull\n)\n \nON\n \nCONFLICT\n \n(\nCustomerId\n)\n \nDO\n\n\nUPDATE\n\n\nSET\n \nFirstName\n=\n(\nCONCAT\n(\nCustomer\n.\nFirstName\n,\n \nexcluded\n.\nFirstName\n)),\n\n    \nLastName\n=\n(\nexcluded\n.\nLastName\n);", 
            "title": "beam-postgres"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#postgres-specific-data-types", 
            "text": "Postgres has several data types not available from  beam-core . The beam-postgres  library provides several types and functions to make working\nwith these easier.", 
            "title": "Postgres-specific data types"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#the-tsvector-and-tsquery-types", 
            "text": "The  tsvector  and  tsquery  types form the basis of full-text search\nin Postgres. They correspond to the haskell types  TsVector  and TsQuery , which are just newtype-wrappers over  ByteString .  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             pure   ( Pg . toTsVector   ( Just   Pg . english )   ( as_   @ String   ( val_   The quick brown fox jumps over the lazy dog )))  \n\n         \n    \n         \n             SELECT   to_tsvector ( english ,   The quick brown fox jumps over the lazy dog )   AS   res0", 
            "title": "The tsvector and tsquery types"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#postgres-extensions", 
            "text": "", 
            "title": "Postgres extensions"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#select-locking-clause", 
            "text": "Postgres allows you to explicitly lock rows retrieved during a select\nusing the  locking\nclause .  Beam supports most of the Postgres locking clause. However, there are some\ninvariants that are currently not checked at compile time. For example, Postgres\ndoes not allow locking clauses with queries that use  UNION ,  EXCEPT , or INTERSECT  or those with aggregates. Since all these queries have the same type\nin Beam, we cannot catch these errors at compile-time. Current guidance is to\nonly use the locking clause in top-level queries that you know to be\nsafe.  The following example finds all customers living in Dublin, and requests a  ROW\nSHARE  lock for each row. This prevents concurrent updates from updating these\nrows until the current transaction is complete.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             Pg . lockingAllTablesFor_   Pg . PgSelectLockingStrengthShare   Nothing   $ \n   filter_   ( \\ c   -   fromMaybe_     ( addressCity   ( customerAddress   c ))   ==.   Dublin )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( COALESCE ( t0 . City ,   ))   =   ( Dublin ) \n   FOR   SHARE  \n\n         \n    \n         \n    \n                 \n                      Now, suppose we want to update these rows, so we'll want to lock them for an update.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             Pg . lockingAllTablesFor_   Pg . PgSelectLockingStrengthUpdate   Nothing   $ \n   filter_   ( \\ c   -   fromMaybe_     ( addressCity   ( customerAddress   c ))   ==.   Dublin )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( COALESCE ( t0 . City ,   ))   =   ( Dublin ) \n   FOR \n   UPDATE  \n\n         \n    \n         \n    \n                 \n                      However, because there may be a lot of customers in Dublin that we'd like to\nupdate, this may block for a long time. Perhaps, we'd only like to lock rows\nthat aren't already locked. This is inconsistent in general, but we do not\nalways care.  Postgres offers the  SKIP LOCKED  clause for this  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             Pg . lockingAllTablesFor_   Pg . PgSelectLockingStrengthUpdate   ( Just   Pg . PgSelectLockingOptionsSkipLocked )   $ \n   filter_   ( \\ c   -   fromMaybe_     ( addressCity   ( customerAddress   c ))   ==.   Dublin )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( COALESCE ( t0 . City ,   ))   =   ( Dublin ) \n   FOR \n   UPDATE   SKIP   LOCKED  \n\n         \n    \n         \n    \n                 \n                      Or, if we do care, and don't want to wait anyway, we can ask Postgres to fail\nearly instead of blocking, using  NO WAIT  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             Pg . lockingAllTablesFor_   Pg . PgSelectLockingStrengthUpdate   ( Just   Pg . PgSelectLockingOptionsNoWait )   $ \n   filter_   ( \\ c   -   fromMaybe_     ( addressCity   ( customerAddress   c ))   ==.   Dublin )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( COALESCE ( t0 . City ,   ))   =   ( Dublin ) \n   FOR \n   UPDATE   NOWAIT  \n\n         \n    \n         \n    \n                 \n                      We can also specify the locking clauses when  JOIN ing. Suppose we want to get\nall customers who live in London  and  have a support rep who lives in Paris,\nand skipping rows that we can't lock.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             Pg . lockingAllTablesFor_   Pg . PgSelectLockingStrengthShare   ( Just   Pg . PgSelectLockingOptionsSkipLocked )   $ \n   do   customer   -   filter_   ( \\ c   -   fromMaybe_     ( addressCity   ( customerAddress   c ))   ==.   London )   $ \n                  all_   ( customer   chinookDb ) \n      employee   -   join_   ( employee   chinookDb ) \n                        ( \\ e   -   fromMaybe_     ( addressCity   ( employeeAddress   e ))   ==.   Paris   . \n                               just_   ( pk   e )   ==.   customerSupportRep   customer ) \n      pure   ( customerFirstName   customer ,   customerLastName   customer ,   pk   employee )  \n\n         \n    \n         \n             SELECT   t0 . FirstName   AS   res0 , \n        t0 . LastName   AS   res1 , \n        t1 . EmployeeId   AS   res2  FROM   Customer   AS   t0  INNER   JOIN   Employee   AS   t1   ON   (( COALESCE ( t1 . City ,   ))   =   ( Paris ))  AND   (( t1 . EmployeeId )   IS   NOT   DISTINCT \n      FROM   ( t0 . SupportRepId ))  WHERE   ( COALESCE ( t0 . City ,   ))   =   ( London ) \n   FOR   SHARE   SKIP   LOCKED  \n\n         \n    \n         \n    \n                 \n                      You may notice that this query will lock rows in both the customers and\nemployees table. This may not be what you want. You can also specify which\ntables to lock by using the  lockingFor_  function. This requires you to specify\nwhich locks you want to hold by returning them from your query. For example, to\nlock only the customers table  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             Pg . lockingFor_   Pg . PgSelectLockingStrengthShare   ( Just   Pg . PgSelectLockingOptionsSkipLocked )   $ \n   do   ( customerLock ,   customer )   -   Pg . locked_   ( customer   chinookDb ) \n      guard_   ( fromMaybe_     ( addressCity   ( customerAddress   customer ))   ==.   London ) \n      employee   -   filter_   ( \\ e   -   fromMaybe_     ( addressCity   ( employeeAddress   e ))   ==.   Paris   . \n                                 just_   ( pk   e )   ==.   customerSupportRep   customer )   $ \n                  all_   ( employee   chinookDb ) \n      pure   (( customerFirstName   customer ,   customerLastName   customer ,   pk   employee )   ` Pg . withLocks_ `   customerLock )  \n\n         \n    \n         \n             SELECT   t0 . FirstName   AS   res0 , \n        t0 . LastName   AS   res1 , \n        t1 . EmployeeId   AS   res2  FROM   Customer   AS   t0  CROSS   JOIN   Employee   AS   t1  WHERE   (( COALESCE ( t0 . City ,   ))   =   ( London )) \n   AND   ((( COALESCE ( t1 . City ,   ))   =   ( Paris )) \n        AND   (( t1 . EmployeeId )   IS   NOT   DISTINCT \n             FROM   ( t0 . SupportRepId ))) \n   FOR   SHARE   OF   t0   SKIP   LOCKED  \n\n         \n    \n         \n    \n                 \n                      In order to use the explicit locking clause, you need to use the  locked_ \nfunction to get a reference to a lock for a particular table. This forces the\nlocked table to be part of the join, which is a requirement for the Postgres\nlocking clause. You can think of  locked_  as exactly like  all_ , except it\nreturns a table lock as the first return value.   Tip  Locks can be combined monoidally, using  mappend  or  ( ) . You can use this\nto lock multiple tables, by passing the result of  mappend  to  withLocks_ .  If you return  mempty  as the first argument, then this recovers the standard\nbehavior of locking all tables.   lockingFor_  is the most general locking combinator. You can recover the same\nbehavior as  lockingAllTablesFor_  by using the  lockAll_  function.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             Pg . lockingFor_   Pg . PgSelectLockingStrengthShare   ( Just   Pg . PgSelectLockingOptionsSkipLocked )   $ \n   do   ( customerLock ,   customer )   -   Pg . locked_   ( customer   chinookDb ) \n      guard_   ( fromMaybe_     ( addressCity   ( customerAddress   customer ))   ==.   London ) \n      employee   -   filter_   ( \\ e   -   fromMaybe_     ( addressCity   ( employeeAddress   e ))   ==.   Paris   . \n                                 just_   ( pk   e )   ==.   customerSupportRep   customer )   $ \n                  all_   ( employee   chinookDb ) \n      pure   ( Pg . lockAll_   ( customerFirstName   customer ,   customerLastName   customer ,   pk   employee ))  \n\n         \n    \n         \n             SELECT   t0 . FirstName   AS   res0 , \n        t0 . LastName   AS   res1 , \n        t1 . EmployeeId   AS   res2  FROM   Customer   AS   t0  CROSS   JOIN   Employee   AS   t1  WHERE   (( COALESCE ( t0 . City ,   ))   =   ( London )) \n   AND   ((( COALESCE ( t1 . City ,   ))   =   ( Paris )) \n        AND   (( t1 . EmployeeId )   IS   NOT   DISTINCT \n             FROM   ( t0 . SupportRepId ))) \n   FOR   SHARE   SKIP   LOCKED  \n\n         \n    \n         \n    \n                 \n                       Tip  Table locks have the type  PgLockedTables s , where  s  is the thread\nparameter, as described here", 
            "title": "SELECT locking clause"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#distinct-on-support", 
            "text": "Postgres supports the  DISTINCT ON  clause with selects to return distinct\nresults based on a particular key. The  beam-postgres  package provides the pgNubBy_  function to use this feature.  For example, to get an arbitrary customer from each distinct area code  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             Pg . pgNubBy_   ( addressPostalCode   .   customerAddress )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   DISTINCT   ON   ( t0 . PostalCode )   t0 . CustomerId   AS   res0 , \n                    t0 . FirstName   AS   res1 , \n                    t0 . LastName   AS   res2 , \n                    t0 . Company   AS   res3 , \n                    t0 . Address   AS   res4 , \n                    t0 . City   AS   res5 , \n                    t0 . State   AS   res6 , \n                    t0 . Country   AS   res7 , \n                    t0 . PostalCode   AS   res8 , \n                    t0 . Phone   AS   res9 , \n                    t0 . Fax   AS   res10 , \n                    t0 . Email   AS   res11 , \n                    t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0", 
            "title": "DISTINCT ON support"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#aggregates", 
            "text": "", 
            "title": "Aggregates"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#string_agg", 
            "text": "The Postgres  string_agg  aggregate combines all column values in a group\nseparated by a given separator.  beam-postgres  provides  pgStringAgg  and pgStringAggOver  to use the unquantified and quantified versions of the string_agg  aggregate appropriately.  For example, to put together a list of all cities in all the postal codes we have for customers,  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ c   -   (   group_   ( addressPostalCode   ( customerAddress   c )) \n                   ,   Pg . pgStringAgg   ( coalesce_   [ addressCity   ( customerAddress   c )]   )   , )   )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . PostalCode   AS   res0 , \n        string_agg ( COALESCE ( t0 . City ,   ),   , )   AS   res1  FROM   Customer   AS   t0  GROUP   BY   t0 . PostalCode  \n\n         \n    \n         \n    \n                 \n                      The above will include one city multiple times if its shared by multiple customers.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ c   -   (   group_   ( addressPostalCode   ( customerAddress   c )) \n                   ,   Pg . pgStringAggOver   distinctInGroup_   ( coalesce_   [ addressCity   ( customerAddress   c )]   )   , )   )   $ \n   all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . PostalCode   AS   res0 , \n        string_agg ( DISTINCT   COALESCE ( t0 . City ,   ),   , )   AS   res1  FROM   Customer   AS   t0  GROUP   BY   t0 . PostalCode", 
            "title": "string_agg"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#on-conflict", 
            "text": "Beam supports  ON CONFLICT  statements in a Postgres-specific version of insert . The code below uses the following imports to ensure the correct  insert  is used:  import   Database.Beam   hiding   ( insert )  import   qualified   Database.Beam.Postgres   as   Pg   The 3rd argument of the  insert  from  Database.Beam.Postgres  allows\nyou to specify an  ON CONFLICT  clause. You can use onConflictDefault  in order to recover the standard behavior.  insert   ::   DatabaseEntity   Postgres   db   ( TableEntity   table ) \n        -   SqlInsertValues   PgInsertValuesSyntax   table \n        -   PgInsertOnConflict   table \n        -   SqlInsert   PgInsertSyntax   An explicit  ON CONFLICT  statement requires to specify the indexes\nwhich are conflicting and an action to take when a conflict is\ndiscovered. The  onConflict  function allows you to specify these\nparts of the  ON CONFLICT  clause.  onConflict   ::   Beamable   tbl \n            =   PgInsertOnConflictTarget   tbl \n            -   PgConflictAction   tbl \n            -   PgInsertOnConflict   tbl", 
            "title": "ON CONFLICT"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#acting-on-any-conflict", 
            "text": "The  anyConflict  value causes the action to be executed when any\nindex or constraint is violated by the specified  INSERT . The\nfollowing example causes any conflicting update to be ignored. This\ncould be useful if you want to upsert rows into a database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- import qualified Database.Beam.Postgres as Pg  let \n   newCustomer   =   Customer   42   John   Doe   Nothing   ( Address   ( Just   Street )   ( Just   City )   ( Just   State )   Nothing   Nothing )   Nothing   Nothing   john.doe@johndoe.com   nothing_  runInsert   $ \n   Pg . insert   ( customer   chinookDb )   ( insertValues   [ newCustomer ])   $ \n     Pg . onConflict \n       Pg . anyConflict \n       Pg . onConflictDoNothing  \n\n         \n    \n         \n             INSERT   INTO   Customer ( CustomerId , \n                        FirstName , \n                        LastName , \n                        Company , \n                        Address , \n                        City , \n                        State , \n                        Country , \n                        PostalCode , \n                        Phone , \n                        Fax , \n                        Email , \n                        SupportRepId )  VALUES   ( 42 , \n         John , \n         Doe , \n         null , \n         Street , \n         City , \n         State , \n         null , \n         null , \n         null , \n         null , \n         john.doe@johndoe.com , \n         null )   ON   CONFLICT   DO   NOTHING ;", 
            "title": "Acting on any conflict"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#acting-only-on-certain-conflicts", 
            "text": "Sometimes you only want to perform an action if a certain constraint\nis violated.  If the conflicting index or constraint is on a field,\nyou can specify the fields with the function  conflictingFields .  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- import qualified Database.Beam.Postgres as Pg  let \n   newCustomer   =   Customer   42   John   Doe   Nothing   ( Address   ( Just   Street )   ( Just   City )   ( Just   State )   Nothing   Nothing )   Nothing   Nothing   john.doe@johndoe.com   nothing_  runInsert   $ \n   Pg . insert   ( customer   chinookDb )   ( insertValues   [ newCustomer ])   $ \n     Pg . onConflict \n       ( Pg . conflictingFields   primaryKey ) \n       Pg . onConflictSetAll  \n\n         \n    \n         \n             INSERT   INTO   Customer ( CustomerId , \n                        FirstName , \n                        LastName , \n                        Company , \n                        Address , \n                        City , \n                        State , \n                        Country , \n                        PostalCode , \n                        Phone , \n                        Fax , \n                        Email , \n                        SupportRepId )  VALUES   ( 42 , \n         John , \n         Doe , \n         null , \n         Street , \n         City , \n         State , \n         null , \n         null , \n         null , \n         null , \n         john.doe@johndoe.com , \n         null )   ON   CONFLICT   ( CustomerId )   DO  UPDATE  SET   CustomerId = ( excluded . CustomerId ), \n     FirstName = ( excluded . FirstName ), \n     LastName = ( excluded . LastName ), \n     Company = ( excluded . Company ), \n     Address = ( excluded . Address ), \n     City = ( excluded . City ), \n     State = ( excluded . State ), \n     Country = ( excluded . Country ), \n     PostalCode = ( excluded . PostalCode ), \n     Phone = ( excluded . Phone ), \n     Fax = ( excluded . Fax ), \n     Email = ( excluded . Email ), \n     SupportRepId = ( excluded . SupportRepId );  \n\n         \n    \n         \n    \n                 \n                       Tip  To specify a conflict on the primary keys, use  conflictingField primaryKey .   If the conflict target is an index, use  conflictingConstraint , and supply the name of the constraint  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- import qualified Database.Beam.Postgres as Pg  let \n   newCustomer   =   Customer   42   John   Doe   Nothing   ( Address   ( Just   Street )   ( Just   City )   ( Just   State )   Nothing   Nothing )   Nothing   Nothing   john.doe@johndoe.com   nothing_  runInsert   $ \n   Pg . insert   ( customer   chinookDb )   ( insertValues   [ newCustomer ])   $ \n     Pg . onConflict \n       ( Pg . conflictingConstraint   PK_Customer ) \n       Pg . onConflictSetAll  \n\n         \n    \n         \n             INSERT   INTO   Customer ( CustomerId , \n                        FirstName , \n                        LastName , \n                        Company , \n                        Address , \n                        City , \n                        State , \n                        Country , \n                        PostalCode , \n                        Phone , \n                        Fax , \n                        Email , \n                        SupportRepId )  VALUES   ( 42 , \n         John , \n         Doe , \n         null , \n         Street , \n         City , \n         State , \n         null , \n         null , \n         null , \n         null , \n         john.doe@johndoe.com , \n         null )   ON   CONFLICT   ON   CONSTRAINT   PK_Customer   DO  UPDATE  SET   CustomerId = ( excluded . CustomerId ), \n     FirstName = ( excluded . FirstName ), \n     LastName = ( excluded . LastName ), \n     Company = ( excluded . Company ), \n     Address = ( excluded . Address ), \n     City = ( excluded . City ), \n     State = ( excluded . State ), \n     Country = ( excluded . Country ), \n     PostalCode = ( excluded . PostalCode ), \n     Phone = ( excluded . Phone ), \n     Fax = ( excluded . Fax ), \n     Email = ( excluded . Email ), \n     SupportRepId = ( excluded . SupportRepId );", 
            "title": "Acting only on certain conflicts"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#specifying-actions", 
            "text": "Often times, you do not want to update every field on a conflict. For\nexample, for upserts, you rarely want to update the primary key. The\nfunction  onConflictUpdateInstead  allows you to restrict which fields\nare updated in the case of a conflict. The required function argument\nis a projection of which fields ought to be updated.  In the example below, we insert a new row, but if a row with the given\nprimary key already exists, we update  only  the first and last name.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- import qualified Database.Beam.Postgres as Pg  let \n   newCustomer   =   Customer   42   John   Doe   Nothing   ( Address   ( Just   Street )   ( Just   City )   ( Just   State )   Nothing   Nothing )   Nothing   Nothing   john.doe@johndoe.com   nothing_  runInsert   $ \n   Pg . insert   ( customer   chinookDb )   ( insertValues   [ newCustomer ])   $ \n     Pg . onConflict \n       ( Pg . conflictingFields   primaryKey ) \n       ( Pg . onConflictUpdateInstead \n          ( \\ c   -   (   customerFirstName   c \n                 ,   customerLastName   c   )))  \n\n         \n    \n         \n             INSERT   INTO   Customer ( CustomerId , \n                        FirstName , \n                        LastName , \n                        Company , \n                        Address , \n                        City , \n                        State , \n                        Country , \n                        PostalCode , \n                        Phone , \n                        Fax , \n                        Email , \n                        SupportRepId )  VALUES   ( 42 , \n         John , \n         Doe , \n         null , \n         Street , \n         City , \n         State , \n         null , \n         null , \n         null , \n         null , \n         john.doe@johndoe.com , \n         null )   ON   CONFLICT   ( CustomerId )   DO  UPDATE  SET   FirstName = ( excluded . FirstName ), \n     LastName = ( excluded . LastName );  \n\n         \n    \n         \n    \n                 \n                      You can also specify a more specific update, using the onConflictUpdateSet  function. This is the most general form of the\npostgres  ON CONFLICT  action. The  excluded  table is provided as the\nsecond argument. The syntax of the updates is similar to that of update .  In the following example, we append the old first name to the new\nfirst name and replace the old last name.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- import qualified Database.Beam.Postgres as Pg  let \n   newCustomer   =   Customer   42   John   Doe   Nothing   ( Address   ( Just   Street )   ( Just   City )   ( Just   State )   Nothing   Nothing )   Nothing   Nothing   john.doe@johndoe.com   nothing_  runInsert   $ \n   Pg . insert   ( customer   chinookDb )   ( insertValues   [ newCustomer ])   $ \n     Pg . onConflict \n       ( Pg . conflictingFields   primaryKey ) \n       ( Pg . onConflictUpdateSet \n         -- tbl is the old row, tblExcluded is the row proposed for insertion \n         ( \\ tbl   tblExcluded   -   mconcat \n           [   customerFirstName   tbl   -.   concat_   [   current_   ( customerFirstName   tbl ),    customerFirstName   tblExcluded   ] \n           ,   customerLastName   tbl   -.   customerLastName   tblExcluded   ] \n         ) \n       )  \n\n         \n    \n         \n             INSERT   INTO   Customer ( CustomerId , \n                        FirstName , \n                        LastName , \n                        Company , \n                        Address , \n                        City , \n                        State , \n                        Country , \n                        PostalCode , \n                        Phone , \n                        Fax , \n                        Email , \n                        SupportRepId )  VALUES   ( 42 , \n         John , \n         Doe , \n         null , \n         Street , \n         City , \n         State , \n         null , \n         null , \n         null , \n         null , \n         john.doe@johndoe.com , \n         null )   ON   CONFLICT   ( CustomerId )   DO  UPDATE  SET   FirstName = ( CONCAT ( Customer . FirstName ,   excluded . FirstName )), \n     LastName = ( excluded . LastName );", 
            "title": "Specifying actions"
        }, 
        {
            "location": "/user-guide/backends/beam-sqlite/", 
            "text": "SQLite is a lightweight RDBMS meant for embedding in larger applications.\nBecause it is not designed to be full-featured, not all Beam queries will work\nwith SQLite. The module \nDatabase.Beam.SQLite.Checked\n provides many symbols\nusually imported from the \nDatabase.Beam\n module that enforce extra checks on\nqueries to assure compliance with SQLite. Use this module in code that is SQLite\nspecific for maximal compile-time safety. Note that this module should be\nimported instead of \nDatabase.Beam\n to avoid name clashes.\n\n\nCompatibility\n\n\nSQLite is compatible enough with Beam's query syntax, that adapting to its\nquirks is pretty straightforwards. The main special case for SQLite is its\nhandling of nested set operations. On most backends, beam can output these\ndirectly, but SQLite requires us to generate subqueries.", 
            "title": "beam-sqlite"
        }, 
        {
            "location": "/user-guide/backends/beam-sqlite/#compatibility", 
            "text": "SQLite is compatible enough with Beam's query syntax, that adapting to its\nquirks is pretty straightforwards. The main special case for SQLite is its\nhandling of nested set operations. On most backends, beam can output these\ndirectly, but SQLite requires us to generate subqueries.", 
            "title": "Compatibility"
        }, 
        {
            "location": "/user-guide/custom-backends/", 
            "text": "Writing a custom backend", 
            "title": "Writing a Custom Backend"
        }, 
        {
            "location": "/about/compatibility/", 
            "text": "Beam strives to cover the full breadth of the relevant SQL\nstandards. In general, if there is something in a SQL standard that is\nnot implemented in a generic manner in \nbeam-core\n, feel free to file\nan issue requesting support. There are some features that beam\npurposefully omits because no major RDBMS implements them. For\nexample, database-level assertions are not supported in any of the\ndefault beam backends, and thus are not supported by \nbeam-core\n. If\nyou have a need for these features, feel free to file an issue. Be\nsure to motivate your use case with examples and a testing strategy.\n\n\nThe relevant SQL standards are SQL-92, SQL:1999, SQL:2003, SQL:2008,\nand SQL:2011. Because not all the standards are not publicly\naccessible, I've done my best to piece together features from various\ndocuments available online. I believe I've covered most of the common\ncases, but there may be pieces of functionality that are missing. File\nan issue if this is the case.\n\n\nThe table below summarizes the features defined in each SQL standard and beam's\nsupport for them. FULL means beam supports everything in that feature. NONE\nmeans that there is no support for that feature, and none planned. N/A means\nthat the feature only applies to RDBMSs, not the SQL language. WONTFIX means\nthat the feature has been considered and willfully ignored. UNKNOWN means not\nenough investigation has gone into the feature to make a determination. TODO\nmeans the feature has not been implemented yet, but an implementation is\nplanned.\n\n\n\n\nTip\n\n\nThe 'TODO' items are a great way to contribute to beam!\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\nStatus\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nB011 Embedded Ada\n\n\nNONE\n\n\n\n\n\n\n\n\nB012 Embedded C\n\n\nNONE\n\n\n\n\n\n\n\n\nB013 Embedded COBOL\n\n\nNONE\n\n\n\n\n\n\n\n\nB014 Embedded FORTRAN\n\n\nNONE\n\n\n\n\n\n\n\n\nB015 Embedded MUMPS\n\n\nNONE\n\n\n\n\n\n\n\n\nB016 Embedded Pascal\n\n\nNONE\n\n\n\n\n\n\n\n\nB017 Embedded PL/I\n\n\nNONE\n\n\n\n\n\n\n\n\nB021 Direct SQL\n\n\nNONE\n\n\n\n\n\n\n\n\nB031 Basic dynamic SQL\n\n\nNONE\n\n\n\n\n\n\n\n\nB032 Extended dynamic SQL\n\n\nNONE\n\n\n\n\n\n\n\n\nB033 Untyped SQL-invoked function arguments\n\n\nNONE\n\n\n\n\n\n\n\n\nB034 Dynamic specification of cursor attributes\n\n\nNONE\n\n\n\n\n\n\n\n\nB035 Non-extended descriptor names\n\n\nNONE\n\n\n\n\n\n\n\n\nB051 Enhanced execution rights\n\n\nNONE\n\n\n\n\n\n\n\n\nB111 Module language Ada\n\n\nNONE\n\n\n\n\n\n\n\n\nB112 Module language C\n\n\nNONE\n\n\n\n\n\n\n\n\nB113 Module language COBOL\n\n\nNONE\n\n\n\n\n\n\n\n\nB114 Module language Fortran\n\n\nNONE\n\n\n\n\n\n\n\n\nB115 Module language MUMPS\n\n\nNONE\n\n\n\n\n\n\n\n\nB116 Module language Pascal\n\n\nNONE\n\n\n\n\n\n\n\n\nB117 Module language PL/I\n\n\nNONE\n\n\n\n\n\n\n\n\nB121 Routine language Ada\n\n\nNONE\n\n\n\n\n\n\n\n\nB122 Routine language C\n\n\nNONE\n\n\n\n\n\n\n\n\nB123 Routine language COBOL\n\n\nNONE\n\n\n\n\n\n\n\n\nB124 Routine language Fortran\n\n\nNONE\n\n\n\n\n\n\n\n\nB125 Routine language MUMPS\n\n\nNONE\n\n\n\n\n\n\n\n\nB126 Routine language Pascal\n\n\nNONE\n\n\n\n\n\n\n\n\nB127 Routine language PL/I\n\n\nNONE\n\n\n\n\n\n\n\n\nB128 Routine language SQL\n\n\nNONE\n\n\n\n\n\n\n\n\nB211 Module language Ada: VARCHAR and NUMERIC support\n\n\nNONE\n\n\n\n\n\n\n\n\nB221 Routine language Ada: VARCHAR and NUMERIC support\n\n\nNONE\n\n\n\n\n\n\n\n\nE011 - Numeric data types\n\n\n\n\n\n\n\n\n\n\nE011-01 INTEGER and SMALLINT data types\n\n\nFULL\n\n\nUse \nInt32\n for \nINTEGER\n, \nInt16\n for \nSMALLINT\n\n\n\n\n\n\nE011-02 REAL, DOUBLE PRECISION, FLOAT\n\n\nFULL\n\n\nUse \nDouble\n and \nFloat\n\n\n\n\n\n\nE011-03 DECIMAL and NUMERIC data types\n\n\nFULL\n\n\nUse \nScientific\n. You can provide the database precision using \nbeam-migrate\n\n\n\n\n\n\nE011-04 Arithmetic operators\n\n\nFULL\n\n\nUse the \nNum\n instance for \nQGenExpr\n\n\n\n\n\n\nE011-05 Numeric comparison\n\n\nFULL\n\n\nUse the \n.\n suffixed operators (i.e., \n==.\n, \n/=.\n, \n.\n, etc)\n\n\n\n\n\n\nE011-06 Implicit casting among numeric data types\n\n\nWONTFIX\n\n\nBeam never implicitly casts. Use \ncast_\n\n\n\n\n\n\nE021 Character string types\n\n\n\n\n\n\n\n\n\n\nE021-01 CHARACTER data type\n\n\nFULL\n\n\nUse \nText\n. Use \nbeam-migrate\n to specify width\n\n\n\n\n\n\nE021-02 CHARACTER VARYING data type\n\n\nFULL\n\n\nUse \nText\n. Use \nbeam-migrate\n to specify width.\n\n\n\n\n\n\nE021-03 Character literals\n\n\nFULL\n\n\nUse \nval_\n\n\n\n\n\n\nE021-04 CHARACTER_LENGTH function\n\n\nFULL\n\n\nUse \ncharLength_\n\n\n\n\n\n\nE021-05 OCTET_LENGTH function\n\n\nFULL\n\n\nUse \noctetLength_\n\n\n\n\n\n\nE021-06 SUBSTRING function\n\n\nTODO\n\n\n\n\n\n\n\n\nE021-07 Character concatenation\n\n\nFULL\n\n\nUse \nconcat_\n\n\n\n\n\n\nE021-08 UPPER and LOWER functions\n\n\nFULL\n\n\nUse \nupper_\n and \nlower_\n\n\n\n\n\n\nE021-09 TRIM function\n\n\nPARTIAL\n\n\nUse \ntrim_\n. Full support may be provided on backends that implement it\n\n\n\n\n\n\nE021-10 Implicit casting among string types\n\n\nWONTFIX\n\n\nBeam never implicitly casts. Use \ncast_\n\n\n\n\n\n\nE021-11 POSITION function\n\n\nFULL\n\n\nUse \nposition_\n\n\n\n\n\n\nE021-12 Character comparison\n\n\nFULL\n\n\nUse comparison operators (See E011-05)\n\n\n\n\n\n\nE031 Identifiers\n\n\n\n\n\n\n\n\n\n\nE031-01 Delimited identifiers\n\n\nTODO\n\n\nFind out more\n\n\n\n\n\n\nE021-02 Lower case identifiers\n\n\nTODO\n\n\n\n\n\n\n\n\nE021-03 Trailing underscore\n\n\nN/A\n\n\nBeam will use whatever column names you specify\n\n\n\n\n\n\nE051 Basic query specification\n\n\n\n\n\n\n\n\n\n\nE051-01 SELECT DISTINCT\n\n\nFULL\n\n\nUse \nnub_\n\n\n\n\n\n\nE051-02 GROUP BY clause\n\n\nFULL\n\n\nSee \naggregate_\n or read the \nsection on aggregates\n\n\n\n\n\n\nE051-04 GROUP BY can contain columns not in SELECT\n\n\nTODO\n\n\nUnsure how this applies to beam in particular\n\n\n\n\n\n\nE051-05 Select list items can be renamed\n\n\nN/A\n\n\nBeam uses this feature internally, the user never needs it\n\n\n\n\n\n\nE051-06 HAVING clause\n\n\nFULL\n\n\nguard_\n and \nfilter_\n are appropriately converted to \nHAVING\n when allowed\n\n\n\n\n\n\nE051-07 Qualified * in select list\n\n\nN/A\n\n\nBeam handles projections instead\n\n\n\n\n\n\nE051-08 Correlation names in FROM\n\n\nTODO\n\n\nUnsure how this applies to beam\n\n\n\n\n\n\nE051-09 Rename columns in the FROM clause\n\n\nNONE\n\n\nBeam doesn't need this\n\n\n\n\n\n\nE061 Basic predicates and search conditions\n\n\n\n\n\n\n\n\n\n\nE061-01 Comparison predicate\n\n\nFULL\n\n\nUse the comparison operators (see E011-05)\n\n\n\n\n\n\nE061-02 BETWEEN predicate\n\n\nFULL\n\n\nUse \nbetween_\n\n\n\n\n\n\nE061-03 IN predicate with list of values\n\n\nFULL\n\n\nUse \nin_\n\n\n\n\n\n\nE061-04 LIKE predicate\n\n\nFULL\n\n\nUse \nlike_\n\n\n\n\n\n\nE061-05 LIKE predicate ESCAPE clause\n\n\nTODO\n\n\nUnsure how this would apply\n\n\n\n\n\n\nE061-06 NULL predicate\n\n\nFULL\n\n\nUse \nisNothing_\n and \nisJust_\n\n\n\n\n\n\nE061-07 Quantified comparison predicate\n\n\nFULL\n\n\nUse one of the \nquantified comparison operators\n (\n==*.\n, \n/=*.\n, \n*.\n, \n*.\n, \n=*.\n, \n=*.\n)\n\n\n\n\n\n\nE051-08 EXISTS predicate\n\n\nFULL\n\n\nUse \nexists_\n\n\n\n\n\n\nE061-09 Subqueries in comparison predicate\n\n\nFULL\n\n\nUse \nsubquery_\n as usual\n\n\n\n\n\n\nE061-11 Subqueries in IN predicate\n\n\nFULL\n\n\n\n\n\n\n\n\nE061-12 Subqueries in quantified comparison predicate\n\n\nFULL\n\n\n\n\n\n\n\n\nE061-13 Correlated subqueries\n\n\nFULL\n\n\nUse \nsubquery_\n\n\n\n\n\n\nE061-14 Search condition\n\n\nFULL\n\n\nConstruct \nQGenExprs\n with type \nBool\n\n\n\n\n\n\nE071 Basic query expressions\n\n\n\n\n\n\n\n\n\n\nE071-01 UNION DISTINCT table operator\n\n\nFULL\n\n\nUse \nunion_\n\n\n\n\n\n\nE071-02 UNION ALL table operator\n\n\nFULL\n\n\nUse \nunionAll_\n\n\n\n\n\n\nE071-03 EXCEPT DISTINCT table operator\n\n\nFULL\n\n\nUse \nexcept_\n\n\n\n\n\n\nE071-05 Columns combined via operators need not have same type\n\n\nWONTFIX\n\n\nBeam is strongly typed\n\n\n\n\n\n\nE071-06 Table operators in subqueries\n\n\nFULL\n\n\nSupported for backends that support it\n\n\n\n\n\n\nE081 Basic privileges\n\n\nNONE\n\n\nDatabase security is not beam's focus. \nbeam-migrate\n may expose this in the future\n\n\n\n\n\n\nE091 Set functions\n\n\n\n\n\n\n\n\n\n\nE091-01 AVG\n\n\nFULL\n\n\nUse \navg_\n or \navgOver_\n\n\n\n\n\n\nE091-02 COUNT\n\n\nFULL\n\n\nUse \ncountAll_\n, \ncountAllOver_\n, \ncount_\n, or \ncountOver_\n\n\n\n\n\n\nE091-03 MAX\n\n\nFULL\n\n\nUse \nmax_\n or \nmaxOver_\n\n\n\n\n\n\nE091-04 MIN\n\n\nFULL\n\n\nUse \nmin_\n or \nminOver_\n\n\n\n\n\n\nE091-05 SUM\n\n\nFULL\n\n\nUse \nsum_\n or \nsumOver_\n\n\n\n\n\n\nE091-06 ALL quantifier\n\n\nFULL\n\n\nUse the \n*Over_\n functions with the \nallInGroupExplicitly_\n quantifier\n\n\n\n\n\n\nE091-07 DISTINCT quantifier\n\n\nFULL\n\n\nUse the \n*Over_\n functions with the \ndistinctInGroup_\n quantifier\n\n\n\n\n\n\nE101 Basic data manipulation\n\n\n\n\n\n\n\n\n\n\nE101-01 INSERT statement\n\n\nFULL\n\n\nUse \ninsert\n and \nSqlInsert\n\n\n\n\n\n\nE101-03 Searched UPDATE\n\n\nFULL\n\n\nUse \nupdate\n and \nSqlUpdate\n\n\n\n\n\n\nE101-04 Searched DELETE\n\n\nFULL\n\n\nUse \ndelete\n and \nSqlDelete\n\n\n\n\n\n\nE111 Single row SELECT statement\n\n\nFULL\n\n\nUse \nselect\n as expected\n\n\n\n\n\n\nE121 Basic cursor support\n\n\nNONE\n\n\nUse the backends explicitly\n\n\n\n\n\n\nE131 Null value support\n\n\nPARTIAL\n\n\nUse \nMaybe\n column types, \nNullable\n, and the \njust_\n, \nnothing_\n, and \nmaybe_\n functions\n\n\n\n\n\n\nE141 Basic integrity constraints\n\n\n\n\nImplemented in \nbeam-migrate\n\n\n\n\n\n\nE141-01 NOT NULL constraints\n\n\nFULL\n\n\nUse \nnotNull_\n\n\n\n\n\n\nE141-02 UNIQUE constraints of NOT NULL columns\n\n\nTODO\n\n\n\n\n\n\n\n\nE141-03 PRIMARY KEY constraints\n\n\nFULL\n\n\nInstantiate \nTable\n with the correct \nPrimaryKey\n\n\n\n\n\n\nE141-04 Basic FOREIGN KEY constraints\n\n\nTODO\n\n\nYou can embed the \nPrimaryKey\n of the relation directly.\n\n\n\n\n\n\nE141-06 CHECK constraints\n\n\nTODO\n\n\n\n\n\n\n\n\nE141-07 Column defaults\n\n\nFULL\n\n\nUse \ndefault_\n from \nbeam-migrate\n\n\n\n\n\n\nE141-08 NOT NULL inferred on PRIMARY KEY\n\n\nN/A\n\n\n\n\n\n\n\n\nE141-10 Names in a foreign key can be specified in any order\n\n\nN/A\n\n\n\n\n\n\n\n\nE151 Transaction support\n\n\nNone\n\n\nUse the backend functions explicitly\n\n\n\n\n\n\nE152 SET TRANSACTION statement\n\n\nN/A\n\n\n\n\n\n\n\n\nE153 Updatable queries with subqueries\n\n\nTODO\n\n\nNot a common feature, but would be trivial to support\n\n\n\n\n\n\nE161 SQL comments with double minus\n\n\nN/A\n\n\n\n\n\n\n\n\nE171 SQLSTATE support\n\n\nN/A\n\n\n\n\n\n\n\n\nE182 Host language binding\n\n\nN/A\n\n\n\n\n\n\n\n\nF031 Basic schema manipulation\n\n\n\n\n\n\n\n\n\n\nF031-01 CREATE TABLE for persistent base tables\n\n\nFULL\n\n\nUse \ncreateTable_\n in \nbeam-migrate\n\n\n\n\n\n\nF031-02 CREATE VIEW statement\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-03 GRANT statement\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-04 ALTER TABLE statement: ADD COLUMN clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-13 DROP TABLE statement: RESTRICT clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-16 DROP VIEW statement: RESTRICT clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-19 REVOKE statement: RESTRICT clause\n\n\nNONE\n\n\nSee note for E081\n\n\n\n\n\n\nF032 CASCADE drop behavior\n\n\nTODO\n\n\nWould be in \nbeam-migrate\n\n\n\n\n\n\nF033 ALTER TABLE statement: DROP COLUMN clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF034 Extended REVOKE statement\n\n\nNONE\n\n\n\n\n\n\n\n\nF041 Basic joined table\n\n\n\n\n\n\n\n\n\n\nF041-01 Inner join\n\n\nFULL\n\n\nUse the \nmonadic join interface\n\n\n\n\n\n\nF041-02 INNER keyword\n\n\nN/A\n\n\nThe \nINNER\n keyword is just syntactic sugar. The regular joins do what you want.\n\n\n\n\n\n\nF041-03 LEFT OUTER JOIN\n\n\nFULL\n\n\nUse \nleftJoin_\n\n\n\n\n\n\nF041-04 RIGHT OUTER JOIN\n\n\nPARTIAL\n\n\nSupported in backend syntaxes, not exposed. Can always be written using LEFT OUTER JOIN\n\n\n\n\n\n\nF041-05 Outer joins can be nested\n\n\nFULL\n\n\nouterJoin_\n can be nested arbitrarily\n\n\n\n\n\n\nF041-07 The inner table in outer join can be used in inner join\n\n\nTODO\n\n\nHow does this apply to us?\n\n\n\n\n\n\nF041-08 All comparison operators in JOIN\n\n\nFULL\n\n\nArbitrary \nQGenExpr\ns are supported.\n\n\n\n\n\n\nF051 Basic date and time\n\n\n\n\n\n\n\n\n\n\nF051-01 DATE data type\n\n\nFULL\n\n\nUse \nDay\n from \nData.Time\n and \nval_\n\n\n\n\n\n\nF051-02 TIME data type\n\n\nFULL\n\n\nUse \nTimeOfDay\n from \nData.Time\n and \nval_\n\n\n\n\n\n\nF051-03 TIMESTAMP datatype\n\n\nFULL\n\n\nUse \nLocalTime\n from \nData.Time\n and \nval_\n. Precision can be specified in \nbeam-migrate\n\n\n\n\n\n\nF051-04 Comparison predicate on time types\n\n\nFULL\n\n\nUse comparison operatiors (See E011-05)\n\n\n\n\n\n\nF051-05 Explicit cast between date-time types and string\n\n\nTODO\n\n\n\n\n\n\n\n\nF051-06 CURRENT_DATE\n\n\nTODO\n\n\n\n\n\n\n\n\nF051-07 LOCALTIME\n\n\nTODO\n\n\n\n\n\n\n\n\nF051-08 LOCALTIMESTAMP\n\n\nTODO\n\n\n\n\n\n\n\n\nF081 UNION and EXCEPT in views\n\n\nFULL\n\n\nViews can use any query\n\n\n\n\n\n\nF111 Isolation levels other than SERIALIZABLE\n\n\nNONE\n\n\nUse backends\n\n\n\n\n\n\nF121 Basic diagnostics mangement\n\n\nNONE\n\n\nUse backends\n\n\n\n\n\n\nF122 Extended diagnostics management\n\n\nNONE\n\n\nUse backends\n\n\n\n\n\n\nF123 All diagnostics\n\n\nNONE\n\n\nUse backends\n\n\n\n\n\n\nF131 Grouped operations\n\n\nTODO\n\n\nDepends on grouped views\n\n\n\n\n\n\nF171 Multiple schemas per user\n\n\nN/A\n\n\nDepends on backend\n\n\n\n\n\n\nF191 Referential delete actions\n\n\nTODO\n\n\n\n\n\n\n\n\nF181 Multiple module support\n\n\nN/A\n\n\n\n\n\n\n\n\nF200 TRUNCATE TABLE statement\n\n\nTODO\n\n\nMay be added in the future\n\n\n\n\n\n\nF201 CAST function\n\n\nFULL\n\n\nSee \ncast_\n\n\n\n\n\n\nF202 TRUNCATE TABLE: identity column restart option\n\n\nTODO\n\n\nDepends on F200\n\n\n\n\n\n\nF221 Explicit defaults\n\n\nFULL\n\n\nUse \ndefault_\n and \ninsertExpressions\n when inserting\n\n\n\n\n\n\nF222 INSERT statement: DEFAULT VALUES clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF251 Domain support\n\n\nPARTIAL\n\n\nUse \nDomainTypeEntity\n\n\n\n\n\n\nF261 CASE expression\n\n\n\n\n\n\n\n\n\n\nF261-01 Simple CASE\n\n\nTODO\n\n\nUse searched case (see F261-02)\n\n\n\n\n\n\nF261-02 Searched CASE\n\n\nFULL\n\n\nUse \nif_\n, \nthen_\n, and \nelse_\n\n\n\n\n\n\nF261-03 NULLIF\n\n\nFULL\n\n\nUse \nnullIf_\n\n\n\n\n\n\nF261-04 COALESCE\n\n\nFULL\n\n\nUse \ncoalesce_\n\n\n\n\n\n\nF262 Extended CASE expression\n\n\nWONTFIX\n\n\nBeam allows any expression in a \nWHEN\n condition\n\n\n\n\n\n\nF263 Comma-separater predicates in simple CASE expression\n\n\nWONTFIX\n\n\nUnnecessary\n\n\n\n\n\n\nF271 Compound character literals\n\n\nN/A\n\n\nThis is syntactic sugar\n\n\n\n\n\n\nF281 LIKE enhancements\n\n\nFULL\n\n\nSupported in backends that support this\n\n\n\n\n\n\nF291 UNIQUE predicate\n\n\nFULL\n\n\nUse \nunique_\n\n\n\n\n\n\nF301 CORRESPONDING in query expressions\n\n\nN/A\n\n\nBeam set functions work based off the query result type, not the column name\n\n\n\n\n\n\nF302 INTERSECT table operator\n\n\nFULL\n\n\nUse \nintersect_\n\n\n\n\n\n\nF302-01 INTERSECT DISTINCT table operator\n\n\nFULL\n\n\nUse \nintersect_\n\n\n\n\n\n\nF302-02 INTERSET ALL table operator\n\n\nFULL\n\n\nUse \nintersectAll_\n\n\n\n\n\n\nF304 EXCEPT ALL table operator\n\n\nFULL\n\n\nUse \nexceptAll_\n\n\n\n\n\n\nF311 Schema definition statement\n\n\nTODO\n\n\nWould be in \nbeam-migrate\n\n\n\n\n\n\nF312 MERGE statement\n\n\nTODO\n\n\n\n\n\n\n\n\nF313 Enhanced MERGE statement\n\n\nTODO\n\n\n\n\n\n\n\n\nF314 MERGE statement with DELETE branch\n\n\nTODO\n\n\n\n\n\n\n\n\nF321 User authorization\n\n\nN/A\n\n\n\n\n\n\n\n\nF361 Subprogram support\n\n\nN/A\n\n\n\n\n\n\n\n\nF381 Extended schema manipulation\n\n\nTODO\n\n\n\n\n\n\n\n\nF382 Alter column data type\n\n\nTODO\n\n\n\n\n\n\n\n\nF384 Drop identity property clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF385 Drop column generation expression clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF386 Set identity column generation clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF391 Long identifiers\n\n\nFULL\n\n\nSupported in backends that support it\n\n\n\n\n\n\nF392 Unicode escapes in identifiers\n\n\nTODO\n\n\nUnsure how this applies\n\n\n\n\n\n\nF393 Unicode escapes in literals\n\n\nTODO\n\n\nUnsure how this applies\n\n\n\n\n\n\nF394 Optional normal form specification\n\n\nN/A\n\n\n\n\n\n\n\n\nF401 Extended joined table\n\n\nFULL\n\n\nFull outer join using \nouterJoin_\n. Natural join is not needed. A cross join is generated automatically when there are no join conditions.\n\n\n\n\n\n\nF402 Named column joins for LOBs, arrays, and multisets\n\n\nPARTIAL\n\n\nSupported in backends that support it\n\n\n\n\n\n\nF403 Partitioned join tables\n\n\nTODO\n\n\n\n\n\n\n\n\nF411 Time zone specification\n\n\nTODO\n\n\n\n\n\n\n\n\nF421 National character\n\n\nFULL\n\n\nSupported in \nbeam-migrate\n as a data type for \nText\n\n\n\n\n\n\nF431 Read-only scrollable cursors\n\n\nN/A\n\n\nUse the underlying backend\n\n\n\n\n\n\nF441 Extended set function support\n\n\nTODO\n\n\n\n\n\n\n\n\nF442 Mixed column references in set functions\n\n\nTODO\n\n\nUnsure how this would work with beam\n\n\n\n\n\n\nF451 Character set definition\n\n\nTODO\n\n\nLikely would go in \nbeam-migrate\n\n\n\n\n\n\nF461 Named character sets\n\n\nTODO\n\n\nSee F451\n\n\n\n\n\n\nF491 Constraint management\n\n\nTODO\n\n\n\n\n\n\n\n\nF492 Optional table constraint enforcement\n\n\nTODO\n\n\n\n\n\n\n\n\nF521 Assertions\n\n\nTODO\n\n\n\n\n\n\n\n\nF531 Temporary tables\n\n\nTODO\n\n\n\n\n\n\n\n\nF481 Expanded NULL predicate\n\n\nFULL\n\n\nSupported in backends that support it\n\n\n\n\n\n\nF555 Enhanced seconds precision\n\n\nTODO\n\n\n\n\n\n\n\n\nF561 Full value expressions\n\n\nTODO\n\n\n\n\n\n\n\n\nF571 Truth value tests\n\n\nTODO\n\n\n\n\n\n\n\n\nF591 Derived tables\n\n\nTODO\n\n\n\n\n\n\n\n\nF611 Indicator data types\n\n\nTODO\n\n\n\n\n\n\n\n\nF641 Row and table constructors\n\n\nPARTIAL\n\n\nUse \nrow_\n (TODO)\n\n\n\n\n\n\nF651 Catalog name qualifiers\n\n\nTODO\n\n\n\n\n\n\n\n\nF661 Simple tables\n\n\nTODO\n\n\n\n\n\n\n\n\nF671 Subqueries in CHECK constraints\n\n\nTODO\n\n\nPlanned with E141-06\n\n\n\n\n\n\nF672 Retrospective CHECK constraints\n\n\nTODO\n\n\nWould require temporal DB support\n\n\n\n\n\n\nF690 Collation support\n\n\nPARTIAL\n\n\nbeam-migrate\n supports some collation features\n\n\n\n\n\n\nF692 Enhanced collation support\n\n\nTODO\n\n\n\n\n\n\n\n\nF693 SQL-session and client module collations\n\n\nTODO\n\n\n\n\n\n\n\n\nF695 Translation support\n\n\nTODO\n\n\n\n\n\n\n\n\nF701 Referential update actions\n\n\nTODO\n\n\n\n\n\n\n\n\nF711 ALTER domain\n\n\nTODO\n\n\n\n\n\n\n\n\nF721 Deferrable constraints\n\n\nPARTIAL\n\n\nThe syntax exists in \nbeam-migrate\n\n\n\n\n\n\nF731 INSERT column privileges\n\n\nN/A\n\n\n\n\n\n\n\n\nF741 Referential MATCH type\n\n\nPARTIAL\n\n\nExists in the syntax in \nbeam-migrate\n, not exposed yet (TODO)\n\n\n\n\n\n\nF751 View CHECK enhancements\n\n\nTODO\n\n\n\n\n\n\n\n\nF761 Session management\n\n\nTODO\n\n\n\n\n\n\n\n\nF762 CURRENT_CATALOG\n\n\nTODO\n\n\n\n\n\n\n\n\nF763 CURRENT_SCHEMA\n\n\nTODO\n\n\n\n\n\n\n\n\nF812 Basic flagging\n\n\nN/A\n\n\n\n\n\n\n\n\nF841 LIKE_REGEX predicate\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF842 OCCURENCES_REGEX function\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF843 POSITION_REGEX function\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF844 SUBSTRING_REGEX function\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF845 TRANSLATE_REGEX function\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF846 Octet support in regular expression operators\n\n\nTODO\n\n\n\n\n\n\n\n\nF847 Nonconstant regular expression\n\n\nTODO\n\n\nEasy once regex support is added\n\n\n\n\n\n\nF850 Top-level \n in \n\n\nFULL\n\n\nUse \norderBy_\n as usual. Beam will do the right thing behind the scenes.\n\n\n\n\n\n\nF851 \n in subqueries\n\n\nFULL\n\n\nWorks in backends that support it\n\n\n\n\n\n\nF852 Top-level \n in views\n\n\nFULL\n\n\nViews can use any query\n\n\n\n\n\n\nF855 Nested \n in \n\n\nUNKNOWN\n\n\n\n\n\n\n\n\nF856 Nested \n in \n\n\nN/A\n\n\nBeam automatically optimizes nested \norderBy_\n calls\n\n\n\n\n\n\nF857 Top-level \n in \n\n\nFULL\n\n\nlimit_\n and \noffset_\n are correctly translated to dialect-specific pagination mechanisms\n\n\n\n\n\n\nF858 \n in subqueries\n\n\nFULL\n\n\n\n\n\n\n\n\nF859 Top-level \n in subqueries\n\n\nFULL\n\n\n\n\n\n\n\n\n*\nF860 dynamic \n in \n\n\nTODO\n\n\n\n\n\n\n\n\n*\nF861 Top-level \n in \n\n\nFULL\n\n\nSee note for F587\n\n\n\n\n\n\nF862 \n in subqueries\n\n\nFULL\n\n\n\n\n\n\n\n\nF863 Nested \n in \n\n\nFULL\n\n\n\n\n\n\n\n\nF864 Top-level \n in views\n\n\nFULL\n\n\n\n\n\n\n\n\nF865 dynamic \n in \n\n\nTODO\n\n\n\n\n\n\n\n\nF866 FETCH FIRST clause: PERCENT option\n\n\nTODO\n\n\n\n\n\n\n\n\nF867 FETCH FIRST clause: WITH TIES option\n\n\nTODO\n\n\n\n\n\n\n\n\nR010 Row pattern recognition: FROM clause\n\n\nTODO\n\n\n\n\n\n\n\n\nR020 Row pattern recognition: WINDOW clause\n\n\nTODO\n\n\n\n\n\n\n\n\nR030 Row pattern recognition: full aggregate support\n\n\nTODO\n\n\n\n\n\n\n\n\nS011 Distinct data types\n\n\nTODO\n\n\n\n\n\n\n\n\nS023 Basic structured types\n\n\nTODO\n\n\n\n\n\n\n\n\nS024 Enhanced structured types\n\n\nTODO\n\n\n\n\n\n\n\n\nS025 Final structured types\n\n\nTODO\n\n\n\n\n\n\n\n\nS026 Self-referencing structured types\n\n\nTODO\n\n\n\n\n\n\n\n\nS027 Create method by specific method name\n\n\nTODO\n\n\n\n\n\n\n\n\nS028 Permutable UDT options list\n\n\nTODO\n\n\n\n\n\n\n\n\nS041 Basic reference types\n\n\nTODO\n\n\n\n\n\n\n\n\nS043 Enhanced reference types\n\n\nTODO\n\n\n\n\n\n\n\n\nS051 Create table of type\n\n\nTODO\n\n\n\n\n\n\n\n\nS071 SQL paths in function and type name resolution\n\n\nN/A\n\n\nBeam qualifies everything anyway\n\n\n\n\n\n\nS081 Subtables\n\n\nPARTIAL\n\n\nYou can use them right now, but there's no support for their creation or management in \nbeam-migrate\n\n\n\n\n\n\nS091 Basic array support\n\n\nPARTIAL\n\n\nSupported in some backends (\nbeam-postgres\n for example)\n\n\n\n\n\n\nS092 Arrays of user-defined types\n\n\nTODO\n\n\nDepends on user-defined types\n\n\n\n\n\n\nS094 Arrays of reference types\n\n\nTODO\n\n\n\n\n\n\n\n\nS095 Array constructors by query\n\n\nPARTIAL\n\n\n\n\n\n\n\n\nS096 Optional array bounds\n\n\nPARTIAL\n\n\nSupported in \nbeam-postgres\n\n\n\n\n\n\nS097 Array element assignment\n\n\nTODO\n\n\nNot yet, but should be easy enough in \nbeam-postgres\n\n\n\n\n\n\nS098 ARRAY_AGG\n\n\nPARTIAL\n\n\nSupported in \nbeam-postgres\n\n\n\n\n\n\nS111 ONLY in query expressions\n\n\nTODO\n\n\n\n\n\n\n\n\nS151 Type predicate\n\n\nTODO\n\n\n\n\n\n\n\n\nS161 Subtype treatment\n\n\nTODO\n\n\n\n\n\n\n\n\nS162 Subtype treatment for references\n\n\nTODO\n\n\n\n\n\n\n\n\nS201 SQL-invoked routines on arrays\n\n\nTODO\n\n\nWould be subsumed by sql-routines (T-321)\n\n\n\n\n\n\nS202 SQL-invoked routines on multisets\n\n\nTODO\n\n\nWould be subsumed by sql-routines (T-321)\n\n\n\n\n\n\nS211 User-defined cast functions\n\n\nTODO\n\n\n\n\n\n\n\n\nS231 Structured type locators\n\n\nTODO\n\n\n\n\n\n\n\n\nS232 Array locators\n\n\nTODO\n\n\n\n\n\n\n\n\nS233 Multiset locators\n\n\nTODO\n\n\n\n\n\n\n\n\nS241 Transform functions\n\n\nTODO\n\n\n\n\n\n\n\n\nS242 Alter transform statement\n\n\nTODO\n\n\n\n\n\n\n\n\nS251 User-defined orderings\n\n\nTODO\n\n\n\n\n\n\n\n\nS261 Specific type method\n\n\nTODO\n\n\n\n\n\n\n\n\nS271 Basic multiset support\n\n\nPARTIAL\n\n\nSupported in \nbeam-postgres\n\n\n\n\n\n\nS272 Multisets of user-defined types\n\n\nTODO\n\n\n\n\n\n\n\n\nS274 Multisets reference types\n\n\nTODO\n\n\n\n\n\n\n\n\nS275 Advanced multiset support\n\n\nTODO\n\n\n\n\n\n\n\n\nS281 Nested collection types\n\n\nTODO\n\n\n\n\n\n\n\n\nS291 Unique constraint on entire row\n\n\nTODO\n\n\n\n\n\n\n\n\nS301 Enhanced UNNEST\n\n\nTODO\n\n\n\n\n\n\n\n\nS401 Distinct types based on array types\n\n\nTODO\n\n\n\n\n\n\n\n\nS402 Distinct types based on distinct types\n\n\nTODO\n\n\n\n\n\n\n\n\nS403 ARRAY_MAX_CARDINALITY\n\n\nTODO\n\n\n\n\n\n\n\n\nS404 TRIM_ARRAY\n\n\nTODO\n\n\n\n\n\n\n\n\nT021 BINARY and VARBINARY data types\n\n\nFULL\n\n\n\n\n\n\n\n\nT022 Advanced support for BINARY and VARBINARY data types\n\n\nTODO\n\n\n\n\n\n\n\n\nT023 Compound binary literals\n\n\nN/A\n\n\nBeam handles serialization\n\n\n\n\n\n\nT024 Spaces in binary literals\n\n\nN/A\n\n\nBeam handles serialization\n\n\n\n\n\n\nT031 Boolean data type\n\n\nFULL\n\n\n\n\n\n\n\n\nT041 Basic LOB data type support\n\n\nTODO\n\n\n\n\n\n\n\n\nT042 Extended LOB data type support\n\n\nTODO\n\n\n\n\n\n\n\n\nT043 Multiplier T\n\n\nTODO\n\n\n\n\n\n\n\n\nT044 Multiplier P\n\n\nTODO\n\n\n\n\n\n\n\n\nT051 Row types\n\n\nPARTIAL\n\n\n\n\n\n\n\n\nT061 UCS support\n\n\nTODO\n\n\n\n\n\n\n\n\nT071 BIGINT data type\n\n\nFULL\n\n\n\n\n\n\n\n\nT101 Enhanced nullability detection\n\n\nTODO\n\n\n\n\n\n\n\n\nT111 Updatable joins, unions, and columns\n\n\nTODO\n\n\n\n\n\n\n\n\nT121 WITH (excluding recursive) in query expression\n\n\nFULL\n\n\nUse \nselectWith\n, \nselecting\n, and \nreuse\n. See the \nsection\n in the users guide\n\n\n\n\n\n\nT122 WITH (excluding recursive) in subquery\n\n\nTODO\n\n\n\n\n\n\n\n\nT131 Recursive query\n\n\nFULL\n\n\nUse \nselectWith\n and the \nMonadFix With\n instance. See the \nsection\n for more details\n\n\n\n\n\n\nT132 Recursive query in subquery\n\n\nTODO\n\n\n\n\n\n\n\n\nT141 SIMILAR predicate\n\n\nFULL\n\n\n\n\n\n\n\n\nT151 DISTINCT predicate\n\n\nFULL\n\n\n\n\n\n\n\n\nT152 DISTINCT predicate with negation\n\n\nTODO\n\n\n\n\n\n\n\n\nT171 LIKE clause in table definition\n\n\nTODO\n\n\n\n\n\n\n\n\nT172 AS subquery clause in table definition\n\n\nTODO\n\n\n\n\n\n\n\n\nT173 Extended LIKE clause in table definition\n\n\nTODO\n\n\n\n\n\n\n\n\nT174 Identity columns\n\n\nTODO\n\n\n\n\n\n\n\n\nT175 Generated columns\n\n\nTODO\n\n\n\n\n\n\n\n\nT176 Sequence generator support\n\n\nTODO\n\n\n\n\n\n\n\n\nT177 Sequence generator support: simple restart option\n\n\nTODO\n\n\n\n\n\n\n\n\nT178 Identity columns: simple restart option\n\n\nTODO\n\n\n\n\n\n\n\n\nT180 System-versioned tables\n\n\nTODO\n\n\n\n\n\n\n\n\nT181 Application-time period tables\n\n\nTODO\n\n\n\n\n\n\n\n\nT191 Referential action RESTART\n\n\nTODO\n\n\n\n\n\n\n\n\nT201 Comparable data types for referential constraints\n\n\nTODO\n\n\n\n\n\n\n\n\nT211 Basic trigger capability\n\n\nTODO\n\n\n\n\n\n\n\n\nT212 Enhanced trigger capability\n\n\nTODO\n\n\n\n\n\n\n\n\nT213 INSTEAD OF triggers\n\n\nTODO\n\n\n\n\n\n\n\n\nT231 Sensitive cursors\n\n\nTODO\n\n\n\n\n\n\n\n\nT241 START TRANSACTION statement\n\n\nWONTFIX\n\n\nUse the backend library\n\n\n\n\n\n\nT251 SET TRANSACTION option: LOCAL option\n\n\nWONTFIX\n\n\nUse the backend library\n\n\n\n\n\n\nT261 Chained transactions\n\n\nN/A\n\n\n\n\n\n\n\n\nT271 Savepoints\n\n\nN/A\n\n\n\n\n\n\n\n\nT272 Enhanced savepoint management\n\n\nN/A\n\n\n\n\n\n\n\n\nT281 SELECT privilege with column granularity\n\n\nN/A\n\n\n\n\n\n\n\n\nT285 Enhanced derived column names\n\n\nN/A\n\n\n\n\n\n\n\n\nT301 Functional dependencies\n\n\nTODO\n\n\n\n\n\n\n\n\nT312 OVERLAY function\n\n\nTODO\n\n\n\n\n\n\n\n\nT321 Basic SQL-invoked routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT323 Explicit security for external routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT324 Explicit security for SQL routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT325 Qualified SQL parameter references\n\n\nN/A\n\n\nBeam will likely use the qualified ones by default. Likely not exposed to user\n\n\n\n\n\n\nT326 Table functions\n\n\nTODO\n\n\n\n\n\n\n\n\nT331 Basic roles\n\n\nN/A\n\n\n\n\n\n\n\n\nT332 Extended roles\n\n\nN/A\n\n\n\n\n\n\n\n\nT341 Overleading of SQL-invoked functions and procodures\n\n\nWONTFIX\n\n\nHaskell doesn't allow overloading, and this seems complicated and unnecessary\n\n\n\n\n\n\nT351 Bracketed comments\n\n\nN/A\n\n\n\n\n\n\n\n\nT431 Extended grouping capabalities\n\n\nTODO\n\n\n\n\n\n\n\n\nT432 Nested and concatenated GROUPING SETs\n\n\nTODO\n\n\n\n\n\n\n\n\nT433 Multiargument GROUPING function\n\n\nTODO\n\n\n\n\n\n\n\n\nT434 GROUP BY DISTINCT\n\n\nTODO\n\n\n\n\n\n\n\n\nT441 ABS and MOD functions\n\n\nFULL\n\n\n\n\n\n\n\n\nT461 Symmetric BETWEEN predicate\n\n\nFULL\n\n\nBeam doesn't check this\n\n\n\n\n\n\nT471 Result sets return value\n\n\nTODO\n\n\n\n\n\n\n\n\nT472 DESCRIBE CURSOR\n\n\nN/A\n\n\nUse the backend library\n\n\n\n\n\n\nT491 LATERAL derived table\n\n\nTODO\n\n\n\n\n\n\n\n\nT495 Combined data change and retrieval\n\n\nTODO\n\n\n\n\n\n\n\n\nT501 Enhanced EXISTS predicate\n\n\nTODO\n\n\n\n\n\n\n\n\nT502 Period predicates\n\n\nTODO\n\n\n\n\n\n\n\n\nT511 Transaction counts\n\n\nTODO\n\n\n\n\n\n\n\n\nT521 Nested arguments in CALL statement\n\n\nTODO\n\n\n\n\n\n\n\n\nT522 Default values for IN parameters of SQL-invoked procs\n\n\nTODO\n\n\n\n\n\n\n\n\nT551 Optional key words for DEFAULT syntax\n\n\nTODO\n\n\n\n\n\n\n\n\nT561 Holdable locators\n\n\nTODO\n\n\n\n\n\n\n\n\nT571 Array-returning SQL-invoked functions\n\n\nTODO\n\n\nWill be supported once SQL-invoked functions are\n\n\n\n\n\n\nT572 Multiset-returning SQL-invoked functions\n\n\nTODO\n\n\n\n\n\n\n\n\nT581 Regular expression substring function\n\n\nTODO\n\n\n\n\n\n\n\n\nT591 UNIQUE constraints of possible NULL columns\n\n\nTODO\n\n\n\n\n\n\n\n\nT601 Local cursor references\n\n\nN/A\n\n\n\n\n\n\n\n\nT611 Elementary OLAP operations\n\n\nFULL\n\n\nSee \nwithWindow_\n, \nwindow functions\n\n\n\n\n\n\nT612 Advanced OLAP operations\n\n\nPARTIAL\n\n\nNo exclusions yet. See \npercentRank_\n, \ncumeDist_\n, and \ndenseRank_\n\n\n\n\n\n\nT613 Sampling\n\n\nTODO\n\n\n\n\n\n\n\n\nT614 NTILE function\n\n\nFULL\n\n\nntile_\n\n\n\n\n\n\nT615 LEAD and LAG function\n\n\nFULL\n\n\nlead1_\n, \nlag1_\n, \nlead_\n, \nlag_\n, \nleadWithDefault_\n, \nlagWithDefault_\n\n\n\n\n\n\nT616 Null treatment for LEAD and LAG functions\n\n\nTODO\n\n\n\n\n\n\n\n\nT617 FIRST_VALUE and LAST_VALUE function\n\n\nFULL\n\n\nlastValue_\n and \nfirstValue_\n respectively\n\n\n\n\n\n\nT618 NTH_VALUE function\n\n\nFULL\n\n\nnthValue_\n\n\n\n\n\n\nT619 Nested window function\n\n\nTODO\n\n\n\n\n\n\n\n\nT620 WINDOW clause: GROUPS option\n\n\nTODO\n\n\n\n\n\n\n\n\nT621 Enhanced numeric functions\n\n\nFULL\n\n\nAll functions and aggregates in \nDatabase.Beam.Query.Extension\n\n\n\n\n\n\nT641 Multiple column assignment\n\n\nTODO\n\n\n\n\n\n\n\n\nT651 SQL-schema statements in SQL routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT652 SQL-dynamic statements in SQL routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT653 SQL-schema statements in external routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT654 SQL-dynamic statements in external routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT655 Cyclically dependent routines\n\n\nTODO", 
            "title": "Compatibility Matrix"
        }, 
        {
            "location": "/about/license/", 
            "text": "The MIT License (MIT)\n\n\nCopyright \u00a9 2015-2018 Travis Athougies\nand\n\nthe Beam authors\n\n\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \u201cSoftware\u201d), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.", 
            "title": "License"
        }, 
        {
            "location": "/about/license/#the-mit-license-mit", 
            "text": "Copyright \u00a9 2015-2018 Travis Athougies\nand the Beam authors  Permission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \u201cSoftware\u201d), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:  The above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.  THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.", 
            "title": "The MIT License (MIT)"
        }, 
        {
            "location": "/about/release-notes/", 
            "text": "Beam Release Notes\n\n\n0.7.0.0\n\n\nCorrect boolean handling\n\n\nPrevious versions of beam used the SQL \n=\n operator to compare potentially\n\nNULL\n values. This is incorrect, as \nNULL = NULL =\n UNKNOWN\n in ANSI-compliant\nimplementations. Beam has changed its emitted SQL to produce proper comparisons,\nbut this can dramatically affect performance in some backends. Particularly,\nproper JOIN index usage in Postgres requires an exact match on an equality\nconstructor, which may not be what you get when using the proper boolean\nhandling.\n\n\nIf you are okay using SQL null handling, you can use the new \n==?.\n and \n/=?.\n\noperators which produce an expression with type \nSqlBool\n instead. \nSqlBool\n is\na type that can represent the SQL \nBOOL\n type in all its gritty glory. Note\nhowever, that these operators do not compare for haskell equality, only SQL\nequality, so please understand what that means before using them.\n\n\nCorrespondingly, many functions that took \nBool\n expressions now have\ncorresponding versions that take \nSqlBool\n. For example, to use \nguard_\n with a\n\nSqlBool\n expression use \nguard_'\n (note the prime).\n\n\n(Note: I don't really like that we have to do this, but this is the only way\nunless we introspect user expressions. Beam's philosophy is to be as direct as\npossible. The \n==.\n operator corresponds to haskell \n==\n, and so produces the\nboolean we would expect as Haskell programmers. The \n==?.\n operator is a new\noperator that users must explicitly opt in to. Both produce the most direct code\npossible on each backend.)\n\n\nAggregations return \nMaybe\n types\n\n\nIn previous versions of beam, aggregations such as \navg_\n, \nsum_\n, etc\nreturned the an expression of the same type as its inputs. However,\nthis does not match standard SQL behavior, where these aggregates can\nreturn NULL if no rows are selected for the aggregation. This breaks\nolder code, but is more correct. To restore the older behavior, use\nthe \nfromMaybe_\n function to supply a default value.\n\n\nMiscellaneous name changes\n\n\nThe \nDatabase.Beam.Query.lookup\n function was renamed to \nlookup_\n to\navoid overlap with the \nPrelude\n function of the same name.\n\n\nReintroduce explicit backends to \nDatabase\n class\n\n\nSome database entites only work on particular backends. For example,\nbeam-postgres extension support only works in beam-postgres. The lack\nof a backend parameter on the \nDatabase\n type class essentially\nmandated that every database entity worked on every backend. By\nintroducing a backend parameter to \nDatabase\n, we allow the user to\nrestrict which backends a database can work on.\n\n\nThe old behavior is still easily recovered. Whereas before you'd write\n\n\ninstance\n \nDatabase\n \nMyDatabase\n\n\n\n\n\n\nNow write\n\n\ninstance\n \nDatabase\n \nbe\n \nMyDatabase\n\n\n\n\n\n\nRequire backends to explicitly declare types that can be compared for equality\n\n\nBeam previously allowed any two types to be compared for SQL\nequality. This is no longer the case. Rather, only types that are\ninstances of \nHasSqlEqualityCheck\n for the given expression syntax can\nbe checked for equality. Correspondingly, only types that are\ninstances of \nHasSqlQuantifiedEqualityCheck\n can be checked for\nquantified equality.\n\n\nThis change is somewhat invasive, as the relationship and join\noperators depend on the ability to check primary keys for\nequality. You may have to add appropriate class constraints to your\nqueries. In order to assert that a table can be compared for equality,\nyou can use the \nHasTableEquality\n constraint synonym.\n\n\nFor Backends\n\n\nBackend implementors should establish instances of\n\nHasSqlEqualityCheck\n and \nHasSqlQuantifiedEqualityCheck\n for every\ntype that can be compared in their syntax. You may choose to implement\na custom equality and inequality operator. Alternatively, you can\nleave the instances empty to use the defaults, which match the old\nbehavior.\n\n\nProperly deal with NULL values in equality\n\n\nPrevious versions of Beam would use SQL \n=\n and \n operators to\ncompare potentially \nNULL\n values. However, \nNULL = NULL\n is always\nfalse, according to the SQL standard, so this behavior is incorrect.\n\n\nNow, Beam will generate a \nCASE .. WHEN ..\n statement to explicitly\nhandle mismatching \nNULL\ns. This is the 'expected' behavior from the\nHaskell perspective, but does not match what one may expect in\nSQL. Note that it is always better to explicitly handle \nNULL\ns using\n\nmaybe_\n, and beam recommends this approach in robust code.\n\n\nRemove \nAuto\n for fields with default values\n\n\nAuto\n was a convenience type for dealing with tables where some\ncolumns have been given a default value. \nAuto\n worked well enough but\nit was a very leaky abstraction. Moreover, it was\nunnecessary. Everything you can do with \nAuto\n can be done more safely\nwith \ndefault_\n.\n\n\nFor example, instead of using\n\n\ninsertValues\n \n[\n \nTable1\n \n(\nAuto\n \nNothing\n)\n \nField Value\n \nAnother Field Value\n \n]\n\n\n\n\n\n\nuse\n\n\ninsertExpressions\n \n[\n \nTable1\n \ndefault_\n \n(\nval_\n \nField Value\n)\n \n(\nval_\n \nAnother Field Value\n)\n \n]\n\n\n\n\n\n\n0.6.0.0\n\n\n\n\nMostly complete SQL92, SQL99 support\n\n\nPiecemeal support for SQL2003 and SQL2008 features\n\n\nCompletely modular backends\n\n\nVarious bug improvements and fixes\n\n\n\n\n0.5.0.0\n\n\n\n\nMove to using finally tagless style for SQL generation\n\n\nSplit out backends from \nbeam-core\n\n\nAllow non-table entities to be stored in databases\n\n\nBasic migrations support", 
            "title": "Release Notes"
        }, 
        {
            "location": "/about/release-notes/#beam-release-notes", 
            "text": "", 
            "title": "Beam Release Notes"
        }, 
        {
            "location": "/about/release-notes/#0700", 
            "text": "", 
            "title": "0.7.0.0"
        }, 
        {
            "location": "/about/release-notes/#correct-boolean-handling", 
            "text": "Previous versions of beam used the SQL  =  operator to compare potentially NULL  values. This is incorrect, as  NULL = NULL =  UNKNOWN  in ANSI-compliant\nimplementations. Beam has changed its emitted SQL to produce proper comparisons,\nbut this can dramatically affect performance in some backends. Particularly,\nproper JOIN index usage in Postgres requires an exact match on an equality\nconstructor, which may not be what you get when using the proper boolean\nhandling.  If you are okay using SQL null handling, you can use the new  ==?.  and  /=?. \noperators which produce an expression with type  SqlBool  instead.  SqlBool  is\na type that can represent the SQL  BOOL  type in all its gritty glory. Note\nhowever, that these operators do not compare for haskell equality, only SQL\nequality, so please understand what that means before using them.  Correspondingly, many functions that took  Bool  expressions now have\ncorresponding versions that take  SqlBool . For example, to use  guard_  with a SqlBool  expression use  guard_'  (note the prime).  (Note: I don't really like that we have to do this, but this is the only way\nunless we introspect user expressions. Beam's philosophy is to be as direct as\npossible. The  ==.  operator corresponds to haskell  == , and so produces the\nboolean we would expect as Haskell programmers. The  ==?.  operator is a new\noperator that users must explicitly opt in to. Both produce the most direct code\npossible on each backend.)", 
            "title": "Correct boolean handling"
        }, 
        {
            "location": "/about/release-notes/#aggregations-return-maybe-types", 
            "text": "In previous versions of beam, aggregations such as  avg_ ,  sum_ , etc\nreturned the an expression of the same type as its inputs. However,\nthis does not match standard SQL behavior, where these aggregates can\nreturn NULL if no rows are selected for the aggregation. This breaks\nolder code, but is more correct. To restore the older behavior, use\nthe  fromMaybe_  function to supply a default value.", 
            "title": "Aggregations return Maybe types"
        }, 
        {
            "location": "/about/release-notes/#miscellaneous-name-changes", 
            "text": "The  Database.Beam.Query.lookup  function was renamed to  lookup_  to\navoid overlap with the  Prelude  function of the same name.", 
            "title": "Miscellaneous name changes"
        }, 
        {
            "location": "/about/release-notes/#reintroduce-explicit-backends-to-database-class", 
            "text": "Some database entites only work on particular backends. For example,\nbeam-postgres extension support only works in beam-postgres. The lack\nof a backend parameter on the  Database  type class essentially\nmandated that every database entity worked on every backend. By\nintroducing a backend parameter to  Database , we allow the user to\nrestrict which backends a database can work on.  The old behavior is still easily recovered. Whereas before you'd write  instance   Database   MyDatabase   Now write  instance   Database   be   MyDatabase", 
            "title": "Reintroduce explicit backends to Database class"
        }, 
        {
            "location": "/about/release-notes/#require-backends-to-explicitly-declare-types-that-can-be-compared-for-equality", 
            "text": "Beam previously allowed any two types to be compared for SQL\nequality. This is no longer the case. Rather, only types that are\ninstances of  HasSqlEqualityCheck  for the given expression syntax can\nbe checked for equality. Correspondingly, only types that are\ninstances of  HasSqlQuantifiedEqualityCheck  can be checked for\nquantified equality.  This change is somewhat invasive, as the relationship and join\noperators depend on the ability to check primary keys for\nequality. You may have to add appropriate class constraints to your\nqueries. In order to assert that a table can be compared for equality,\nyou can use the  HasTableEquality  constraint synonym.", 
            "title": "Require backends to explicitly declare types that can be compared for equality"
        }, 
        {
            "location": "/about/release-notes/#for-backends", 
            "text": "Backend implementors should establish instances of HasSqlEqualityCheck  and  HasSqlQuantifiedEqualityCheck  for every\ntype that can be compared in their syntax. You may choose to implement\na custom equality and inequality operator. Alternatively, you can\nleave the instances empty to use the defaults, which match the old\nbehavior.", 
            "title": "For Backends"
        }, 
        {
            "location": "/about/release-notes/#properly-deal-with-null-values-in-equality", 
            "text": "Previous versions of Beam would use SQL  =  and   operators to\ncompare potentially  NULL  values. However,  NULL = NULL  is always\nfalse, according to the SQL standard, so this behavior is incorrect.  Now, Beam will generate a  CASE .. WHEN ..  statement to explicitly\nhandle mismatching  NULL s. This is the 'expected' behavior from the\nHaskell perspective, but does not match what one may expect in\nSQL. Note that it is always better to explicitly handle  NULL s using maybe_ , and beam recommends this approach in robust code.", 
            "title": "Properly deal with NULL values in equality"
        }, 
        {
            "location": "/about/release-notes/#remove-auto-for-fields-with-default-values", 
            "text": "Auto  was a convenience type for dealing with tables where some\ncolumns have been given a default value.  Auto  worked well enough but\nit was a very leaky abstraction. Moreover, it was\nunnecessary. Everything you can do with  Auto  can be done more safely\nwith  default_ .  For example, instead of using  insertValues   [   Table1   ( Auto   Nothing )   Field Value   Another Field Value   ]   use  insertExpressions   [   Table1   default_   ( val_   Field Value )   ( val_   Another Field Value )   ]", 
            "title": "Remove Auto for fields with default values"
        }, 
        {
            "location": "/about/release-notes/#0600", 
            "text": "Mostly complete SQL92, SQL99 support  Piecemeal support for SQL2003 and SQL2008 features  Completely modular backends  Various bug improvements and fixes", 
            "title": "0.6.0.0"
        }, 
        {
            "location": "/about/release-notes/#0500", 
            "text": "Move to using finally tagless style for SQL generation  Split out backends from  beam-core  Allow non-table entities to be stored in databases  Basic migrations support", 
            "title": "0.5.0.0"
        }
    ]
}